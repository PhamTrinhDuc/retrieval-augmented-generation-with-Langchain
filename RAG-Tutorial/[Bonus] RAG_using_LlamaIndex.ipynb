{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b07fd84d06c4b5e8328224269830ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f87912d1a84a40f0b61666968e670784",
              "IPY_MODEL_e39c43078ad245b19c2aaf6f23bc7dae",
              "IPY_MODEL_cab2f39a272849529bf7ac723d95225b"
            ],
            "layout": "IPY_MODEL_2036d10a95884a52b846979cc00a8f33"
          }
        },
        "f87912d1a84a40f0b61666968e670784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caf184988ade4c2a9d9b2d5e30e45c16",
            "placeholder": "​",
            "style": "IPY_MODEL_3cf2865319c340f6ac6b522fcf579d6e",
            "value": "modules.json: 100%"
          }
        },
        "e39c43078ad245b19c2aaf6f23bc7dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7beecc923ced43df8f244ac78d22c7d4",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83112e5c94fa4c71844886956ec2853d",
            "value": 349
          }
        },
        "cab2f39a272849529bf7ac723d95225b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89940556db04ad4a79fd7b0fcc79565",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc5c37c73904ad7a180d1d35f051fa9",
            "value": " 349/349 [00:00&lt;00:00, 23.6kB/s]"
          }
        },
        "2036d10a95884a52b846979cc00a8f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caf184988ade4c2a9d9b2d5e30e45c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf2865319c340f6ac6b522fcf579d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7beecc923ced43df8f244ac78d22c7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83112e5c94fa4c71844886956ec2853d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c89940556db04ad4a79fd7b0fcc79565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc5c37c73904ad7a180d1d35f051fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69399e3790a84fb19e87ad71e3647e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3f7d019b5b4443abed19e68f00aecc7",
              "IPY_MODEL_3e3e3d60d25a4091a4e66b24234ed752",
              "IPY_MODEL_fef12ba4b6714891a637bf5f37eba614"
            ],
            "layout": "IPY_MODEL_b98168b76f13476d8f52c6bb7e27b5e9"
          }
        },
        "a3f7d019b5b4443abed19e68f00aecc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_016aa641ea8448deaa054f27ed1951f2",
            "placeholder": "​",
            "style": "IPY_MODEL_bb8f44ad4c4742398a12fc7b52719f38",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "3e3e3d60d25a4091a4e66b24234ed752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9259f2fd4bad4c988ef6437efdf0d929",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_766c0a233e094bd9bdb568832a887f04",
            "value": 124
          }
        },
        "fef12ba4b6714891a637bf5f37eba614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20190d384ca448da45874fe40f97cf0",
            "placeholder": "​",
            "style": "IPY_MODEL_26b410593a914463bd4e38632ec17fb6",
            "value": " 124/124 [00:00&lt;00:00, 8.59kB/s]"
          }
        },
        "b98168b76f13476d8f52c6bb7e27b5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016aa641ea8448deaa054f27ed1951f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8f44ad4c4742398a12fc7b52719f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9259f2fd4bad4c988ef6437efdf0d929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "766c0a233e094bd9bdb568832a887f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d20190d384ca448da45874fe40f97cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b410593a914463bd4e38632ec17fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "907c6f3155914aad93c19c1efb090cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11ff66b4975347fd88f0931121df5097",
              "IPY_MODEL_5be10defe6534213ad7701ec09bd3b54",
              "IPY_MODEL_6d130d151a424d57a68ce661802e6599"
            ],
            "layout": "IPY_MODEL_8dd93d3f3227410486dabeced424b06a"
          }
        },
        "11ff66b4975347fd88f0931121df5097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91ea5feb74c42d1ad5e895669c5c600",
            "placeholder": "​",
            "style": "IPY_MODEL_d718a8c80d0d4cd3becc49752a43cd6a",
            "value": "README.md: 100%"
          }
        },
        "5be10defe6534213ad7701ec09bd3b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28ad449062c24510944d092a511c8ce2",
            "max": 94783,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b87ff1ec1b94d3e9c76eb32a8a67961",
            "value": 94783
          }
        },
        "6d130d151a424d57a68ce661802e6599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26d0f9f2d75744d18ae8eb4b56108407",
            "placeholder": "​",
            "style": "IPY_MODEL_1aabd50e960e41b695ed9d4384268b8c",
            "value": " 94.8k/94.8k [00:00&lt;00:00, 1.47MB/s]"
          }
        },
        "8dd93d3f3227410486dabeced424b06a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b91ea5feb74c42d1ad5e895669c5c600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d718a8c80d0d4cd3becc49752a43cd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28ad449062c24510944d092a511c8ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b87ff1ec1b94d3e9c76eb32a8a67961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26d0f9f2d75744d18ae8eb4b56108407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aabd50e960e41b695ed9d4384268b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d7af0cdfc11463dbdabbe76c4c00203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a588f34075e4c0a879034b5e6eb7367",
              "IPY_MODEL_8fe93ceb154f4b26b0beea0b6f36528a",
              "IPY_MODEL_40f51e98d682444d818165e378d48eff"
            ],
            "layout": "IPY_MODEL_7cefa8c1113549abb64da60b2823372b"
          }
        },
        "2a588f34075e4c0a879034b5e6eb7367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_711980cd8dfa417a93d6ec9fa4ec2984",
            "placeholder": "​",
            "style": "IPY_MODEL_e5519690cf4e455ebafce4f3c233221e",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "8fe93ceb154f4b26b0beea0b6f36528a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c514ad192ec74df793aaed79e3f4ac1f",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3c966692f414f3f84ca49adb6489770",
            "value": 52
          }
        },
        "40f51e98d682444d818165e378d48eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e69c0e4917ff4c3992a8de75186f2cd4",
            "placeholder": "​",
            "style": "IPY_MODEL_0e08490a73564f5290ffc96097f5cbba",
            "value": " 52.0/52.0 [00:00&lt;00:00, 2.98kB/s]"
          }
        },
        "7cefa8c1113549abb64da60b2823372b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711980cd8dfa417a93d6ec9fa4ec2984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5519690cf4e455ebafce4f3c233221e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c514ad192ec74df793aaed79e3f4ac1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c966692f414f3f84ca49adb6489770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e69c0e4917ff4c3992a8de75186f2cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e08490a73564f5290ffc96097f5cbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fe728cc429747f8b24617454f1999cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c172fe89037445e6a33adee0e361872e",
              "IPY_MODEL_c5fbd2f8d3b34a668b49f085d0f825e6",
              "IPY_MODEL_5ffb029ea13645519f519f6a550b588c"
            ],
            "layout": "IPY_MODEL_65114908d1554b968e260545d639a936"
          }
        },
        "c172fe89037445e6a33adee0e361872e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af49fac7a0784401adb95584b074d0c5",
            "placeholder": "​",
            "style": "IPY_MODEL_e4866abda70c499ea6edfbb7b7c584bb",
            "value": "config.json: 100%"
          }
        },
        "c5fbd2f8d3b34a668b49f085d0f825e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83afaa09f0bc44559d96ae3862bac3da",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e4fe345b49940eda968f266cedebcda",
            "value": 743
          }
        },
        "5ffb029ea13645519f519f6a550b588c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8306192b348f437c8871c12e477621b6",
            "placeholder": "​",
            "style": "IPY_MODEL_290102a46ca4417195e0f0ddd44d6779",
            "value": " 743/743 [00:00&lt;00:00, 41.6kB/s]"
          }
        },
        "65114908d1554b968e260545d639a936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af49fac7a0784401adb95584b074d0c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4866abda70c499ea6edfbb7b7c584bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83afaa09f0bc44559d96ae3862bac3da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4fe345b49940eda968f266cedebcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8306192b348f437c8871c12e477621b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "290102a46ca4417195e0f0ddd44d6779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46d96e093a424443a0ab8df494ea0da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ef8f253137c459c8ee86b6488bb21b9",
              "IPY_MODEL_60c46d7c611942d3bb0e25ea65fa14bd",
              "IPY_MODEL_2031343f401d4a22bf8a2f94573f80a6"
            ],
            "layout": "IPY_MODEL_4a5ee58062e144b3bd1b3aa799e7772c"
          }
        },
        "1ef8f253137c459c8ee86b6488bb21b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a49be722e0c4db7b5f520899286c197",
            "placeholder": "​",
            "style": "IPY_MODEL_11f433c497bf4f7a95a118b3419b6cc8",
            "value": "model.safetensors: 100%"
          }
        },
        "60c46d7c611942d3bb0e25ea65fa14bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7772baffcac0402ab97265c39a076dea",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_112b6016b4a44dc69257a46bea078581",
            "value": 133466304
          }
        },
        "2031343f401d4a22bf8a2f94573f80a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c9e3fc0a3b84ae98e427ff4222dc33c",
            "placeholder": "​",
            "style": "IPY_MODEL_37bd1f74a03e4d02a4612e67c154782f",
            "value": " 133M/133M [00:00&lt;00:00, 192MB/s]"
          }
        },
        "4a5ee58062e144b3bd1b3aa799e7772c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a49be722e0c4db7b5f520899286c197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f433c497bf4f7a95a118b3419b6cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7772baffcac0402ab97265c39a076dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "112b6016b4a44dc69257a46bea078581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c9e3fc0a3b84ae98e427ff4222dc33c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37bd1f74a03e4d02a4612e67c154782f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c94232799bac4073aa21a2902ea3f444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6474ce9bb5e24c97be8d9e2ae8475b11",
              "IPY_MODEL_9353bb28cc714e26b9010631179c2a26",
              "IPY_MODEL_150b64cac2684e418e30bfb0d134c5e2"
            ],
            "layout": "IPY_MODEL_f59c0f8d8d42415f8473fffd866022d9"
          }
        },
        "6474ce9bb5e24c97be8d9e2ae8475b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7041867aad824641b78242faa98a373e",
            "placeholder": "​",
            "style": "IPY_MODEL_cfd7f86732fe41d6a0fa9a3547b9d6ab",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9353bb28cc714e26b9010631179c2a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e422747d7c34d95ba75d9ef975dd19f",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19583ce0740a4a5a9c7aed111ff06143",
            "value": 366
          }
        },
        "150b64cac2684e418e30bfb0d134c5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce446d51e781405fbbaff33207dfb6de",
            "placeholder": "​",
            "style": "IPY_MODEL_853c2deba595489bbe77b4d4c223c1d6",
            "value": " 366/366 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "f59c0f8d8d42415f8473fffd866022d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7041867aad824641b78242faa98a373e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd7f86732fe41d6a0fa9a3547b9d6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e422747d7c34d95ba75d9ef975dd19f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19583ce0740a4a5a9c7aed111ff06143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce446d51e781405fbbaff33207dfb6de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "853c2deba595489bbe77b4d4c223c1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1a8d9153bb4b1991f3b2f5a40b0e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_840734df58cf47c6914b609f4a8a421d",
              "IPY_MODEL_e3fdc7cf6ec54f38b75b738ce02a1ea2",
              "IPY_MODEL_4f2fa76a0b594a028dc7f7c7d874ec32"
            ],
            "layout": "IPY_MODEL_7d63a841f6f74014906d9cb7e7e3cdb7"
          }
        },
        "840734df58cf47c6914b609f4a8a421d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b6b2be85ce44b39c745d9e7fdb5315",
            "placeholder": "​",
            "style": "IPY_MODEL_7d9bf0adc8c441b88bef01b56718b40b",
            "value": "vocab.txt: 100%"
          }
        },
        "e3fdc7cf6ec54f38b75b738ce02a1ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaaf85c530e04087b37f47b8fe121307",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4521762d9f8a4b15a9a6cfb9a418f453",
            "value": 231508
          }
        },
        "4f2fa76a0b594a028dc7f7c7d874ec32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3189fcc4773744b5b24a365484a4c839",
            "placeholder": "​",
            "style": "IPY_MODEL_939b17513726486dbc75f15a39aa00ae",
            "value": " 232k/232k [00:00&lt;00:00, 4.17MB/s]"
          }
        },
        "7d63a841f6f74014906d9cb7e7e3cdb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9b6b2be85ce44b39c745d9e7fdb5315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d9bf0adc8c441b88bef01b56718b40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaaf85c530e04087b37f47b8fe121307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4521762d9f8a4b15a9a6cfb9a418f453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3189fcc4773744b5b24a365484a4c839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "939b17513726486dbc75f15a39aa00ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f20a976b46ab4fc1bb3c4a674ab65699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb73fb121ca74c3d8bc2ef5818660da3",
              "IPY_MODEL_3bff91f6dc0645d893783f991883d0b9",
              "IPY_MODEL_2d27b9288a10423fbf8144c2dbbfab70"
            ],
            "layout": "IPY_MODEL_5f22a9ad421b4fa7abeab8dfbebdb5a1"
          }
        },
        "bb73fb121ca74c3d8bc2ef5818660da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8025109e9a8848be8c2d737613761dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_6413d62969da4ec794405309557dd8a2",
            "value": "tokenizer.json: 100%"
          }
        },
        "3bff91f6dc0645d893783f991883d0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2bdebb7d254ca7ab6881792f1f7ff0",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbc8d4ee82ae4b4f9d677f2f02ca5dfd",
            "value": 711396
          }
        },
        "2d27b9288a10423fbf8144c2dbbfab70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_520ffe3a8e1a4416a35687a454bfc8b6",
            "placeholder": "​",
            "style": "IPY_MODEL_ff2a74a97bfb4b53ad325422aaa6aaca",
            "value": " 711k/711k [00:00&lt;00:00, 3.15MB/s]"
          }
        },
        "5f22a9ad421b4fa7abeab8dfbebdb5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8025109e9a8848be8c2d737613761dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6413d62969da4ec794405309557dd8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2bdebb7d254ca7ab6881792f1f7ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbc8d4ee82ae4b4f9d677f2f02ca5dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "520ffe3a8e1a4416a35687a454bfc8b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2a74a97bfb4b53ad325422aaa6aaca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2dd49a25e3b446f83bc2040efb5386c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_794dffe5add3466ab6f7d190a740e846",
              "IPY_MODEL_163700b605ba467897b7876f3cf588b8",
              "IPY_MODEL_70f19524d18e42dd8596f8bac9e61d1c"
            ],
            "layout": "IPY_MODEL_2a48f399bc024284bb373e966ed01a3a"
          }
        },
        "794dffe5add3466ab6f7d190a740e846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8acbab6dc2704299b264f7e0fe84970c",
            "placeholder": "​",
            "style": "IPY_MODEL_371ec9cf9ec8463fa48b6b129c17eee7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "163700b605ba467897b7876f3cf588b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec1cf36c3d947f69e9c6f04f5acbf10",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e68f634665d941ab9b6692de45bf3bfa",
            "value": 125
          }
        },
        "70f19524d18e42dd8596f8bac9e61d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_556a61f975bd4955bf5f20723e8fa12a",
            "placeholder": "​",
            "style": "IPY_MODEL_59291bd0431c4569940925b017b63599",
            "value": " 125/125 [00:00&lt;00:00, 7.71kB/s]"
          }
        },
        "2a48f399bc024284bb373e966ed01a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8acbab6dc2704299b264f7e0fe84970c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "371ec9cf9ec8463fa48b6b129c17eee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec1cf36c3d947f69e9c6f04f5acbf10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e68f634665d941ab9b6692de45bf3bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "556a61f975bd4955bf5f20723e8fa12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59291bd0431c4569940925b017b63599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "677b1dde51094cff972fe307897c8da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2670d4e620934b4cb76b0d41139c2192",
              "IPY_MODEL_70d685d1578f457696d45074d9314967",
              "IPY_MODEL_28f0a55637ab4bc085c8c4864be5a638"
            ],
            "layout": "IPY_MODEL_daadd46f0c69460baae61eafa570cc94"
          }
        },
        "2670d4e620934b4cb76b0d41139c2192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19d179a4b42543dfb5f8d02426e365da",
            "placeholder": "​",
            "style": "IPY_MODEL_957b60bf864b48708ff106de0e9e628a",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "70d685d1578f457696d45074d9314967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bee880e30c04c6b9f59ebaf240872f4",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dfc8a79a2dd4f46b87806e99a9fed0f",
            "value": 190
          }
        },
        "28f0a55637ab4bc085c8c4864be5a638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7265f5d04141a58949366bd0b649d0",
            "placeholder": "​",
            "style": "IPY_MODEL_b7429779b3204982b0405948fd164e78",
            "value": " 190/190 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "daadd46f0c69460baae61eafa570cc94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d179a4b42543dfb5f8d02426e365da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957b60bf864b48708ff106de0e9e628a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bee880e30c04c6b9f59ebaf240872f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dfc8a79a2dd4f46b87806e99a9fed0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f7265f5d04141a58949366bd0b649d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7429779b3204982b0405948fd164e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBn96lAtFSGi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install llama-index\n",
        "!pip install pypdf\n",
        "!pip install llama-index-llms-huggingface\n",
        "!pip install install llama-index-embeddings-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "aHaAXX5KFur7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install weaviate-client\n",
        "!pip install llama-index-vector-stores-weaviate\n",
        "!pip install torch sentence-transformers"
      ],
      "metadata": {
        "id": "yFmvRP5IGCpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-llms-groq"
      ],
      "metadata": {
        "id": "LHfGQwZrGFaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/BachNgoH/AIO_Documents.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFmsPjf0GHYW",
        "outputId": "71768b54-68c4-4baa-d151-bdb3f34462f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AIO_Documents'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 106 (delta 13), reused 51 (delta 7), pack-reused 49\u001b[K\n",
            "Receiving objects: 100% (106/106), 111.22 MiB | 28.46 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Ingestion"
      ],
      "metadata": {
        "id": "2hvFU4n6JRCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Load PDF"
      ],
      "metadata": {
        "id": "JFJ1oesN8ug6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` pypdf ```"
      ],
      "metadata": {
        "id": "_iegBViqAxVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pypdf\n",
        "\n",
        "file_name = \"/content/AIO_Documents/Documents/Mamba.pdf\"\n",
        "\n",
        "pdf_file = open(file_name, 'rb')\n",
        "\n",
        "reader = pypdf.PdfReader(pdf_file)\n",
        "\n",
        "context = \"\"\n",
        "for page in reader.pages:\n",
        "    text = page.extract_text()\n",
        "    context += text + \"\\n\"\n",
        "pdf_file.close()"
      ],
      "metadata": {
        "id": "So1HSI-MGy5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OBtcfxgGy7t",
        "outputId": "8be0bf87-f25e-4321-e6a7-32d4fd7ecd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI VIET NAM – 2024\n",
            "Text Classification with Mamba - Project\n",
            "Minh-Duc Bui, Khai-Xuan Trinh, và Quang-Vinh Dinh\n",
            "Ngày 25 tháng 2 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Gần đây, Mamba là kiến trúc mới ra mắt và được sự hưởng ứng mạnh mẽ từ cộng đồng các nhà nghiên\n",
            "cứu. Mamba trở thành trend vì khả năng vượt trội hơn Transformer (kiến trúc phổ biến ở thời điểm\n",
            "hiện tại). Sự vượt trội được thể hiện ở cả 3 tiêu chí chính để đánh giá 1 model: accuracy, speed, và\n",
            "computional cost.\n",
            "Trong project này, ta sẽ tìm hiểu cơ bản về kiến trúc Mamba và áp dụng Mamba vào bài toán text\n",
            "classification.\n",
            "1\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Nội dung\n",
            "1.Mô tả dataset IMDB\n",
            "IMDB dataset là bộ data bao gồm 50,000 đánh giá về phim. Đây là bộ dữ liệu được sử dụng cho\n",
            "việc phân loại đánh giá tiêu cực và tích cực. Bộ dữ liệu được chia làm 2 phần bằng nhau, 25,000\n",
            "mẫu để train, và 25,000 mẫu để kiểm thử. Bên cạnh đó, bộ dữ liệu cũng cung cấp 50,000 mẫu dữ\n",
            "liệu chưa đánh nhãn để hỗ trợ quá trình train. Tuy nhiên trong project này ta chỉ sử dụng phần\n",
            "dữ liệu đã được đánh nhãn để train model.\n",
            "Hình 1: Ví dụ minh họa về dataset IMDB.\n",
            "2.Model Mamba cho bài toán Text classification\n",
            "(a)Install and import libraries: Đầu tiên ta sẽ install một số thư viện cần thiết của Hug-\n",
            "gingface và Mamba:\n",
            "1!pip install datasets evaluate accelerate\n",
            "2!pip install causal-conv1d>=1.1.0\n",
            "3!pip install mamba-ssm\n",
            "Sau đó ta sẽ tiến hành login vào HuggingFace để download dataset và model có sẵn. Khi\n",
            "chạy block code này thì HuggingFace sẽ đưa ra một đường dẫn đến trang HuggingFace để\n",
            "lấy mã token. Lưu ý để thuận tiện cho quá trình train và đưa model lên Huggingface Hub\n",
            "thì ta nên sử dụng token có quyền ghi của Huggingface.\n",
            "1from huggingface_hub import notebook_login\n",
            "2notebook_login()\n",
            "Cuối cùng ta sẽ import các thư viện chính được sử dụng trong phần này:\n",
            "2\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1import os\n",
            "2import random\n",
            "3import json\n",
            "4import torch\n",
            "5import torch.nn as nn\n",
            "6from collections import namedtuple\n",
            "7from dataclasses import dataclass, field, asdict\n",
            "8from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
            "9from mamba_ssm.utils.hf import load_config_hf, load_state_dict_hf\n",
            "10\n",
            "11import evaluate\n",
            "12import numpy as np\n",
            "13from datasets import load_dataset\n",
            "14from transformers import Trainer\n",
            "15from transformers import AutoTokenizer, TrainingArguments\n",
            "(b)Download dataset:\n",
            "1# Tải bộ dataset\n",
            "2imdb = load_dataset(\"imdb\")\n",
            "(c)Build Custom Mamba Model: Xây dựng model Mamba để phân loại văn bản.\n",
            "3\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Setup config:\n",
            "1# Config class của Mamba\n",
            "2class MambaConfig:\n",
            "3d_model: int = 2560\n",
            "4n_layer: int = 64\n",
            "5vocab_size: int = 50277\n",
            "6ssm_cfg: dict = field(default_factory=dict)\n",
            "7rms_norm: bool = True\n",
            "8residual_in_fp32: bool = True\n",
            "9fused_add_norm: bool = True\n",
            "10 pad_vocab_size_multiple: int = 8\n",
            "11\n",
            "12 def to_json_string(self):\n",
            "13 return json.dumps(asdict(self))\n",
            "14\n",
            "15 def to_dict(self):\n",
            "16 return asdict(self)\n",
            "•Định nghĩa class head (classifier) để phục vụ cho việc phân loại văn bản:\n",
            "1# Định nghĩa class head để phân loại\n",
            "2class MambaClassificationHead(nn.Module):\n",
            "3def __init__(self, d_model, num_classes, **kwargs):\n",
            "4 super(MambaClassificationHead, self).__init__()\n",
            "5 # Sử dụng một lớp tuyến tính để thực hiện phân loại dựa trên\n",
            "đầu vào có kích thước d_model và num_classes cần phân loại.\n",
            "6 self.classification_head = nn.Linear(d_model, num_classes,\n",
            "**kwargs)\n",
            "7\n",
            "8def forward(self, hidden_states):\n",
            "9 return self.classification_head(hidden_states)\n",
            "•Định nghĩa model Mamba:\n",
            "1class MambaTextClassification(MambaLMHeadModel):\n",
            "2def __init__(\n",
            "3 self,\n",
            "4 config: MambaConfig,\n",
            "5 initializer_cfg=None,\n",
            "6 device=None,\n",
            "7 dtype=None,\n",
            "8) -> None:\n",
            "9 super().__init__(config, initializer_cfg, device, dtype)\n",
            "10\n",
            "11 # Tạo một đầu phân loại sử dụng MambaClassificationHead với\n",
            "kích thước đầu vào là d_model và số lớp là 2.\n",
            "12 self.classification_head = MambaClassificationHead(d_model=\n",
            "config.d_model, num_classes=2)\n",
            "13\n",
            "14 del self.lm_head\n",
            "15\n",
            "16 def forward(self, input_ids, attention_mask=None, labels=None):\n",
            "4\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "17 # Truyền input_ids qua model gốc để nhận hidden_states.\n",
            "18 hidden_states = self.backbone(input_ids)\n",
            "19\n",
            "20 # Lấy trung bình của hidden_states theo chiều thứ 2 để tạo\n",
            "ra [CLS] feature đại điện\n",
            "21 mean_hidden_states = hidden_states.mean(dim=1)\n",
            "22\n",
            "23 # Đưa mean_hidden_states qua đầu phân loại để nhận logits.\n",
            "24 logits = self.classification_head(mean_hidden_states)\n",
            "25\n",
            "26 if labels is None:\n",
            "27 ClassificationOutput = namedtuple(\"ClassificationOutput\",\n",
            "[\"logits\"])\n",
            "28 return ClassificationOutput(logits=logits)\n",
            "29 else:\n",
            "30 ClassificationOutput = namedtuple(\"ClassificationOutput\",\n",
            "[\"loss\", \"logits\"])\n",
            "31\n",
            "32 # Sử dụng hàm mất mát CrossEntropyLoss để tính loss.\n",
            "33 loss_fct = nn.CrossEntropyLoss()\n",
            "34 loss = loss_fct(logits, labels)\n",
            "35\n",
            "36 return ClassificationOutput(loss=loss, logits=logits)\n",
            "37\n",
            "38 def predict(self, text, tokenizer, id2label=None):\n",
            "39 input_ids = torch.tensor(tokenizer(text)[’input_ids’],\n",
            "device=’cuda’)[None]\n",
            "40 with torch.no_grad():\n",
            "41 logits = self.forward(input_ids).logits[0]\n",
            "42 label = np.argmax(logits.cpu().numpy())\n",
            "43\n",
            "44 if id2label is not None:\n",
            "45 return id2label[label]\n",
            "46 else:\n",
            "47 return label\n",
            "48\n",
            "49 @classmethod\n",
            "50 def from_pretrained(cls, pretrained_model_name, device=None,\n",
            "dtype=None, **kwargs):\n",
            "51 # Tải cấu hình từ model đã được train trước đó.\n",
            "52 config_data = load_config_hf(pretrained_model_name)\n",
            "53 config = MambaConfig(**config_data)\n",
            "54\n",
            "55 # Khởi tạo model từ cấu hình và chuyển nó đến thiết bị và ki\n",
            "ểu dữ liệu mong muốn.\n",
            "56 model = cls(config, device=device, dtype=dtype, **kwargs)\n",
            "57\n",
            "58 # Tải trạng thái model đã được train trước đó.\n",
            "59 model_state_dict = load_state_dict_hf(pretrained_model_name,\n",
            "device=device, dtype=dtype)\n",
            "60 model.load_state_dict(model_state_dict, strict=False)\n",
            "61\n",
            "62 # In ra các tham số embedding mới được khởi tạo.\n",
            "63 print(\"Newly initialized embedding:\", set(model.state_dict()\n",
            ".keys()) - set(model_state_dict.keys()))\n",
            "64 return model\n",
            "•Cuối cùng ta sẽ tải trọng số và tokenizer của model Mamba đã được pretrain từ trước.\n",
            "5\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Trọng số của model Mamba pretrain sẽ không bao gồm các tham số của phần head\n",
            "(classifier) MambaClassificationHead mà ta tự định nghĩa. Do đó, phần head này sẽ được\n",
            "khởi tạo tham số từ đầu:\n",
            "1# Tải model Mamba từ model đã được train trước đó.\n",
            "2model = MambaTextClassification.from_pretrained(\"state-spaces/mamba\n",
            "-130m\")\n",
            "3model.to(\"cuda\")\n",
            "4\n",
            "5# Tải tokenizer của model Mamba từ model gpt-neox-20b.\n",
            "6tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
            "7# Đặt id của token pad bằng id của token eos trong tokenizer.\n",
            "8tokenizer.pad_token_id = tokenizer.eos_token_id\n",
            "(d)Preprocess dataset: Trong phần này ta sẽ tiến hành tokenize dataset cho tập train và tập\n",
            "test. Vì số lượng sample của tập test khá lớn nên để thuận tiện cho quá trình train ta sẽ lấy\n",
            "ra 1 phần nhỏ của tập test để đánh giá model.\n",
            "1# Tạo chức năng tiền xử lý để mã hóa văn bản và cắt bớt các chuỗi không\n",
            "dài hơn độ dài đầu vào tối đa của mã thông báo\n",
            "2def preprocess_function(examples):\n",
            "3samples = tokenizer(examples[\"text\"], truncation=True)\n",
            "4# Không cần attention_mask\n",
            "5# Cụ thể hơn về token masking của mamba có thể tham khảo: https://\n",
            "github.com/state-spaces/mamba/issues/49\n",
            "6samples.pop(’attention_mask’)\n",
            "7return samples\n",
            "8\n",
            "9# Thực hiện mã hóa văn bản\n",
            "10tokenized_imdb = imdb.map(preprocess_function, batched=True)\n",
            "11\n",
            "12# Set seed cho hàm random\n",
            "13random.seed(42)\n",
            "14\n",
            "15# Tạo tập train và test\n",
            "16train_dataset = tokenized_imdb[\"train\"]\n",
            "17test_dataset = tokenized_imdb[\"test\"]\n",
            "18\n",
            "19# Tạo tập evaluation để đánh giá trong lúc train\n",
            "20# Do số lượng tập test lớn nên chỉ lấy mẫu 1% tập dữ liệu test để đánh\n",
            "giá\n",
            "21total_samples = len(test_dataset)\n",
            "22eval_samples = int(0.1 * total_samples)\n",
            "23eval_indices = random.sample(range(total_samples), eval_samples)\n",
            "24eval_dataset = test_dataset.select(eval_indices)\n",
            "(e)Evaluation metric: Để đánh giá performance của model ta sẽ sử dụng metric accuracy từ\n",
            "thư viện evaluate:\n",
            "1# Tải module \"accuracy\" từ thư viện evaluate.\n",
            "2accuracy = evaluate.load(\"accuracy\")\n",
            "3\n",
            "6\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4# Định nghĩa hàm compute_metrics để tính các độ đo hiệu suất (metrics)\n",
            "cho việc đánh giá model.\n",
            "5def compute_metrics(eval_pred):\n",
            "6predictions, labels = eval_pred\n",
            "7\n",
            "8# Lấy chỉ số của lớp có xác suất cao nhất trong predictions.\n",
            "9predictions = np.argmax(predictions, axis=1)\n",
            "10\n",
            "11 # Sử dụng module \"accuracy\" để tính độ chính xác dựa trên\n",
            "predictions và labels.\n",
            "12 return accuracy.compute(predictions=predictions, references=labels)\n",
            "(f)Train model: Sau khi đã chuẩn bị xong dataset, ta sẽ tiến hành setup một số tham số trong\n",
            "quá trình train và tiến hành train model.\n",
            "•Trước hết, ta sẽ định nghĩa một số hyper-parameter mà ta sẽ sử dụng để train model:\n",
            "1# Định nghĩa tên project để log thông tin quá trình train trên wandb\n",
            "2# os.environ[\"WANDB_PROJECT\"] = \"mamba_tutorial\"\n",
            "3\n",
            "4# Định nghĩa các tham số train trong class TrainingArguments.\n",
            "5# Cụ thể hơn về các tham số hỗ trợ có thể tham khảo: https://\n",
            "huggingface.co/docs/transformers/main_classes/trainer\n",
            "6training_args = TrainingArguments(\n",
            "7output_dir=\"mamba_text_classification\", # Tên folder output\n",
            "8learning_rate=5e-5,\n",
            "9per_device_train_batch_size=4, # Số lượng train sample trên mỗi\n",
            "device\n",
            "10 per_device_eval_batch_size=16, # Số lượng eval sample trên mỗi\n",
            "device\n",
            "11 num_train_epochs=1, # Số epoch train\n",
            "12 warmup_ratio=0.01, # Tỉ lệ tăng dần lr trong giai đoạn warmup\n",
            "13 lr_scheduler_type=\"cosine\", # Loại scheduler để giảm lr\n",
            "14 report_to=\"none\", # \"wandb\" nếu muốn log kết quả\n",
            "15 evaluation_strategy=\"steps\", # Xác định metric đánh giá sau mỗi\n",
            "số bước\n",
            "16 eval_steps=0.1, # Số bước giữa các đợt đánh giá\n",
            "17 save_strategy=\"steps\", # Xác định khi nào lưu checkpoint\n",
            "18 save_steps=0.1, # Số bước giữa các lần lưu checkpoint\n",
            "19 logging_strategy=\"steps\", # Xác định khi nào in thông tin log\n",
            "20 logging_steps=1, # Số bước giữa các lần in thông tin log\n",
            "21 push_to_hub=True, # Đẩy kết quả lên Hub\n",
            "22 load_best_model_at_end=True, # Load model có kết quả evaluation\n",
            "tốt nhất trong quá trình train\n",
            "23)\n",
            "•Sau đó ta sẽ khởi tạo class MambaTrainer kế thừa từ class Trainer. Đầu tiên, ta sẽ tạo hàm\n",
            "compute_loss() để định nghĩa hàm loss sử dụng trong quá trình train. Vì ta đã triển khai\n",
            "hàm loss là cross-entropy trong hàm forward của model, nên ta chỉ cần trích xuất giá trị\n",
            "mất mát từ kết quả trả về của hàm forward. Sau đó ta sẽ tiếp tục code hàm save_model()\n",
            "để định nghĩa cách lưu model. Để lưu model, ta cần ghi lại các tham số, tokenizer, và\n",
            "cấu hình (config) của model.\n",
            "7\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1# Định nghĩa một class MambaTrainer kế thừa từ class Trainer.\n",
            "2class MambaTrainer(Trainer):\n",
            "3\n",
            "4# Định nghĩa hàm compute_loss để tính toán hàm mất mát trong quá\n",
            "trình train.\n",
            "5def compute_loss(self, model, inputs, return_outputs=False):\n",
            "6 # Lấy giá trị input_ids và labels từ inputs.\n",
            "7 input_ids = inputs.pop(\"input_ids\")\n",
            "8 labels = inputs.pop(’labels’)\n",
            "9\n",
            "10 # Gọi hàm forward của model với input_ids và labels để nhận\n",
            "các kết quả.\n",
            "11 outputs = model(input_ids=input_ids, labels=labels)\n",
            "12\n",
            "13 # Lấy giá trị loss từ kết quả của model.\n",
            "14 loss = outputs.loss\n",
            "15\n",
            "16 # Trả về cả loss và outputs nếu return_outputs là True, ngượ\n",
            "c lại chỉ trả về loss.\n",
            "17 return (loss, outputs) if return_outputs else loss\n",
            "18\n",
            "19 # Định nghĩa hàm save_model để lưu model trong quá trình train.\n",
            "20 def save_model(self, output_dir = None, _internal_call = False):\n",
            "21 # Kiểm tra nếu thư mục lưu trữ không được chỉ định, sử dụng\n",
            "thư mục mặc định từ đối số ’args’.\n",
            "22 if output_dir is None:\n",
            "23 output_dir = self.args.output_dir\n",
            "24\n",
            "25 # Nếu thư mục đầu ra không tồn tại, tạo mới nó.\n",
            "26 if not os.path.exists(output_dir):\n",
            "27 os.makedirs(output_dir)\n",
            "28\n",
            "29 # Lưu trạng thái của model PyTorch vào file ’pytorch_model.\n",
            "bin’ trong thư mục đầu ra.\n",
            "30 torch.save(self.model.state_dict(), f\"{output_dir}/\n",
            "pytorch_model.bin\")\n",
            "31\n",
            "32 # Lưu trạng thái của tokenizer vào thư mục đầu ra.\n",
            "33 self.tokenizer.save_pretrained(output_dir)\n",
            "34\n",
            "35 # Lưu cấu hình của model vào file ’config.json’ trong thư mụ\n",
            "c đầu ra.\n",
            "36 with open(f’{output_dir}/config.json’, ’w’) as f:\n",
            "37 json.dump(self.model.config.to_dict(), f)\n",
            "•Cuối cùng ta sẽ khởi tạo class MambaTrainer , đây là class chính để train model. Sau khi đã\n",
            "khởi tạo thì ta chỉ cần gọi trainer.train() thì quá trình train model sẽ được tiến hành:\n",
            "1# Khởi tạo classs MambaTrainer để thực hiện quá trình train của\n",
            "model.\n",
            "2trainer = MambaTrainer(\n",
            "3model=model, # Model cần train\n",
            "4train_dataset=train_dataset, # Dữ liệu train\n",
            "5eval_dataset=eval_dataset, # Dữ liệu đánh giá\n",
            "8\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "6tokenizer=tokenizer, # Tokenizer sử dụng để mã hóa dữ liệu\n",
            "7args=training_args, # Các tham số train đã được định nghĩa trước\n",
            "đó\n",
            "8compute_metrics=compute_metrics # Hàm tính các độ đo hiệu suất (\n",
            "metrics) cho đánh giá\n",
            "9)\n",
            "10# Bắt đầu quá trình train bằng cách gọi hàm train() trên classs\n",
            "trainer.\n",
            "11trainer.train()\n",
            "•Sau khi quá trình train hoàn tất, ta sẽ đưa weight, config của model lên HuggingFace\n",
            "Hub để lưu lại:\n",
            "1# Đẩy model lên huggingface hub\n",
            "2trainer.push_to_hub(commit_message=\"Training complete\")\n",
            "3\n",
            "4>> Output: CommitInfo(commit_url=’https://huggingface.co/\n",
            "trinhxuankhai/mamba_text_classification/commit/816827\n",
            "ae91a91dd9006a9ef66ecefd837382998b’, commit_message=’Training\n",
            "complete’, commit_description=’’, oid=’816827\n",
            "ae91a91dd9006a9ef66ecefd837382998b’, pr_url=None, pr_revision=\n",
            "None, pr_num=None)\n",
            "(g)Run Testing: Sau khi đã hoàn tất quá trình train, ta sẽ đánh giá model trên tập test và in\n",
            "ra kết quả đánh giá của model:\n",
            "1# Thực hiện dự đoán trên tập dữ liệu validation\n",
            "2outputs = trainer.predict(test_dataset)\n",
            "3print(outputs.metrics)\n",
            "4\n",
            "5>> Output: {’test_loss’: 0.21128389239311218, ’test_accuracy’: 0.94708,\n",
            "’test_runtime’: 1308.2019, ’test_samples_per_second’: 19.11, ’\n",
            "test_steps_per_second’: 1.195}\n",
            "9\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(h)Load and inference model from Hub: Ở phần trước, sau khi ta đưa model lên Hugging-\n",
            "face Hub, nếu muốn inference model ta có thể gọi hàm from_pretrained của model Mambata\n",
            "đã định nghĩa ở trước để load pretrain model. Sau đó ta sẽ truyền văn bản cần phân loại,\n",
            "tokenize và id của từng class vô hàm predictcủa model để thực hiện dự đoán kết quả.\n",
            "1# Tải model Mamba từ model đã được train trước đó.\n",
            "2model = MambaTextClassification.from_pretrained(\"trinhxuankhai/\n",
            "mamba_text_classification\")\n",
            "3model.to(\"cuda\")\n",
            "4\n",
            "5# Tải tokenizer của model Mamba từ model đã được train trước đó.\n",
            "6tokenizer = AutoTokenizer.from_pretrained(\"trinhxuankhai/\n",
            "mamba_text_classification\")\n",
            "7# Đặt id của token pad bằng id của token eos trong tokenizer.\n",
            "8tokenizer.pad_token_id = tokenizer.eos_token_id\n",
            "Sau đây ta sẽ chạy thử một sample trên tập test:\n",
            "1id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
            "2text = imdb[’test’][0][’text’]\n",
            "3label = imdb[’test’][0][’label’]\n",
            "4response = model.predict(text, tokenizer, id2label)\n",
            "5print(f’Classify: {text}\\nGT: {id2label[label]}\\nPredict: {response}’)\n",
            "6\n",
            "7>> Output:\n",
            "8- Classify: I love sci-fi and am willing to put up with a lot. Sci-fi\n",
            "movies/TV are usually underfunded, under-appreciated and\n",
            "misunderstood. I tried to like this, I really did, but it is to good\n",
            "TV sci-fi as Babylon 5 is to Star Trek (the original).\n",
            "9- GT: NEGATIVE\n",
            "10- Predict: NEGATIVE\n",
            "10\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. Trong state space model, dạng recurrent phù hợp cho quá trình inference vì?\n",
            "(a) Khả năng tính toán song song.\n",
            "(b) Độ phức tạp O(n2).\n",
            "(c) Độ phức tạp O(n).\n",
            "(d) Khả năng xử lý long sequence.\n",
            "2. Trong state space model, dạng convolutional có tính chất nào sau đây?\n",
            "(a) Độ phức tạp O(n2).\n",
            "(b) Không thể tính toán song song.\n",
            "(c) Khả năng tính toán song song.\n",
            "(d) Khả năng attention.\n",
            "3. Trong structured state space model (S4), ma trận HiPPO được sử dụng để khởi tạo ma trận A vì:\n",
            "(a) Khả năng tính toán song song.\n",
            "(b) Tăng tham số để model học.\n",
            "(c) Giảm tham số để model học.\n",
            "(d) Tăng khả năng ghi nhớ sequence.\n",
            "4. Trong state space model, biểu thức Dx ttrong công thức yt=Ch t+Dx tđóng vai trò gì?\n",
            "(a) Activation function.\n",
            "(b) LayerNorm.\n",
            "(c) Skip-connection.\n",
            "(d) BatchNorm.\n",
            "5. Trong state space model, ta chỉ có thể sử dụng dạng recurrent để inference là nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "6. Trong state space model, dạng convolutional phù hợp để train vì độ phức tạp O(n)so với O(n2)\n",
            "của dạng recurrent là nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "7. Trong state space model, dạng convolutional phù hợp để train vì khả năng tính toán song song là\n",
            "nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "8. Trong state space model, dạng recurrent phù hợp để inference vì có khả năng tính toán song song\n",
            "là nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "11\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "9. Trong state space model, dạng recurrent phù hợp để inference vì độ phức tạp O(1)khi tạo ra từng\n",
            "token là nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "10. Đâu là contribution của Mamba?\n",
            "(a) Khả năng tính toán song song ở dạng convolutional.\n",
            "(b) Khả năng tính toán song song ở dạng recurrent.\n",
            "(c) Khả năng tính toán song song ở 2 dạng convolutional và recurrent.\n",
            "(d) Khả năng tính toán song song khi inference.\n",
            "11. Đâu là contribution của Mamba?\n",
            "(a) Khả năng tạo ra trọng số phụ thuộc vào input\n",
            "(b) Khả năng tạo ra trọng số không dựa vào input.\n",
            "(c) Khả năng tạo ra trọng số phụ thuộc vào label.\n",
            "(d) Khả năng tạo ra trọng số không phụ thuộc vào label.\n",
            "- Hết -\n",
            "12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```SimpleDirectoryReader```"
      ],
      "metadata": {
        "id": "ByslFv64A4Ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"/content/AIO_Documents/Documents\").load_data()\n"
      ],
      "metadata": {
        "id": "kbUCbsrSIJ2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0].text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "I5V4tA28J7W8",
        "outputId": "2cd089a9-4017-46e4-9411-ebbbea2d9840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tutorial on Denoising Diffusion-based\\nGenerative Modeling\\nNguyen Vu Hoa Binh Khai Trinh Xuan Hoang-Bach ngo Minh-Hung An\\nNgày 7 tháng 2 năm 2024\\nPhần I: Một số khái niệm cơ bản\\nTrước khi chúng ta bắt đầu tìm hiểu về Stable Diffusion (SD) thì ở phần này chúng ta sẽ cùng nhau\\ntổng quan lại một số kiến thức nền tảng, những khái niệm trong phần này sẽ là cơ sở để chúng ta hiểu\\nvà chứng minh được cách mà một mô hình SD vận hành.\\n1 Wiener process\\nWiener process còn được gọi là Brownian process (Brownian motion), là một quá trình ngẫu nhiên\\nkhông giảm dần theo thời gian. Được đặt tên theo nhà toán học và nhà vật lý học Norbert Wiener và\\nRobert Brown.\\nMột số đặc điểm của Wiener process:\\n•Liên tục : Nó là một quá trình liên tục trong không gian và thời gian. Điều này có nghĩa rằng nó\\nkhông bị gián đoạn và có giá trị tại mọi thời điểm.\\n•Không xác định : Wiener process có tính chất ngẫu nhiên mạnh, nghĩa là không thể dự đoán\\nđược cách nó di chuyển tại một thời điểm cụ thể. Nó thường được mô tả bằng một biến ngẫu\\nnhiên theo phân phối chuẩn (normal).\\n•Điểm xuất phát : Quá trình Wiener thường được mô tả bằng một điểm xuất phát, sau đó tiến\\nhành theo một quá trình ngẫu nhiên không giảm dần.\\n•Được sử dụng rộng rãi : Quá trình Wiener được sử dụng trong nhiều lĩnh vực như tài chính\\n(để mô phỏng biến động giá cổ phiếu), khoa học máy tính (để mô phỏng quá trình ngẫu nhiên),\\ntoán học,...\\nWiener process là một ví dụ quan trọng trong lĩnh vực lý thuyết xác suất và quá trình ngẫu nhiên\\nvà chúng thường được sử dụng để mô phỏng và nghiên cứu sự biến đổi ngẫu nhiên trong các hệ thống\\nthực tế.\\n1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Text splitter"
      ],
      "metadata": {
        "id": "wacBACwE8zRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``` SentenceSplitter ```"
      ],
      "metadata": {
        "id": "TYfedayN_a7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core import Settings, VectorStoreIndex\n",
        "\n",
        "\n",
        "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=128)\n",
        "processed_documents = text_splitter(documents)\n",
        "print(\"Before splitting\", len(documents))\n",
        "print(\"After splitting\", len(processed_documents))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF_PYwtCJeDB",
        "outputId": "ea525c3d-f8d5-4584-f279-122f98ada7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before splitting 483\n",
            "After splitting 897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(processed_documents[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noJTTROW9W3j",
        "outputId": "e50aba9c-9a74-43e1-a3e9-b408dc4a244f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tutorial on Denoising Diffusion-based\n",
            "Generative Modeling\n",
            "Nguyen Vu Hoa Binh Khai Trinh Xuan Hoang-Bach ngo Minh-Hung An\n",
            "Ngày 7 tháng 2 năm 2024\n",
            "Phần I: Một số khái niệm cơ bản\n",
            "Trước khi chúng ta bắt đầu tìm hiểu về Stable Diffusion (SD) thì ở phần này chúng ta sẽ cùng nhau\n",
            "tổng quan lại một số kiến thức nền tảng, những khái niệm trong phần này sẽ là cơ sở để chúng ta hiểu\n",
            "và chứng minh được cách mà một mô hình SD vận hành.\n",
            "1 Wiener process\n",
            "Wiener process còn được gọi là Brownian process (Brownian motion), là một quá trình ngẫu nhiên\n",
            "không giảm dần theo thời gian. Được đặt tên theo nhà toán học và nhà vật lý học Norbert Wiener và\n",
            "Robert Brown.\n",
            "Một số đặc điểm của Wiener process:\n",
            "•Liên tục : Nó là một quá trình liên tục trong không gian và thời gian. Điều này có nghĩa rằng nó\n",
            "không bị gián đoạn và có giá trị tại mọi thời điểm.\n",
            "•Không xác định : Wiener process có tính chất ngẫu nhiên mạnh, nghĩa là không thể dự đoán\n",
            "được cách nó di chuyển tại một thời điểm cụ thể. Nó thường được mô tả bằng một biến ngẫu\n",
            "nhiên theo phân phối chuẩn (normal).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(processed_documents[1].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK8IMHv9922U",
        "outputId": "1f71724c-1cf9-4b88-9321-ce7846190a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "•Không xác định : Wiener process có tính chất ngẫu nhiên mạnh, nghĩa là không thể dự đoán\n",
            "được cách nó di chuyển tại một thời điểm cụ thể. Nó thường được mô tả bằng một biến ngẫu\n",
            "nhiên theo phân phối chuẩn (normal).\n",
            "•Điểm xuất phát : Quá trình Wiener thường được mô tả bằng một điểm xuất phát, sau đó tiến\n",
            "hành theo một quá trình ngẫu nhiên không giảm dần.\n",
            "•Được sử dụng rộng rãi : Quá trình Wiener được sử dụng trong nhiều lĩnh vực như tài chính\n",
            "(để mô phỏng biến động giá cổ phiếu), khoa học máy tính (để mô phỏng quá trình ngẫu nhiên),\n",
            "toán học,...\n",
            "Wiener process là một ví dụ quan trọng trong lĩnh vực lý thuyết xác suất và quá trình ngẫu nhiên\n",
            "và chúng thường được sử dụng để mô phỏng và nghiên cứu sự biến đổi ngẫu nhiên trong các hệ thống\n",
            "thực tế.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```SemanticSplitterNodeParser```"
      ],
      "metadata": {
        "id": "aNkCd2BS_i5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import (\n",
        "    SentenceSplitter,\n",
        "    SemanticSplitterNodeParser\n",
        ")\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "wdAISzxL_jUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "embed_model = HuggingFaceEmbedding(model_name = 'BAAI/bge-small-en-v1.5', device=device)\n",
        "\n",
        "splitter = SemanticSplitterNodeParser(\n",
        "    buffer_size=1, breakpoint_percentile_threshold=95, embed_model=embed_model\n",
        ")\n",
        "\n",
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "\n",
        "for node in nodes:\n",
        "    print(\"-\" * 100)\n",
        "    print(node.get_content())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8b07fd84d06c4b5e8328224269830ce4",
            "f87912d1a84a40f0b61666968e670784",
            "e39c43078ad245b19c2aaf6f23bc7dae",
            "cab2f39a272849529bf7ac723d95225b",
            "2036d10a95884a52b846979cc00a8f33",
            "caf184988ade4c2a9d9b2d5e30e45c16",
            "3cf2865319c340f6ac6b522fcf579d6e",
            "7beecc923ced43df8f244ac78d22c7d4",
            "83112e5c94fa4c71844886956ec2853d",
            "c89940556db04ad4a79fd7b0fcc79565",
            "bdc5c37c73904ad7a180d1d35f051fa9",
            "69399e3790a84fb19e87ad71e3647e1d",
            "a3f7d019b5b4443abed19e68f00aecc7",
            "3e3e3d60d25a4091a4e66b24234ed752",
            "fef12ba4b6714891a637bf5f37eba614",
            "b98168b76f13476d8f52c6bb7e27b5e9",
            "016aa641ea8448deaa054f27ed1951f2",
            "bb8f44ad4c4742398a12fc7b52719f38",
            "9259f2fd4bad4c988ef6437efdf0d929",
            "766c0a233e094bd9bdb568832a887f04",
            "d20190d384ca448da45874fe40f97cf0",
            "26b410593a914463bd4e38632ec17fb6",
            "907c6f3155914aad93c19c1efb090cec",
            "11ff66b4975347fd88f0931121df5097",
            "5be10defe6534213ad7701ec09bd3b54",
            "6d130d151a424d57a68ce661802e6599",
            "8dd93d3f3227410486dabeced424b06a",
            "b91ea5feb74c42d1ad5e895669c5c600",
            "d718a8c80d0d4cd3becc49752a43cd6a",
            "28ad449062c24510944d092a511c8ce2",
            "4b87ff1ec1b94d3e9c76eb32a8a67961",
            "26d0f9f2d75744d18ae8eb4b56108407",
            "1aabd50e960e41b695ed9d4384268b8c",
            "0d7af0cdfc11463dbdabbe76c4c00203",
            "2a588f34075e4c0a879034b5e6eb7367",
            "8fe93ceb154f4b26b0beea0b6f36528a",
            "40f51e98d682444d818165e378d48eff",
            "7cefa8c1113549abb64da60b2823372b",
            "711980cd8dfa417a93d6ec9fa4ec2984",
            "e5519690cf4e455ebafce4f3c233221e",
            "c514ad192ec74df793aaed79e3f4ac1f",
            "b3c966692f414f3f84ca49adb6489770",
            "e69c0e4917ff4c3992a8de75186f2cd4",
            "0e08490a73564f5290ffc96097f5cbba",
            "1fe728cc429747f8b24617454f1999cc",
            "c172fe89037445e6a33adee0e361872e",
            "c5fbd2f8d3b34a668b49f085d0f825e6",
            "5ffb029ea13645519f519f6a550b588c",
            "65114908d1554b968e260545d639a936",
            "af49fac7a0784401adb95584b074d0c5",
            "e4866abda70c499ea6edfbb7b7c584bb",
            "83afaa09f0bc44559d96ae3862bac3da",
            "1e4fe345b49940eda968f266cedebcda",
            "8306192b348f437c8871c12e477621b6",
            "290102a46ca4417195e0f0ddd44d6779",
            "46d96e093a424443a0ab8df494ea0da8",
            "1ef8f253137c459c8ee86b6488bb21b9",
            "60c46d7c611942d3bb0e25ea65fa14bd",
            "2031343f401d4a22bf8a2f94573f80a6",
            "4a5ee58062e144b3bd1b3aa799e7772c",
            "0a49be722e0c4db7b5f520899286c197",
            "11f433c497bf4f7a95a118b3419b6cc8",
            "7772baffcac0402ab97265c39a076dea",
            "112b6016b4a44dc69257a46bea078581",
            "4c9e3fc0a3b84ae98e427ff4222dc33c",
            "37bd1f74a03e4d02a4612e67c154782f",
            "c94232799bac4073aa21a2902ea3f444",
            "6474ce9bb5e24c97be8d9e2ae8475b11",
            "9353bb28cc714e26b9010631179c2a26",
            "150b64cac2684e418e30bfb0d134c5e2",
            "f59c0f8d8d42415f8473fffd866022d9",
            "7041867aad824641b78242faa98a373e",
            "cfd7f86732fe41d6a0fa9a3547b9d6ab",
            "2e422747d7c34d95ba75d9ef975dd19f",
            "19583ce0740a4a5a9c7aed111ff06143",
            "ce446d51e781405fbbaff33207dfb6de",
            "853c2deba595489bbe77b4d4c223c1d6",
            "1c1a8d9153bb4b1991f3b2f5a40b0e59",
            "840734df58cf47c6914b609f4a8a421d",
            "e3fdc7cf6ec54f38b75b738ce02a1ea2",
            "4f2fa76a0b594a028dc7f7c7d874ec32",
            "7d63a841f6f74014906d9cb7e7e3cdb7",
            "e9b6b2be85ce44b39c745d9e7fdb5315",
            "7d9bf0adc8c441b88bef01b56718b40b",
            "eaaf85c530e04087b37f47b8fe121307",
            "4521762d9f8a4b15a9a6cfb9a418f453",
            "3189fcc4773744b5b24a365484a4c839",
            "939b17513726486dbc75f15a39aa00ae",
            "f20a976b46ab4fc1bb3c4a674ab65699",
            "bb73fb121ca74c3d8bc2ef5818660da3",
            "3bff91f6dc0645d893783f991883d0b9",
            "2d27b9288a10423fbf8144c2dbbfab70",
            "5f22a9ad421b4fa7abeab8dfbebdb5a1",
            "8025109e9a8848be8c2d737613761dd5",
            "6413d62969da4ec794405309557dd8a2",
            "5d2bdebb7d254ca7ab6881792f1f7ff0",
            "fbc8d4ee82ae4b4f9d677f2f02ca5dfd",
            "520ffe3a8e1a4416a35687a454bfc8b6",
            "ff2a74a97bfb4b53ad325422aaa6aaca",
            "e2dd49a25e3b446f83bc2040efb5386c",
            "794dffe5add3466ab6f7d190a740e846",
            "163700b605ba467897b7876f3cf588b8",
            "70f19524d18e42dd8596f8bac9e61d1c",
            "2a48f399bc024284bb373e966ed01a3a",
            "8acbab6dc2704299b264f7e0fe84970c",
            "371ec9cf9ec8463fa48b6b129c17eee7",
            "aec1cf36c3d947f69e9c6f04f5acbf10",
            "e68f634665d941ab9b6692de45bf3bfa",
            "556a61f975bd4955bf5f20723e8fa12a",
            "59291bd0431c4569940925b017b63599",
            "677b1dde51094cff972fe307897c8da2",
            "2670d4e620934b4cb76b0d41139c2192",
            "70d685d1578f457696d45074d9314967",
            "28f0a55637ab4bc085c8c4864be5a638",
            "daadd46f0c69460baae61eafa570cc94",
            "19d179a4b42543dfb5f8d02426e365da",
            "957b60bf864b48708ff106de0e9e628a",
            "5bee880e30c04c6b9f59ebaf240872f4",
            "3dfc8a79a2dd4f46b87806e99a9fed0f",
            "7f7265f5d04141a58949366bd0b649d0",
            "b7429779b3204982b0405948fd164e78"
          ]
        },
        "id": "qiLHSIod___Z",
        "outputId": "af77147c-d5ec-40df-c289-0626f5582062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b07fd84d06c4b5e8328224269830ce4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69399e3790a84fb19e87ad71e3647e1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "907c6f3155914aad93c19c1efb090cec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d7af0cdfc11463dbdabbe76c4c00203"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fe728cc429747f8b24617454f1999cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46d96e093a424443a0ab8df494ea0da8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c94232799bac4073aa21a2902ea3f444"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c1a8d9153bb4b1991f3b2f5a40b0e59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f20a976b46ab4fc1bb3c4a674ab65699"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2dd49a25e3b446f83bc2040efb5386c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "677b1dde51094cff972fe307897c8da2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Tutorial on Denoising Diffusion-based\n",
            "Generative Modeling\n",
            "Nguyen Vu Hoa Binh Khai Trinh Xuan Hoang-Bach ngo Minh-Hung An\n",
            "Ngày 7 tháng 2 năm 2024\n",
            "Phần I: Một số khái niệm cơ bản\n",
            "Trước khi chúng ta bắt đầu tìm hiểu về Stable Diffusion (SD) thì ở phần này chúng ta sẽ cùng nhau\n",
            "tổng quan lại một số kiến thức nền tảng, những khái niệm trong phần này sẽ là cơ sở để chúng ta hiểu\n",
            "và chứng minh được cách mà một mô hình SD vận hành.\n",
            "1 Wiener process\n",
            "Wiener process còn được gọi là Brownian process (Brownian motion), là một quá trình ngẫu nhiên\n",
            "không giảm dần theo thời gian. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Được đặt tên theo nhà toán học và nhà vật lý học Norbert Wiener và\n",
            "Robert Brown.\n",
            "Một số đặc điểm của Wiener process:\n",
            "•Liên tục : Nó là một quá trình liên tục trong không gian và thời gian. Điều này có nghĩa rằng nó\n",
            "không bị gián đoạn và có giá trị tại mọi thời điểm.\n",
            "•Không xác định : Wiener process có tính chất ngẫu nhiên mạnh, nghĩa là không thể dự đoán\n",
            "được cách nó di chuyển tại một thời điểm cụ thể. Nó thường được mô tả bằng một biến ngẫu\n",
            "nhiên theo phân phối chuẩn (normal).\n",
            "•Điểm xuất phát : Quá trình Wiener thường được mô tả bằng một điểm xuất phát, sau đó tiến\n",
            "hành theo một quá trình ngẫu nhiên không giảm dần.\n",
            "•Được sử dụng rộng rãi : Quá trình Wiener được sử dụng trong nhiều lĩnh vực như tài chính\n",
            "(để mô phỏng biến động giá cổ phiếu), khoa học máy tính (để mô phỏng quá trình ngẫu nhiên),\n",
            "toán học,...\n",
            "Wiener process là một ví dụ quan trọng trong lĩnh vực lý thuyết xác suất và quá trình ngẫu nhiên\n",
            "và chúng thường được sử dụng để mô phỏng và nghiên cứu sự biến đổi ngẫu nhiên trong các hệ thống\n",
            "thực tế.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 1: Hình ảnh minh họa cho Wiener process\n",
            "2 Stochastic Differential Equation (SDE)\n",
            "Phương trình vi phân (SDE) là một loại phương trình chứa thành phần ngẫu nhiên. Chúng được sử\n",
            "dụng để mô tả sự biến đổi ngẫu nhiên trong các quá trình theo thời gian, như sự biến động giá cổ phiếu\n",
            "trong tài chính, phân phối không đều trong sinh học, hay các hiện tượng tự nhiên khác có yếu tố ngẫu\n",
            "nhiên.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "dX(t) =a(X(t), t)dt+b(X(t), t)dW(t) (1)\n",
            "Trong đó:\n",
            "•X(t)là quá trình stochastics cần mô phỏng.\n",
            "•a(X(t), t)vàb(X(t), t)là các hàm thường chứa thành phần xác định và có thể chứa thành phần\n",
            "ngẫu nhiên.\n",
            "•dtlà một khoảng thời gian vô cùng nhỏ.\n",
            "•dW(t)là một biến ngẫu nhiên, thường là một Wiener process, có phân phối chuẩn với giá trị kỳ\n",
            "vọng bằng 0 và phương sai bằng dt\n",
            "Sự biến đổi ngẫu nhiên được biểu thị bằng phần tử b(X(t), t)dW(t). Sự biến đổi này làm cho các\n",
            "giá trị X(t)biến đổi theo thời gian theo một cách không xác định và có tính chất ngẫu nhiên.\n",
            "3 Euler-Maruyama\n",
            "Euler-Maruyzama là một phương pháp số học để giải các phương trình vi phân stochastics (SDE). Nó\n",
            "thường được sử dụng để mô phỏng các quá trình ngẫu nhiên trong khoa học máy tính, tài chính, sinh\n",
            "học và nhiều lĩnh vực khác.\n",
            "Phương pháp này chủ yếu được sử dụng khi có một phương trình vi phân stochastics, có sự biến đổi\n",
            "ngẫu nhiên. Euler-Maruyama chia khoảng thời gian thành các bước nhỏ và ước tính giá trị của hàm số\n",
            "tại mỗi time step. Tại mỗi bước, nó sử dụng giá trị của hàm số ở bước trước và một ngẫu nhiên được\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "tạo ra theo phân phối chuẩn để tính giá trị tiếp theo. Phương pháp này có thể được biểu thị bằng công\n",
            "thức:\n",
            "Xn+1=Xn+f(Xn, tx).∆t+g(Xn, tx).√\n",
            "∆t.Zn+1 (2)\n",
            "Trong đó:\n",
            "•Xnlà giá trị ước tính tại thời điểm tn\n",
            "•f(Xn, tn)là phần không xác định (deterministic) của phương trình vi phân stochastics.\n",
            "•g(Xn, tn)là ngẫu nhiên của phương trình vi phân stochastics.\n",
            "•∆tlà khoảng thời gian giữa các bước.\n",
            "•Zn+1là phân phối chuẩn hóa hoặc chuẩn tắc (mean 0, variance 1)\n",
            "Hình 2: Euler-Maruyama có độ đơn giản và dễ triển khai, nhưng nó có thể có sai số và yếu tố ngẫu\n",
            "nhiên khi giải phương trình stochastics. Thường được sử dụng khi cần một phương pháp gần đúng cho\n",
            "mô phỏng thay vì một giải pháp chính xác\n",
            "4 Heat kernel\n",
            "Heat kernel (Gaussian heat kernel) - thường được sử dụng để mô tả sự lan truyền của nhiệt trong không\n",
            "gian 2D/3D và cũng có ứng dụng trong nhiều lĩnh vực khác. Heat kernel có tính chất lan truyền nhiệt\n",
            "từ một điểm cố định ra xa theo thời gian và không gian.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Heat kernel thường được biểu diễn dưới dạng một hàm số, phụ thuộc vào biến thời gian t và không\n",
            "gian x và thường được ký hiệu là H(t, x)hoặc Kt(x). Hàm này thường được định nghĩa dựa trên phân\n",
            "phối Gaussian và có dạng:\n",
            "H(t, x) =1\n",
            "(4πt)d/2e−||x||2\n",
            "4t(3)\n",
            "Trong đó:\n",
            "•dlà số chiều của không gian 2D/3D\n",
            "•t là thời gian.\n",
            "•x là vị trí trong không gian (vector x có d chiều)\n",
            "•||x||là độ dài của vector x.\n",
            "Hình 3: Heat kernel có các tính chất quan trọng bao gồm tính duy nhất của nó khi tất cả điểm bắt\n",
            "đầu và thời gian khác nhau và tính xấp xỉ khi t tiến gần đến 0 hoặc vô cùng. Nó thường được sử dụng\n",
            "trong lý thuyết xác suất để mô tả quá trình diffusion và trong xử lý ảnh để làm mịn hoặc làm nổi bật\n",
            "các đặc trưng của ảnh.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "5 Delta Dirac Function\n",
            "Delta dirac là hàm đặc trưng với tích phân của nó bằng 1 trên toàn bộ trục số thực và bằng 0 ở mọi\n",
            "điểm ngoại trừ điểm gốc (x=0 hoặc k=0). Cụ thể, mô tả hàm delta dirac có thể được biểu diễn như\n",
            "sau:\n",
            "δ(x) =(\n",
            "+∞ifx= 0\n",
            "0ifx̸= 0(4)\n",
            "Z+∞\n",
            "−∞δ(x)dx= 1 (5)\n",
            "Z+∞\n",
            "−∞f(x)δ(x−ξ)dx=f(ξ) (6)\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 4: Hàm delta dirac thường được sử dụng trong các ứng dụng toán học và kỹ thuật như biểu diễn\n",
            "các hàm xác định tại một điểm duy nhất hoặc trong lý thuyết xác suất để biểu diễn phân phối xác suất\n",
            "của một biến ngẫu nhiên tại một giá trị duy nhất.\n",
            "6 Heat equation\n",
            "Heat Equation là một phương trình đạo hàm riêng sử dụng để mô tả sự truyền nhiệt (heat) trong các\n",
            "hệ thống vật lý. Nó giúp chúng ta dự đoán và mô tả cách nhiệt độ thay đổi theo thời gian và không\n",
            "gian trong các vật thể hoặc hệ thống.\n",
            "Phương trình nhiệt thường được biểu diễn như sau:\n",
            "∂u\n",
            "∂t=α∇2u (7)\n",
            "Trong đó:\n",
            "•∂u\n",
            "∂tlà đạo hàm riêng theo thời gian của nhiệt độ (u)\n",
            "•αlà hệ số dẫn nhiệt, biểu thị tốc độ truyền nhiệt trong vật thể.\n",
            "•∇2ulà Laplacian của nhiệt độ (u), biểu thị sự biến đổi trong không gian của nhiệt dộ.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 5: Phương trình này nói lên rằng sự thay đổi của nhiệt độ tại một điểm cụ thể trong không gian\n",
            "∂u\n",
            "∂tphụ thuộc vào tốc độ dẫn nhiệt αvà biến đổi không gian của nhiệt độ ∇2u\n",
            "7 Ito interpretation\n",
            "Ito interpretation là một khái niệm quan trọng trong lý thuyết xử lý stochastics (lý thuyết xử lý ngẫu\n",
            "nhiên), đặc biệt trong lĩnh vực tài chính và toán học. Nó liên quan đến việc diễn giải và giải thích\n",
            "phương trình stochastics dạng Ito, một công cụ quan trọng để mô hình hóa các biến ngẫu nhiên trong\n",
            "thời gian thực.\n",
            "Nó giúp chúng ta hiểu cách các yếu tố ngẫu nhiên, cũng như các yếu tố quá trình xử lý (process\n",
            "components) tác động và tương tác với nhau trong phương trình và làm thế nào chúng tạo ra sự biến\n",
            "đổi của biến ngẫu nhiên.\n",
            "Phương trình stochastics dạng Ito là một phương trình vi phân stochastics sử dụng để mô hình hóa\n",
            "và mô tả sự biến đổi của biến ngẫu nhiên theo thời gian. Phương trình này thường được biểu diễn dưới\n",
            "dạng:\n",
            "dX=a(X, t)dt+b(X, t)dW (8)\n",
            "Trong đó:\n",
            "•dXlà thay đổi infinitesimal (vô cực nhỏ) của biến ngẫu nhiên X theo thời gian. Nó biểu thị sự\n",
            "biến đổi ngẫu nhiên của biến X trong một khoảng rất nhỏ của thời gian dt.\n",
            "•a(X, t)dtlà thành phần xác định (deterministic component) của sự biến đổi của X. Nó phụ thuộc\n",
            "vào giá trị hiện tại của X và thời gian t. Thành phần này mô tả sự thay đổi trung bình hoặc sự\n",
            "biến đổi xác định của X theo thời gian.\n",
            "•b(X, t)dWlà thành phần ngẫu nhiên (stochastic component) của sự biến đổi của X. Nó phụ thuộc\n",
            "vào giá trị hiện tại của X và thời gian t, cũng như vào dạng ngẫu nhiên dW. Thành phần này mô\n",
            "tả sự biến đổi ngẫu nhiên của X dưới tác động của dạng ngẫu nhiên dW\n",
            "•dWlà dạng ngẫu nhiên Wiener. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nó thường được mô tả là một biến ngẫu nhiên liên tục và không\n",
            "thể dự đoán, với tính chất ∆W=Z√\n",
            "dt, trong đó Z là một biến ngẫu nhiên theo phân phối Gauss.\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Chúng ta sẽ xét một ví dụ về việc sử dụng Ito interpretation để giải quyết một bài toán cụ thể trong\n",
            "tài chính. Giả sử chúng ta muốn mô hình hóa giá cổ phiếu trong thời gian thực và dự đoán sự biến đổi\n",
            "của nó.\n",
            "Phương trình stochastics dạng itô cho giá cổ phiếu có thể được biểu diễn như sau:\n",
            "dS=µSdt +σSdW (9)\n",
            "Trong đó:\n",
            "•S là giá cổ phiếu\n",
            "•µlà tỷ suất lợi nhuận kỳ vọng hàng ngày.\n",
            "•σlà biến động thị trường (volatility)\n",
            "•dWlà phần còn lại, là dạng ngẫu nhiên của biến đổi giá cổ phiếu theo thời gian.\n",
            "Ito interpretation cho phương trình này sẽ giải thích các thành phần của nó như sau:\n",
            "•µSdtmô tả sự thay đôỉ trung bình của giá cổ phiếu theo thời gian.\n",
            "•σSdWmô tả biến động ngẫu nhiên của giá cổ phiếu dưới tác động của dạng ngẫu nhiên dW\n",
            "Sử dụng Ito interpretation, chúng ta hiểu rằng sự biến đổi của giá cổ phiếu không chỉ do lợi nhuận\n",
            "kỳ vọng µSdtmà còn do yếu tố biến động thị trường ngẫu nhiên σSdW.\n",
            "Dựa vào phương trình này và Ito interpretation, chúng ta có thể mô hình hóa và dự đoán giá cổ\n",
            "phiếu trong tương lai dưới tác động của cả yếu tố lợi nhuận kỳ vọng và biến động thị trường, giúp người\n",
            "giao dịch và nhà đầu tư hiểu rõ các yếu tố quyết định giá cổ phiếu và đưa ra quyết định thông minh\n",
            "trong thị trường tài chính.\n",
            "8 Drift function\n",
            "Drift function là một hàm số mô tả thành phần xác định và xác định hướng thay đổi trung bình của\n",
            "biến ngẫu nhiên theo thời gian. Drift function thường được ký hiệu bằng a(X, t)trong phương trình ito:\n",
            "dX=a(X, t)dt+... (10)\n",
            "Trong phương trình này, a(X, t)là drift function, chịu trách nhiệm cho sự thay đổi trung bình của\n",
            "biến X trong khoảng thời gian dt. Drift function có thể thay đổi theo giá trị hiện tại của X và thời gian\n",
            "t và có thể có một sự phụ thuộc phức tạp vào các yếu tố khác nhau.\n",
            "Drift function là một phần quan trọng trong việc mô hình hóa các hiện tượng ngẫu nhiên và dự\n",
            "đoán sự biến đổi của các biến ngẫu nhiên. Nó cung cấp thông tin về hướng diễn ra của sự biến đổi của\n",
            "biến ngẫu nhiên và là một phần quan trọng trong việc hiểu và mô hình hóa các hiện tượng thực tế.\n",
            "9 Fokker-Planck equation\n",
            "Fokker-Planck equation là một loại phương trình vi phân riêng phần parabol (partial differential equa-\n",
            "tion) trong lý thuyết xác suất và quá trình ngẫu nhiên. Phương trình này mô tả cách phân phối xác\n",
            "suất của một quá trình stochastics (ngẫu nhiên) thay đổi theo thời gian.\n",
            "Cụ thể, Fokker-Planck equation xuất hiện trong bối cảnh mô hình hóa sự biến đổi của một hệ thống\n",
            "có tính chất ngẫu nhiên, ví dụ, trong lý thuyết tài chính, vật lý thống kê và vật lý động lượng. Phương\n",
            "trình này giúp dự đoán cách mật độ xác suất của hệ thống thay đổi theo thời gian.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Fokker-Planck equation có dạng tổng quát như sau:\n",
            "∂p(x, t)\n",
            "∂t=−∂\n",
            "∂x[f(x, t)p(x, t) ] +∂2\n",
            "∂x2\u0014g(x, t)2\n",
            "2p(x, t)\u0015\n",
            "(11)\n",
            "Trong đó:\n",
            "•∂p(x,t)\n",
            "∂tlà đạo hàm riêng của mật độ xác suất p(x, t)theo thời gian t. Nó mô tả cách mật độ xác\n",
            "suất thay đổi theo thời gian.\n",
            "•∂\n",
            "∂xlà đạo hàm riêng theo x. Phần này mô tả cách mật độ xác suất thay đổi theo không gian (vị\n",
            "trí x)\n",
            "•f(x, t)là drift function, miêu tả cách giá trị trung bình của biến ngẫu nhiên x(t)thay đổi theo\n",
            "thời gian t. f(x, t)là một hàm của x và t và được sử dụng để mô tả sự thay đổi trung bình của\n",
            "quá trình.\n",
            "•∂2\n",
            "∂x2là đạo hàm riêng theo hai vị trí x. Phần này liên quan đến độ lớn của biến thể ngẫu nhiên\n",
            "(nhiễu) và mô tả cách sự biến đổi ngẫu nhiên của x(t) phân tán trong không gian (ví trí x). Hàm\n",
            "g(x, t)thường đo lường mức độ của biến ngẫu nhiên, vàg(x,t)2\n",
            "2chính là phần diffusion\n",
            "Phương trình này mô tả cách mật độ xác suất thay đổi theo thời gian do tác động của các thành\n",
            "phần xác định và ngẫu nhiên. Fokker-Planck equation là một công cụ quan trọng để nghiên cứu và dự\n",
            "đoán hành vi của các hệ thống phức tạp trong điền kiện ngẫu nhiên.\n",
            "10 Ornstein-Uhlenbeck processes\n",
            "Ornstein-Uhlenbeck processes là một quá trình stochastics (ngẫu nhiên) thường được sử dụng trong lý\n",
            "thuyết xác suất và thống kê để mô hình hóa sự biến đổi và trạng thái cân bằng của các hệ thống có sự\n",
            "phản hồi trở lại. Cụ thể, các OU process có xu hướng trở về một giá trị trung bình cố định dưới tác\n",
            "động của nhiễu ngẫu nhiên. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Chúng có nhiều ứng dụng trong nhiều lĩnh vực như tài chính, vật lý, sinh\n",
            "học và điều khiển tự động.\n",
            "OU process có thể bao gồm nhiều các biến thể như OU phi tuyến tính, OU colored noise hoặc các\n",
            "biến thể khác nhằm mô tả các hiện tượng phức tạp hơn.\n",
            "Một OU process cơ bản có dạng sau:\n",
            "dXt=θ(µ−Xt)dt+σdW t (12)\n",
            "Trong đó:\n",
            "•Xtlà OU process, biểu thị sự biến đổi của hệ thống tại thời điểm t.\n",
            "•θlà hệ số phản hồi, đo lường mức độ mà Xttrở về giá trị trung bình µ\n",
            "•µlà giá trị trung bình của process.\n",
            "•σlà độ lớn của biến thể noise, thường dựa trên quá trình Wiener Wt\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 6: Các biến thể OU process có thể điều chỉnh các thành phần này để thích nghi với các tình huống\n",
            "cụ thể hoặc để mô hình biến đổi phức tạp hơn trong thời gian. Chúng có thể được sử dụng để mô hình\n",
            "hóa các quá trình ngẫu nhiên có cấu trúc phản hồi và trạng thái cân bằng trong nhiều ứng dụng khác\n",
            "nhau.\n",
            "11 Monte Carlo method\n",
            "Phương pháp Monte Carlo là một phương pháp toán học và thống kê dựa trên việc sử dụng số ngẫu\n",
            "nhiên để giải các vấn đề có thể có sự ngẫu nhiên trong quá trình tính toán. Phương pháp này được đặt\n",
            "tên theo sòng bài Monte Carlo ở Monaco, nơi có trò chơi roulette với tính ngẫu nhiên tương tự.\n",
            "Cụ thể, phương pháp Monte Carlo được sử dụng để xấp xỉ giá trị của một biểu thức toán học bằng\n",
            "cách thực hiện một loạt các mẫu ngẫu nhiên và tính toán giá trị trung bình của chúng. Phương pháp\n",
            "này được ứng dụng rộng rãi trong nhiều lĩnh vực như vật lý, thống kê, tài chính.\n",
            "Các bước cơ bản của phương pháp Monte Carlo là:\n",
            "•Xác định vấn đề: Chọn một vấn đề cần giải và biểu diễn nó dưới dạng một biểu thức toán học\n",
            "hoặc mô hình.\n",
            "•Tạo số ngẫu nhiên: Sinh ra một loạt các số ngẫu nhiên theo một phân phối xác định\n",
            "•Áp dụng mẫu ngẫu nhiên: Sử dụng các số ngẫu nhiên để đưa vào biểu thức hoặc mô hình đã chọn\n",
            "và tính giá trị tương ứng.\n",
            "•Tính toán giá trị trung bình: lấy trung bình của tất cả các giá trị đã tính từ các mẫu để xấp xỉ\n",
            "giá trị cuối cùng của biểu thức hoặc mô hình.\n",
            "Phương pháp Monte Carlo thường được sử dụng khi không thể tính toán chính xác giá trị mong\n",
            "muốn một cách trực tiếp, nhưng có thể dễ dàng tạo ra các mẫu ngẫu nhiên và tính toán xấp xỉ.\n",
            "12 Boundary conditions\n",
            "Điều kiện biên (Boundary conditions) là các điều kiện được áp dụng tại ranh giới của miền không gian\n",
            "khi giải một vấn đề toán học hoặc vật lý. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Các điều kiện biên quy định cách giải phương trình hay hệ\n",
            "phương trình trong miền không gian cụ thể đó.\n",
            "Trong trường hợp phương trình Fokker-Planck (FPE), điều kiện biên có thể bao gồm các điều kiện\n",
            "về phân phối xác suất tại các ranh giới của miền không gian. Cụ thể:\n",
            "•Đối với phương trình FPE mô tả quá trình lan truyền xác suất, điều kiện biên có thể xác định\n",
            "phân phối xác suất tại các giới hạn của không gian chúng ta quan tâm.\n",
            "•Ví dụ, nếu không gian của biến xác suất là R, điều kiện biên có thể là p(∞, t) = 0vàp(−∞, t) = 0,\n",
            "giả định rằng xác suất tại ∞và−∞là không có.\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Đối với các phương trình FPE tương ứng với time-reversed process, điều kiện khởi tạo tại t=T\n",
            "là quan trọng.\n",
            "•Nếup(x, T)được xác định là phân phối xác suất ổn định của reverse process, điều kiện khởi tạo\n",
            "có thể đặt ra giả định nó có sẵn và có thể là một phân phối xác suất đã biết từ các điều kiện khác\n",
            "của vấn đề.\n",
            "Điều kiện biên có thể thay đổi tùy thuộc vào bối cảnh cụ thể và vấn đề mà chúng ta đang xem xét.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trong nhiều trường hợp, chúng được xác định để đảm bảo tính duy nhất và ổn định của giải pháp.\n",
            "13 Effect of diffusion on Gaussian mixture\n",
            "Một chút mở rộng cho quá trình diffusion 1D, chúng ta sử dụng một điều kiện ban đầu là gaussian\n",
            "mixture gồm M mixture components.\n",
            "p0(x) =MX\n",
            "j=1wj1q\n",
            "2πs2\n",
            "jexp(\n",
            "−[x−µj]2\n",
            "2s2\n",
            "j)\n",
            "(13)\n",
            "Trong đó:\n",
            "•µjlà trung bình của thành phần thứ j trong hỗn hợp gaussian.\n",
            "•sjlà độ lệch chuẩn của thành phần thứ j trong gaussian mixture.\n",
            "•wjlà trọng số của thành phần thứ j, sao choPM\n",
            "j=1wj= 1\n",
            "Transition Probability cho Quá Trình Diffusion 1D:\n",
            "p(x, t|x0,0) =1√\n",
            "2πσ2texp\u001a\n",
            "−(x−x0)2\n",
            "2σ2t\u001b\n",
            ". (14)\n",
            "Tích Phân để Tính Xác Suất Tại Thời Điểm t:\n",
            "p(x, t) =Z∞\n",
            "−∞p(x, t|x0,0)p0(x0)dx0\n",
            "=MX\n",
            "j=1wj1q\n",
            "2π(s2\n",
            "j+σ2t)exp(\n",
            "−[x−µj]2\n",
            "2(s2\n",
            "j+σ2t))\n",
            ".(15)\n",
            "Trong đó:\n",
            "•p(x, t)là xác suất phân phối tại vị trí x và thời điểm t sau quá trình diffusion từ điều kiện ban\n",
            "đầu là Gaussian Mixture p0(x).\n",
            "•Đoạn tích phân trên là tích phân qua tất cả các điều kiện ban đầu có thể, mỗi điều kiện ban đầu\n",
            "được đánh trọng số bởi p0(x0).\n",
            "•Kết quả là một tổng của các Gaussian với trung bình µjvà độ lệch chuẩn (s2\n",
            "j+σ2t), nghĩa là tất\n",
            "cả các thành phần trong mixture được \"lan truyền\" và có phương sai tăng lên sau mỗi khoảng\n",
            "thời gian t.\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Denoising Diffusion Probabilistic\n",
            "Models (DDPM)\n",
            "DDPM là một phương pháp để tạo ra dữ liệu mới, chẳng hạn như hình ảnh, âm thanh, hoặc văn bản,\n",
            "một cách tự nhiên. Bao gồm hai quá trình chính là Forward Diffusion và Reverse Diffusion. Trong đó:\n",
            "•Quá trình Phân tán - Forward Diffusion : Bắt đầu từ dữ liệu thực, mô hình áp dụng một\n",
            "chuỗi các bước tạo nhiễu ngẫu nhiên, dần dần thêm nhiễu vào dữ liệu ban đầu cho đến khi toàn\n",
            "bộ cấu trúc của dữ liệu gốc biến mất, để lại chỉ một mẫu nhiễu.\n",
            "•Quá trình Khử nhiễu - Reverse Diffusion : Đây là quá trình ngược lại, trong đó mô hình học\n",
            "cách loại bỏ dần dần nhiễu khỏi mẫu nhiễu, với mục tiêu cuối cùng là tái tạo dữ liệu gốc. Quá\n",
            "trình này được thực hiện thông qua một loạt các bước, với mỗi bước cố gắng phục hồi một phần\n",
            "của cấu trúc dữ liệu ban đầu từ dữ liệu bị nhiễu.\n",
            "Bên cạnh đó, để tạo ra được một dữ liệu mới từ DDPM thì chúng ta cần phải làm cho mô hình học\n",
            "cách thực hiện quá trình khử nhiễu một cách hiệu quả. Mô hình được huấn luyện để dự đoán nhiễu và\n",
            "loại bỏ nó, từ đó phục hồi dữ liệu gốc từ mẫu nhiễu. Sau khi huấn luyện, mô hình có thể sử dụng quá\n",
            "trình khử nhiễu để tạo ra dữ liệu mới. Bắt đầu từ nhiễu ngẫu nhiên, mô hình thực hiện quá trình khử\n",
            "nhiễu để tạo ra mẫu dữ liệu mới mà không cần dựa trên dữ liệu gốc.\n",
            "Hình 7: DDPM được sử dụng trong nhiều ứng dụng khác nhau, từ tạo hình ảnh đến tạo văn bản và âm\n",
            "thanh. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Một trong những ưu điểm chính của DDPM là khả năng tạo ra dữ liệu có chất lượng cao và tự\n",
            "nhiên.\n",
            "14 Forward Diffusion\n",
            "Ở phần này chúng ta sẽ tìm hiểu về Forward Diffusion - bước đầu tiên trong DDPM. Quá trình này\n",
            "là quá trình phá vỡ hình ảnh gốc bằng cách thêm dần các noise vào tại các thời điểm từ [x0:xT]và\n",
            "giả sử rằng chúng ta sử dụng Normal Distribution để sinh ra các hình ảnh nhiễu tại các thời điểm từ\n",
            "[x0:xT]. Công thức của Normal Distribution cho từng thời điểm x được định nghĩa như sau:\n",
            "q(xt|xt−1) =N(xt;p\n",
            "1−βtxt−1, βtI) (16)\n",
            "Trong đó:\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•q(xt|xt−1): Là Conditional Distribution của dữ liệu tại thời điểm t, với dữ liệu tại thời điểm t\n",
            "trước đó\n",
            "•N(xt;√1−βtxt−1, βtI): Là Công thức phân phối chuẩn (Normal Distribution). I là ma trận đơn\n",
            "vị, điều này có nghĩa là noise được thêm vào tại các thời điểm T đều là độc lập xuyên suốt các\n",
            "chiều không gian của dữ liệu.\n",
            "•√1−βtxt−1: Mean của Normal Distribution cho thời điểm t hiện tại.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•βt: Tham số điều khiển số lượng noise được thêm vào tại mỗi thời điểm T.\n",
            "•βtI: Covariance Matrix của noise được thêm vào.\n",
            "Như vậy, ta có công thức tổng quan cho Normal Distribution với thời điểm [x0:xT]là:\n",
            "q(x1:T|x0) =TY\n",
            "t=1q(xt|xt−1) (17)\n",
            "Hình 8: Forward Diffusion được mô tả dưới dạng một chuỗi Markov, trong đó size của từng bước được\n",
            "xác định thông qua variance schedule. Điểm đặc biệt của Markovian process chính là khả năng thu được\n",
            "mẫu tại bất kỳ khoảng thời gian nào một cách chính xác mà không cần trải qua các bước trung gian.\n",
            "Bên cạnh đó, variance schedule được thiết kế một cách tỉ mỉ, nhằm đảm bảo mẫu sẽ dần biến đổi thành\n",
            "white noise khi đạt đến bước thời gian T.\n",
            "14.1 Basic of diffusion\n",
            "Trước tiên chúng ta có quá trình diffusion một chiều trên đường thẳng số thực. Sử dụng phương trình\n",
            "vi phân stochastic (SDE) để mô tả quá trình này:\n",
            "˙x=σ η(t) (18)\n",
            "Trong đó:\n",
            "•σlà một hằng số dương\n",
            "•η(t)là Gaussian white noise\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Để giải thích ý nghĩa của biểu thức trên chúng ta cần định nghĩa nó dưới dạng giới hạng ∆tnhỏ\n",
            "của quá trình rời rạc, trong đó x(t+ ∆t)được tính dựa trên x(t)và một số rđược rút ra từ phân phối\n",
            "chuẩn (normal distribution) với mean 0 và variance 1. Đây là một ví dụ cơ bản của Euler Maruyama.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tiếp theo xem xét sự thay đổi của mật độ xác suất p(x, t)tức xác suất hệ thống ở vị trí x tại thời\n",
            "điểm t, theo thời gian. Nó đề cập đến diffusion equation:\n",
            "x(t+ ∆t) =x(t) +σ√\n",
            "∆t r (19)\n",
            "thể hiện rằng mật độ xác suất p(x, t)thay đổi theo thời gian theo cách được mô tả bởi phương trình\n",
            "trên.\n",
            "Diffusion equation còn được gọi là heat equation - mô tả cách mật độ xác suất p(x, t)thay đổi theo\n",
            "thời gian trong một quá trình diffusion. Cụ thể, nó cho biết cách độ dày của xác suất tại một vị trí x\n",
            "thời gian t thay đổi theo thời gian.\n",
            "Diffusion equation là một phương trình quan trọng trong lý thuyết xác suất và quá trình ngẫu nhiên,\n",
            "nó có thể được xuất phát từ một loạt các quy tắc cơ bản về sự biến đổi ngẫu nhiên. Bây giờ chúng ta\n",
            "sẽ tìm hiểu cách mà phương trình này được tạo ra.\n",
            "Bước đầu tiên là suy ra một biểu thức cho sự biến đổi xác suất p(x, t)theo thời gian t khi không có\n",
            "sự tương tác hoặc mật độ xác suất ban đầu tại các vị trí khác. Một cách tự nhiên, nó sẽ thay đổi theo\n",
            "cường độ biến đổi ngẫu nhiên ( σ) và tỷ lệ độ dày không gian (∂2p(x,t)\n",
            "∂x2). Dựa vào điều này chúng ta sẽ\n",
            "mô tả diffusion equation thông qua hệ số nhiệt D=σ2/2với D là một diffusion constant.\n",
            "∂p(x, t)\n",
            "∂t=σ2\n",
            "2∂2p(x, t)\n",
            "∂x2. (20)\n",
            "Phương trình này mô tả sự biến đổi của mật độ xác suất p(x, t)theo thời gian t và vị trí không gian\n",
            "x trong diffusion process. Nó cho biết tốc độ biến đổi của xác suất tại một thời diểm t bằng một nửa\n",
            "của bình phương độ dày không gian và cường độ biến đổi theo thời gian.\n",
            "Để giải diffusion equation này với một điều kiện cụ thể là p(x,0) = δ(x−x0), trong đó δ(x)là một\n",
            "hàm delta dirac. Điều này có nghĩa là chúng ta đang xem xét một trường hợp trong đó chúng ta biết\n",
            "chính xác rằng vị trí ban đầu là tại x0\n",
            "Với điều kiện ban đầu p(x,0) = δ(x−x0). Công thức cho heat kernel được áp dụng để giải phương\n",
            "trình với điều kiện này. Và chúng ta sẽ có:\n",
            "p(x, t|x0,0) =1√\n",
            "2πσ2texp\u001a\n",
            "−(x−x0)2\n",
            "2σ2t\u001b\n",
            ". (21)\n",
            "Công thức này cho biết xác suất hệ thống ở vị trí x tại thời điểm t, khi ta đã biết rằng hệ thống\n",
            "ban đầu ở vị trí x0tại thời điểm 0.\n",
            "Nói cách khác, heat kernel cho biết cách xác suất của sự di chuyển của hệ thống từ vị trí x0tại thời\n",
            "điểm 0 đến vị trí x tại thời điểm t phụ thuộc vào sự phân tán không gian và thời gian ( σ2vàt). Nó là\n",
            "một biểu thức quan trọng trong lý thuyết diffusion.\n",
            "Lưu ý: Một câu hỏi đặt ra là liệu heat kernel có được dùng để giải diffusion equation với điều kiện\n",
            "p(x,0)cụ thể hay không?. Một cách rõ ràng hơn về vai trò của heat kernel ở đây đó là:\n",
            "•Base diffusion equation : mô tả cách mật độ xác suất p(x, t)thay đổi theo thời gian và không\n",
            "gian trong diffusion process. Nó là một phương trình cơ bản trong lý thuyết xác suất và quá trình\n",
            "ngẫu nhiên.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Côngthứcheatkernel: Côngthứcheatkernelkhôngphảilàmộtcáchđểgiảidiffusionequation,\n",
            "mà là một cách biểu diễn mật độ xác suất p(x, t)tại một thời điểm t sau một khoảng thời gian\n",
            "từ điểm ban đầu có thông tin cụ thể (biểu thị bằng hàm delta dirac).\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Tại sao sử dụng heat kernel? : Heat kernel được sử dụng để biểu diễn mật độ xác suất trong\n",
            "trường hợp cụ thể khi chúng ta đã biết một điểm cụ thể mà fist step ở đó. Nó cho biết xác suất\n",
            "sẽ xuất hiện ở các vị trí khác nhau sau một khoảng thời gian t dựa trên điểm ban đầu đã biết.\n",
            "Trong bối cảnh của diffusion nó sẽ giúp làm mịn hình ảnh và mô tả sự lan truyền của dữ liệu.\n",
            "Kết luận : Về cơ bản, heat kernel không giúp giải phương trình diffusion mà là một công cụ để biểu\n",
            "diễn kết quả phương trình diffusion cho một điều kiện ban đầu cụ thể và nó có thể được sử dụng để\n",
            "tính toán xác suất của sự di chuyển của hệ thống trong không gian và thời gian.\n",
            "Cuối cùng để tính toán mật độ xác suất p(x, t)dựa trên xác suất ban đầu p0(x0)và heat kernel\n",
            "p(x, t|x0,0). Để làm điều này, chúng ta tính tích phân qua tất cả các vị trí ban đầu có thể x0bằng cách\n",
            "sử dụng heat kernel. Điều này cho phép chúng ta tính toán mật độ xác suất cuối cùng p(x, t)tại mọi\n",
            "vị trí x và thời điểm t dựa trên mật độ xác suất ban đầu p0(x0). Công thức này giúp hiểu cách mật độ\n",
            "xác suất thay đổi theo thời gian và không gian trong quá trình diffusion.\n",
            "p(x, t) =Z∞\n",
            "−∞p(x, t|x0,0)p0(x0)dx0. (22)\n",
            "Trong đó:\n",
            "•p(x, t)là mật độ xác suất của hệ thống tại vị trí x tại thời điểm t.\n",
            "•p(x, t|x0,0)là heat kernel. Cho biết xác suất di chuyển từ vị trí ban đầu x0tại thời điểm 0 đến vị\n",
            "trí x tại thời điểm t, dựa trên sự phân tán không gian và thời gian.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•p0(x0)là mật độ xác suất ban đầu tại vị trí x0tại thời điểm 0.\n",
            "14.2 Basics of stochastic differential equations (SDEs)\n",
            "Diffusion là một ví dụ đơn giản về quá trình ngẫu nhiên được điều chỉnh bởi SDE - một phương trình\n",
            "mô tả sự biến đổi của một biến ngẫu nhiên x(t) theo thời gian t có dạng:\n",
            "˙x=f(x, t) +g(x, t)η(t) (23)\n",
            "Trong đó:\n",
            "•˙xlà đạo hàm riêng theo thời gian của x(t).\n",
            "•f(x, t)là drift function, miêu tả sự biến đổi trung bình của x(t) theo thời gian.\n",
            "•g(x, t)là hàm nhiễu hoặc diffusion, miêu tả sự biến đổi ngẫu nhiên của x(t).\n",
            "•η(t)là Gaussian white noise.\n",
            "Áp dụng phương trình itô để theo dõi các biến đổi ngẫu nhiên của phương trình trên là sự hạn chế\n",
            "của quá trình rời rạc khi ta giảm bước thời gian ∆tvề 0. Với ∆trất nhỏ chúng ta miêu tả cách giá trị\n",
            "x(t)biến đổi ngẫu nhiên trong thời gian ngắn ∆tdưới tác động của biến ngẫu nhiên.\n",
            "x(t+ ∆t) =x(t) +f(x(t), t)∆t+g(x, t)√\n",
            "∆t r (24)\n",
            "Trong đó:\n",
            "•x(t+ ∆t)là giá trị của biến ngẫu nhiên x tại thời điểm t+ ∆t\n",
            "•x(t)là giá trị của biến ngẫu nhiên x tại thời điểm t.\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•f(x(t), t)∆tlà thành phần drift. Nó miêu tả cách giá trị trung bình của x(t) thay đổi theo thời\n",
            "gian t. f(x(t), t)là một hàm của x và t được sử dụng để mô tả sự thay đổi trung bình của quá\n",
            "trình.\n",
            "•g(x, t)√\n",
            "∆t rlà thành phần \"nhiễu\" hoặc diffusion. g(x, t)là một hàm x và t đo lường mức độ\n",
            "của biến ngẫu nhiên trong quá trình.√\n",
            "∆tlà căn bậc hai của ∆t, và r là một số ngẫu nhiên được\n",
            "lấy mẫu từ normal distribution ( r∼ N(0,1)).\n",
            "Công thức trên là một dạng tổng quát của Euler-Maruyama.\n",
            "Thường thì phương trình Fokker-Planck equation (FPE) khó có thể được giải một cách chính xác\n",
            "hoặc khá khó khăn để có được giải pháp chính xác cho p(x, t)(mật độ xác suất). Nên chúng ta sẽ cung\n",
            "cấp phương trình SDE cho OU process, nó mô tả cách x(t)biến đổi theo thời gian. Trong trường hợp\n",
            "một chiều, phương trình SDE có dạng:\n",
            "˙x=1\n",
            "τ[µ−x] +σr\n",
            "2\n",
            "τη(t). (25)\n",
            "Trong đó:\n",
            "•τlà tham số liên quan đến tốc độ trung bình trở về\n",
            "•µlà giá trị trung bình mà quá trình trung bình trở về\n",
            "•σlà độ lớn của biến ngẫu nhiên.\n",
            "•η(t)là white gaussian noise.\n",
            "Công thức cho p(x, t|x0,0)là một biểu thức phụ thuộc vào x, x 0, tvà miêu tả cách mật độ xác suất\n",
            "thay đổi theo thời gian cho OU process khi ta biết rằng tại t= 0đã có giá trị x0. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Công thức này là\n",
            "heat kernel của OU process.\n",
            "p(x, t|x0,0) =1p\n",
            "2πs(t)2exp\u001a\n",
            "−[x−µ(t)]2\n",
            "2s(t)2\u001b\n",
            "(26)\n",
            "Trong công thức này:\n",
            "•µ(t)là giá trị trung bình tại thời điểm t và được tính như sau:\n",
            "µ(t) :=x0e−t/τ+µ\u0010\n",
            "1−e−t/τ\u0011\n",
            "(27)\n",
            "•s(t)2là phương sai tại thời điểm t và được tính như sau:\n",
            "s(t)2:=σ2\u0010\n",
            "1−e−2t/τ\u0011\n",
            "(28)\n",
            "OU process có một đặc điểm quan trọng đó là khi thời gian tăng lên, mật độ xác suất p(x, t)ít phụ\n",
            "thuộc vào p0(x), tức là giá trị ban đầu p0(x)mất dần ảnh hưởng vào quá trình tiến đến trạng thái ổn\n",
            "định pss(x).\n",
            "p(x, t) =Z∞\n",
            "−∞p(x, t|x0,0)p0(x0)dx0. (29)\n",
            "Trong đó:\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•p(x, t)là mật độ xác suất tại thời điểm t cho OU process. Nó miêu tả xác suất mà biến x(t) có\n",
            "giá trị x tại thời điểm t, khi chúng ta đã biết mật độ xác suất ban đầu p0(x0)tạit= 0.\n",
            "•p(x, t|x0,0)là heat kernel của OU process, đã được tính toán trước đó và miêu tả cách mật độ\n",
            "xác suất thay đổi theo thời gian từ t= 0đến t khi biết rằng tại t= 0, x đã có giá trị x0.\n",
            "•p0(x0)là mật độ xác suất ban đầu tại t= 0, tức là mật độ xác suất ban đầu của biến x(t)tại\n",
            "t= 0. Nó là điều kiện ban đầu cho quá trình.\n",
            "Tích phân này có nghĩa là chúng ta đang tính toán mật độ xác suất p(x, t)bằng cách tích phân trên\n",
            "tất cả các giá trị có thể có của x0từ âm vô vùng đến dương vô cùng. Điều này có nghĩa rằng chúng ta\n",
            "xem xét mọi giá trị ban đầu có thể cho x tại t= 0(từ âm vô cùng đến dương vô cùng) và tính xác suất\n",
            "màx(t)sẽ có giá trị x tại thời điểm t sau khi đã biết mật độ xác suất ban đầu p0(x0)tạit= 0\n",
            "Tới đây chúng ta có thể thấy rằng OU process có khả năng quên dần đi điều kiên ban đầu. Khi thời\n",
            "gian t tăng lên vô cùng, heat kernel p(x, t|x0,0)của OU process tiến đến phân phối ổn định pss(x)mà\n",
            "chúng ta đã xác định trước đó.\n",
            "Điều quan trọng ở đây là p(x, t|x0,0)không còn phụ thuộc mạnh và x0khi t lớn. Nó nghĩa là dù\n",
            "ban đầu x có giá trị nào tại t= 0, khi t tăng lên đủ lớn, mật độ xác suất p(x, t)tại thời điểm t không\n",
            "còn quá phụ thuộc vào giá trị ban đầu x0. Thay vào đó, nó tiến gần đến một phân phối ổn định pss(x)\n",
            "với giá trị trung bình µvà phương sai σ2\n",
            "Ở 3 công thức trên chúng ta đã giải phương trình OU process và tính toán heat kernel tại thời điểm\n",
            "t cụ thể. Và chúng ta đã thấy cách mật độ xác suất tiền gần đến giá trị ổn định khi thời gian dài. Cuối\n",
            "cùng chúng ta nhận thấy rằng OU process có khả năng quên dần đi điều kiện ban đầu khi thời gian\n",
            "tăng lên với một số lý do.\n",
            "Trước tiên chúng ta nhắc lại công thức 12 như sau:\n",
            "dXt=θ(µ−Xt)dt+σdW t\n",
            "•Tính Chất Hồi Quy : OU process có tính chất hồi quy về giá trị trung bình dài hạn. Điều này\n",
            "có nghĩa là, không phụ thuộc vào giá trị khởi tạo, quá trình sẽ dần dần hội tụ về một giá trị trung\n",
            "bình cố định qua thời gian. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Do đó, ảnh hưởng của điều kiện ban đầu giảm dần theo thời gian. Từ\n",
            "phương trình, ta thấy rằng khi Xtlớn hơn µthìθ(µ−Xt)sẽ âm dẫn đến việc giảm Xtvề phía µ\n",
            "và ngược lại. Điều này cho thấy quá trình có tính hồi quy.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Sự Cân Bằng Giữa Xu Hướng và Nhiễu : Trong OU process, có một sự cân bằng giữa xu\n",
            "hướng hồi quy về giá trị trung bình và ảnh hưởng của nhiễu ngẫu nhiên. Khi thời gian trôi đi,\n",
            "ảnh hưởng của nhiễu ngẫu nhiên trở nên quan trọng hơn so với điều kiện ban đầu.\n",
            "•Decay Factor : Trong công thức của OU process, có một hệ số giảm dần liên quan đến thời gian,\n",
            "điều này làm cho ảnh hưởng của điều kiện ban đầu giảm đi theo cấp số nhân khi thời gian tăng\n",
            "lên. hệ số giảm dần được thể hiện thông qua θ. Giá trị lớn của θcó nghĩa là hệ số giảm dần nhanh,\n",
            "làm cho ảnh hưởng của điều kiện ban đầu giảm nhanh theo thời gian.\n",
            "•Tính Dừng : OU process là một quá trình dừng, nghĩa là các đặc trưng thống kê của nó (như kỳ\n",
            "vọng và phương sai) không thay đổi theo thời gian. Điều này giúp quá trình trở nên ít phụ thuộc\n",
            "vào điều kiện ban đầu khi thời gian tăng lên.\n",
            "14.3 More general SDEs\n",
            "Bây giờ chúng ta sẽ cùng tìm hiểu về phương trình vi phân ngẫu nhiên (SDE) đa biến và phương trình\n",
            "Fokker-Planck tương ứng. Quay trở lại với SDE, với x(t)là một vector N-chiều (x(t)∈RN)ta có:\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "˙x=f(x, t) +g(x, t)η(t) (30)\n",
            "Trong đó:\n",
            "•f(x, t)là một hàm ánh xạ vector từ x và thời gian t sang một vector trong RN\n",
            "•g(x, t)là một ma trận N×M(trong đó N là số chiều của x và M là số chiều của vector noise\n",
            "η(t)). Ma trận này phụ thuộc vào x và t.\n",
            "•η(t)là một vector M chiều của các thành phần gaussian noise độc lập\n",
            "Tiếp theo chúng ta sẽ có Euler-Maruyama đa biến với:\n",
            "x(t+ ∆t) =x(t) +f(x(t), t)∆t+g(x(t), t)√\n",
            "∆tr (31)\n",
            "Trong đó r là một vector r= (r1, ..., r M)Tvới mỗi thành phần riđược lấy mẫu từ phân phối chuẩn.\n",
            "Công thức Fokker-Planck cho phương trình SDE đa biến có dạng:\n",
            "∂p(x, t)\n",
            "∂t=NX\n",
            "j=1−∂\n",
            "∂xj[fj(x, t)p(x, t) ] +NX\n",
            "j=1NX\n",
            "k=1∂2\n",
            "∂xj∂xk[Djk(x, t)p(x, t) ] (32)\n",
            "Trong đó:\n",
            "•D(x, t)là một ma trận N×Ngọi là \"diffusion tensor\". Các phần tử của ma trận này được tính\n",
            "như sau:\n",
            "Djk(x, t) =1\n",
            "2MX\n",
            "ℓ=1σjℓ(x, t)σkℓ(x, t).\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•σjℓ(x, t)là các phần tử của ma trận g(x, t). Ma trận này chứa thông tin về biến đổi của mỗi thành\n",
            "phần của x do nhiễu.\n",
            "Cuối cùng, chúng ta sẽ tập trung vào trường hợp đơn giản hơn trong đó g(x, t)không còn là một\n",
            "ma trận N×Mmà chỉ là một hàm số g(x, t)vàM=N(tức số chiều của nhiễu và số chiều của x bằng\n",
            "nhau). Điều này đồng nghĩa với việc mỗi chiều của x có nhiễu riêng của nó (không có sự kết nối) và tất\n",
            "cả các nhiễu có cùng độ lớn g(x,t).\n",
            "Phương trình Fokker-Planck đơn giản lại như sau:\n",
            "∂p(x, t)\n",
            "∂t=−∇ · [f(x, t)p(x, t) ] +∇2\u0014g(x, t)2\n",
            "2p(x, t)\u0015\n",
            "=−∇ ·\u0014\n",
            "f(x, t)p(x, t)− ∇\u0012g(x, t)2\n",
            "2p(x, t)\u0013 \u0015\n",
            ".(33)\n",
            "14.4 What SDEs should we use to corrupt samples\n",
            "Ở phần này chúng ta sẽ thảo luận về việc lựa chọn stochastics process để biến đổi mẫu từ một phân\n",
            "phối cố định sang mẫu từ phân phối mục tiêu.\n",
            "Chúng ta có 3 lưu ý cần xem xét:\n",
            "•Mục tiêu là tìm một quá trình ngẫu nhiên đơn giản đủ để tính toán mật độ xác suất p(t)một\n",
            "cách chính xác khi t đủ lớn. Điều này quan trọng vì quá trình ngược (reverse diffusion) sẽ chuyển\n",
            "chúng ta từ p(x, t)về phân phối mục tiêu. Khi chúng ta biết phân phối p(x, t)sau một thời gian\n",
            "đủ lớn, chúng ta biết cách lấy mẫu từ phân phối này để tạo ra các mẫu reverse diffusion từ phân\n",
            "phối mục tiêu.\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Mục tiêu là làm cho p(x, t)(với t đủ lớn) trở thành một phân phối dễ lấy mẫu (ví dụ: phân phối\n",
            "gauss). Điều này làm cho việc tạo ra các mẫu reverse diffusion từ p(x,t) trở nên dễ dàng.\n",
            "•Chúng ta muốn mẫu bị biến đổi mạnh, tức là không còn dấu vết của mẫu ban đầu. Điều này đòi\n",
            "hỏi việc chúng ta phải đưa rất nhiều nhiễu vào các mẫu. Điều này có thể đạt được thông qua việc\n",
            "sử dụng hệ số nhiễu lớn hoặc thông qua việc biến đổi trong một khoảng thời gian rất dài. Tuy\n",
            "nhiên, việc định nghĩa \"lớn\" khác nhau cho từng tập dữ liệu. Vì vậy, để tránh phải điều chỉnh\n",
            "tham số nhiễu một cách thủ công sau khi nhận thấy rằng chúng ta chưa làm cho mẫu bị biến đổi\n",
            "đủ \"nhiều\", một giải pháp là sử dụng nhiễu tăng lên theo cấp số mũ (exponential) theo thời gian.\n",
            "Như vậy chúng ta sẽ có đủ nhiễu.\n",
            "Việc lựa chọn stochastics process:\n",
            "•Cần loại bỏ quá trình ngẫu nhiên tiềm năng vì hầu hết các phương trình Fokker-Planck không\n",
            "thể được giải chính xác. Các quá trình được mô tả ở trên đã được đưa qua quá trình biến đổi\n",
            "ngẫu nhiên và OU process.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Cả hai quá trình biến đổi ở trong thời gian dài (long time limit), chuyển đổi mẫu thành các mẫu\n",
            "từ phân phối gauss. Việc này đảm bảo rằng p(x, t)(với t đủ lớn) trở thành một phân phối dễ lấy\n",
            "mẫu. (có thể lấy mẫu từ phân phối gauss)\n",
            "14.5 Variance Exploding SDE (VE SDE)\n",
            "Phần này chúng ta sẽ tìm hiểu về Variance Exploding (VE) trong SDE và cách xây dựng phân phối\n",
            "chuyển đổi (transition probability) tương ứng.\n",
            "Phương trình SDE cho VE được xác định bởi:\n",
            "˙x=r\n",
            "d[σ2(t)]\n",
            "dtη(t) (34)\n",
            "Vớiσ2(t)là một hàm tăng dần và x(t)thuộc không gian RN. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Phương trình này mô tả một quá trình\n",
            "nhiễu trong đó mức độ nhiễu tăng lên theo thời gian.\n",
            "Phân phối chuyển đổi cho quá trình VE mô tả xác suất của VE khi thời gian tiến đến t, dựa trên\n",
            "giá trị ban đầu x0tạit= 0. Và sau đó công thức được phân rã thành tích của N phân phối Gauss 1D.\n",
            "p(x, t|x(0),0) =1\n",
            "hp\n",
            "2πσ2(t)iNexp(\n",
            "−\u0002\n",
            "x−x(0)\u00032\n",
            "2σ2(t))\n",
            "=NY\n",
            "j=11p\n",
            "2πσ2(t)exp\n",
            "\n",
            "−h\n",
            "xj−x(0)\n",
            "ji2\n",
            "2σ2(t)\n",
            "\n",
            ".(35)\n",
            "Hàm σ2(t)quyết định cách biến thiên của mức độ nhiễu theo thời gian. Để tăng quá trình diffusion\n",
            "chúng ta có thể để cho quá trình nhiễu tăng theo cấp số mũ:\n",
            "σ2(t) :=σ2\n",
            "min\u0012σ2\n",
            "max\n",
            "σ2\n",
            "min\u0013t/T\n",
            "=σ2\n",
            "minexp\u001at\n",
            "Tlog\u0012σ2\n",
            "max\n",
            "σ2\n",
            "min\u0013\u001b\n",
            "(36)\n",
            "Trong đó T là thời gian chúng ta áp dụng quá trình nhiễu trên các mẫu. Điều quan trọng không\n",
            "phải là việc đặt tham số mà là việc hàm σ2(t)tăng theo cấp số mũ theo thời gian. Điều này sẽ giúp cho\n",
            "sự biến đổi mạnh hơn theo thời gian.\n",
            "18\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "14.6 Variance Preserving SDE (VP SDE)\n",
            "Ở phần này chúng ta sẽ tìm hiểu về Variance Preserving (VP) trong SDE.\n",
            "Phương trình SDE cho VP được định nghĩa bởi:\n",
            "˙x=−β(t)\n",
            "2x+p\n",
            "β(t)η(t) (37)\n",
            "Trong đó, β(t)là một hàm tăng dần và x(t)thuộc không gian RN. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Phương trình này mô tả một\n",
            "quá trình nhiễu trong đó mức độ nhiễu để duy trì phương sai ban đầu.\n",
            "Phân phối chuyển đổi p(x, t|x0,0)VP cho biết xác suất để quá trình nhiễu đang tiến đến một giá\n",
            "trị x tại thời điểm t dựa trên giá trị ban đầu x0tại thời điểm t= 0\n",
            "p(x, t|x(0),0) =1\n",
            "hp\n",
            "2πσ2(t)iNexp(\n",
            "−[x−µ(t)]2\n",
            "2σ2(t))\n",
            "=NY\n",
            "j=11p\n",
            "2πσ2(t)exp(\n",
            "−[xj−µj(t)]2\n",
            "2σ2(t)) (38)\n",
            "Với\n",
            "µ(t) :=x(0)e−1\n",
            "2Rt\n",
            "0β(s)ds\n",
            "σ2(t) := 1 −e−Rt\n",
            "0β(s)ds.(39)\n",
            "Trong đó\n",
            "•x là một vector N chiều, biểu thị tọa độ của quá trình nhiễu tại thời điểm t.\n",
            "•x(0)là giá trị ban đầu của quá trình nhiễu tại t= 0\n",
            "•t là thời gian của quá trình nhiễu.\n",
            "Biểu thức này dựa trên phân phối gauss và có thể được chia thành N phần độc lập, mỗi thành phần\n",
            "biểu thị một chiều của vector x.\n",
            "•Mẫu từng chiều xjcủa vector x (với j từ 1 đến N) được mô tả bằng một phân phối gauss 1D với\n",
            "giá trị trung bình µj(t)và phương sai σ2(t).\n",
            "•µj(t)là giá trị trung bình tại thời điểm t cho chiều thứ j của vector x. Nó được tính bằng cách\n",
            "áp dụng một hàm mũ giảm dần của thời gian lên giá trị ban đầu x(0)tại t=0.\n",
            "•σ2(t)là phương sai tại thời điểm t cho chiều thứ j của vector x. Nó giảm dần theo thời gian, làm\n",
            "cho mức độ nhiễu trong quá trình nhiễu giảm dần dến khi đạt giá trị ổn định (steady-state).\n",
            "Tổng cộng, biểu thức này giúp xác định các chiều riêng lẻ của quá trình nhiễu biến đổi và tương\n",
            "tác với thời gian. Khi thời gian tiến đến đủ lâu (t tiến đến vô cùng), phân phối sẽ hội tụ đến một phân\n",
            "phối gauss tiêu chuẩn với trung bình 0 và phương sai 1 độc lập cho mỗi chiều.\n",
            "p(x, t)t→∞− − − → pss(x) =1\n",
            "\u0002√\n",
            "2π\u0003Nexp\u001a\n",
            "−x2\n",
            "2\u001b\n",
            "=NY\n",
            "j=11√\n",
            "2πexp(\n",
            "−x2\n",
            "j\n",
            "2)\n",
            "(40)\n",
            "19\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Còn một điểm chú ý nữa là hàm β(t)quyết định cách biến đổi của mức độ nhiễu theo thời gian.\n",
            "Bên cạnh việc tăng nhiễu theo cấp số mũ, hàm này có thể được chọn để tăng một cách tuyến tính:\n",
            "β(t) :=βmin+ (βmax−βmin)t\n",
            "T(41)\n",
            "Trong đó T là thời gian áp dụng quá trình nhiễu trên các mẫu. Điều quan trọng là β(t)tăng tuyến\n",
            "tính thay vì tăng mũ theo thời gian. Điều này đảm bảo rằng cuối cùng, mức độ nhiễu không giảm và\n",
            "làm cho sự biến đổi được duy trì.\n",
            "Bên cạnh đó chúng ta còn có phương trình sub-VP tương tự VP như sau:\n",
            "˙x=−β(t)\n",
            "2x+r\n",
            "β(t)h\n",
            "1−e−2Rt\n",
            "0β(s)dsi\n",
            "η(t) (42)\n",
            "15 Reverse diffusion\n",
            "15.1 Reversing 1D diffusion\n",
            "Trước tiên chúng ta sẽ tìm hiểu về reverse 1D. Ở phần trước quá trình forward chúng ta thấy rằng\n",
            "diffusion khiến noise được khuếch tán dần ra (theo thời gian) và làm thay đổi mẫu ban đầu. Tại đây\n",
            "chúng ta sẽ kỳ vọng reverse lại quá trình diffusion thì mẫu của chúng ta sẽ trở về như cũ.\n",
            "˙x=x0−x\n",
            "T−t+σ η(t) (43)\n",
            "Công thức trên (OU process) phản ảnh một quá trình trong đó biến ngẫu nhiên xtiếp tục được tái\n",
            "tạo về một giá trị x0theo thời gian. Thành phầnx0−x\n",
            "T−ttạo ra sự hồi phục về giá trị x0, vàσ η(t)thêm\n",
            "nhiễu để tạo sự biến động ngẫu nhiên.\n",
            "Nói cách khác, quá trình trên nén một Gaussian cho đến khi nó trở thành Delta Dirac Function với\n",
            "centered x0tạ thời điểm T. Đây cũng là một xác suất chuyển đổi (transition probability) của quá trình\n",
            "reverse.\n",
            "q(x, t|x0,0) =1p\n",
            "2πσ2(T−t)exp\u001a\n",
            "−(x−x0)2\n",
            "2σ2(T−t)\u001b\n",
            ". (44)\n",
            "Trong đó xác suất chuyển đổi q(x, t|x0,0)là xác suất để OU process chuyển từ giá trị ban đầu x0\n",
            "tại thời điểm 0 đến giá trị xtại thời điểm t- được định nghĩa bởi hàm Gaussian, xác suất chuyển đổi\n",
            "giảm theo thời gian và tập trung xung quanh giá trị x0. Điều này phản ánh khả năng của quá trình\n",
            "OU hồi phục về trung bình và giảm thiểu biến động ngẫu nhiên theo thời gian.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Note: Ký hiệu q là để tránh nhầm lẫn với quá trình forward diffusion (p).\n",
            "Vì Reverse process được điều chỉnh bởi SDE nên chúng ta sẽ áp dụng Eurler-Maruyama để biểu\n",
            "diễn nó.\n",
            "x(t+ ∆t) =x(t) +x0−x\n",
            "T−t∆t+σ√\n",
            "∆t r . (45)\n",
            "Trong đó Euler-Maruyama x(t+ ∆t) =x(t) +x0−x\n",
            "T−t∆t+σ√\n",
            "∆t rmô phỏng cách mỗi bước thời gian,\n",
            "giá trị xthay đổi. Thành phần tái tạox0−x\n",
            "T−t∆tđảm bảo rằng giá trị xhồi phục về x0dần dần theo thời\n",
            "gian. Nhiễu σ√\n",
            "∆t rtăng cường biến động ngẫu nhiên, thể hiện sự không chắc chắn trong quá trình\n",
            "reverse.\n",
            "Tóm lại, OU process và xác suất chuyển đổi giúp mô tả các quá trình trong đó các giá trị có xu\n",
            "hướng hồi phục về giá trị trung bình với biến động ngẫu nhiên. Các bước Euler-Maruyama được sử\n",
            "dụng để mô phỏng số liệu và thu thập thông tin về quá trình reverse.\n",
            "20\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "15.2 Reversing more general stochastic processes\n",
            "Ta có Forward process được mô tả bời SDE\n",
            "˙x=f(x, t) +g(t)η(t)\n",
            "Trong đó f(x, t)là drift function, g(t)là thành phần nhiễu và η(t)là white noise (gauss).\n",
            "Với Reverse process chúng ta sẽ đảo ngược thời gian được tạo ra cho Forward process từ thời điểm\n",
            "t= 0đếnt=T. Time-reversed SDE được định nghĩa:\n",
            "˙x=−f(x, T−t) +g(T−t)2∂\n",
            "∂xlogp(x, T−t) +g(T−t)η(t). (46)\n",
            "Tại đây chúng ta tìm hiểu một chút về mối quan hệ giữa forward process và reversed process. Nếu\n",
            "p(x, t)đại diện cho phân phối xác suất của forward process tại thời điểm t, thì q(x, t)là phân phối xác\n",
            "suất của reverse process thỏa mãn q(x, t) =p(x, T−t). Mối quan hệ này có nghĩa là phân phối xác suất\n",
            "tiến triển theo thời gian theo một cách tương tự. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Chỉ là hai hướng ngược nhau.\n",
            "Mở rộng sang N-dim Ito-interpreted SDEs bao gồm một vector x và vector noise η(t). Reversed\n",
            "process cho N-dim có dạng:\n",
            "˙x=−f(x, T−t) +g(T−t)2∇xlogp(x, T−t) +g(T−t)η(t). (47)\n",
            "Phần này chúng ta đã xác định reversed process của một stochastics process do một loại phương\n",
            "trình vi phân ngẫu nhiên điều khiển.\n",
            "Bây giờ chúng ta sẽ chứng minh mối quan hệ giữa forward và reverse process trên:\n",
            "q(x, t) =p(x, T−t)\n",
            "Áp dụng kiến thức về lý thuyết xác suất vào phương trình Fokker-Planck (FPE). Ta có Forward\n",
            "process được xác định bởi:\n",
            "∂p(x, t)\n",
            "∂t=−∇ · [f(x, t)p(x, t) ] +∇2\u0014g(x, t)2\n",
            "2p(x, t)\u0015\n",
            "=−∇ ·\u0014\n",
            "f(x, t)p(x, t)− ∇\u0012g(x, t)2\n",
            "2p(x, t)\u0013 \u0015\n",
            ".(48)\n",
            "Giả sử p(x, t)là phân phối xác suất của forward process với điều kiện ban đầu p(x,0) = p0(x). Xác\n",
            "định FPE cho reversed process bằng cách thay t bằng T−ttrong FPE cho forward process.\n",
            "∂q(x, t)\n",
            "∂t=−∇ ·\u0014\n",
            "f(x, T−t)q(x, t)− ∇\u0012g(x, T−t)2\n",
            "2q(x, t)\u0013 \u0015\n",
            "(49)\n",
            "Điều này giống với FPE cho forward process, chỉ là chúng ta thay đổi thời gian từ tthành T−t. Vì\n",
            "p(x,0) = p0(x), giả sử rằng q(x, T)sẽ là phân phối xác suất của quá trình đảo ngược.\n",
            "Để xác định mối quan hệ này chính xác, cần áp dụng điều kiện biên phù hợp cho q(x, t)tạit=T.\n",
            "Điều này có thể được thực hiện thông qua điều kiện biên hoặc điều kiện khởi tạo phù hợp.\n",
            "Dựa vào đối số điều kiện biên và điều kiện khởi tạo, có thể chứng minh được mối quan hệ trên. (Để\n",
            "chứng minh cụ thể hơn còn phải phụ thuộc vào chi tiết bài toán cụ thể).\n",
            "21\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "15.3 Score functions\n",
            "Score function là một khái niệm quan trọng trong reverse process. Được định nghĩa như sau:\n",
            "s(x, t) :=∇xp(x, t). (50)\n",
            "Trong đó s(x, t)là score function, một vector được tính bằng đạo hàm gradient của p(x, t)theo x.\n",
            "Vai trò của Score function:\n",
            "•Khi ta muốn thực thi reverse process trên một nhiễu nào đó và chuyển đổi nó thành một mẫu từ\n",
            "phân phối mục tiêu (target distribution).\n",
            "•Tuy nhiên, vấn đề chính trong phương pháp này là chúng ta không biết chính xác giá trị của\n",
            "p(x,t). Nếu chúng ta biết, chúng ta có thể lấy mẫu trực tiếp từ nó thay vì thực hiện quá trình\n",
            "reverse.\n",
            "Tuy chúng ta không biết p(x, t)nhưng chúng ta có thể học được score function. Quan trọng hơn,\n",
            "việc học score function thậm chí là dễ hơn so với việc học trực tiếp p(x, t), vì nhiệm vụ này yêu cầu học\n",
            "một normalization factor => đây là một điều tương đối khó khăn.\n",
            "15.4 Examples of score functions\n",
            "Score function liên kết một vector field với mỗi time step của stochastics process. Mỗi vector chỉ hướng\n",
            "xác suất tăng dần.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "15.4.1 1D diffusion from a point mass\n",
            "Xét quá trình 1D diffusion với điều kiện ban đầu là Delta Function tại x0. Nói cách khác, ta xem xét\n",
            "sự lan truyền của một phân phối Delta tại x0theo thời gian.\n",
            "1D Diffusion with Delta Function Initial Condition\n",
            "p(x, t) =1√\n",
            "2πσ2texp\u001a\n",
            "−(x−x0)2\n",
            "2σ2t\u001b\n",
            ". (51)\n",
            "Trong đó:\n",
            "•p(x, t)là xác suất phân phối tại vị trí x và thời điểm t cho quá trình 1D diffusion.\n",
            "•x0là vị trí ban đầu của Delta Function.\n",
            "•σlà tham số đặc trưng cho độ rộng của phân phối.\n",
            "Score Function for the 1D Diffusion\n",
            "s(x, t) =∂\n",
            "∂xlogp(x, t) =−(x−x0)\n",
            "σ2t. (52)\n",
            "Trong đó:\n",
            "•s(x, t)là score function cho quá trình 1D diffusion, được tính bằng cách lấy đạo hàm riêng theo\n",
            "x của logarithm của p(x,t).\n",
            "•Score function mô tả sự thay đổi của logarithm của phân phôí theo x tại mỗi điểm x và thời điểm\n",
            "t.\n",
            "•Trong trường hợp này, score function cho biết càng xa khỏi vị trí x0càng có trị tuyệt đối lớn hơn,\n",
            "với độ rộng của phân phối σvà thời gian tlàm mẫu số. Điều này phản ánh sự lan truyền rộng và\n",
            "chậm của phân phối trong thời gian.\n",
            "22\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "15.4.2 1D OU process from a point mass\n",
            "Trong 1D OU process với điều kiện ban đầu là Delta function tại x0.\n",
            "1D OU Process with Delta Function Initial Condition\n",
            "p(x, t) =1p\n",
            "2πs(t)2exp\u001a\n",
            "−[x−µ(t)]2\n",
            "2s(t)2\u001b\n",
            ". (53)\n",
            "Trong đó:\n",
            "•p(x, t)là xác suất phân phối tại xvà thời điểm tcho 1D OU process.\n",
            "•x0là vị trí ban đầu của Delta Function.\n",
            "•µ(t)vàs(t)là giá trị kỳ vọng và độ lệch chuẩn của OU process tại thời điểm t.\n",
            "Score Function for the 1D OU Process\n",
            "s(x, t) =∂\n",
            "∂xlogp(x, t) =−[x−µ(t)]\n",
            "s(t)2. (54)\n",
            "Trong đó:\n",
            "•s(x, t)là score function cho 1D OU process, được tính bằng cách lấy đạo hàm riêng theo x của\n",
            "logarithm của p(x, t).\n",
            "•Score function mô tả sự thay đổi của logarithm của phân phối theo x tại mỗi điểm x và thời điểm\n",
            "t.\n",
            "•Trong trường hợp này, score function cho biết càng xa khỏi giá trị kỳ vọng µ(t), càng có giá trị\n",
            "tuyệt đối lớn hơn, với độ lệch chuẩn s(t)làm mẫu số. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Điều này phản ánh tính chất của OU process,\n",
            "nơi xác suất của sự biến động ngẫu nhiên tăng lên khi x cách xa giá trị kỳ vọng.\n",
            "15.4.3 1D diffusion from a Gaussian mixture\n",
            "Ta có 1D Gaussian mixture với M mixture components:\n",
            "p0(x) =MX\n",
            "j=1wj1q\n",
            "2πs2\n",
            "jexp(\n",
            "−[x−µj]2\n",
            "2s2\n",
            "j)\n",
            "(55)\n",
            "Xác Suất Sau Quá Trình Diffusion\n",
            "p(x, t) =Z∞\n",
            "−∞p(x, t|x0,0)p0(x0)dx0\n",
            "=MX\n",
            "j=1wj1q\n",
            "2π(s2\n",
            "j+σ2t)exp(\n",
            "−[x−µj]2\n",
            "2(s2\n",
            "j+σ2t))\n",
            ".(56)\n",
            "Trong đó:\n",
            "•p(x, t)là xác suất phân phối tại vị trí x và thời điểm t sau quá trình diffusion từ điều kiện ban\n",
            "đầu là hỗn hợp Gaussian p0(x0).\n",
            "•Đoạn tích phân trên là tích phân qua tất cả các điều kiện ban đầu có thể, mỗi điều kiện ban đầu\n",
            "được đánh trọng số bởi p0(x0).\n",
            "23\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Kết quả là một tổng của các Gaussian với trung bình µjvà độ lệch chuẩn s2\n",
            "j+σ2t.\n",
            "Score Function Tương Ứng\n",
            "s(x) =∂\n",
            "∂xlogp(x, t) =−1\n",
            "p(x, t)MX\n",
            "j=1wj(x−µj)\n",
            "s2\n",
            "j+σ2t1q\n",
            "2π(s2\n",
            "j+σ2t)exp(\n",
            "−[x−µj]2\n",
            "2(s2\n",
            "j+σ2t))\n",
            ".(57)\n",
            "Trong đó:\n",
            "•s(x)là score function, là đạo hàm riêng theo xcủa logarit của xác suất p(x, t).\n",
            "•Tổ hợp của các thành phần của s(x)là tổng trọng số của các đạo hàm riêng theo x của các thành\n",
            "phần Gaussian trong mixture.\n",
            "•Score function thường được sử dụng trong các mô hình generative để học xác suất và tạo dữ liệu\n",
            "mới\n",
            "15.5 Learning the score function\n",
            "Bây giờ chúng ta sẽ thử ước lượng tham số θcủa score function sθ(x, t)trong bối cảnh của mô hình\n",
            "generative.\n",
            "Hàm Mục Tiêu Ban Đầu\n",
            "J(θ)?:=1\n",
            "2Z\n",
            "dxdt[sθ(x, t)− ∇ xlogp(x, t)]2. (58)\n",
            "Trong đó:\n",
            "•J(θ)là hàm mục tiêu ban đầu dựa trên việc so sánh score function xấp xỉ sθ(x, t)với đạo hàm\n",
            "của log xác suất p(x, t)theo x\n",
            "•Tuy nhiên, hàm này không ưu tiên bất kỳ giá trị cụ thể nào của x hơn các giá trị khác.\n",
            "Để giải quyết điều này chúng ta cần một sự điều chỉnh nhỏ là:\n",
            "J(θ)?:=1\n",
            "2Z\n",
            "dxdt p(x, t) [sθ(x, t)− ∇ xlogp(x, t)]2. (59)\n",
            "Trong đó:\n",
            "•Trọng số p(x, t)giúp ưu tiên việc xấp xỉ score function cho các giá trị x mà có xác suất cao.\n",
            "•Tuy nhiên, việc ước lượng đạo hàm của logp(x, t)có thể khó khăn do phụ thuộc mạnh mẽ vào\n",
            "p(x,0)(xác suất ban đầu).\n",
            "Thêm Trọng Số Theo Thời Gian\n",
            "Jnaive(θ) :=1\n",
            "2Z\n",
            "dxdt λ(t)p(x, t) [sθ(x, t)− ∇ xlogp(x, t)]2. (60)\n",
            "Trọng số thời gian λ(t)được thêm vào để có thể xử lý sự thay đổi về quy mô của độ lệch từ score\n",
            "function chính xác. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trọng số này giúp xử lý việc quy mô của độ lệch có thể thay đổi theo thời gian.\n",
            "Vấn Đề với Hàm Mục Tiêu Điều Chỉnh\n",
            "•Khó khăn trong việc ước lượng đạo hàm của logp(x, t)do phụ thuộc mạnh mẽ vào p(x,0).\n",
            "24\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Không biết phân phối mục tiêu, điều này là lý do chính trong quá trình học của model.\n",
            "Giải Pháp: Hàm Mục Tiêu Thay Thế Một hàm mục tiêu thay thế được giới thiệu để giải quyết\n",
            "vấn đề ước lượng đạo hàm với việc sử dụng xác suất chuyển tiếp p(x, t|x(0),0)để giảm khả năng khó\n",
            "khăn trong việc ước lượng đạo hàm của logp(x, t).\n",
            "Hàm mục tiêu mới là:\n",
            "Jmod(θ) :=1\n",
            "2Z\n",
            "dxdx(0)dt p(x, t|x(0),0)p(x(0))h\n",
            "sθ(x, t)− ∇ xlogp(x, t|x(0),0)i2\n",
            ".(61)\n",
            "Điều này dẫn đến hai hàm mục tiêu là giống nhau, tính theo θvới một hằng số cộng.\n",
            "Sau đây là quá trình tính đạo hàm của hai hàm naive và mod theo bộ tham số θ.\n",
            "∇θJnaive(θ) =Z\n",
            "dxdt p(x, t) [sθ(x, t)− ∇ xlogp(x, t)]· ∇θsθ(x, t)\n",
            "=Z\n",
            "dxdt p(x, t)\u0014\n",
            "sθ(x, t)−∇xp(x, t)\n",
            "p(x, t)\u0015\n",
            "· ∇θsθ(x, t)\n",
            "=Z\n",
            "dxdt[p(x, t)sθ(x, t)− ∇ xp(x, t) ]· ∇θsθ(x, t)\n",
            "=Z\n",
            "dxdx(0)dt p(x(0))h\n",
            "p(x, t|x(0),0)sθ(x, t)− ∇ xp(x, t|x(0),0)i\n",
            "· ∇θsθ(x, t)\n",
            "=Z\n",
            "dxdx(0)dt p(x, t|x(0),0)p(x(0))h\n",
            "sθ(x, t)− ∇ xlogp(x, t|x(0),0)i\n",
            "· ∇θsθ(x, t)(62)\n",
            "∇θJmod(θ) =Z\n",
            "dxdx(0)dt p(x, t|x(0),0)p(x(0))h\n",
            "sθ(x, t)− ∇ xlogp(x, t|x(0),0)i\n",
            "· ∇θsθ(x, t).(63)\n",
            "Đạo hàm của Jmod(θ)được tính tương tự như Jnaive(θ)nhưng sử dụng xác suất chuyển tiếp có điều\n",
            "kiệnp(x, t|x(0),0)thay vì xác suất p(x, t). Cuối cùng biểu thức cho cả hai đạo hàm là giống nhau, chỉ\n",
            "khác nhau ở một hằng số cộng.\n",
            "Việc xây dựng hàm mục tiêu J(θ)để tối ưu hóa trong bối cảnh ước lượng đạo hàm của xác suất\n",
            "chuyển tiếp.\n",
            "J(θ) :=1\n",
            "2Z\n",
            "dxdx(0)dt p(x, t|x(0),0)p(x(0))h\n",
            "sθ(x, t)− ∇ xlogp(x, t|x(0),0)i2\n",
            "=1\n",
            "2Etn\n",
            "λ(t)Ex(0)Ex|x(0)h\n",
            "∥sθ(x, t)− ∇ xlogp(x, t|x(0),0)∥2\n",
            "2i o\n",
            ".(64)\n",
            "Trong đó:\n",
            "•Hàm mục tiêu J(θ)là một hàm của bộ tham số θ.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Nó bao gồm một phần tích phân trên không gian x và x(0)cũng như qua thời gian t.\n",
            "•p(x, t|x(0),0)là xác suất chuyển tiếp có điều kiện, p(x(0))là xác suất ban đầu, và sθ(x, t)là hàm\n",
            "điểm số được tham số hóa.\n",
            "Giải thích biểu thức:\n",
            "•Phần đầu của J(θ)tính tổng trung bình của bình phương sự chênh lệch giữa score function thực\n",
            "tế và đạo hàm của log xác suất chuyển tiếp có điều kiện theo x(0).\n",
            "25\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Phần thứ hai của J(θ)diễn giải lại phần đầu với kỳ vọng theo thời gian t và các kỳ vọng xác suất\n",
            "ban đầu và xác suất chuyển tiếp có điều kiện theo x(0)và x.\n",
            "Chúng ta có một số chú ý sau:\n",
            "•Elà ký hiệu cho kỳ vọng theo thời gian t và Ex(0)vàEx|x(0)là ký hiệu cho kỳ vọng theo xác suất\n",
            "ban đầu và xác suất chuyển tiếp có điều kiện.\n",
            "•λ(t)là một hệ số trọng số có thể thay đổi theo thời gian, giúp điều chỉnh độ quan trọng của các\n",
            "khoảng thời gian khác nhau trong việc ước lượng gradient.\n",
            "•||.||2là norm L2và∥sθ(x, t)−∇ xlogp(x, t|x(0),0)∥2\n",
            "2là bình phương của khoảng cách giữa hai\n",
            "vector.\n",
            "•Việc sử dụng đạo hàm của log xác xuất chuyển tiếp có điều kiện thay vì xác suất chuyển tiếp trực\n",
            "tiếp giúp giảm độ phức tạp khi tính đạo hàm.\n",
            "15.6 Approximating the objective function using samples\n",
            "Để tính xấp xỉ cho objective function chúng ta sử dụng kỳ vọng và Monte Carlo.\n",
            "•Khi hàm mục tiêu được viết dưới dạng kỳ vọng, nó gợi ý về một chiến lược rõ ràng để xấp xỉ nó\n",
            "bằng cách sử dụng mẫu (Monte Carlo).\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Đưa ra một mẫu x(0)từ phân phối mục tiêu.\n",
            "Các bước xấp xỉ:\n",
            "•Lấy một mẫu thời gian t theo phân phối đồng đều từ khoảng [0, T].\n",
            "•Sử dụng kiến thức về xác suất chuyển tiếp để lấy mẫu x gần bằng với xác suất p(x, t|x(0),0)\n",
            "•Sử dụng kiến thức về xác suất chuyển tiếp để đánh giá ∇xlogp(x, t|x(0),0)\n",
            "Ta có Approximating the objective function:\n",
            "J(θ)≈1\n",
            "2λ(t)h\n",
            "sθ(x, t)− ∇ xlogp(x, t|x(0),0)i2\n",
            ". (65)\n",
            "Nếu có một Batch S, ta có thể xấp xỉ hàm mục tiêu bằng cách lặp lại quy trình với mỗi mẫu và xây\n",
            "dựng hàm xấp xỉ như sau:\n",
            "J(θ)≈1\n",
            "2SSX\n",
            "j=1λ(tj)h\n",
            "sθ(xj, tj)− ∇ xlogp(xj, t|x(0)\n",
            "j,0)i2\n",
            ". (66)\n",
            "Trong trường hợp cụ thể của quá trình ngẫu nhiên, log xác suất chuyển tiếp (transition probability)\n",
            "có dạng đơn giản, giúp giảm độ phức tạp khi tính toán đạo hàm.\n",
            "p(x, t|x(0),0) =1\n",
            "hp\n",
            "2πσ2(t)iNexp(\n",
            "−\u0002\n",
            "x−x(0)\u00032\n",
            "2σ2(t))\n",
            ", (67)\n",
            "∇xlogp(x, t|x(0),0) =−\u0002\n",
            "x−x(0)\u0003\n",
            "σ2(t).\n",
            "- Hết -\n",
            "26\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 8 tháng 4 năm 2024\n",
            "Basic Python - Work with SQLite Database\n",
            "Hoàng-Nguyên Vũ\n",
            "1.Mô tả: Làm quen với Cơ sở dữ liệu SQLite\n",
            "•SQLite là một hệ quản trị cơ sở dữ liệu hay còn gọi là hệ thống cơ sở dữ liệu\n",
            "quan hệ nhỏ gọn, khác với các hệ quản trị khác như MySQL, SQL Server, Ocr-\n",
            "acle, PostgreSQL... SQLite là một thư viện phần mềm mà triển khai một SQL\n",
            "Database Engine truyền thống, không cần mô hình client-server nên rất nhỏ gọn.\n",
            "SQLite được sử dụng vào rất nhiều chương trình từ desktop đến mobile hay là\n",
            "website..\n",
            "•Ngoài những lý do trên thì không thể không kể đến những ưu điểm khi sử dụng\n",
            "SQLite, sau đây là phần ưu điểm của SQLite. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ưu điểm của SQLite:\n",
            "– Nhẹ và dễ sử dụng: SQLite không yêu cầu cài đặt máy chủ riêng biệt và\n",
            "có thể được nhúng trực tiếp vào ứng dụng Python của bạn.\n",
            "– Hiệu suất cao: SQLite cung cấp hiệu suất truy vấn nhanh và có thể xử lý\n",
            "lượng dữ liệu lớn.\n",
            "– Đa nền tảng: SQLite có sẵn trên hầu hết các nền tảng, bao gồm Windows,\n",
            "MacOS, Linux và Android.\n",
            "– Miễn phí và mã nguồn mở: SQLite là phần mềm miễn phí và mã nguồn\n",
            "mở, có nghĩa là bạn có thể sử dụng và sửa đổi nó cho mục đích của riêng bạn.\n",
            "2.Làm quen với các câu lệnh SQL trong SQLite Database:\n",
            "- Ví dụ chúng ta cần quản lý thông tin khách hàng gồm các trường dữ liệu cơ bản như\n",
            "sau:\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 8 tháng 4 năm 2024\n",
            "Bảng 1: Bảng quản lý thông tin của khách hàng\n",
            "CUSTOMER\n",
            "Email Name Phone\n",
            "Phân tích sơ lược, chúng ta dễ thấy mỗi khách hàng chỉ có duy nhất 1 email, nên email\n",
            "sẽ đóng vai trò là khóa chính, nhằm dễ xác định thông tin của một khách hàng trong\n",
            "hệ thống. Để quản lý các thông tin trên và và truy vấn chúng ta sẽ có những thao\n",
            "tác chính như sau: Tạo bảng (CREATE TABLE) , lấy dữ liệu từ bảng (SELECT) ,\n",
            "thêm mới dữ liệu (INSERT) , cập nhật dữ liệu (UPDATE) , xóa dữ liệu (DELETE) .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "+Tạo bảng mới (CREATE TABLE): Để tạo bảng trên ta sẽ sử dụng như sau:\n",
            "1-- Tạo Bảng CUSTOMERS gồm 3 cột email, name, phone với email là\n",
            "khóa chính\n",
            "2CREATE TABLE customers (\n",
            "3email TEXT PRIMARY KEY,\n",
            "4name TEXT NOT NULL,\n",
            "5phone TEXT\n",
            "6);\n",
            "+Lấy dữ liệu (SELECT): Chúng ta có 2 cách lấy dữ liệu từ bảng trong cơ sở dữ\n",
            "liệu bao gồm: lấy hết dữ liệu của toàn bộ cột trong bảng và lấy dữ liệu từ các cột\n",
            "được chỉ định. Cách truy vấn (Query) có cấu trúc tổng quát như sau:\n",
            "1SELECT column1, column2, ...\n",
            "2FROM table_name;\n",
            "A. Lấy toàn bộ dữ liệu của tất cả cột trong bảng:\n",
            "1-- Lấy toàn bộ dữ liệu của tất cả cột trong bảng CUSTOMERS\n",
            "2SELECT *\n",
            "3FROM CUSTOMERS;\n",
            "B. Lấy dữ liệu từ các cột được chỉ định trong bảng:\n",
            "1-- Lấy dữ liệu từ các cột được chỉ định trong bảng CUSTOMERS\n",
            "2SELECT NAME, PHONE\n",
            "3FROM CUSTOMERS;\n",
            "C. Lấy dữ liệu theo điều kiện trong bảng (Filter):\n",
            "1-- Lấy dữ liệu theo điều kiện email = giá trị truyền vào từ bảng\n",
            "CUSTOMERS\n",
            "2SELECT NAME, PHONE\n",
            "3FROM CUSTOMERS\n",
            "4WHERRE 1 = 1\n",
            "5AND EMAIL = ’aivietnam@aivietnam.edu.vn’;\n",
            "+Thêm dữ liệu (INSERT): Để thêm dữ liệu vào bảng chúng ta có thể thực thi\n",
            "với câu lệnh có cấu trúc tổng quát như sau:\n",
            "1INSERT INTO table_name (column1, column2, column3, ...)\n",
            "2VALUES (value1, value2, value3, ...);\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 8 tháng 4 năm 2024\n",
            "Ví dụ:\n",
            "1-- Thêm mới 1 dòng trong bảng CUSTOMERS\n",
            "2INSERT INTO CUSTOMERS(EMAIL, NAME, PHONE)\n",
            "3VALUES(’nguyen@nguyen.com’, ’Nguyen’, ’123456789’);\n",
            "4\n",
            "5-- Thêm mới nhiều dòng trong bảng CUSTOMERS\n",
            "6INSERT INTO CUSTOMERS(EMAIL, NAME, PHONE)\n",
            "7VALUES\n",
            "8(’nguyen@aivietnam.edu.vn’, ’Nguyen’, ’123456789’),\n",
            "9(’admin@aivietnam.edu.vn’, ’Vinh’, ’1122334455’);\n",
            "+Cập nhật dữ liệu (UPDATE): Để cập nhật dữ liệu vào bảng chúng ta có thể\n",
            "thực thi với câu lệnh có cấu trúc tổng quát như sau:\n",
            "1UPDATE table_name\n",
            "2SET column1 = value1, column2 = value2, ...\n",
            "3WHERE condition;\n",
            "Vídụ:Cậpnhậttêncủaemaillànguyen@aivietnam.edu.vnthànhHoangNguyen.\n",
            "1-- Cập nhật tên của email là nguyen@aivietnam.edu.vn thành Hoang\n",
            "Nguyen\n",
            "2UPDATE CUSTOMERS\n",
            "3SET NAME = ’Hoang Nguyen’\n",
            "4WHERE 1 = 1\n",
            "5AND EMAIL = ’nguyen@aivietnam.edu.vn’;\n",
            "+Xóa dữ liệu (DELETE): Để xóa dữ liệu khỏi bảng chúng ta có thể thực thi\n",
            "với câu lệnh có cấu trúc tổng quát như sau:\n",
            "1DELETE FROM table_name\n",
            "2WHERE condition;\n",
            "Ví dụ:Xóa email nguyen@aivietnam.edu.vn khỏi bảng CUSTOMERS\n",
            "1-- Xóa email: nguyen@aivietnam.edu.vn khỏi bảng CUSTOMERS\n",
            "2DELETE FROM CUSTOMERS\n",
            "3WHERE 1 = 1\n",
            "4AND EMAIL = ’nguyen@aivietnam.edu.vn’;\n",
            "3.Sử dụng SQLite trong Python:\n",
            "•Tạo kết nối đến CSDL: Để sử dụng SQLite và tương tác với cơ sử dữ liệu\n",
            "SQLite trong python, chúng ta cần tạo kết nối đến CSDL bằng câu lệnh như sau:\n",
            "1import sqlite3\n",
            "2# Tạo kết nối tới CSDL có tên là database.sqlite\n",
            "3# Nếu database.sqlite chưa tồn tại trong hệ thống thì nó sẽ\n",
            "4# tự tạo mới\n",
            "5connection = sqlite3.connect(’database.sqlite’)\n",
            "6cursor = connection.cursor()\n",
            "→Sau khi tạo kết nối đến cơ sở dữ liệu xong, chúng ta có Object có tên cursor\n",
            "nhằm giúp chúng ta thực thi và tương tác các câu lệnh truy vấn (SELECT,\n",
            "INSERT, UPDATE, DELETE,...) đến cơ sở dữ liệu.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 8 tháng 4 năm 2024\n",
            "•Tạo bảng: Để tạo bảng mới xong cơ sở dữ liệu chúng ta sẽ thực hiện như sau:\n",
            "1# Tạo bảng CUSTOMERS:\n",
            "2cursor.execute(\"\"\"\n",
            "3CREATE TABLE CUSTOMERS (\n",
            "4EMAIL TEXT PRIMARY KEY,\n",
            "5NAME TEXT NOT NULL,\n",
            "6PHONE TEXT NOT NULL\n",
            "7);\n",
            "8\"\"\")\n",
            "•Thêm dữ liệu vào bảng (INSERT): Sau khi thực hiện tạo bảng ở bước trên,\n",
            "lúc này bảng CUSTOMERS của chúng ta hoàn toàn không có dữ liệu, nên chúng\n",
            "ta sẽ thêm dữ liệu vào bảng bằng cách thực thi câu SQL như sau:\n",
            "1# Insert data mới\n",
            "2cursor.execute(\"\"\"\n",
            "3INSERT INTO CUSTOMERS(EMAIL, NAME, PHONE)\n",
            "4VALUES\n",
            "5(’nguyen@aivietnam.edu.vn’, ’Nguyen’, ’123456789’),\n",
            "6(’admin@aivietnam.edu.vn’, ’Vinh’, ’1122334455’);\n",
            "7\"\"\")\n",
            "8\n",
            "9connection.commit()\n",
            "→Mở rộng: Khi thực hiện thao tác INSERT/UPDATE/DELETE, khi thực hiện\n",
            "cursor.execute() trên cơ sở dữ liệu SQLite, những thay đổi này chỉ được lưu trữ\n",
            "tạm thời trong bộ nhớ. Nên chúng ta cần phải thực bước commit để lưu những\n",
            "thay đổi này vào CSDL, đảm bảo chúng được lưu trữ vĩnh viễn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Lấy dữ liệu (SELECT): Sau khi thực hiện bước tạo dữ liệu ở trên, chúng ta sẽ\n",
            "kiểm tra dữ liệu vừa thêm bằng cách thực thi câu SQL như sau:\n",
            "1import pandas as pd\n",
            "2# Lấy tất cả data từ bảng CUSTOMER\n",
            "3data=pd.read_sql_query(\"SELECT * FROM CUSTOMERS\", connection)\n",
            "4print(data)\n",
            "→Kết quả:\n",
            "Hình 1: Kết quả sau khi thực hiện SELECT\n",
            "•Cập nhật dữ liệu (UPDATE): Để thực hiện cập nhật dữ liệu trong CSDL,\n",
            "chúng ta sẽ thực thi câu SQL như sau:\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 8 tháng 4 năm 2024\n",
            "Cập nhật tên của email : nguyen@aivietnam.edu.vn sang giá trị mới và kiểm tra\n",
            "kết quả sau khi cập nhật.\n",
            "1# Update name của email: nguyen@aivietnam.edu.vn\n",
            "2cursor.execute(\"\"\"\n",
            "3UPDATE CUSTOMERS\n",
            "4SET NAME = ’Hoang Nguyen’\n",
            "5WHERE 1 = 1\n",
            "6AND EMAIL = ’nguyen@aivietnam.edu.vn’;\n",
            "7\"\"\")\n",
            "8\n",
            "9connection.commit()\n",
            "10\n",
            "11data=pd.read_sql_query(\"SELECT * FROM CUSTOMERS\", connection)\n",
            "12print(data)\n",
            "→Kết quả:\n",
            "Hình 2: Kết quả sau khi thực hiện UPDATE\n",
            "•Xóa dữ liệu (DELETE): Để thực hiện xóa dữ liệu trong CSDL, chúng ta sẽ\n",
            "thực thi câu SQL như sau:\n",
            "Xóa email : nguyen@aivietnam.edu.vn khỏi bảng CUSTOMERS và kiểm tra kết\n",
            "quả sau khi cập nhật.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1# Update name của email: nguyen@aivietnam.edu.vn\n",
            "2cursor.execute(\"\"\"\n",
            "3DELETE FROM CUSTOMERS\n",
            "4WHERE 1 = 1\n",
            "5AND EMAIL = ’nguyen@aivietnam.edu.vn’;\n",
            "6\"\"\")\n",
            "7\n",
            "8connection.commit()\n",
            "9\n",
            "10data=pd.read_sql_query(\"SELECT * FROM CUSTOMERS\", connection)\n",
            "11print(data)\n",
            "→Kết quả:\n",
            "Hình 3: Kết quả sau khi thực hiện DELETE\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 8 tháng 4 năm 2024\n",
            "4.Bài tập:\n",
            "•Hãy tạo mới bảng có tên PRODUCT có các cột như sau:\n",
            "Bảng 2: Bảng quản lý sản phẩm\n",
            "PRODUCT\n",
            "Cột Kiểu dữ liệu Chú thích\n",
            "ID INTEGER Khóa chính\n",
            "NAME TEXT Not null\n",
            "PRICE INTEGER Not null\n",
            "Câu 1:Hãy thêm mới các dòng có giá trị như sau và kiểm tra kết quả:\n",
            "PRODUCT\n",
            "ID NAME PRICE\n",
            "1 iPhone 15 18000000\n",
            "2 Galaxy Z-Fold 5 30000000\n",
            "→Kết quả:\n",
            "Câu 2:Hãy cập nhật giá mới cho Galaxy Z-Fold 5 thành 50.000.000 và kiểm tra\n",
            "kết quả:\n",
            "→Kết quả:\n",
            "Câu 3:Hãy xóa iPhone 15 ra khỏi CSDL và kiểm tra kết quả:\n",
            "→Kết quả:\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 9 tháng 4 năm 2024\n",
            "Basic Python - Work with SQLite Database\n",
            "Hoàng-Nguyên Vũ\n",
            "1.Mô tả: Thống kê cơ bản trong SQLite\n",
            "•SQLcung cấp nhiều hàm để thực hiện các phép tính thống kê cơ bản trên dữ\n",
            "liệu. Các hàm này được sử dụng để tính toán các giá trị như tổng, trung bình,\n",
            "giá trị tối đa, giá trị tối thiểu, v.v. Dưới đây là một số hàm thống kê cơ bản trong\n",
            "SQL:\n",
            "– SUM(): Tính tổng của các giá trị trong một cột.\n",
            "– AVG(): Tính trung bình của các giá trị trong một cột.\n",
            "– MIN(): Tìm giá trị nhỏ nhất trong một cột.\n",
            "– MAX(): Tìm giá trị lớn nhất trong một cột.\n",
            "– COUNT(): Đếm số lượng các giá trị trong một cột.\n",
            "Ví dụ:Giả sử bạn có một bảng Product với các cột name,brandvàprice. Bạn\n",
            "muốn biết:\n",
            "–Tổng doanh thu của tất cả các sản phẩm.\n",
            "–Doanh thu trung bình của các sản phẩm.\n",
            "–Giá sản phẩm cao nhất.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "–Số lượng các sản phẩm khác nhau.\n",
            "Câu lệnh SQL cho các yêu cầu trên sẽ như sau:\n",
            "1# Query để lấy tổng giá bán toàn bộ sản phẩm trong bảng Product\n",
            "2query = \"\"\"\n",
            "3SELECT SUM(price) AS total_revenue\n",
            "4FROM PRODUCT;\n",
            "5\"\"\"\n",
            "6\n",
            "7data_sum = pd.read_sql_query(query, connection)\n",
            "8print(data_sum)\n",
            "9\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 9 tháng 4 năm 2024\n",
            "10# Query để lấy thông tin sản phẩm có giá bán cao nhất\n",
            "11query = \"\"\"\n",
            "12SELECT NAME, MAX(price) AS PRICE\n",
            "13FROM PRODUCT;\n",
            "14\"\"\"\n",
            "15data_max = pd.read_sql_query(query, connection)\n",
            "16print(data_max)\n",
            "→Kết quả:\n",
            "•Hàm thống kê với GROUP BY:\n",
            "GROUP BY là một mệnh đề trong SQL được sử dụng để nhóm các hàng dựa\n",
            "trên các giá trị chung trong một hoặc nhiều cột và thực hiện các phép tính tổng\n",
            "hợp trên các nhóm đó.\n",
            "Hàm thống kê được sử dụng để tính toán các giá trị như tổng, trung bình, giá trị\n",
            "tối đa, giá trị tối thiểu, v.v. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "trên các nhóm dữ liệu.\n",
            "Ví dụ:Giả sử bạn có một bảng Product với các cột name,brandvàprice. Bạn\n",
            "muốn biết:\n",
            "–Doanh thu tổng cho mỗi hãng (BRAND) của sản phẩm.\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 9 tháng 4 năm 2024\n",
            "–Giá bán thấp nhất của mỗi danh mục.\n",
            "Cách thực thi câu lệnh SQL cho 2 yêu cầu trên sẽ như sau:\n",
            "1# Query để lấy tổng giá bán toàn bộ sản phẩm theo hãng trong bảng\n",
            "Product\n",
            "2query = \"\"\"\n",
            "3SELECT BRAND, SUM(price) AS total_revenue\n",
            "4FROM PRODUCT\n",
            "5GROUP BY BRAND;\n",
            "6\"\"\"\n",
            "7data_sum_by_brand = pd.read_sql_query(query, connection)\n",
            "8print(data_sum_by_brand)\n",
            "9\n",
            "10# Query để lấy thông tin sản phẩm có giá bán thấp nhất\n",
            "11query = \"\"\"\n",
            "12SELECT NAME, BRAND, MIN(price) AS PRICE\n",
            "13FROM PRODUCT\n",
            "14GROUP BY BRAND;\n",
            "15\"\"\"\n",
            "16data_min_by_brand = pd.read_sql_query(query, connection)\n",
            "17print(data_min_by_brand)\n",
            "→Kết quả:\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 9 tháng 4 năm 2024\n",
            "2.Bài tập:\n",
            "•Hãy tạo mới bảng có tên STOCK có các cột như sau:\n",
            "Bảng 1: Bảng quản lý cổ phiếu\n",
            "STOCK\n",
            "Cột Kiểu dữ liệu Chú thích\n",
            "ID INTEGER Khóa chính\n",
            "NAME TEXT Not null\n",
            "BUY INTEGER Not null\n",
            "INVESTOR TEXT Not null\n",
            "Hãy thêm mới các dòng có giá trị như sau:\n",
            "STOCK\n",
            "ID NAME BUY INVESTOR\n",
            "1 ACB 29.45 Nguyen\n",
            "2 VIC 44.55 Nguyen\n",
            "3 GMD 74.30 Nguyen\n",
            "4 ACB 28.45 Vinh\n",
            "5 VIC 40.55 Vinh\n",
            "6 GMD 60.30 Vinh\n",
            "Câu 1:Hãy viết lệnh SQL để truy vấn và in ra kết quả thống kê tổng giá bán\n",
            "(BUY) của bảng STOCK:\n",
            "Kết quả: Tổng giá bán = 277.69\n",
            "Câu 2:Hãy viết lệnh SQL để thống kê mã cổ phiếu có giá mua (BUY) lớn nhất\n",
            "theo nhà đầu tư (Investor):\n",
            "→Kết quả:\n",
            "aivietnam.edu.vn www.facebook.com/aivietnam.edu.vn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – COURSE 2024\n",
            "Decision Tree\n",
            "Trung-Trực Trần\n",
            "Ngày 17 tháng 2 năm 2024\n",
            "1 Giới thiệu.\n",
            "Cây quyết định (Decision Tree) là một trong những thuật toán máy học phổ biến nhất. Nó\n",
            "là một công cụ mạnh mẽ được sử dụng cho việc phân loại và dự đoán trong học máy và khai\n",
            "phá dữ liệu.\n",
            "Cây quyết định thực hiện quá trình học bằng cách phân chia tập dữ liệu thành các phần\n",
            "nhỏ hơn và xây dựng một cây quyết định dựa trên các quy tắc. Mỗi nút trên cây biểu diễn\n",
            "một thuộc tính (hoặc biến độc lập), mỗi cạnh đi từ nút cha đến các nút con biểu diễn các\n",
            "quy tắc quyết định, và mỗi lá trên cây biểu diễn một lớp hoặc một giá trị dự đoán.\n",
            "2 Công thức cây quyết định\n",
            "2.1 Gini Impurity\n",
            "Công thức Gini Impurity được sử dụng trong thuật toán cây quyết định để đo lường độ\n",
            "không chính xác của một dự đoán khi phân loại một tập dữ liệu.\n",
            "cần lưu ý là Gini Impurity càng nhỏ (gần 0) thì tập dữ liệu đó càng \"thuần khiết\", nghĩa\n",
            "là các mẫu trong cùng một nhóm có xu hướng thuộc vào cùng một lớp. Ngược lại, nếu Gini\n",
            "Impurity cao (gần 1), thì việc phân loại các mẫu trong nhóm đó trở nên không chắc chắn.\n",
            "Giả sử bạn đang xem xét một tập dữ liệu chia thành K nhóm, mỗi nhóm chứa một phần\n",
            "tỷ lệ pivới i=1,2,...,K.\n",
            "Công thức được biểu diễn như sau:\n",
            "IG= 1−KX\n",
            "i=1p2\n",
            "i (1)\n",
            "Trong đó:\n",
            "•IGlà Gini Impurity.\n",
            "•pilà tỷ lệ các mẫu thuộc vào lớp i.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Khi xây dựng cây quyết định, chúng ta cần chọn thuộc tính và giá trị phân chia sao cho\n",
            "Gini Impurity sau phân chia là nhỏ nhất, tức là mức độ \"thuần khiết\" cho dữ liệu thuộc về\n",
            "từng nhóm con được tạo ra.\n",
            "Đối với tệp dữ liệu gồm 2 labels (i=2) thì chỉ số IGsẽ đạt ngưỡng lớn nhất là bằng 0.5\n",
            "(Dữ liệu sẽ bị nhiễu lớn nhất).\n",
            "Hình 1: Ví dụ 1 với 2 label xanh và đen\n",
            "Với ví dụ ở hình 1, ta có 2 label là xanh và đen. Với 5 viên bi thuộc xanh và 3 viên bi\n",
            "thuộc đen ta có thể tính được xác suất suất hiện của lần lượt 2 tập là5\n",
            "8và3\n",
            "8. Áp dụng công\n",
            "thức Gini Impurity ta sẽ tính được:\n",
            "IG= 1−5\n",
            "82−3\n",
            "82= 0.46875.\n",
            "Vì ví dụ chỉ có 2 label là xanh và đen nên kết quả 0.46 có thể coi là tính không thuần\n",
            "khiết tiệm cận mức cao nhất (Max=0.5).\n",
            "2.2 Entropy\n",
            "Entropy trong cây quyết định là một khái niệm được sử dụng để đo lường sự không chắc chắn\n",
            "trong dữ liệu (Trung bình surprise). Trong ngữ cảnh của cây quyết định, entropy thường\n",
            "được sử dụng để đo lường mức độ không chắc chắn của phân phối lớp trong tập dữ liệu.\n",
            "Entropy được tính bằng công thức sau:\n",
            "Entropy (S) =−cX\n",
            "i=1pilog2(pi) (2)\n",
            "Trong đó:\n",
            "•S là tập dữ liệu.\n",
            "•c là số lớp trong tập dữ liệu.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•pilà tỷ lệ của lớp i trong tập dữ liệu.\n",
            "Entropy càng cao khi tỷ lệ của các lớp trong tập dữ liệu gần bằng nhau, và càng thấp\n",
            "khi một lớp chiếm đa số.\n",
            "Khi xây dựng cây quyết định, chúng ta cố gắng chia tập dữ liệu sao cho entropy sau khi\n",
            "chia là thấp nhất có thể. Điều này giúp cây quyết định có thể học được các quy tắc quyết\n",
            "định hiệu quả từ dữ liệu.\n",
            "Quyết định về cách chia tập dữ liệu dựa trên entropy thường được thực hiện bằng cách\n",
            "so sánh entropy trước và sau khi chia, và chọn cách chia mà giảm entropy nhiều nhất.\n",
            "2.2.1 Diễn giải công thức Entropy\n",
            "Để hiểu rõ hơn về công thức Entropy chúng ta hãy cùng sơ lược lại cái yếu tố chính và cách\n",
            "công thức hình thành.\n",
            "Hình 2: Ví dụ 2 gồm 10 viên bi xanh và đỏ\n",
            "Với ví dụ ở hình 2 chúng ta có thể thấy đây là một tập dataset gồm 10 viên bi và có 2\n",
            "label (xanh-đỏ). Với 8 viên bi là xanh và 2 viên bi là đỏ ta có thể tính xác suất của từng\n",
            "trường hợp là P(A)=8\n",
            "10=4\n",
            "5và P(B)2\n",
            "10=1\n",
            "5\n",
            "Từ xác suất trên chúng ta có thể tính được độ ngạc nhiên khi xảy ra trường hợp đó\n",
            "surprise=1\n",
            "P. Vậy độ ngạc nhiên của trường hợp bi xanh và bi đỏ là surprise(A)=1\n",
            "4\n",
            "5=1.25 và\n",
            "surprise(B)=1\n",
            "1\n",
            "1\n",
            "5=5.\n",
            "Công thức surprise:\n",
            "surprise =1\n",
            "P(E)(3)\n",
            "•Với P(E) là xác suất xảy ra sự kiện E.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 3: Minh hoạ đồ thị tương quan giữa surprise và log\n",
            "Như ta có thể thấy ở hình 3, với surprise=1\n",
            "P(E)thì surprise ∈[1,∞]. Nếu xác suất là 0%\n",
            "thì mức độ ngạc nhiên sẽ là dương vô cùng và với xác suất là 100%thì kết quả lại trả về\n",
            "mức độ ngạc nhiên là 1. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Điều này khác vô lý ở vế 2 vì với xác suất 100%thì mức độ ngạc\n",
            "nhiên nên trả về 0 (Không bất ngờ).\n",
            "Vì vậy nên chúng ta sử dụng hàm Log để có thể đổi cận của surprise ∈[1,∞] thành\n",
            "surprise ∈[0,∞].\n",
            "Công thức hàm log khi áp dụng vào surprise:\n",
            "log(1\n",
            "P(E)) =−log(P(E)) (4)\n",
            "Điều này đã giúp cho công thức trở nên hợp lý hơn khi xác suất xảy ra bằng 100%thì\n",
            "mức độ ngạc nhiên sẽ trả về 0.\n",
            "Từ các suy luận trên ta có công thức trung bình của mức độ ngạc nhiên:\n",
            "Entropy =−cX\n",
            "i=1pilog2(pi) (5)\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2.3 Ví dụ thực tế về Decision Tree dùng Entropy (Classify)\n",
            "2.3.1 Data có biến rời rạc\n",
            "Ta có một dataset về chơi tenis, với 2 labelslà yes (có chơi tenis) và no(không chơi tenis)\n",
            "với 14 samples và các cột (outlook, temperature, humidity, wind) là các Features .\n",
            "Bảng 1: Dữ liệu\n",
            "STT Outlook Temperature Humidity Wind PlayTennis\n",
            "1 Sunny Hot High Weak No\n",
            "2 Sunny Hot High Strong No\n",
            "3 Overcast Hot High Weak Yes\n",
            "4 Rainy Mild High Weak Yes\n",
            "5 Rainy Cool Normal Weak Yes\n",
            "6 Rainy Cool Normal Strong No\n",
            "7 Overcast Cool Normal Strong Yes\n",
            "8 Sunny Mild High Weak No\n",
            "9 Sunny Cool Normal Weak Yes\n",
            "10 Rainy Mild Normal Weak Yes\n",
            "11 Sunny Mild Normal Strong Yes\n",
            "12 Overcast Mild High Strong Yes\n",
            "13 Overcast Hot Normal Weak Yes\n",
            "14 Rainy Mild High Strong No\n",
            "Chúng ta cần tính Entropy của các Features và tính information gain theo công thức sau.\n",
            "Hình 4: Công thức tính entropy và gain\n",
            "Nếu entropy nhánh giảm càng nhiều chúng ta sẽ nhận được Gain càng lớn nên ta ưu tiên\n",
            "chọn Features có Gain lớn nhất.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Với data có [9 yes, 5 no]: Entropy(data)= −5\n",
            "14.log 2(5\n",
            "14)−9\n",
            "14.log 2(9\n",
            "14)= 0.94.\n",
            "Tính gain cho feature Outlook:\n",
            "•Entropy(Sunny)= −2\n",
            "5.log 2(2\n",
            "5)−3\n",
            "5.log 2(3\n",
            "5)= 0.971.\n",
            "•Entropy(Rainy)= −3\n",
            "5.log 2(3\n",
            "5)−2\n",
            "5.log 2(2\n",
            "5)= 0.971.\n",
            "•Entropy(Overcast)= −4\n",
            "4.log 2(4\n",
            "4)−0\n",
            "4.log 2(0\n",
            "4)= 0.\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Gain(Outlook)= 0.94−0.971.5\n",
            "14−0.971.5\n",
            "14−0= 0.246.\n",
            "Tính gain cho feature Temperature:\n",
            "•Entropy(Hot)= −2\n",
            "4.log 2(2\n",
            "4)−2\n",
            "4.log 2(2\n",
            "4)= 1.\n",
            "•Entropy(Mild)= −4\n",
            "6.log 2(4\n",
            "6)−2\n",
            "6.log 2(2\n",
            "6)= 0.918.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Entropy(Cool)= −3\n",
            "4.log 2(3\n",
            "4)−1\n",
            "4.log 2(1\n",
            "4)= 0.811.\n",
            "•Gain(Outlook)= 0.94−1.4\n",
            "14−0.918.6\n",
            "14−0.811.4\n",
            "14= 0.029.\n",
            "Tính gain cho feature Humidity:\n",
            "•Entropy(High)= −3\n",
            "7.log 2(3\n",
            "7)−4\n",
            "7.log 2(4\n",
            "7)= 0.985.\n",
            "•Entropy(Normal)= −6\n",
            "7.log 2(6\n",
            "7)−1\n",
            "7.log 2(1\n",
            "7)= 0.592.\n",
            "•Gain(Humidity)= 0.94−0.985.7\n",
            "14−0.592.7\n",
            "14= 0.151.\n",
            "Tính gain cho feature Wind:\n",
            "•Entropy(Weak)= −6\n",
            "8.log 2(6\n",
            "8)−2\n",
            "8.log 2(2\n",
            "6)= 0.811.\n",
            "•Entropy(Strong)= −3\n",
            "6.log 2(3\n",
            "6)−3\n",
            "6.log 2(3\n",
            "6)= 1.\n",
            "•Gain(Wind)= 0.94−0.811.8\n",
            "14−1.6\n",
            "14= 0.048.\n",
            "Sau khi tính Gain, ta chọn Outlook làm gốc vì Outlook có chỉ số Gain lớn nhất (Nghĩa\n",
            "là entropy giảm nhiều nhất) ta được sơ đồ như sau:\n",
            "Hình 5: Nút gốc của cây\n",
            "ta có thể thấy với Outlook(Overcast) thì tất cả samples đều là yes thì Entropy=0 ta có\n",
            "thể trả về yes cho Overcast.\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Đối với 2 thuộc tính Sunny [2 yes, 3 no], Rainy [3 yes, 2 no] ta phải tính thêm các điều\n",
            "kiện của các features. Bằng cách tính gain lần lượt của Temperature, Humidity và Wind.\n",
            "Nhưng với điều kiện Outlook phải là Sunny hoặc Rainy. Từ dữ liệu trên ta có được dataset\n",
            "ở bảng 2.\n",
            "Bảng 2: Dữ liệu thu gọn\n",
            "STT Outlook Temperature Humidity Wind PlayTennis\n",
            "1 Sunny Hot High Weak No\n",
            "2 Sunny Hot High Strong No\n",
            "3 Rainy Mild High Weak Yes\n",
            "4 Rainy Cool Normal Weak Yes\n",
            "5 Rainy Cool Normal Strong No\n",
            "6 Sunny Mild High Weak No\n",
            "7 Sunny Cool Normal Weak Yes\n",
            "8 Rainy Mild Normal Weak Yes\n",
            "9 Sunny Mild Normal Strong Yes\n",
            "10 Rainy Mild High Strong No\n",
            "Bây giờ chúng ta lặp lại các bước tính gain của các Features với điều kiện là Out-\n",
            "look=Sunny và Outlook=Rainy.\n",
            "Đối với Outlook là Sunny\n",
            "Bảng 3: Dữ liệu Outlook(Sunny)\n",
            "STT Outlook Temperature Humidity Wind PlayTennis\n",
            "1 Sunny Hot High Weak No\n",
            "2 Sunny Hot High Strong No\n",
            "3 Sunny Mild High Weak No\n",
            "4 Sunny Cool Normal Weak Yes\n",
            "5 Sunny Mild Normal Strong Yes\n",
            "Ở đây Entropy tổng sẽ là Entropy của Sunny:\n",
            "Entropy(Sunny)= −2\n",
            "5.log 2(2\n",
            "5)−3\n",
            "5.log 2(3\n",
            "5)= 0.971.\n",
            "Tính Gain cho Temperature\n",
            "•Entropy(Cool)= 0.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Entropy(Mild)= 1.\n",
            "•Entropy(Hot)= 0.\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Gain(Temperature)= 0.571.\n",
            "Tính Gain cho Humidity\n",
            "•Entropy(High)= 0.\n",
            "•Entropy(Normal)= 0.\n",
            "•Gain(Humidity)= 0.971.\n",
            "Tính Gain cho Wind\n",
            "•Entropy(Weak)= 0.918.\n",
            "•Entropy(Strong)= 1.\n",
            "•Gain(Wind)= 0.1977.\n",
            "Sau khi tính Gain, ta chọn Humidity làm gốc vì Humidity có chỉ số Gain lớn nhất (Nghĩa\n",
            "là entropy giảm nhiều nhất).\n",
            "Hình 6: Tree\n",
            "ta có thể thấy với Humidity(High) thì tất cả samples đều là no thì Entropy=0 ta có thể\n",
            "trả về no cho High. Tương tự với Normal sẽ trả về yes.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bảng 4: Dữ liệu Outlook(Rainy)\n",
            "STT Outlook Temperature Humidity Wind PlayTennis\n",
            "1 Rainy Mild High Weak Yes\n",
            "2 Rainy Cool Normal Weak Yes\n",
            "3 Rainy Cool Normal Strong No\n",
            "4 Rainy Mild Normal Weak Yes\n",
            "5 Rainy Mild High Strong No\n",
            "Đối với Outlook là Rainy\n",
            "Ở đây Entropy tổng sẽ là Entropy của Rainy:\n",
            "Entropy(Rainy)= −3\n",
            "5.log 2(3\n",
            "5)−2\n",
            "5.log 2(2\n",
            "5)= 0.971.\n",
            "Tương tự như trên, chúng ta tính được gain lần lượt cho Temperature, Humidity và Wind\n",
            "là: 0.0202, 0.0202, 0.971\n",
            "Sau khi tính Gain, ta chọn Wind làm gốc vì Wind có chỉ số Gain lớn nhất (Nghĩa là\n",
            "entropy giảm nhiều nhất).\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 7: Final Tree\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "ta có thể thấy với Wind(Strong) thì tất cả samples đều là no thì Entropy=0 ta có thể\n",
            "trả về no cho Strong. Tương tự với Weak sẽ trả về yes.\n",
            "2.3.2 Data có biến liên tục\n",
            "Ta có 1 tệp data với các biến là độ dài của cách hoa với 2 label là 0 và 1.\n",
            "Bảng 5: Dữ liệu liên tục\n",
            "STT Petal_Length Label\n",
            "1 1 0\n",
            "2 1.3 0\n",
            "3 0.9 0\n",
            "4 1.7 1\n",
            "5 1.8 1\n",
            "6 1.2 1\n",
            "Đầu tiên chúng ta phải sắp xếp dữ liệu của tệp data trên từ bé đến lớn hoặc từ lớn đến\n",
            "bé, từ đó chúng ta có 1 dataset mới như sau. Sau đó chúng ta tiếp tục tính trung bình cộng\n",
            "của từng đôi.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ta tính gain của các thuộc tính Trung bình để tìm gain lớn nhất, với cách tính là xét\n",
            "các giá trị bé hơn trung bình đang xét và các giá trị lớn hơn trung bình.\n",
            "Hình 8: Minh hoạ Tree Data liên tục\n",
            "Như vậy ta tính gain lần lượt của 0.95, 1.1, 1.25, 1.5, 1.75 và có kết quả là gain của 1.1\n",
            "sẽ là lớn nhất, ta chọn điều kiện <=1.1 làm nút gốc.\n",
            "Tính tương tự như ví dụ tính cây bằng biến rời rạc, ta được một sơ đồ cây cho biến liên\n",
            "tục như sau.\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bảng 6: Dữ liệu liên tục (sắp xếp từ bé đến lớn theo Petal_Length) và trung bình cộng\n",
            "STT Petal_Length Label Trung bình\n",
            "3 0.9 0\n",
            "1 1 0 0.95\n",
            "2 1.2 1 1.1\n",
            "6 1.3 0 1.25\n",
            "4 1.7 1 1.5\n",
            "5 1.8 1 1.75\n",
            "Hình 9: Minh hoạ Decison Tree với Data liên tục\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2.4 Ví dụ về Decision Tree dùng Mean và Variance (Regression)\n",
            "Chúng ta có một table thể hiện sự tương quan giữa năm kinh nghiệm (Exp) và mức lương\n",
            "tương ứng (Salary) với năm kinh nghiệm là feature và lương là label.\n",
            "Bảng 7: Dữ liệu liên tục\n",
            "STT Experience Salary\n",
            "1 1 0\n",
            "2 1.5 0\n",
            "3 2 0\n",
            "4 2.5 0\n",
            "5 3 60\n",
            "6 3.5 64\n",
            "7 4 55\n",
            "8 4.5 61\n",
            "9 5 66\n",
            "10 5.5 83\n",
            "11 6 93\n",
            "12 6.5 91\n",
            "13 7 98\n",
            "14 7.5 101\n",
            "Để có thể hoàn thành bài toán dự đoán Decision Tree, chúng ta cần tính lần lượt\n",
            "Mean(data), Variance(Data).\n",
            "Với Mean và Variance được biểu diễn như sau:\n",
            "Mean =1\n",
            "SnX\n",
            "i=1Si (6)\n",
            "•Mean là giá trị trung bình.\n",
            "•S là số lượng các phần tử trong tập hợp dữ liệu.\n",
            "•Silà số lượng các phần tử trong tập hợp dữ liệu.\n",
            "mse =1\n",
            "SnX\n",
            "i=1(Si−Mean )2(7)\n",
            "•mse là phương sai.\n",
            "•Mean là giá trị trung bình.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•S là số lượng các phần tử trong tập hợp dữ liệu.\n",
            "•Silà số lượng các phần tử trong tập hợp dữ liệu.\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Chúng ta lần lượt tách dataset theo hàng và phân chia thành dataset-right và dataset-left\n",
            "để có thể tính amseMean và mse của left và right, ưu tiên lựa chọn amsecó giá trị nhỏ nhất.\n",
            "Sau khi áp dụng công thức ta có được dataset-left và dataset-right với chỉ số amsenhỏ\n",
            "nhất như sau.\n",
            "STT Experience Salary\n",
            "1 1 0\n",
            "2 1.5 0\n",
            "3 2 0\n",
            "4 2.5 0\n",
            "Bảng 8: Dataset-leftSTT Experience Salary\n",
            "1 3 60\n",
            "2 3.5 64\n",
            "3 4 55\n",
            "4 4.5 61\n",
            "5 5 66\n",
            "6 5.5 83\n",
            "7 6 93\n",
            "8 6.5 91\n",
            "9 7 98\n",
            "10 7.5 101\n",
            "Bảng 9: Dataset-right\n",
            "Lần lượt các chỉ số của Mean và Variance của data-left và data-right là: 0,0 và 77.2,\n",
            "282.35.\n",
            "Hình 10: Minh hoạ cách tính amse\n",
            "•với L là số lượng data ở data-left.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•với R là số lượng data ở data-right.\n",
            "•với S là số lượng data ở data gốc.\n",
            "Lặp lại việc tách và tìm min( amse) chúng ta có được một sơ đồ cây với Depth=3 như\n",
            "sau:\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 11: Ví dụ Decision Tree Regression\n",
            "Chúng ta có thể tiếp tục tách data đến khi Squared_error đạt 0.0 nhưng vì để tránh bị\n",
            "Overfitting nên mô hình dừng ở Depth=3 với chỉ số Squared_error ở mức chấp nhận được.\n",
            "THAT’S IT, THANK YOU FOR READING ♡♡♡\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "Multi-agent LLMs\n",
            "Dinh-Thang Duong, Nguyen-Thuan Duong và Quang-Vinh Dinh\n",
            "Ngày 5 tháng 5 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Multi-agent LLMs là một hướng phát triển liên quan đến mô hình ngôn ngữ lớn. Trong đó, ta ứng\n",
            "dụng LLMs kết hợp với các agentscó khả năng sử dụng một công cụ hoặc một chức năng bên ngoài\n",
            "nào đó, nhằm giải quyết bài toán của chúng ta. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ví dụ, ta có thể cài đặt cho LLMs sử dụng calculator\n",
            "để giải quyết các phép tính, từ đó sẽ đảm bảo kết quả đầu ra của mô hình.\n",
            "Hình 1: Minh họa về các agent trong môi trường ChatDev. Ảnh: link.\n",
            "Trong bài viết này, chúng ta sẽ xây dựng một ứng dụng về Multi-agent LLMs tạo sinh code đồng\n",
            "thời kiểm tra code thông qua trình thực thi. Mã nguồn được xây dựng bằng thư viện Autogen. Theo\n",
            "đó, ta sẽ xây dựng một ứng dụng có dạng như Chatbot. Ở đó, sẽ có hai agent tự giao tiếp với nhau\n",
            "gồm AssistantAgent và UserProxyAgent:\n",
            "•AssistantAgent là một LLM, có vai trò tạo sinh code theo yêu cầu và kiểm tra lại code nếu cần.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•UserProxyAgent có vai trò gửi yêu cầu tạo sinh đến AssistantAgent và thực thi code nhận được\n",
            "để kiểm tra code đã chạy được hay chưa.\n",
            "Thông qua hội thoại giữa hai agent này, ta sẽ có được một đoạn code theo yêu cầu đã được kiểm\n",
            "tra thông qua trình thực thi. Tổng quan, pipeline của project như sau:\n",
            "Hình 2: Pipeline của project.\n",
            "1. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Từ yêu cầu về tạo sinh một đoạn code với chức năng nào đó từ người dùng, ta kết hợp với context\n",
            "có sẵn trong Autogen để hình thành nội dung khởi đầu của cuộc hội thoại giữa hai agent.\n",
            "2. Với nội dung trên, ta tiến hành cho hai agent giao tiếp với nhau.\n",
            "3. Từ nội dung chat giữa hai agent, ta trích ra nội dung cần thiết để làm kết quả của chương trình\n",
            "(ở đây là đoạn code được tạo sinh theo yêu cầu và kết quả thực thi).\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Cài đặt chương trình\n",
            "Trong phần này, chúng ta sẽ tiến hành cài đặt nội dung của project. Mã nguồn được xây dựng trên hệ\n",
            "điều hành Ubuntu với GPU 24GB. Các bước thực hiện như sau:\n",
            "1.Tổ chức thư mục code: Để mã nguồn trở nên rõ ràng nhằm phục vụ cho mục đích đọc hiểu\n",
            "code, chúng ta sẽ có ảnh minh họa tổ chức cây thư mục như sau:\n",
            "multiagent_llms/\n",
            "agent.py\n",
            "app.py\n",
            "chat.py\n",
            "utils.py\n",
            "OAI_CONFIG_LIST.json\n",
            "requirements.txt\n",
            "2.Cập nhật file requirements.txt :Ta liệt kê một số thư viện cần thiết để chạy được source code\n",
            "thông qua file requirements như sau:\n",
            "1pyautogen ==0.2.27\n",
            "2gradio ==4.29.0\n",
            "3.Cập nhật file agent.py:Trong file này, ta định nghĩa các hàm khởi tạo các agents. Nội dung như\n",
            "sau:\n",
            "(a)Import các thư viện và modules cần thiết:\n",
            "1import autogen\n",
            "2from autogen import AssistantAgent , UserProxyAgent\n",
            "3from autogen . code_utils import extract_code\n",
            "4\n",
            "5TIMEOUT = 60\n",
            "(b)Khai báo biến config cho LLM (AssistantAgent): AssistAgent của chúng ta là một\n",
            "LLM. Theo đó, đối với việc sử dụng GPT, AutoGen yêu cầu ta cung cấp một file .json có\n",
            "chứa API KEY và model version. Các bạn tạo một file tên OAI_CONFIG_LIST.json\n",
            "có nội dung sau:\n",
            "1[\n",
            "2 {\n",
            "3 \" model \": \"gpt -3.5 - turbo \",\n",
            "4 \" api_key \": \" Type your API_KEY here \"\n",
            "5 }\n",
            "6]\n",
            "Quay lại file code agent.py, các bạn đọc file và import config như sau:\n",
            "1config_list = autogen . config_list_from_json (\"./ OAI_CONFIG_LIST . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "json \")\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(c)Xây dựng hàm check điều kiện dừng hội thoại cho UserProxyAgent: UserProxyA-\n",
            "gent cần nhận được đoạn code được tạo sinh từ Agent còn lại để thực thi. Vì vậy, ta sẽ khai\n",
            "báo một hàm kết thúc lượt nhắn của UserProxyAgent nếu chưa nhận được code và ngược\n",
            "lại:\n",
            "1def _is_termination_msg ( message ):\n",
            "2 if isinstance ( message , dict ):\n",
            "3 message = message .get(\" content \")\n",
            "4 if message is None :\n",
            "5 return False\n",
            "6 cb = extract_code ( message )\n",
            "7 contain_code = False\n",
            "8 for c in cb:\n",
            "9 if c[0] == \" python \":\n",
            "10 contain_code = True\n",
            "11 break\n",
            "12 return not contain_code\n",
            "(d)Xây dựng hàm khởi tạo các agents: Để thuận tiện trong việc triển khai code, ta xây\n",
            "dựng hàm initialize_agents() để tạo hai agent, sử dụng trong phần code của file khác trong\n",
            "source code:\n",
            "1def initialize_agents ():\n",
            "2 assistant = AssistantAgent (\n",
            "3 name =\" assistant \",\n",
            "4 max_consecutive_auto_reply =5,\n",
            "5 llm_config ={\n",
            "6 \" timeout \": TIMEOUT ,\n",
            "7 \" config_list \": config_list ,\n",
            "8 },\n",
            "9 )\n",
            "10\n",
            "11 userproxy = UserProxyAgent (\n",
            "12 name =\" userproxy \",\n",
            "13 human_input_mode =\" NEVER \",\n",
            "14 is_termination_msg = _is_termination_msg ,\n",
            "15 max_consecutive_auto_reply =5,\n",
            "16 code_execution_config ={\n",
            "17 \" work_dir \": \" coding \",\n",
            "18 \" use_docker \": False ,\n",
            "19 },\n",
            "20 )\n",
            "21\n",
            "22 return assistant , userproxy\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 3: Minh họa về tương tác giữa hai agent - UserProxyAgent (Trình thực thi code) và AssistantAgent\n",
            "(LLM tạo sinh code).\n",
            "4.Cập nhật file utils.py:Trong file này, ta định một class liên quan đến threading, sẽ được sử\n",
            "dụng ở file chat.py. Nội dung file utils.py như sau:\n",
            "1import sys\n",
            "2import threading\n",
            "3\n",
            "4LOG_LEVEL = \" INFO \"\n",
            "5TIMEOUT = 60\n",
            "6\n",
            "7class thread_with_trace ( threading . Thread ):\n",
            "8 def __init__ (self , *args , ** keywords ):\n",
            "9 threading . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Thread . __init__ (self , *args , ** keywords )\n",
            "10 self . killed = False\n",
            "11 self . _return = None\n",
            "12\n",
            "13 def start ( self ):\n",
            "14 self . __run_backup = self .run\n",
            "15 self . run = self . __run\n",
            "16 threading . Thread . start ( self )\n",
            "17\n",
            "18 def __run ( self ):\n",
            "19 sys . settrace ( self . globaltrace )\n",
            "20 self . __run_backup ()\n",
            "21 self . run = self . __run_backup\n",
            "22\n",
            "23 def run( self ):\n",
            "24 if self . _target is not None :\n",
            "25 self . _return = self . _target (* self ._args , ** self . _kwargs )\n",
            "26\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "27 def globaltrace (self , frame , event , arg):\n",
            "28 if event == \" call \":\n",
            "29 return self . localtrace\n",
            "30 else :\n",
            "31 return None\n",
            "32\n",
            "33 def localtrace (self , frame , event , arg ):\n",
            "34 if self . killed :\n",
            "35 if event == \" line \":\n",
            "36 raise SystemExit ()\n",
            "37 return self . localtrace\n",
            "38\n",
            "39 def kill ( self ):\n",
            "40 self . killed = True\n",
            "41\n",
            "42 def join (self , timeout =0):\n",
            "43 threading . Thread . join (self , timeout )\n",
            "44 return self . _return\n",
            "5.Cập nhật file chat.py:Trong file này, ta định nghĩa các hàm xây dựng hộp hội thoại (chatbox)\n",
            "giữa hai agent. Từ đó, cho chúng tương tác qua lại và lấy về kết quả cuối cùng - lịch sử cuộc trò\n",
            "chuyện giữa hai agent, từ đó trích xuất được đoạn code và kết quả thực thi. Theo đó, ta triển\n",
            "khai như sau:\n",
            "(a)Import các thư viện và module cần thiết:\n",
            "1import os\n",
            "2from autogen import OpenAIWrapper\n",
            "3from agent import initialize_agents , config_list\n",
            "4from utils import *\n",
            "(b)Khởi tạo agents: Ta khởi tạo hai agent, UserProxyAgent và AssistantAgent. Đây là hai\n",
            "agent sẽ tương tác qua lại với nhau trong chatbox:\n",
            "1assistant , userproxy = initialize_agents ()\n",
            "(c)Xâydựnghàmchuyểnđổiformatlịchsửhộithoại: Đểđưathôngtincáccuộchộithoại\n",
            "giữa 2 agent tại quá khứ trong chatbox vào model GPT, ta sẽ xây dựng hàm chuyển đổi thông\n",
            "tin lịch sử ta ghi nhận được sang format của OpenAI thông qua hàm chat_to_oai_message() :\n",
            "1def chat_to_oai_message ( chat_history ):\n",
            "2 \"\"\" Convert chat history to OpenAI message format .\"\"\"\n",
            "3 messages = []\n",
            "4 if LOG_LEVEL == \" DEBUG \":\n",
            "5 print (f\" chat_to_oai_message : { chat_history }\")\n",
            "6 for msg in chat_history :\n",
            "7 messages . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "append (\n",
            "8 {\n",
            "9 \" content \": msg [0]. split () [0] if msg [0]. startswith (\" exitcode \")\n",
            "else msg [0] ,\n",
            "10 \" role \": \" user \",\n",
            "11 }\n",
            "12 )\n",
            "13 messages . append ({\" content \": msg [1] , \" role \": \" assistant \"})\n",
            "14 return messages\n",
            "(d)Xây dựng hàm chuyển đổi ngược format lịch sử hội thoại: Để hiển thị thông tin lịch\n",
            "sử lên giao diện của chúng ta sau khi chạy xong, ta cần lấy lại thông tin lịch sử từ GPT.\n",
            "Vì thông tin đang ở format của OpenAI, ta cần có hàm chuyển đổi ngược lại thành một list\n",
            "như ban đầu. Theo đó, ta khai báo hàm oai_message_to_chat() :\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1def oai_message_to_chat ( oai_messages , sender ):\n",
            "2 \"\"\" Convert OpenAI message format to chat history .\"\"\"\n",
            "3 chat_history = []\n",
            "4 messages = oai_messages [ sender ]\n",
            "5 if LOG_LEVEL == \" DEBUG \":\n",
            "6 print (f\" oai_message_to_chat : { messages }\")\n",
            "7 for i in range (0, len( messages ), 2):\n",
            "8 chat_history . append (\n",
            "9 [\n",
            "10 messages [i][\" content \"],\n",
            "11 messages [i + 1][\" content \"] if i + 1 < len( messages ) else \"\",\n",
            "12 ]\n",
            "13 )\n",
            "14 return chat_history\n",
            "(e)Xây dựng hàm khởi tạo đoạn hội thoại ban đầu: Khi bắt đầu chương trình, ta cần\n",
            "khởi tạo môi trường chat cho hai agent. Ta có hàm initiate_chat() như sau:\n",
            "1def initiate_chat ( config_list , user_message , chat_history ):\n",
            "2 if LOG_LEVEL == \" DEBUG \":\n",
            "3 print (f\" chat_history_init : { chat_history }\")\n",
            "4\n",
            "5 if len( config_list [0]. get(\" api_key \", \"\")) < 2:\n",
            "6 chat_history . append (\n",
            "7 [\n",
            "8 user_message ,\n",
            "9 ]\n",
            "10 )\n",
            "11 return chat_history\n",
            "12 else :\n",
            "13 llm_config = {\n",
            "14 \" timeout \": TIMEOUT ,\n",
            "15 \" config_list \": config_list ,\n",
            "16 }\n",
            "17 assistant . llm_config . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "update ( llm_config )\n",
            "18 assistant . client = OpenAIWrapper (** assistant . llm_config )\n",
            "19\n",
            "20 if user_message . strip (). lower (). startswith (\" show file :\"):\n",
            "21 filename = user_message . strip (). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "lower (). replace (\" show file :\", \"\").\n",
            "strip ()\n",
            "22 filepath = os. path . join (\" coding \", filename )\n",
            "23 if os. path . exists ( filepath ):\n",
            "24 chat_history . append ([ user_message , ( filepath ,) ])\n",
            "25 else :\n",
            "26 chat_history . append ([ user_message , f\" File { filename } not found .\"\n",
            "])\n",
            "27 return chat_history\n",
            "28\n",
            "29 assistant . reset ()\n",
            "30 oai_messages = chat_to_oai_message ( chat_history )\n",
            "31 assistant . _oai_system_message_origin = assistant . _oai_system_message . copy\n",
            "()\n",
            "32 assistant . _oai_system_message += oai_messages\n",
            "33\n",
            "34 try :\n",
            "35 userproxy . initiate_chat ( assistant , message = user_message )\n",
            "36 messages = userproxy . chat_messages\n",
            "37 chat_history += oai_message_to_chat ( messages , assistant )\n",
            "38 except Exception as e:\n",
            "39 chat_history . append ([ user_message , str (e)])\n",
            "40\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "41 assistant . _oai_system_message = assistant . _oai_system_message_origin . copy\n",
            "()\n",
            "42 if LOG_LEVEL == \" DEBUG \":\n",
            "43 print (f\" chat_history : { chat_history }\")\n",
            "44 return chat_history\n",
            "(f)Xây dựng hàm trả về kết quả đoạn hội thoại: Ta xây dựng hàm trả về kết quả của\n",
            "chương trình. Kết quả chương trình của chúng ta là lịch sử đoạn hội thoại giữa hai agent\n",
            "(code của AssistantAgent và kết quả thực thi code của UserProxyAgent). Theo đo, hàm trả\n",
            "về kết quả được triển khai như sau:\n",
            "1def chatbot_reply_thread ( input_text , chat_history , config_list ):\n",
            "2 \"\"\" Chat with the agent through terminal . \"\"\"\n",
            "3 thread = thread_with_trace ( target = initiate_chat , args =( config_list ,\n",
            "input_text , chat_history ))\n",
            "4 thread . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "start ()\n",
            "5 try :\n",
            "6 messages = thread . join ( timeout = TIMEOUT )\n",
            "7 if thread . is_alive ():\n",
            "8 thread . kill ()\n",
            "9 thread . join ()\n",
            "10 messages = [\n",
            "11 input_text ,\n",
            "12 \" Timeout Error : Please check your API keys and try again\n",
            "later .\",\n",
            "13 ]\n",
            "14 except Exception as e:\n",
            "15 messages = [\n",
            "16 [\n",
            "17 input_text ,\n",
            "18 str (e) if len(str(e)) > 0 else \" Invalid Request to OpenAI ,\n",
            "please check your API keys .\",\n",
            "19 ]\n",
            "20 ]\n",
            "21 return messages\n",
            "22\n",
            "23def chatbot_reply ( input_text , chat_history , config_list ):\n",
            "24 \"\"\" Chat with the agent through terminal . \"\"\"\n",
            "25 return chatbot_reply_thread ( input_text , chat_history , config_list )\n",
            "26\n",
            "27def chat_respond ( message , chat_history , model , oai_key , aoai_key , aoai_base ):\n",
            "28 chat_history [:] = chatbot_reply ( message , chat_history , config_list )\n",
            "29 if LOG_LEVEL == \" DEBUG \":\n",
            "30 print (f\" return chat_history : { chat_history }\")\n",
            "31 return \"\"\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 4: Minh họa việc trả về nội dung đoạn hội thoại (carryover) giữa hai agent. Các carryover theo\n",
            "thời gian trở thành lịch sử đoạn hội thoại làm context cho các lần chat khác.\n",
            "6.Cập nhật file app.py:Cuối cùng, ta xây dựng một giao diện đơn giản để tương tác với chương\n",
            "trình, trực quan hóa hội thoại giữa hai agent cũng như kết quả của chương trình mà ta mong\n",
            "muốn. Theo đó, ta sẽ xây dựng giao diện bằng thư viện Gradio. Triển khai như sau:\n",
            "(a)Import các thư viện và modules cần thiết: Tại đây, ta sẽ import thư viện Gradio. Ta\n",
            "sẽ sử dụng giao diện chat cơ bản của Gradio là ChatInterface :\n",
            "1import gradio as gr\n",
            "2from gradio import ChatInterface\n",
            "3\n",
            "4from chat import chat_respond\n",
            "5\n",
            "6LOG_LEVEL = \" INFO \"\n",
            "(b)Xây dựng block Gradio: Để triển khai giao diện, ta xây dựng một block gradio với các\n",
            "thành phần trên giao diện như sau:\n",
            "1with gr. Blocks () as demo :\n",
            "2\n",
            "3 description = gr. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Markdown (\"\"\"\n",
            "4 # Microsoft AutoGen\n",
            "5 ## Multi - agent Conversation\n",
            "6 \"\"\" )\n",
            "7\n",
            "8 chatbot = gr. Chatbot (\n",
            "9 [],\n",
            "10 elem_id =\" chatbot \",\n",
            "11 bubble_full_width =False ,\n",
            "12 avatar_images =(\n",
            "13 \"../ images / human .png\",\n",
            "14 \"../ images / autogen .png\",\n",
            "15 ),\n",
            "16 render =False ,\n",
            "17 height =600 ,\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "18 )\n",
            "19\n",
            "20 txt_input = gr. Textbox (\n",
            "21 scale =4,\n",
            "22 show_label =False ,\n",
            "23 placeholder =\" Enter text and press enter \",\n",
            "24 container =False ,\n",
            "25 render =False ,\n",
            "26 autofocus =True ,\n",
            "27 )\n",
            "28\n",
            "29 chatiface = ChatInterface (\n",
            "30 chat_respond ,\n",
            "31 chatbot = chatbot ,\n",
            "32 textbox = txt_input ,\n",
            "33 examples =[\n",
            "34 [\" write a python function to count the sum of two numbers ?\"],\n",
            "35 [\" what if the production of two numbers ?\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\"],\n",
            "36 [\" Plot a chart of the last year ’s stock prices of Microsoft ,\n",
            "Google and Apple and save to stock_price .png.\"],\n",
            "37 [\" show file : stock_price .png\"],\n",
            "38 ],\n",
            "39 )\n",
            "(c)Khởi động giao diện: Cuối cùng, ta cài đặt lệnh khởi động giao diện khi chạy file app.py\n",
            "như sau:\n",
            "1if __name__ == \" __main__ \":\n",
            "2 demo . launch ( share =False , server_name =\" 0.0.0.0 \", server_port =7868)\n",
            "Hình 5: Giao diện ứng dụng Multi-agent LLMs sau khi được triển khai và chạy thử một ví dụ.\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. Trong Multi-agent LLMs, khái niệm agent có thể được hiểu như là?\n",
            "(a) Là một Docker Container.\n",
            "(b) Là một máy ảo (Virtual machine).\n",
            "(c) Là một mô hình LLM.\n",
            "(d) Là một thực thể (Entity) có khả năng nhận và gửi thông điệp (Message) đến các agent khác.\n",
            "2. Đâu là ưu điểm của việc sử dụng phối hợp của nhiều agent (Multi-agent)?\n",
            "(a) Giải quyết một vấn đề nhanh hơn.\n",
            "(b) Có khả năng giải quyết đa dạng các bài toán hơn.\n",
            "(c) Giải quyết được các vấn đề, bài toán khó và phức tạp.\n",
            "(d) Dễ dàng cài đặt.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3. Xét đoạn code dưới đây:\n",
            "1import os\n",
            "2from autogen import ConversableAgent\n",
            "3\n",
            "4agent = ConversableAgent (\n",
            "5 \" chatbot \",\n",
            "6 llm_config ={\" config_list \": [{\n",
            "7 \" model \": \"gpt -3.5 - turbo \",\n",
            "8 \" api_key \": os. environ .get (\" OPENAI_API_KEY \")\n",
            "9 }]} ,\n",
            "10)\n",
            "Agent trên được khởi tạo như là:\n",
            "(a) Một mô hình LLM.\n",
            "(b) Một công cụ thực thi code.\n",
            "(c) Một máy ảo.\n",
            "(d) Công cụ lưu trữ lịch sử hội thoại.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "4. Một agent có khả năng thực thi script (Code Executors) (ví dụ như python code) sẽ tồn tại rủi\n",
            "ro tiềm ẩn nào?\n",
            "(a) Giống như chúng ta chạy code python nên không có rủi ro.\n",
            "(b) LLM có thể sinh ra các script nhằm đánh cắp dữ liệu của máy HOST.\n",
            "(c) Khiến máy HOST bị chậm do tiêu tốn tài nguyên CPU/GPU.\n",
            "(d) Tiêu tốn không gian lưu trữ dữ liệu mà agent tải về.\n",
            "5. ĐâuKHÔNG là một giái pháp để giảm thiểu rủi ro cho một Code Executors Agent?\n",
            "(a) Luôn luôn yêu cầu sự kiểm tra của con người trước khi cho agent thực thi code.\n",
            "(b) Sử dụng máy ảo để thực thi code.\n",
            "(c) Sử dụng công cụ Containerization (ví dụ Docker Container).\n",
            "(d) Sử dụng Jupyter Notebook để thực thi code.\n",
            "6. Xét đoạn code dưới đây:\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1executor = DockerCommandLineCodeExecutor (\n",
            "2 image =\" python :3.11 - slim \",\n",
            "3 timeout =10 ,\n",
            "4 work_dir = temp_dir .name ,\n",
            "5)\n",
            "Ý nghĩa của dòng thứ 2 là gì?\n",
            "(a) Khai báo tên của docker container.\n",
            "(b) Khai báo tên của docker image.\n",
            "(c) Khai báo tên docker image được dùng để thực thi.\n",
            "(d) Khai báo tên của Code Executor Agent.\n",
            "7. Xét đoạn code dưới đây:\n",
            "1human_proxy = ConversableAgent (\n",
            "2 \" human_proxy \",\n",
            "3 human_input_mode =\" ALWAYS \",\n",
            "4)\n",
            "Ý nghĩa của dòng thứ 3 là gì?\n",
            "(a) Là message từ user truyển cho agent tại thời điểm khởi tạo.\n",
            "(b) Cho phép agent có khả năng thực thi code.\n",
            "(c) Luôn luôn yêu cầu message của con người trước khi agent thực thi.\n",
            "(d) Cho phép con người truyển message bất cứ khi nào.\n",
            "8. Trong Autogen framework, đâu là cách để chấm dứt cuộc hội thoại, trò chuyện?\n",
            "(a) Dùngmax_turns parameter trong hàm initiate_chat .\n",
            "(b) Dùngmax_consecutive_auto_reply parameter khi khởi tạo agent.\n",
            "(c) Dùngis_termination_msg parameter khi khởi tạo agent.\n",
            "(d) Cả 3 cách trên.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "9. Xét đoạn code dưới đây:\n",
            "1executor = DockerCommandLineCodeExecutor (\n",
            "2 image =\" python :3.11 - slim \",\n",
            "3 timeout =10 ,\n",
            "4 work_dir = temp_dir .name ,\n",
            "5)\n",
            "6\n",
            "7userproxy = UserProxyAgent (\n",
            "8 name =\" userproxy \",\n",
            "9 human_input_mode =\" NEVER \",\n",
            "10 is_termination_msg = lambda msg : \" TERMINATE \" in msg[\" content \"],\n",
            "11 max_consecutive_auto_reply =5,\n",
            "12 code_execution_config ={\" executor \": executor },\n",
            "13)\n",
            "14\n",
            "15executor . stop ()\n",
            "Ý nghĩa của line thứ 15 là gì?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(a) Chấm dứt cuộc hội thoại.\n",
            "(b) Ngắt hội thoại của userproxy agent.\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(c) Dừng docker container được dùng để thực thi code.\n",
            "(d) Dừng việc thực thi code.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "10. Vai trò của Group Chat Manager trong group chat là gì?\n",
            "(a) Chọn ra một Agent duy nhất để thực hiện task.\n",
            "(b) Nhận task từ Boss Agent, sau đó phân tán task cho tất cả các Agent trong group.\n",
            "(c) Thu thập kết quả từ các Agent sau đó đưa ra câu trả lời.\n",
            "(d) Nhận task từ Boss Agent, chọn một Agent thực hiện task, lặp lại cho tới khi hoàn thành.\n",
            "- Hết -\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "VAE-based Image Colorization\n",
            "Khanh Duong, Tien-Huy Nguyen và Nhu-Tai Do\n",
            "Ngày 2 tháng 4 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Image Colorization là quá trình dự đoán màu cho các ảnh đen trắng, giúp tái tạo lại hình ảnh thực\n",
            "tế từ dữ liệu đơn sắc, mang lại trải nghiệm hình ảnh phong phú và sống động. Với đầu vào là một ảnh\n",
            "xám, biểu thị cường độ sáng của ảnh, mô hình sẽ học cách ước tính các kênh màu của ảnh, tạo ra một\n",
            "hình ảnh hợp lý và hài hòa về mặt thị giác.\n",
            "Hình 1: Ví dụ minh họa cho bài toán Image Colorization.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Vấn đề tô màu cho ảnh mang lại một sự thuận lợi đáng kể về mặt dữ liệu, khi mà việc gán nhãn bị\n",
            "loại bỏ hoàn toàn. Bởi, mỗi bức ảnh đều có thể được phân chia thành hai thành phần thông tin chính:\n",
            "gray channel và color channel. Trong đó, gray channel được sử dụng làm đầu vào cho mô hình, đóng\n",
            "vai trò là cơ sở cho quá trình dự đoán. Mô hình sẽ tiến hành dự đoán color channel, tức là thông tin về\n",
            "màu sắc, dựa trên gray channel. Khi mà mô hình đã hoàn thành việc dự đoán, color channel sẽ được\n",
            "kết hợp với gray channel để tạo ra một ảnh hoàn chỉnh.\n",
            "Trong các bài toán tô màu cho ảnh, không gian màu phổ biến thường được sử dụng là Labthay vì\n",
            "RGBnhư trong các bài toán xử lý ảnh thông thường, trong đó:\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 2: Minh họa cho không gian màu Lab\n",
            "•L (Lightness) : Đây là thành phần đại diện cho độ sáng của một pixel trong ảnh. Thành phần L\n",
            "có thể được xem như phiên bản grayscale của ảnh.\n",
            "•a (Green-Red) : Thành phần abiểu diễn sự khác biệt màu giữa các màu xanh lam và đỏ. Khi\n",
            "giá trị của atăng, màu sắc trở nên đỏ hơn. Khi giá trị giảm, màu sắc trở nên xanh hơn.\n",
            "•b (Blue-Yellow) : Thành phần bbiểu diễn sự khác biệt màu giữa các màu xanh lá cây và màu\n",
            "vàng. Khi giá trị của btăng, màu sắc trở nên vàng hơn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Khi giá trị giảm, màu sắc trở nên xanh\n",
            "hơn.\n",
            "Bằng cách sử dụng không gian màu Lab, mô hình của chúng ta sẽ nhận đầu vào là kênh L, đại diện\n",
            "cho độ sáng, và sử dụng kênh abnhư ground truth của mô hình. Vì vậy, số lượng kênh màu cần dự\n",
            "đoán là 2, bao gồm thành phần màu a và b, giúp giảm bớt độ phức tạp so với việc dự đoán 3 kênh màu\n",
            "khi sử dụng không gian màu RGB.\n",
            "Có nhiều phương pháp được sử dụng để thực hiện việc tô màu cho ảnh, bao gồm sử dụng mạng\n",
            "CNN truyền thống, hay các mạng tạo sinh đã và đang phát triển trong những năm gần đây như GAN,\n",
            "VAE (Variational Autoencoder) và cả Diffusion Models. Mỗi phương pháp mang lại những ưu điểm và\n",
            "hạn chế riêng, đều hướng tới mục tiêu cuối cùng là tạo ra các ảnh màu tự nhiên và chân thực.\n",
            "Trong phần này, chúng ta sẽ tập trung vào việc xây dựng một mô hình dựa trên VAE để giải quyết\n",
            "vấn đề Image Colorization. Input và output của chương trình như sau:\n",
            "•Input:Ảnh xám G (L channel).\n",
            "•Output: Trường ảnh màu C (ab channels).\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Nội dung\n",
            "Trong phần này, chúng ta sẽ triển khai mô hình VAE-base Image Colorization dựa trên bài báo Learning\n",
            "Diverse Image Colorization để học cách tạo ra tập ảnh màu đa dạng về mặt kết quả. Cụ thể, ta sẽ xây\n",
            "dựng chương trình dựa trên bộ dữ liệu LFW (Labeled Faces in the Wild Home), một trong những bộ\n",
            "dữ liệu quan trọng và phổ biến trong lĩnh vực nhận dạng khuôn mặt. Bộ dữ liệu này chứa các hình ảnh\n",
            "của khuôn mặt được thu thập từ các bức ảnh chụp thực tế, bao gồm nhiều điều kiện ánh sáng, góc chụp\n",
            "và nền khác nhau.\n",
            "Hình 3: Ảnh minh họa cho LFW dataset\n",
            "Theo đó, nội dung thực nghiệm sẽ trình bày với các thành phần như sau:\n",
            "a) Data Preparation: Chuẩn bị dữ liệu cho tập huấn luyện.\n",
            "b) Models: Xây dựng mô hình VAE và mô hình MDN (Mixture Density Network).\n",
            "c) Loss Functions: Xây dựng hàm mất mát cho mô hình VAE và mô hình MDN.\n",
            "d) Trainer: Xây dựng các hàm để huấn luyện cho từng mô hình.\n",
            "e) Inference: Minh họa kết quả đạt được sau khi huấn luyện mô hình.\n",
            "1.Data Preparation\n",
            "Đầu tiên, chúng ta cần chuẩn bị bộ dữ liệu LFW thông qua dòng lệnh dưới đây. Bộ dữ liệu bao\n",
            "gồm hơn 12,000 ảnh train và 1,000 ảnh test. Cùng với đó là một bộ đặc trưng tương ứng với từng\n",
            "ảnh, trích xuất từ một mạng VGG được huấn luyện mạnh mẽ trên bộ dữ liệu lớn ImageNet.\n",
            "Tải dữ liệu\n",
            "1! gdown 187 x5YSXYibG4QwC5m_Hx8cNzPGVTXv6G\n",
            "2! unzip -q data .zip\n",
            "3!rm data .zip\n",
            "Khai báo các thư viện:\n",
            "1import os\n",
            "2import numpy as np\n",
            "3from tqdm import tqdm\n",
            "4import torch\n",
            "5import torch .nn as nn\n",
            "6import torch .nn. functional as F\n",
            "7import torch . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "optim as optim\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "8from torch . utils . data import DataLoader\n",
            "9import cv2\n",
            "10import numpy as np\n",
            "11from torch . utils . data import Dataset\n",
            "Khởi tạo class ColorDataset:\n",
            "1class ColorDataset ( Dataset ):\n",
            "2 def __init__ (self , out_directory , listdir =None ,\n",
            "3 featslistdir =None , shape =(64 , 64) ,\n",
            "4 outshape =(256 , 256) , split =\" train \"):\n",
            "5\n",
            "6 # Save paths to a list\n",
            "7 self . img_fns = []\n",
            "8 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "feats_fns = []\n",
            "9\n",
            "10 with open (\"%s/ list .%s. vae.txt\" % ( listdir , split ), \"r\") as ftr:\n",
            "11 for img_fn in ftr :\n",
            "12 self . img_fns . append ( img_fn . strip (\"\\n\"))\n",
            "13\n",
            "14 with open (\"%s/ list .%s. txt\" % ( featslistdir , split ), \"r\") as ftr:\n",
            "15 for feats_fn in ftr:\n",
            "16 self . feats_fns . append ( feats_fn . strip (\"\\n\"))\n",
            "17\n",
            "18 self . img_num = min( len( self . img_fns ), len( self . feats_fns ))\n",
            "19 self . shape = shape\n",
            "20 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "outshape = outshape\n",
            "21 self . out_directory = out_directory\n",
            "22\n",
            "23 # Create a dictionary to save weight of 313 ab bins\n",
            "24 self . lossweights = None\n",
            "25 countbins = 1.0 / np. load (\" data / zhang_weights / prior_probs .npy \")\n",
            "26 binedges = np. load (\" data / zhang_weights / ab_quantize .npy\"). reshape (2, 313)\n",
            "27 lossweights = {}\n",
            "28 for i in range (313) :\n",
            "29 if binedges [0, i] not in lossweights :\n",
            "30 lossweights [ binedges [0, i]] = {}\n",
            "31 lossweights [ binedges [0, i]][ binedges [1, i]] = countbins [i]\n",
            "32 self . binedges = binedges\n",
            "33 self . lossweights = lossweights\n",
            "34\n",
            "35 def __len__ ( self ):\n",
            "36 return self . img_num\n",
            "37\n",
            "38 def __getitem__ (self , idx):\n",
            "39 # Declare empty arrays to get values\n",
            "40 color_ab = np. zeros ((2 , self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "shape [0] , self . shape [1]) ,\n",
            "41 dtype =\"f\")\n",
            "42 weights = np. ones ((2 , self . shape [0] , self . shape [1]) ,\n",
            "43 dtype =\"f\")\n",
            "44 recon_const = np. zeros ((1 , self . shape [0] , self . shape [1]) ,\n",
            "45 dtype =\"f\")\n",
            "46 recon_const_outres = np. zeros ((1 , self . outshape [0] , self . outshape [1]) ,\n",
            "47 dtype =\"f\")\n",
            "48 greyfeats = np. zeros ((512 , 28, 28) , dtype =\"f\")\n",
            "49\n",
            "50 # Read and reshape\n",
            "51 img_large = cv2. imread ( self . img_fns [idx ])\n",
            "52 if self . shape is not None :\n",
            "53 img = cv2. resize ( img_large , ( self . shape [0] , self . shape [1]) )\n",
            "54 img_outres = cv2. resize ( img_large ,\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "55 ( self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "outshape [0] , self . outshape [1]) )\n",
            "56\n",
            "57 # Convert BGR to LAB\n",
            "58 img_lab = cv2. cvtColor (img , cv2. COLOR_BGR2LAB )\n",
            "59 img_lab_outres = cv2. cvtColor ( img_outres , cv2. COLOR_BGR2LAB )\n",
            "60\n",
            "61 # Normalize to [ -1..1]\n",
            "62 img_lab = (( img_lab * 2.0) / 255.0) - 1.0\n",
            "63 img_lab_outres = (( img_lab_outres * 2.0) / 255.0) - 1.0\n",
            "64\n",
            "65 recon_const [0, :, :] = img_lab [... , 0]\n",
            "66 recon_const_outres [0, :, :] = img_lab_outres [... , 0]\n",
            "67\n",
            "68 color_ab [0, :, :] = img_lab [... , 1]. reshape (1, self . shape [0] ,\n",
            "69 self . shape [1])\n",
            "70 color_ab [1, :, :] = img_lab [... , 2]. reshape (1, self . shape [0] ,\n",
            "71 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "shape [1])\n",
            "72\n",
            "73 if self . lossweights is not None :\n",
            "74 weights = self . __getweights__ ( color_ab )\n",
            "75\n",
            "76 # Load feature maps\n",
            "77 featobj = np. load ( self . feats_fns [idx ])\n",
            "78 greyfeats [:, :, :] = featobj [\" arr_0 \"]\n",
            "79\n",
            "80 return color_ab , recon_const , weights , recon_const_outres , greyfeats\n",
            "81\n",
            "82 def __getweights__ (self , img):\n",
            "83 \"\"\"\n",
            "84 Calculate weight values for each pixel of an image .\n",
            "85 \"\"\"\n",
            "86 img_vec = img. reshape ( -1)\n",
            "87 img_vec = img_vec * 128.0\n",
            "88 img_lossweights = np. zeros (img.shape , dtype =\"f\")\n",
            "89 img_vec_a = img_vec [: np. prod ( self . shape )]\n",
            "90 binedges_a = self . binedges [0, ...]. reshape ( -1)\n",
            "91 binid_a = [ binedges_a . flat [np.abs( binedges_a - v). argmin ()]\n",
            "92 for v in img_vec_a ]\n",
            "93 img_vec_b = img_vec [np. prod ( self . shape ) :]\n",
            "94 binedges_b = self . binedges [1, ...]. reshape ( -1)\n",
            "95 binid_b = [ binedges_b . flat [np.abs( binedges_b - v). argmin ()]\n",
            "96 for v in img_vec_b ]\n",
            "97 binweights = np. array ([ self . lossweights [v1 ][ v2] for v1 , v2 in zip( binid_a\n",
            ", binid_b )])\n",
            "98 img_lossweights [0, :, :] = binweights . reshape ( self . shape [0] ,\n",
            "99 self . shape [1])\n",
            "100 img_lossweights [1, :, :] = binweights . reshape ( self . shape [0] , self . shape\n",
            "[1])\n",
            "101 return img_lossweights\n",
            "102\n",
            "103 def saveoutput_gt (self , net_op , gt , prefix , batch_size ,\n",
            "104 num_cols =8, net_recon_const = None ):\n",
            "105 \"\"\"\n",
            "106 Save images\n",
            "107 \"\"\"\n",
            "108 net_out_img = self . __tiledoutput__ ( net_op , batch_size , num_cols = num_cols ,\n",
            "109 net_recon_const = net_recon_const )\n",
            "110 gt_out_img = self . __tiledoutput__ (gt , batch_size , num_cols = num_cols ,\n",
            "111 net_recon_const = net_recon_const )\n",
            "112\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "113 num_rows = np. int_ (np. ceil (( batch_size * 1.0) / num_cols ))\n",
            "114 border_img = 255 * np. ones (( num_rows * self . outshape [0] , 128 , 3) ,\n",
            "115 dtype =\" uint8 \")\n",
            "116 out_fn_pred = \"%s/%s.png\" % ( self . out_directory , prefix )\n",
            "117 cv2 . imwrite ( out_fn_pred ,\n",
            "118 np. concatenate (( net_out_img , border_img , gt_out_img ), axis =1)\n",
            ")\n",
            "119\n",
            "120 def __tiledoutput__ (self , net_op , batch_size ,\n",
            "121 num_cols =8, net_recon_const = None ):\n",
            "122 \"\"\"\n",
            "123 Generate a combined image from these inputs by stitching the images into\n",
            "a large image .\n",
            "124 \"\"\"\n",
            "125 num_rows = np. int_ (np. ceil (( batch_size * 1.0) / num_cols ))\n",
            "126 out_img = np. zeros (( num_rows * self . outshape [0] , num_cols * self . outshape [1] ,\n",
            "3) ,\n",
            "127 dtype =\" uint8 \")\n",
            "128 img_lab = np. zeros (( self . outshape [0] , self . outshape [1] , 3) ,\n",
            "129 dtype =\" uint8 \")\n",
            "130 c = 0\n",
            "131 r = 0\n",
            "132\n",
            "133 for i in range ( batch_size ):\n",
            "134 if i % num_cols == 0 and i > 0:\n",
            "135 r = r + 1\n",
            "136 c = 0\n",
            "137 img_lab [... , 0] = self . __decodeimg__ ( net_recon_const [i, 0, :, :].\n",
            "reshape ( self . outshape [0] , self . outshape [1]) )\n",
            "138 img_lab [... , 1] = self . __decodeimg__ ( net_op [i, 0, :, :]. reshape ( self .\n",
            "shape [0] , self . shape [1]) )\n",
            "139 img_lab [... , 2] = self . __decodeimg__ ( net_op [i, 1, :, :]. reshape ( self .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "shape [0] , self . shape [1]) )\n",
            "140 img_rgb = cv2. cvtColor ( img_lab , cv2 . COLOR_LAB2BGR )\n",
            "141 out_img [\n",
            "142 r * self . outshape [0] : (r + 1) * self . outshape [0] ,\n",
            "143 c * self . outshape [1] : (c + 1) * self . outshape [1] ,\n",
            "144 ... ,\n",
            "145 ] = img_rgb\n",
            "146 c = c + 1\n",
            "147\n",
            "148 return out_img\n",
            "149\n",
            "150 def __decodeimg__ (self , img_enc ):\n",
            "151 \"\"\"\n",
            "152 Denormalize from [ -1..1] to [0..255]\n",
            "153 \"\"\"\n",
            "154 img_dec = ((( img_enc + 1.0) * 1.0) / 2.0) * 255.0\n",
            "155 img_dec [ img_dec < 0.0] = 0.0\n",
            "156 img_dec [ img_dec > 255.0] = 255.0\n",
            "157 return cv2. resize (np. uint8 ( img_dec ), ( self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "outshape [0] , self . outshape [1])\n",
            ")\n",
            "Khởi tạo các siêu tham số toàn cụ cho chương trình.\n",
            "1# Declare hyperparameters\n",
            "2args = {\n",
            "3 \"gpu\": 1,\n",
            "4 \" epochs \": 2,\n",
            "5 \" batchsize \": 32,\n",
            "6 \" hiddensize \": 64,\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "7 \" nthreads \": 2,\n",
            "8 \" epochs_mdn \": 2,\n",
            "9 \" nmix \": 8,\n",
            "10 \" logstep \": 100 ,\n",
            "11 \" dataset_key \": \"lfw\"\n",
            "12}\n",
            "13\n",
            "14def get_dirpaths ( args ):\n",
            "15 if args [\" dataset_key \"] == \"lfw\":\n",
            "16 out_dir = \" data / output / lfw\"\n",
            "17 listdir = \" data / imglist / lfw\"\n",
            "18 featslistdir = \" data / featslist /lfw \"\n",
            "19 else :\n",
            "20 raise NameError (\"[ ERROR ] Incorrect key: %s\" % ( args . dataset_key ))\n",
            "21 return out_dir , listdir , featslistdir\n",
            "2.Models\n",
            "Chúng ta sẽ tiến hành xây dựng mô hình VAE và mô hình MDN.\n",
            "(a)VAE model: Trong bài toán này, chúng ta sẽ sử dụng một biến thể của mô hình VAE, được\n",
            "gọi là Conditional VAE (CVAE). Mô hình này bao gồm ba phần: khối Encoder chính và khối\n",
            "Decoder chính (hai khối này tạo thành một mạng VAE cơ bản, được bao quanh bởi hình chữ\n",
            "nhật màu đỏ), cùng với một khối Conditional Encoder (khối này giúp mô hình tận dụng tối\n",
            "đa những trường thông tin có sẵn). Đầu vào của mạng VAE cơ bản là trường màu C có kích\n",
            "thước (2 x h x w), và đầu ra là một feature map có kích thước tương tự (2 x h x w). Đồng\n",
            "thời, ảnh xám G (1 x h x w) cũng được sử dụng làm điểm khởi đầu cho khối Conditional\n",
            "Encoder để trích xuất các feature maps chứa thông tin cục bộ, và sau đó được sử dụng làm\n",
            "điều kiện để làm tăng khả năng cho khối Decoder.\n",
            "Hình 4: Ảnh minh họa cho mô hình Conditional VAE.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1import torch\n",
            "2import torch .nn as nn\n",
            "3import torch .nn. functional as F\n",
            "4\n",
            "5class VAE(nn. Module ):\n",
            "6 def __init__ ( self ):\n",
            "7 super (VAE , self ). __init__ ()\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "8 self . hidden_size = 64\n",
            "9\n",
            "10 # Encoder block\n",
            "11 self . enc_conv1 = nn. Conv2d (2, 128 , 5, stride =2, padding =2)\n",
            "12 self . enc_bn1 = nn. BatchNorm2d (128)\n",
            "13 self . enc_conv2 = nn. Conv2d (128 , 256 , 5, stride =2, padding =2)\n",
            "14 self . enc_bn2 = nn. BatchNorm2d (256)\n",
            "15 self . enc_conv3 = nn. Conv2d (256 , 512 , 5, stride =2, padding =2)\n",
            "16 self . enc_bn3 = nn. BatchNorm2d (512)\n",
            "17 self . enc_conv4 = nn. Conv2d (512 , 1024 , 3, stride =2, padding =1)\n",
            "18 self . enc_bn4 = nn. BatchNorm2d (1024)\n",
            "19 self . enc_fc1 = nn. Linear (4*4*1024 , self . hidden_size *2)\n",
            "20 self . enc_dropout1 = nn. Dropout (p =0.7)\n",
            "21\n",
            "22 # Conditional encoder block\n",
            "23 self . cond_enc_conv1 = nn. Conv2d (1, 128 , 5, stride =2, padding =2)\n",
            "24 self . cond_enc_bn1 = nn. BatchNorm2d (128)\n",
            "25 self . cond_enc_conv2 = nn. Conv2d (128 , 256 , 5, stride =2, padding =2)\n",
            "26 self . cond_enc_bn2 = nn. BatchNorm2d (256)\n",
            "27 self . cond_enc_conv3 = nn. Conv2d (256 , 512 , 5, stride =2, padding =2)\n",
            "28 self . cond_enc_bn3 = nn. BatchNorm2d (512)\n",
            "29 self . cond_enc_conv4 = nn. Conv2d (512 , 1024 , 3, stride =2, padding =1)\n",
            "30 self . cond_enc_bn4 = nn. BatchNorm2d (1024)\n",
            "31\n",
            "32 # Decoder block\n",
            "33 self . dec_upsamp1 = nn. Upsample ( scale_factor =4, mode =’bilinear ’)\n",
            "34 self . dec_conv1 = nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Conv2d (1024+ self . hidden_size , 512 , 3, stride =1,\n",
            "padding =1)\n",
            "35 self . dec_bn1 = nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "BatchNorm2d (512)\n",
            "36 self . dec_upsamp2 = nn. Upsample ( scale_factor =2, mode =’bilinear ’)\n",
            "37 self . dec_conv2 = nn. Conv2d (512*2 , 256 , 5, stride =1, padding =2)\n",
            "38 self . dec_bn2 = nn. BatchNorm2d (256)\n",
            "39 self . dec_upsamp3 = nn. Upsample ( scale_factor =2, mode =’bilinear ’)\n",
            "40 self . dec_conv3 = nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Conv2d (256*2 , 128 , 5, stride =1, padding =2)\n",
            "41 self . dec_bn3 = nn. BatchNorm2d (128)\n",
            "42 self . dec_upsamp4 = nn. Upsample ( scale_factor =2, mode =’bilinear ’)\n",
            "43 self . dec_conv4 = nn. Conv2d (128*2 , 64, 5, stride =1, padding =2)\n",
            "44 self . dec_bn4 = nn. BatchNorm2d (64)\n",
            "45 self . dec_upsamp5 = nn. Upsample ( scale_factor =2, mode =’bilinear ’)\n",
            "46 self . dec_conv5 = nn. Conv2d (64 , 2, 5, stride =1, padding =2)\n",
            "47\n",
            "48 def encoder (self , x):\n",
            "49 x = F. relu ( self . enc_conv1 (x))\n",
            "50 x = self . enc_bn1 (x)\n",
            "51 x = F. relu ( self . enc_conv2 (x))\n",
            "52 x = self . enc_bn2 (x)\n",
            "53 x = F. relu ( self . enc_conv3 (x))\n",
            "54 x = self . enc_bn3 (x)\n",
            "55 x = F. relu ( self . enc_conv4 (x))\n",
            "56 x = self . enc_bn4 (x)\n",
            "57 x = x. view (-1, 4*4*1024)\n",
            "58 x = self . enc_dropout1 (x)\n",
            "59 x = self . enc_fc1 (x)\n",
            "60 mu = x[... , : self . hidden_size ]\n",
            "61 logvar = x[... , self . hidden_size :]\n",
            "62 return mu , logvar\n",
            "63\n",
            "64 def cond_encoder (self , x):\n",
            "65 x = F. relu ( self . cond_enc_conv1 (x))\n",
            "66 sc_feat32 = self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "cond_enc_bn1 (x)\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "67 x = F. relu ( self . cond_enc_conv2 ( sc_feat32 ))\n",
            "68 sc_feat16 = self . cond_enc_bn2 (x)\n",
            "69 x = F. relu ( self . cond_enc_conv3 ( sc_feat16 ))\n",
            "70 sc_feat8 = self . cond_enc_bn3 (x)\n",
            "71 x = F. relu ( self . cond_enc_conv4 ( sc_feat8 ))\n",
            "72 sc_feat4 = self . cond_enc_bn4 (x)\n",
            "73 return sc_feat32 , sc_feat16 , sc_feat8 , sc_feat4\n",
            "74\n",
            "75 def decoder (self , z, sc_feat32 , sc_feat16 , sc_feat8 , sc_feat4 ):\n",
            "76 x = z. view (-1, self . hidden_size , 1, 1)\n",
            "77 x = self . dec_upsamp1 (x)\n",
            "78 x = torch . cat ([x, sc_feat4 ], 1)\n",
            "79 x = F. relu ( self . dec_conv1 (x))\n",
            "80 x = self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "dec_bn1 (x)\n",
            "81 x = self . dec_upsamp2 (x)\n",
            "82 x = torch . cat ([x, sc_feat8 ], 1)\n",
            "83 x = F. relu ( self . dec_conv2 (x))\n",
            "84 x = self . dec_bn2 (x)\n",
            "85 x = self . dec_upsamp3 (x)\n",
            "86 x = torch . cat ([x, sc_feat16 ], 1)\n",
            "87 x = F. relu ( self . dec_conv3 (x))\n",
            "88 x = self . dec_bn3 (x)\n",
            "89 x = self . dec_upsamp4 (x)\n",
            "90 x = torch . cat ([x, sc_feat32 ], 1)\n",
            "91 x = F. relu ( self . dec_conv4 (x))\n",
            "92 x = self . dec_bn4 (x)\n",
            "93 x = self . dec_upsamp5 (x)\n",
            "94 x = torch . tanh ( self . dec_conv5 (x))\n",
            "95 return x\n",
            "96\n",
            "97 def forward (self , color , greylevel , z_in = None ):\n",
            "98 sc_feat32 , sc_feat16 , sc_feat8 , sc_feat4 = self . cond_encoder (\n",
            "greylevel )\n",
            "99 mu , logvar = self . encoder ( color )\n",
            "100 if self . training :\n",
            "101 stddev = torch . sqrt ( torch .exp( logvar ))\n",
            "102 eps = torch . randn_like ( stddev )\n",
            "103 z = mu + eps * stddev\n",
            "104 z = z.to( greylevel . device )\n",
            "105 else :\n",
            "106 z = z_in\n",
            "107 z = z.to( greylevel . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "device )\n",
            "108 color_out = self . decoder (z, sc_feat32 , sc_feat16 , sc_feat8 , sc_feat4 )\n",
            "109 return mu , logvar , color_out\n",
            "(b)MDN model\n",
            "Đầu vào của một mạng Conditional Variational Autoencoder (CVAE) yêu cầu thông tin về\n",
            "cả trường màu C và ảnh xám G. Trong quá trình huấn luyện, khối Encoder chính ánh xạ\n",
            "thông tin của trường màu C thành phân phối hậu nghiệm P, sau đó lấy mẫu từ phân phối\n",
            "P để làm điểm khởi đầu cho khối Decoder. Tuy nhiên, trong quá trình dự đoán, không có\n",
            "thông tin về trường màu C được cung cấp. Chính vì thế, một mạng MDN (Mixture Density\n",
            "Network) được đã được thiết kế. MDN nhận đầu vào là vector đặc trưng, được tạo ra bằng\n",
            "cách cho ảnh xám G đi qua mạng VGG đã được huấn luyện trước trong bài báo Colorful\n",
            "Image Colorization. Kết quả đầu ra của mô hình MDN sau đó được sử dụng để tạo ra các\n",
            "tham số phân phối cho mô hình Gaussian Mixture Model, một mô hình thực hiện việc xấp\n",
            "xỉ phân phối P được tạo ra từ khối Encoder vừa được huấn luyện trước đó.\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 5: Ảnh minh họa cho mô hình MDN.\n",
            "1import torch\n",
            "2import torch .nn as nn\n",
            "3import torch .nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "functional as F\n",
            "4\n",
            "5class MDN(nn. Module ):\n",
            "6 def __init__ ( self ):\n",
            "7 super (MDN , self ). __init__ ()\n",
            "8\n",
            "9 self . feats_nch = 512\n",
            "10 self . hidden_size = 64\n",
            "11 self . nmix = 8\n",
            "12 self . nout = ( self . hidden_size + 1) * self . nmix\n",
            "13\n",
            "14 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "model = nn. Sequential (\n",
            "15 nn. Conv2d ( self . feats_nch , 384 , 5, stride =1, padding =2) ,\n",
            "16 nn. BatchNorm2d (384) ,\n",
            "17 nn. ReLU () ,\n",
            "18 nn. Conv2d (384 , 320 , 5, stride =1, padding =2) ,\n",
            "19 nn. BatchNorm2d (320) ,\n",
            "20 nn. ReLU () ,\n",
            "21 nn. Conv2d (320 , 288 , 5, stride =1, padding =2) ,\n",
            "22 nn. BatchNorm2d (288) ,\n",
            "23 nn. ReLU () ,\n",
            "24 nn. Conv2d (288 , 256 , 5, stride =2, padding =2) ,\n",
            "25 nn. BatchNorm2d (256) ,\n",
            "26 nn. ReLU () ,\n",
            "27 nn. Conv2d (256 , 128 , 5, stride =1, padding =2) ,\n",
            "28 nn. BatchNorm2d (128) ,\n",
            "29 nn. ReLU () ,\n",
            "30 nn. Conv2d (128 , 96, 5, stride =2, padding =2) ,\n",
            "31 nn. BatchNorm2d (96) ,\n",
            "32 nn. ReLU () ,\n",
            "33 nn. Conv2d (96 , 64, 5, stride =2, padding =2) ,\n",
            "34 nn. BatchNorm2d (64) ,\n",
            "35 nn. ReLU () ,\n",
            "36 nn. Dropout (p =0.7)\n",
            "37 )\n",
            "38\n",
            "39 self .fc = nn. Linear (4 * 4 * 64, self . nout )\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "40\n",
            "41 def forward (self , feats ):\n",
            "42 x = self . model ( feats )\n",
            "43 x = x. view (-1, 4 * 4 * 64)\n",
            "44 x = F. relu (x)\n",
            "45 x = F. dropout (x, p=0.7 , training = self . training )\n",
            "46 x = self .fc(x)\n",
            "47 return x\n",
            "3.Loss Functions\n",
            "Trong phần này chúng ta xây dựng hàm mất mát cho các mô hình VAE và MDN.\n",
            "VAE Loss\n",
            "Hình 6: Ảnh minh họa cho VAE Loss.\n",
            "1def vae_loss (mu , logvar , pred , gt , lossweights , batchsize ):\n",
            "2 \"\"\"\n",
            "3 Return the loss values of the VAE model .\n",
            "4 \"\"\"\n",
            "5 kl_element = torch .add( torch .add( torch .add(mu.pow (2) , logvar .exp ()), -1) ,\n",
            "logvar .mul ( -1))\n",
            "6 kl_loss = torch .sum ( kl_element ).mul (0.5)\n",
            "7 gt = gt. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "reshape (-1, 64 * 64 * 2)\n",
            "8 pred = pred . reshape (-1, 64 * 64 * 2)\n",
            "9 recon_element = torch . sqrt ( torch .sum( torch .mul ( torch .add(gt , pred .mul ( -1)).\n",
            "pow (2) , lossweights ), 1))\n",
            "10 recon_loss = torch .sum( recon_element ).mul (1.0 / ( batchsize ))\n",
            "11\n",
            "12 recon_element_l2 = torch . sqrt ( torch .sum ( torch .add(gt , pred .mul ( -1)).pow (2) ,\n",
            "1))\n",
            "13 recon_loss_l2 = torch .sum ( recon_element_l2 ).mul (1.0 / ( batchsize ))\n",
            "14\n",
            "15 return kl_loss , recon_loss , recon_loss_l2\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "MDN Loss\n",
            "Hình 7: Ảnh minh họa cho MDN Loss.\n",
            "1def get_gmm_coeffs ( gmm_params ):\n",
            "2 \"\"\"\n",
            "3 Return the distribution coefficients of the GMM .\n",
            "4 \"\"\"\n",
            "5 gmm_mu = gmm_params [... , : args [\" hiddensize \"] * args [\" nmix \"]]\n",
            "6 gmm_mu . contiguous ()\n",
            "7 gmm_pi_activ = gmm_params [... , args [\" hiddensize \"] * args [\" nmix \"] :]\n",
            "8 gmm_pi_activ . contiguous ()\n",
            "9 gmm_pi = F. softmax ( gmm_pi_activ , dim =1)\n",
            "10 return gmm_mu , gmm_pi\n",
            "11\n",
            "12def mdn_loss ( gmm_params , mu , stddev , batchsize ):\n",
            "13 \"\"\"\n",
            "14 Calculates the loss by comparing two distribution\n",
            "15 - the predicted distribution of the MDN ( given by gmm_mu and gmm_pi ) with\n",
            "16 - the target distribution created by the Encoder block ( given by mu and\n",
            "stddev ).\n",
            "17 \"\"\"\n",
            "18 gmm_mu , gmm_pi = get_gmm_coeffs ( gmm_params )\n",
            "19 eps = torch . randn ( stddev . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "size ()). normal_ (). cuda ()\n",
            "20 z = torch . add(mu , torch .mul(eps , stddev ))\n",
            "21 z_flat = z. repeat (1, args [\" nmix \"])\n",
            "22 z_flat = z_flat . reshape ( batchsize * args [\" nmix \"], args [\" hiddensize \"])\n",
            "23 gmm_mu_flat = gmm_mu . reshape ( batchsize * args [\" nmix \"], args [\" hiddensize \"])\n",
            "24 dist_all = torch . sqrt ( torch .sum ( torch .add(z_flat , gmm_mu_flat .mul ( -1)).pow (2)\n",
            ".mul (50) , 1))\n",
            "25 dist_all = dist_all . reshape ( batchsize , args [\" nmix \"])\n",
            "26 dist_min , selectids = torch .min ( dist_all , 1)\n",
            "27 gmm_pi_min = torch . gather (gmm_pi , 1, selectids . reshape (-1, 1))\n",
            "28 gmm_loss = torch . mean ( torch .add (-1 * torch .log ( gmm_pi_min + 1e -30) , dist_min )\n",
            ")\n",
            "29 gmm_loss_l2 = torch . mean ( dist_min )\n",
            "30 return gmm_loss , gmm_loss_l2\n",
            "4.Trainer\n",
            "Trong phần này chúng ta xây dựng hàm huấn luyện cho từng mô hình.\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Train VAE model\n",
            "1def test_vae ( model ):\n",
            "2 model . eval ()\n",
            "3\n",
            "4 # Load hyperparameters\n",
            "5 out_dir , listdir , featslistdir = get_dirpaths ( args )\n",
            "6 batchsize = args [\" batchsize \"]\n",
            "7 hiddensize = args [\" hiddensize \"]\n",
            "8 nmix = args [\" nmix \"]\n",
            "9\n",
            "10 # Create DataLoader\n",
            "11 data = ColorDataset (\n",
            "12 os. path . join ( out_dir , \" images \"),\n",
            "13 listdir = listdir ,\n",
            "14 featslistdir = featslistdir ,\n",
            "15 split =\" test \",\n",
            "16 )\n",
            "17 nbatches = np. int_ (np. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "floor ( data . img_num / batchsize ))\n",
            "18 data_loader = DataLoader (\n",
            "19 dataset =data ,\n",
            "20 num_workers = args [\" nthreads \"],\n",
            "21 batch_size = batchsize ,\n",
            "22 shuffle =False ,\n",
            "23 drop_last =True ,\n",
            "24 )\n",
            "25\n",
            "26 # Eval\n",
            "27 test_loss = 0.0\n",
            "28 for batch_idx , (\n",
            "29 batch ,\n",
            "30 batch_recon_const ,\n",
            "31 batch_weights ,\n",
            "32 batch_recon_const_outres ,\n",
            "33 _,\n",
            "34 ) in tqdm ( enumerate ( data_loader ), total = nbatches ):\n",
            "35\n",
            "36 input_color = batch . cuda ()\n",
            "37 lossweights = batch_weights . cuda ()\n",
            "38 lossweights = lossweights . reshape ( batchsize , -1)\n",
            "39 input_greylevel = batch_recon_const . cuda ()\n",
            "40 z = torch . randn ( batchsize , hiddensize )\n",
            "41\n",
            "42 mu , logvar , color_out = model ( input_color , input_greylevel , z)\n",
            "43 _, _, recon_loss_l2 = vae_loss (\n",
            "44 mu , logvar , color_out , input_color , lossweights , batchsize\n",
            "45 )\n",
            "46 test_loss = test_loss + recon_loss_l2 . item ()\n",
            "47\n",
            "48 test_loss = ( test_loss * 1.0) / nbatches\n",
            "49 model . train ()\n",
            "50\n",
            "51 return test_loss\n",
            "52\n",
            "53\n",
            "54def train_vae ():\n",
            "55 # Load hyperparameters\n",
            "56 out_dir , listdir , featslistdir = get_dirpaths ( args )\n",
            "57 batchsize = args [\" batchsize \"]\n",
            "58 hiddensize = args [\" hiddensize \"]\n",
            "59 nmix = args [\" nmix \"]\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "60 nepochs = args [\" epochs \"]\n",
            "61\n",
            "62 # Create DataLoader\n",
            "63 data = ColorDataset (\n",
            "64 os. path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "join ( out_dir , \" images \"),\n",
            "65 listdir = listdir ,\n",
            "66 featslistdir = featslistdir ,\n",
            "67 split =\" train \",\n",
            "68 )\n",
            "69 nbatches = np. int_ (np. floor ( data . img_num / batchsize ))\n",
            "70 data_loader = DataLoader (\n",
            "71 dataset =data ,\n",
            "72 num_workers = args [\" nthreads \"],\n",
            "73 batch_size = batchsize ,\n",
            "74 shuffle =True ,\n",
            "75 drop_last =True ,\n",
            "76 )\n",
            "77\n",
            "78 # Initialize VAE model\n",
            "79 model = VAE ()\n",
            "80 model . cuda ()\n",
            "81 model . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "train ()\n",
            "82\n",
            "83 optimizer = optim . Adam ( model . parameters () , lr =5e -5)\n",
            "84\n",
            "85 # Train\n",
            "86 itr_idx = 0\n",
            "87 for epochs in range ( nepochs ):\n",
            "88 train_loss = 0.0\n",
            "89\n",
            "90 for batch_idx , (\n",
            "91 batch ,\n",
            "92 batch_recon_const ,\n",
            "93 batch_weights ,\n",
            "94 batch_recon_const_outres ,\n",
            "95 _,\n",
            "96 ) in tqdm ( enumerate ( data_loader ), total = nbatches ):\n",
            "97\n",
            "98 input_color = batch . cuda ()\n",
            "99 lossweights = batch_weights . cuda ()\n",
            "100 lossweights = lossweights . reshape ( batchsize , -1)\n",
            "101 input_greylevel = batch_recon_const . cuda ()\n",
            "102 z = torch . randn ( batchsize , hiddensize )\n",
            "103\n",
            "104 optimizer . zero_grad ()\n",
            "105 mu , logvar , color_out = model ( input_color , input_greylevel , z)\n",
            "106 kl_loss , recon_loss , recon_loss_l2 = vae_loss (\n",
            "107 mu , logvar , color_out , input_color , lossweights , batchsize\n",
            "108 )\n",
            "109 loss = kl_loss .mul (1e -2) + recon_loss\n",
            "110 recon_loss_l2 . detach ()\n",
            "111 loss . backward ()\n",
            "112 optimizer . step ()\n",
            "113\n",
            "114 train_loss = train_loss + recon_loss_l2 . item ()\n",
            "115\n",
            "116 if batch_idx % args [\" logstep \"] == 0:\n",
            "117 data . saveoutput_gt (\n",
            "118 color_out .cpu (). data . numpy () ,\n",
            "119 batch . numpy () ,\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "120 \" train_ %05 d_ %05d\" % (epochs , batch_idx ),\n",
            "121 batchsize ,\n",
            "122 net_recon_const = batch_recon_const_outres . numpy () ,\n",
            "123 )\n",
            "124\n",
            "125 train_loss = ( train_loss * 1.0) / ( nbatches )\n",
            "126 print (\"VAE Train Loss , epoch %d has loss %f\" % (epochs , train_loss ))\n",
            "127 test_loss = test_vae ( model )\n",
            "128 print (\"VAE Test Loss , epoch %d has loss %f\" % (epochs , test_loss ))\n",
            "129\n",
            "130 # Save VAE model\n",
            "131 torch . save ( model . state_dict () , \"%s/ models / model_vae . pth\" % ( out_dir ))\n",
            "132\n",
            "133 print (\" Complete VAE training \")\n",
            "134\n",
            "135train_vae ()\n",
            "Train MDN model\n",
            "1def test_mdn ( model_vae , model_mdn ):\n",
            "2 # Load hyperparameters\n",
            "3 out_dir , listdir , featslistdir = get_dirpaths ( args )\n",
            "4 batchsize = args [\" batchsize \"]\n",
            "5 hiddensize = args [\" hiddensize \"]\n",
            "6 nmix = args [\" nmix \"]\n",
            "7\n",
            "8 # Create DataLoader\n",
            "9 data = ColorDataset (\n",
            "10 os. path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "join ( out_dir , \" images \"), listdir , featslistdir , split =\" test \"\n",
            "11 )\n",
            "12 nbatches = np. int_ (np. floor ( data . img_num / batchsize ))\n",
            "13 data_loader = DataLoader (\n",
            "14 dataset =data ,\n",
            "15 num_workers = args [\" nthreads \"],\n",
            "16 batch_size = batchsize ,\n",
            "17 shuffle =True ,\n",
            "18 drop_last =True ,\n",
            "19 )\n",
            "20\n",
            "21 optimizer = optim . Adam ( model_mdn . parameters () , lr =1e -3)\n",
            "22\n",
            "23 # Eval\n",
            "24 model_vae . eval ()\n",
            "25 model_mdn . eval ()\n",
            "26 itr_idx = 0\n",
            "27 test_loss = 0.0\n",
            "28\n",
            "29 for batch_idx , (batch , batch_recon_const , batch_weights , _, batch_feats ) in\n",
            "tqdm (\n",
            "30 enumerate ( data_loader ), total = nbatches\n",
            "31 ):\n",
            "32 input_color = batch . cuda ()\n",
            "33 input_greylevel = batch_recon_const . cuda ()\n",
            "34 input_feats = batch_feats . cuda ()\n",
            "35 z = torch . randn ( batchsize , hiddensize )\n",
            "36 optimizer . zero_grad ()\n",
            "37\n",
            "38 # Get the parameters of the posterior distribution\n",
            "39 mu , logvar , _ = model_vae ( input_color , input_greylevel , z)\n",
            "40\n",
            "41 # Get the GMM vector\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "42 mdn_gmm_params = model_mdn ( input_feats )\n",
            "43\n",
            "44 # Compare 2 distributions\n",
            "45 loss , _ = mdn_loss ( mdn_gmm_params , mu , torch . sqrt ( torch . exp( logvar )),\n",
            "batchsize )\n",
            "46\n",
            "47 test_loss = test_loss + loss . item ()\n",
            "48\n",
            "49 test_loss = ( test_loss * 1.0) / ( nbatches )\n",
            "50 model_vae . train ()\n",
            "51 return test_loss\n",
            "52\n",
            "53\n",
            "54def train_mdn ():\n",
            "55 # Load hyperparameters\n",
            "56 out_dir , listdir , featslistdir = get_dirpaths ( args )\n",
            "57 batchsize = args [\" batchsize \"]\n",
            "58 hiddensize = args [\" hiddensize \"]\n",
            "59 nmix = args [\" nmix \"]\n",
            "60 nepochs = args [\" epochs_mdn \"]\n",
            "61\n",
            "62 # Create DataLoader\n",
            "63 data = ColorDataset (\n",
            "64 os. path . join ( out_dir , \" images \"), listdir , featslistdir , split =\" train \"\n",
            "65 )\n",
            "66 nbatches = np. int_ (np. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "floor ( data . img_num / batchsize ))\n",
            "67 data_loader = DataLoader (\n",
            "68 dataset =data ,\n",
            "69 num_workers = args [\" nthreads \"],\n",
            "70 batch_size = batchsize ,\n",
            "71 shuffle =True ,\n",
            "72 drop_last =True ,\n",
            "73 )\n",
            "74\n",
            "75 # Initialize VAE model\n",
            "76 model_vae = VAE ()\n",
            "77 model_vae . cuda ()\n",
            "78 model_vae . load_state_dict ( torch . load (\"%s/ models / model_vae .pth\" % ( out_dir )))\n",
            "79 model_vae . eval ()\n",
            "80\n",
            "81 # Initialize MDN model\n",
            "82 model_mdn = MDN ()\n",
            "83 model_mdn . cuda ()\n",
            "84 model_mdn . train ()\n",
            "85\n",
            "86 optimizer = optim . Adam ( model_mdn . parameters () , lr =1e -3)\n",
            "87\n",
            "88 # Train\n",
            "89 itr_idx = 0\n",
            "90 for epochs_mdn in range ( nepochs ):\n",
            "91 train_loss = 0.0\n",
            "92\n",
            "93 for batch_idx , (\n",
            "94 batch ,\n",
            "95 batch_recon_const ,\n",
            "96 batch_weights ,\n",
            "97 _,\n",
            "98 batch_feats ,\n",
            "99 ) in tqdm ( enumerate ( data_loader ), total = nbatches ):\n",
            "100 input_color = batch . cuda ()\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "101 input_greylevel = batch_recon_const . cuda ()\n",
            "102 input_feats = batch_feats . cuda ()\n",
            "103 z = torch . randn ( batchsize , hiddensize )\n",
            "104 optimizer . zero_grad ()\n",
            "105\n",
            "106 # Get the parameters of the posterior distribution\n",
            "107 mu , logvar , _ = model_vae ( input_color , input_greylevel , z)\n",
            "108\n",
            "109 # Get the GMM vector\n",
            "110 mdn_gmm_params = model_mdn ( input_feats )\n",
            "111\n",
            "112 # Compare 2 distributions\n",
            "113 loss , loss_l2 = mdn_loss (\n",
            "114 mdn_gmm_params , mu , torch . sqrt ( torch .exp ( logvar )), batchsize\n",
            "115 )\n",
            "116\n",
            "117 loss . backward ()\n",
            "118 optimizer . step ()\n",
            "119 train_loss = train_loss + loss . item ()\n",
            "120\n",
            "121 train_loss = ( train_loss * 1.0) / ( nbatches )\n",
            "122 test_loss = test_mdn ( model_vae , model_mdn )\n",
            "123 print (\n",
            "124 f\"End of epoch { epochs_mdn :3d} | Train Loss { train_loss :8.3 f} | Test\n",
            "Loss { test_loss :8.3 f}\"\n",
            "125 )\n",
            "126\n",
            "127 # Save MDN model\n",
            "128 torch . save ( model_mdn . state_dict () , \"%s/ models_mdn / model_mdn .pth\" % (\n",
            "out_dir ))\n",
            "129\n",
            "130 print (\" Complete MDN training \")\n",
            "131\n",
            "132train_mdn ()\n",
            "5.Inference\n",
            "Bạn có thể sử dụng checkpoint sẵn có để tiến hành quá trình suy luận thử nghiệm.\n",
            "1# Download VAE checkpoint\n",
            "2! \n",
            "----------------------------------------------------------------------------------------------------\n",
            "gdown 1 wdyK198lXwwZO4NIB7DzJmA5arwUVWDU\n",
            "3# Download MDN checkpoint\n",
            "4! gdown 1 AhilMrR_C04v7_sysuf5ffEVsQllo2W6\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 8: Ảnh minh họa cho Big Model ở giai đoạn inference\n",
            "1def inference ():\n",
            "2 # Load hyperparameters\n",
            "3 out_dir , listdir , featslistdir = get_dirpaths ( args )\n",
            "4 batchsize = args [\" batchsize \"]\n",
            "5 hiddensize = args [\" hiddensize \"]\n",
            "6 nmix = args [\" nmix \"]\n",
            "7\n",
            "8 # Create DataLoader\n",
            "9 data = ColorDataset (\n",
            "10 os. path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "join ( out_dir , \" images \"),\n",
            "11 listdir = listdir ,\n",
            "12 featslistdir = featslistdir ,\n",
            "13 split =\" test \",\n",
            "14 )\n",
            "15\n",
            "16 nbatches = np. int_ (np. floor ( data . img_num / batchsize ))\n",
            "17\n",
            "18 data_loader = DataLoader (\n",
            "19 dataset =data ,\n",
            "20 num_workers = args [\" nthreads \"],\n",
            "21 batch_size = batchsize ,\n",
            "22 shuffle =False ,\n",
            "23 drop_last =True ,\n",
            "24 )\n",
            "25\n",
            "26 # Load VAE model\n",
            "27 model_vae = VAE ()\n",
            "28 model_vae . cuda ()\n",
            "29 model_vae . load_state_dict ( torch . load (\"%s/ models / model_vae .pth\" % ( out_dir )))\n",
            "30 model_vae . eval ()\n",
            "31\n",
            "32 # Load MDN model\n",
            "33 model_mdn = MDN ()\n",
            "34 model_mdn . cuda ()\n",
            "35 model_mdn . load_state_dict ( torch . load (\"%s/ models / model_mdn .pth\" % ( out_dir )))\n",
            "36 model_mdn . eval ()\n",
            "37\n",
            "38 # Infer\n",
            "39 for batch_idx , (\n",
            "18\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "40 batch ,\n",
            "41 batch_recon_const ,\n",
            "42 batch_weights ,\n",
            "43 batch_recon_const_outres ,\n",
            "44 batch_feats ,\n",
            "45 ) in tqdm ( enumerate ( data_loader ), total = nbatches ):\n",
            "46\n",
            "47 input_feats = batch_feats . cuda ()\n",
            "48\n",
            "49 # Get GMM parameters\n",
            "50 mdn_gmm_params = model_mdn ( input_feats )\n",
            "51 gmm_mu , gmm_pi = get_gmm_coeffs ( mdn_gmm_params )\n",
            "52 gmm_pi = gmm_pi . reshape (-1, 1)\n",
            "53 gmm_mu = gmm_mu . reshape (-1, hiddensize )\n",
            "54\n",
            "55 for j in range ( batchsize ):\n",
            "56 batch_j = np. tile ( batch [j, ...]. numpy () , ( batchsize , 1, 1, 1))\n",
            "57 batch_recon_const_j = np. tile (\n",
            "58 batch_recon_const [j, ...]. numpy () , ( batchsize , 1, 1, 1)\n",
            "59 )\n",
            "60 batch_recon_const_outres_j = np. tile (\n",
            "61 batch_recon_const_outres [j, ...]. numpy () , ( batchsize , 1, 1, 1)\n",
            "62 )\n",
            "63\n",
            "64 input_color = torch . from_numpy ( batch_j ). cuda ()\n",
            "65 input_greylevel = torch . from_numpy ( batch_recon_const_j ). cuda ()\n",
            "66\n",
            "67 # Get mean from GMM\n",
            "68 curr_mu = gmm_mu [j * nmix : (j + 1) * nmix , :]\n",
            "69 orderid = np. argsort (\n",
            "70 gmm_pi [j * nmix : (j + 1) * nmix , 0]. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "cpu (). data . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "numpy (). reshape\n",
            "( -1)\n",
            "71 )\n",
            "72\n",
            "73 # Sample from GMM\n",
            "74 z = curr_mu . repeat (int (( batchsize * 1.0) / nmix ), 1)\n",
            "75\n",
            "76 # Predict color\n",
            "77 _, _, color_out = model_vae ( input_color , input_greylevel , z)\n",
            "78\n",
            "79 # Save images\n",
            "80 data . saveoutput_gt (\n",
            "81 color_out .cpu (). data . numpy ()[ orderid , ...] ,\n",
            "82 batch_j [ orderid , ...] ,\n",
            "83 \" divcolor_ %05 d_ %05d\" % ( batch_idx , j),\n",
            "84 nmix ,\n",
            "85 net_recon_const = batch_recon_const_outres_j [ orderid , ...] ,\n",
            "86 )\n",
            "87\n",
            "88 print (\" Complete inference \")\n",
            "89\n",
            "90vae_ckpt = \" model_vae .pth\"\n",
            "91mdn_ckpt = \" model_mdn .pth\"\n",
            "92inference ( vae_ckpt , mdn_ckpt )\n",
            "Kết quả thực nghiệm mô hình sau khi huấn luyện\n",
            "19\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 9: Kết quả thực nghiệm mô hình sau khi huấn luyện.\n",
            "20\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1.VAE có thể được sử dụng trong các ứng dụng nào?\n",
            "(a) Tô màu cho ảnh xám\n",
            "(b) Nén ảnh\n",
            "(c) Sinh ảnh mới\n",
            "(d) Tất cả các phương án trên\n",
            "2.Mô hình VAE cơ bản có bao nhiêu block chính?\n",
            "(a) 1\n",
            "(b) 2\n",
            "(c) 3\n",
            "(d) 4\n",
            "3.Trong VAE, đối tượng cần được mã hóa được biểu diễn như thế nào?\n",
            "(a) Dưới dạng một giá trị số thực.\n",
            "(b) Dưới dạng một phân phối xác suất\n",
            "(c) Dưới dạng một véc-tơ nhị phân\n",
            "(d) Dưới dạng một ma trận đặc trưng\n",
            "4.Trong VAE, khi huấn luyện mô hình, ta muốn KL Divergence Loss đạt giá trị bằng bao nhiêu?\n",
            "(a) 0\n",
            "(b) 1\n",
            "(c) Không có giá trị nhất định\n",
            "(d) Càng lớn càng tốt\n",
            "5.Trong Image Colorization, vì sao không gian màu Lab thường được sử dụng hơn không gian màu\n",
            "RGB (chọn phương án đúng nhất)?\n",
            "(a)Phân biệt rõ ràng giữa độ sáng và màu sắc : Không gian màu Lab phân chia màu sắc và\n",
            "độ sáng thành hai kênh riêng biệt (L, a, và b), giúp mô hình tập trung vào việc tái tạo màu\n",
            "sắc một cách chính xác hơn. Trong khi đó, ảnh RGB có thể làm mất thông tin về độ sáng khi\n",
            "thêm màu vào, gây ra hiệu ứng không mong muốn.\n",
            "(b)Khả năng lưu trữ thông tin màu sắc chi tiết : Các giá trị trong không gian màu Lab là\n",
            "liên tục, ngược lại với các giá trị rời rạc trong không gian màu RGB. Điều này dẫn đến việc\n",
            "không gian màu Lab có khả năng lưu trữ lớn hơn và chính xác hơn trong việc biểu diễn hình\n",
            "ảnh\n",
            "(c)Độ phức tạp thấp hơn khi dự đoán màu sắc : Với không gian màu Lab, chúng ta chỉ cần\n",
            "dự đoán hai kênh màu a và b, thay vì cả ba kênh màu như trong không gian màu RGB. Điều\n",
            "này giúp giảm độ phức tạp của bài toán và tăng hiệu suất của mô hình.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(d) Tất cả đáp án trên.\n",
            "6.Trong quá trình inference, mô hình CVAE có sự tham gia của những thành phần nào?\n",
            "(a) Encoder, Conditional Encoder, Decoder\n",
            "(b) Encoder, Decoder\n",
            "21\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(c) Conditional Encoder, Decoder\n",
            "(d) Decoder\n",
            "- Hết -\n",
            "22\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "Video Classification Project\n",
            "Minh-Duc Bui và Quang-Vinh Dinh\n",
            "Ngày 2 tháng 5 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Video classification là một bài toán quan trọng trong thị giác máy tính và trí tuệ nhân tạo, liên quan\n",
            "đến việc tự động phân loại và gán nhãn các video dựa trên nội dung.\n",
            "Các ứng dụng của video classification rất đa dạng, từ an ninh và giám sát, cải thiện các hệ thống gợi\n",
            "ý nội dung trên nền tảng xem video như YouTube hay Netflix, đến phân tích hành vi người dùng và\n",
            "hỗ trợ các phương tiện tự lái. Để đạt được hiệu quả cao, các model phân loại video cần được train trên\n",
            "các bộ dữ liệu lớn, đa dạng và thường phải xử lý các thách thức như biến động của môi trường, sự thay\n",
            "đổi góc quay, và sự đa dạng về hành vi và tương tác trong video.\n",
            "Hình 1: Minh họa kiến trúc Video Vision Transformer (ViViT) cho bài toán video classification.\n",
            "Trong project này, ta sẽ triển khai một số model phân loại video từ cơ bản đến nâng cao.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Nội dung\n",
            "1.Giới thiệu Video data\n",
            "•Video data : Video là chuỗi của các frame theo thời gian, ví dụ một video có Tframe và mỗi\n",
            "frame có kích thước (3 x W x H) thì video sẽ có kích thước (T x 3 x W x H) (tensor 4 chiều).\n",
            "•Đặc điểm : Video có kích thước rất lớn, ví dụ một video thông thường có khoảng 30 frame,\n",
            "khi kích thước mỗi frame là (3 x 640 x 480) thì dung lượng của video (khi chưa nén) xấp xỉ\n",
            "1.5GB/phút , khi kích thước mỗi frame là (3 x 1920 x 1080) thì dung lượng xấp xỉ 10GB/phút .\n",
            "Video có kích thước rất lớn khi so sánh với các loại data khác như ảnh, âm thanh, hoặc\n",
            "text. Vì thế, trong các bài toán video classification, ta thường dùng video có kích thước nhỏ,\n",
            "(T x 3 x 112 x 112) hoặc (T x 3 x 224 x 224) cùng với số lượng frame Tnhỏ (ví dụ 16 FPS).\n",
            "Đối với các trường hợp video có tính thống nhất từ đầu đến cuối, tức label của video sẽ giống\n",
            "nhau dù ta chỉ nhìn vào 1 phần ngắn của video thì ta có thể chia video thành nhiều clip\n",
            "ngắn và train model. Ví dụ ta có 1 video 30s phân loại các hoạt động thể thao, ta có thể\n",
            "chia video thành các clip ngắn (5s) rồi train model. Khi inference thực tế, ta sẽ chia video\n",
            "thành nhiều clip ngắn rồi predict trên các clip ngắn này, kết quả cuối cùng sẽ được tổng hợp\n",
            "lại (tham khảo hình 2).\n",
            "Hình 2: Minh họa cách chia video thành các clip ngắn khi train và cách inference sau khi đã train model.\n",
            "•Thách thức : các bài toán về video luôn có độ phức tạp rất cao do nhiều tính chất từ video,\n",
            "một số thách thức về video như:\n",
            "–Chỉ một phần nhỏ của đối tượng (quyết định label) xuất hiện trong video,\n",
            "–Video tại các vị trí đông người,\n",
            "–Các hành động chính (quyết định label) chỉ diễn ra trong một khoảng thời gian ngắn\n",
            "trong toàn bộ video,\n",
            "–Video có độ phân giải thấp.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "2.Dataset RWF2000 - bài toán violence detection\n",
            "RWF2000 là dataset về bài toán violence detection (phát hiện hành vi bạo lực), cụ thể ta sẽ phân\n",
            "loại video dựa vào 2 class fight hoặc non-fight behaviour tương ứng với có hoặc không có hành\n",
            "vi bạo lực trong video. Dataset bao gồm 2000 video, mỗi video dài 5s và được quay ở 30 frame\n",
            "(FPS), tổng cộng ta có 300.000 frame.\n",
            "Hình 3: Một số sample từ RWF2000.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3.Cấu trúc data và dataset class\n",
            "Data bao gồm 2 folder chính là train và val, trong mỗi folder chính sẽ có 2 subfolder tương ứng\n",
            "với 2 class là Fight and NonFight. Trong mỗi class bao gồm các folder chứa video, mỗi folder chứa\n",
            "30 frame của video đó.\n",
            "VideoDataset Class:\n",
            "•__init__: Hàm khởi tạo nhận vào root_dir (đường dẫn tới thư mục chứa dataset), phaseđể\n",
            "chỉ định tập dữ liệu là trainhoặc val,transform để áp dụng các biến đổi cho các frame, và\n",
            "n_frames để chỉ định số lượng frame sẽ được lấy từ mỗi video.\n",
            "•_load_videos : Hàm load tất cả các đường dẫn đến frame của các video. Hàm duyệt qua từng\n",
            "thư mục trong trainhoặc val, lấy đường dẫn của từng frame trong mỗi video, sau đó sắp xếp\n",
            "theo thứ tự số. Nếu n_frames được chỉ định, hàm sẽ lấy các frame theo uniform distribution\n",
            "bằng cách sử dụng hàm _uniform_sample .\n",
            "•_uniform_sample : Hàm chọn ra n_frames từ danh sách frames theo uniform distribution.\n",
            "•__getitem__ : Trả về data và label tương ứng khi chỉ định index. Các frame được transform\n",
            "(nếu có), và stack lại để tạo thành một tensor 4 chiều (C, T, H, W) .\n",
            "1class VideoDataset ( Dataset ):\n",
            "2 def __init__ (self , root_dir , phase =\" train \", transform =None , n_frames =\n",
            "None ):\n",
            "3 \"\"\"\n",
            "4 Args :\n",
            "5 root_dir ( string ): Directory with all the videos ( each video as\n",
            "a subdirectory of frames ).\n",
            "6 transform ( callable , optional ): Optional transform to be applied\n",
            "on a sample .\n",
            "7 n_frames (int , optional ): Number of frames to sample from each\n",
            "video , uniformly . If None , use all frames .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "8 \"\"\"\n",
            "9 self . root_dir = root_dir\n",
            "10 self . transform = transform\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "11 self . n_frames = n_frames\n",
            "12 self . phase = phase\n",
            "13 self . videos , self . labels = self . _load_videos ()\n",
            "14\n",
            "15 def _load_videos ( self ):\n",
            "16 videos , labels = [], []\n",
            "17 class_id = 0\n",
            "18\n",
            "19 video_folders = os. listdir (os. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "path . join ( self . root_dir , self . phase ))\n",
            "20\n",
            "21 for folder in video_folders :\n",
            "22 video_paths = os. listdir (os. path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "join ( self . root_dir , self .phase ,\n",
            "folder ))\n",
            "23\n",
            "24 for video_path in video_paths :\n",
            "25 video_folder = os. path . join (\n",
            "26 self . root_dir , self .phase , folder , video_path\n",
            "27 )\n",
            "28 frames = sorted (\n",
            "29 (os. path . join ( video_folder , f) for f in os. listdir (\n",
            "video_folder )),\n",
            "30 key = lambda f: int(\n",
            "31 \"\". join ( filter ( str. isdigit , os. path . basename (f)))\n",
            "32 ),\n",
            "33 )\n",
            "34\n",
            "35 if self . n_frames :\n",
            "36 frames = self . _uniform_sample (frames , self . n_frames )\n",
            "37\n",
            "38 videos . append ( frames )\n",
            "39 labels . append ( class_id )\n",
            "40\n",
            "41 class_id += 1\n",
            "42\n",
            "43 return videos , labels\n",
            "44\n",
            "45 def _uniform_sample (self , frames , n_frames ):\n",
            "46 \"\"\"\n",
            "47 Helper method to uniformly sample n_frames from the frames list .\n",
            "48 \"\"\"\n",
            "49 stride = max (1, len( frames ) // n_frames )\n",
            "50 sampled = [ frames [i] for i in range (0, len( frames ), stride )]\n",
            "51 return sampled [: n_frames ]\n",
            "52\n",
            "53 def __len__ ( self ):\n",
            "54 return len( self . videos )\n",
            "55\n",
            "56 def __getitem__ (self , idx):\n",
            "57 video_frames = self . videos [idx]\n",
            "58 label = self . labels [idx]\n",
            "59 images = []\n",
            "60 for frame_path in video_frames :\n",
            "61 image = Image . open ( frame_path ). convert (\"RGB\")\n",
            "62 if self . transform :\n",
            "63 image = self . transform ( image )\n",
            "64 images . append ( image )\n",
            "65\n",
            "66 # Stack images along new dimension ( sequence length )\n",
            "67 data = torch . stack ( images , dim =0)\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "68\n",
            "69 # Rearrange to have the shape (C, T, H, W)\n",
            "70 data = data . permute (1, 0, 2, 3)\n",
            "71 return data , label\n",
            "72\n",
            "Sau đó ta sẽ tạo dataloader để train model:\n",
            "1BATCH_SIZE = 16\n",
            "2MAX_LEN = 15\n",
            "3IMAGE_SIZE = 224\n",
            "4\n",
            "5\n",
            "6transform = transforms . Compose (\n",
            "7 [\n",
            "8 transforms . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Resize (( IMAGE_SIZE , IMAGE_SIZE )),\n",
            "9 transforms . ToTensor () ,\n",
            "10 ]\n",
            "11)\n",
            "12\n",
            "13# Load dataset\n",
            "14train_dataset = VideoDataset (\n",
            "15 root_dir =\"./ dataset /rwf -2000 \", phase =\" train \", transform = transform ,\n",
            "n_frames = MAX_LEN\n",
            "16)\n",
            "17\n",
            "18val_dataset = VideoDataset (\n",
            "19 root_dir =\"./ dataset /rwf -2000 \", phase =\"val\", transform = transform ,\n",
            "n_frames = MAX_LEN\n",
            "20)\n",
            "21\n",
            "22# Count number of cpus\n",
            "23cpus = os. cpu_count ()\n",
            "24print (f\" Number of cpus : { cpus }\")\n",
            "25\n",
            "26# Create data loaders\n",
            "27train_loader = DataLoader (\n",
            "28 train_dataset , batch_size = BATCH_SIZE , num_workers =cpus , shuffle = True\n",
            "29)\n",
            "30val_loader = DataLoader (\n",
            "31 val_dataset , batch_size = BATCH_SIZE , num_workers =cpus , shuffle = False\n",
            "32)\n",
            "33\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4.Model video classification\n",
            "Trong phần này, ta sẽ dùng một số model khác nhau để giải quyết bài toán video classification.\n",
            "•Single-frame : Single-frame hoạt động bằng cách dùng 2D model bất kì (resnet18) để predict\n",
            "trên mỗi frame và tổng hợp kết quả cuối cùng (average). Model single-frame được mô tả như\n",
            "hình sau, lưu ý, ta chỉ cần dùng 1 model (share weight) để predict trên các frame.\n",
            "1class Model (nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Module ):\n",
            "2 def __init__ (self , num_classes =2):\n",
            "3 super (Model , self ). __init__ ()\n",
            "4 self . resnet = resnet18 ( pretrained = True )\n",
            "5 self . resnet .fc = nn. Sequential (nn. Linear ( self . resnet .fc.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "in_features , 512) )\n",
            "6 self . fc1 = nn. Linear (512 , 128)\n",
            "7 self . fc2 = nn. Linear (128 , num_classes )\n",
            "8\n",
            "9 def forward (self , x_3d ):\n",
            "10 # (bs , C, T, H, W) -> (bs , T, C, H, W)\n",
            "11 x_3d = x_3d . permute (0, 2, 1, 3, 4)\n",
            "12\n",
            "13 logits = []\n",
            "14 for t in range ( x_3d . size (1)):\n",
            "15 out = self . resnet ( x_3d [:, t, :, :, :])\n",
            "16\n",
            "17 x = self . fc1(out)\n",
            "18 x = F. relu (x)\n",
            "19 x = self . fc2(x)\n",
            "20\n",
            "21 logits . append (x)\n",
            "22\n",
            "23 # mean pooling\n",
            "24 logits = torch . stack ( logits , dim =0)\n",
            "25 logits = torch . mean ( logits , dim =0)\n",
            "26 return logits\n",
            "•Late Fusion : Late fusion hoạt động bằng cách dùng 2D model (share weight) để biến đổi\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "mỗi frame thành feature vector, sau đó ta sẽ tổng hợp các feature vector này và đưa vào\n",
            "MLP head để đưa ra prediction cuối cùng. Model late fusion được mô tả như hình sau, ta\n",
            "có thể concat hoặc tính average của các feature vector sau khi qua CNN, khi concat thì kích\n",
            "thước sẽ rất lớn nên ta sẽ tính average các vector.\n",
            "để tiết kiệm tài nguyên tính toán và tránh việc kích thước vec\n",
            "1class Model (nn. Module ):\n",
            "2 def __init__ (self , num_classes =2):\n",
            "3 super (Model , self ). __init__ ()\n",
            "4 self . resnet = resnet18 ( pretrained = True )\n",
            "5 self . resnet .fc = nn. Sequential (nn. Linear ( self . resnet .fc.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "in_features , 512) )\n",
            "6 self . fc1 = nn. Linear (512 , 128)\n",
            "7 self . fc2 = nn. Linear (128 , num_classes )\n",
            "8\n",
            "9 def forward (self , x_3d ):\n",
            "10 # (bs , C, T, H, W) -> (bs , T, C, H, W)\n",
            "11 x_3d = x_3d . permute (0, 2, 1, 3, 4)\n",
            "12\n",
            "13 features = []\n",
            "14 for t in range ( x_3d . size (1)):\n",
            "15 out = self . resnet ( x_3d [:, t, :, :, :])\n",
            "16 features . append ( out)\n",
            "17\n",
            "18 # average pooling\n",
            "19 out = torch . mean ( torch . stack ( features ), 0)\n",
            "20\n",
            "21 x = self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "fc1(out)\n",
            "22 x = F. relu (x)\n",
            "23 x = self . fc2(x)\n",
            "24 return x\n",
            "25\n",
            "•Early Fusion : Early fusion sẽ kết hợp các input frame để tạo thành tensor có kích thước\n",
            "(3*T x H x W) và dùng model 2D (cần thay đổi layer conv đầu tiên để phù hợp với input).\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Model early fusion được mô tả như hình sau:\n",
            "1class Model (nn. Module ):\n",
            "2 def __init__ (self , num_classes =2, num_input_channel =48) :\n",
            "3 super (Model , self ). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "__init__ ()\n",
            "4 self . resnet = resnet18 ( pretrained = True )\n",
            "5 self . resnet . conv1 = nn. Conv2d (\n",
            "6 num_input_channel , 64, kernel_size =7, stride =2, padding =3,\n",
            "bias = False\n",
            "7 )\n",
            "8 self . resnet .fc = nn. Sequential (nn. Linear ( self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "resnet .fc.\n",
            "in_features , 512) )\n",
            "9 self . fc1 = nn. Linear (512 , 128)\n",
            "10 self . fc2 = nn. Linear (128 , num_classes )\n",
            "11\n",
            "12 def forward (self , x_3d ):\n",
            "13 # (bs , C, T, H, W)\n",
            "14 # concatenate all C and T dimensions to make it (bs , C*T, H, W)\n",
            "15 x_3d = x_3d . permute (0, 2, 1, 3, 4). contiguous ()\n",
            "16 x_3d = x_3d . view (\n",
            "17 x_3d . size (0) , x_3d . size (1) * x_3d . size (2) , x_3d . size (3) ,\n",
            "x_3d . size (4)\n",
            "18 )\n",
            "19\n",
            "20 out = self . resnet ( x_3d )\n",
            "21\n",
            "22 x = self . fc1(out)\n",
            "23 x = F. relu (x)\n",
            "24 x = self . fc2(x)\n",
            "25 return x\n",
            "26\n",
            "•CNN-LSTM : Đối với model CNN-LSTM, ta sẽ dùng 2D model (share weight) để extract\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "feature từ mỗi frame độc lập và dùng các feature đó để đưa vào LSTM, mỗi frame sẽ tương\n",
            "ứng với mỗi input của model LSTM. Model được mô tả như hình sau:\n",
            "1class Model (nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Module ):\n",
            "2 def __init__ (self , num_classes =2):\n",
            "3 super (Model , self ). __init__ ()\n",
            "4 self . resnet = resnet18 ( pretrained = True )\n",
            "5 self . resnet .fc = nn. Sequential (nn. Linear ( self . resnet .fc.\n",
            "in_features , 512) )\n",
            "6 self . lstm = nn. LSTM ( input_size =512 , hidden_size =389 , num_layers\n",
            "=3)\n",
            "7 self . fc1 = nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Linear (389 , 128)\n",
            "8 self . fc2 = nn. Linear (128 , num_classes )\n",
            "9\n",
            "10 def forward (self , x_3d ):\n",
            "11 # (bs , C, T, H, W) -> (bs , T, C, H, W)\n",
            "12 x_3d = x_3d . permute (0, 2, 1, 3, 4)\n",
            "13\n",
            "14 hidden = None\n",
            "15 for t in range ( x_3d . size (1)):\n",
            "16 x = self . resnet ( x_3d [:, t, :, :, :])\n",
            "17 out , hidden = self . lstm (x. unsqueeze (0) , hidden )\n",
            "18\n",
            "19 x = self . fc1(out [-1, :, :])\n",
            "20 x = F. relu (x)\n",
            "21 x = self . fc2(x)\n",
            "22 return x\n",
            "23\n",
            "•3D CNN : Ta cũng có thể sử dụng các model chuyên dành cho data 3D để giải quyết bài\n",
            "toán video classification. Do đoạn code tạo model rất lớn nên sẽ không được bao gồm trong\n",
            "file này (tham khảo tại đây). Sau đây là kiến trúc model S3D mà ta sẽ sử dụng:\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Video ViT (ViViT) : Transformer vẫn luôn là backbone được sử dụng rộng rãi trong nhiều\n",
            "các bài toán hiện tại. ViViT là một trong những model đầu tiên sử dụng kiến trúc Vision\n",
            "Transformer (ViT) để áp dụng vào bài toán video classification. Model ViViT được mô tả\n",
            "như hình sau, lưu ý các block Spatial Transformer Encoder là các block share weight.\n",
            "1from transformers import VivitConfig , VivitForVideoClassification\n",
            "2\n",
            "3class Model (nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Module ):\n",
            "4 def __init__ (self , num_classes =2, image_size =224 , num_frames =15) :\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "5 super (Model , self ). __init__ ()\n",
            "6 cfg = VivitConfig ()\n",
            "7 cfg . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "num_classes = num_classes\n",
            "8 cfg . image_size = image_size\n",
            "9 cfg . num_frames = num_frames\n",
            "10\n",
            "11 self . vivit = VivitForVideoClassification . from_pretrained (\n",
            "12 \" google /vivit -b -16x2 - kinetics400 \",\n",
            "13 config =cfg ,\n",
            "14 ignore_mismatched_sizes =True ,\n",
            "15 )\n",
            "16\n",
            "17 def forward (self , x_3d ):\n",
            "18 # (bs , C, T, H, W) -> (bs , T, C, H, W)\n",
            "19 x_3d = x_3d . permute (0, 2, 1, 3, 4)\n",
            "20\n",
            "21 out = self . vivit ( x_3d )\n",
            "22\n",
            "23 return out. logits\n",
            "24\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. Đâu là một cách xử lý video có kích thước lớn?\n",
            "(a) Sử dụng toàn bộ frame trong video.\n",
            "(b) Chia video thành nhiều clip ngắn và train model.\n",
            "(c) Bỏ qua các frame không quan trọng.\n",
            "(d) Sử dụng video với tốc độ khung hình cao.\n",
            "2. RWF2000 là dataset cho bài toán gì?\n",
            "(a) Phát hiện hành vi bạo lực.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(b) Phân loại động vật.\n",
            "(c) Nhận diện khuôn mặt.\n",
            "(d) Dự đoán thời tiết.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3. Đâu là đặc điểm của data trong video classification?\n",
            "(a) Video là chuỗi của các frame theo không gian.\n",
            "(b) Mỗi frame thường có kích thước nhỏ.\n",
            "(c) Video là chuỗi của các frame theo thời gian.\n",
            "(d) Video không chứa dữ liệu âm thanh.\n",
            "4. Trong VideoDataset, hàm _uniform_sample dùng để làm gì?\n",
            "(a) Để sắp xếp các frames theo thứ tự số.\n",
            "(b) Để chuyển đổi các frame sang RGB.\n",
            "(c) Để lấy mẫu đều các frame từ danh sách.\n",
            "(d) Để kết nối với GPU cho việc training nhanh hơn.\n",
            "5. Đâu là kiến trúc sử dụng để chuyển đổi mỗi frame thành feature vector trong late fusion?\n",
            "(a) CNN\n",
            "(b) LSTM\n",
            "(c) MLP\n",
            "(d) RNN\n",
            "6. Trong early fusion, các frame được kết hợp như thế nào trước khi đưa vào model?\n",
            "(a) Tất cả các frames được nén lại thành một frame.\n",
            "(b) Các frames được giữ nguyên và xử lý độc lập.\n",
            "(c) Các frames được đưa vào LSTM như là các input độc lập.\n",
            "(d) Các frame được kết hợp để tạo thành tensor có kích thước (3*T x H x W).\n",
            "7. Single-frame model hoạt động dựa trên nguyên tắc nào?\n",
            "(a) Tổng hợp các feature vector từ mỗi frame.\n",
            "(b) Dùng 2D model để predict trên mỗi frame và tổng hợp kết quả.\n",
            "(c) Xử lý từng frame với một mạng LSTM.\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(d) Kết hợp tất cả frames thành một tensor 3D.\n",
            "8. Trong VideoDataset, __getitem__ trả về gì?\n",
            "(a) Chỉ một tensor của các frames.\n",
            "(b) Một cặp gồm data và label.\n",
            "(c) Một danh sách các đường dẫn đến frame.\n",
            "(d) Kết quả của mô hình đã được train.\n",
            "9. Trong quá trình training, việc xáo trộn (shuffle) dữ liệu trong train_loader có mục đích gì?\n",
            "(a) Giảm dung lượng dữ liệu cần xử lý.\n",
            "(b) Tăng tốc độ training của model.\n",
            "(c) Ngăn ngừa model học theo thứ tự dữ liệu, giúp generalization tốt hơn.\n",
            "(d) Tăng độ chính xác của model trên dữ liệu validation.\n",
            "10. Đâu là lợi ích của việc sử dụng pre-trained models như trong single-frame model?\n",
            "(a) Giảm thời gian inference.\n",
            "(b) Giảm độ chính xác của model.\n",
            "(c) Giúp model có khả năng transfer learning.\n",
            "(d) Giảm số lượng layers cần thiết trong mô hình.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Hết -\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Point Cloud Techniques and Applications\n",
            "Tuan Dang and Phuc Pham\n",
            "Ngày 23 tháng 4 năm 2024\n",
            "1 Introduction to Point Cloud and basic techniques to process\n",
            "Trong phần này chúng ta sẽ được giới thiệu về một số thao tác cơ bản trên 3D Point Clouds data bằng\n",
            "thư viện Open3D.\n",
            "1.1 Cài đặt môi trường\n",
            "Để tránh bị xung đột về thư viện các bạn hãy cài đặt môi trường bằng các câu lệnh sau đây:\n",
            "1conda create -n 3 d_pc python =3.8\n",
            "2conda activate 3 d_pc\n",
            "3pip install open3d ==0.18.0\n",
            "4pip install seaborn\n",
            "5pip install opencv - python\n",
            "1.2 Load a point cloud\n",
            "Có các loại file lưu trữ một đám mây điểm 3D thông dụng đó là file có đuôi .bin, .ply và .txt. Đây chính\n",
            "là code mẫu để load data với \".bin\" file từ bộ data KITTI, \".ply\" từ bộ PCN và \".txt\" từ bộ S3DIS.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1def load_bin ( path ):\n",
            "2 pcd_arr = np. fromfile (path , dtype =np. float32 ). reshape (-1, 4) # x,y,x,r\n",
            "3 return pcd_arr [: ,:3] , pcd_arr [: ,3:]\n",
            "4\n",
            "5def load_ply ( path ):\n",
            "6 pcd = o3d .io. read_point_cloud ( path )\n",
            "7 pcd_arr = np. asarray ( pcd. points )\n",
            "8 pcd_color = np. asarray (pcd . colors )\n",
            "9 return pcd_arr , pcd_color\n",
            "10\n",
            "11def load_txt ( path ):\n",
            "12 pcd_arr = np. loadtxt ( path )\n",
            "13 return pcd_arr [: ,:3] , pcd_arr [: ,3:]\n",
            "Sau đó chúng ta sẽ sử dụng hàm draw_point_clouds để visualize data.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 1: Hình biểu diễn 3D point clouds sau khi load data. Point cloud từ bộ a) KITTI, b) PCN, c)\n",
            "S3DIS.\n",
            "1def draw_point_clouds (array , color = None , logits_color = False , name = \" Open3D \"):\n",
            "2 \"\"\"\n",
            "3 Visualize 3D point clouds from an 3D point cloud array and its corresponding color\n",
            "array .\n",
            "4 Args :\n",
            "5 array (np. array ): a point clouds (N ,3)\n",
            "6 color (np.array , optional ): color of the points . Defaults to None .\n",
            "7 logits_color (bool , optional ): flags if it is True , size of input color must\n",
            "be (N ,3). Otherwise , size of color must be (N ,1). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Defaults to False .\n",
            "8 name (str , optional ): name of display window . Defaults to \" Open3D \".\n",
            "9 \"\"\"\n",
            "10 pcd = o3d. geometry . PointCloud ()\n",
            "11 pcd . points = o3d. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "utility . Vector3dVector ( array )\n",
            "12 if color is not None :\n",
            "13 if logits_color == False :\n",
            "14 colorLength = abs(np.max( color )) + 1\n",
            "15 colorPalette = sns. color_palette (\" Paired \", int( colorLength ))\n",
            "16 colorArray = np. array ( colorPalette )\n",
            "17 color = colorArray [ color ]\n",
            "18 pcd . colors = o3d. utility . Vector3dVector ( color )\n",
            "19 else :\n",
            "20 if np.max( color ) > 1:\n",
            "21 color = color /255.0\n",
            "22 pcd . colors = o3d. utility . Vector3dVector ( color )\n",
            "23\n",
            "24 o3d . visualization . draw_geometries ([ pcd], window_name = name )\n",
            "Kết quả sau được trực quan hoá như hình 1.\n",
            "1.3 Downsampling\n",
            "Dữ liệu 3D point cloud cung cấp thông tin chi tiết về hình dạng và kích thước của các đối tượng\n",
            "trong không gian 3D. Tuy nhiên, lượng dữ liệu lớn này có thể gây tốn kém về tính toán và lưu trữ.\n",
            "Giảm mẫu (Downsampling) là kỹ thuật then chốt giúp giữ lại thông tin quan trọng giảm thiểu kích\n",
            "thước của dữ liệu điểm 3D mà vẫn bảo toàn các đặc trưng cần thiết. Có 2 phương pháp phổ biến:\n",
            "voxel_grid_sampling và farthest_point_sampling.\n",
            "Phân ô voxel (Voxel Grid Sampling) :\n",
            "Ý tưởng: Chia không gian 3D thành các ô nhỏ có kích thước bằng nhau, gọi là voxel.\n",
            "Giảm mẫu:\n",
            "Chọn một điểm đại diện (ví dụ như trọng tâm) cho mỗi voxel. Các điểm nằm trong cùng voxel sẽ được\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 2: Hình so sánh point cloud qua các phương pháp sampling a) original point cloud, b) voxel grid\n",
            "sampling và c) farthest point sampling.\n",
            "thay thế bằng điểm đại diện này.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ưu điểm:\n",
            "- Giữ được thông tin về mật độ điểm của dữ liệu gốc.\n",
            "- Kiểm soát được mức độ giảm mẫu chính xác.\n",
            "- Dễ dàng thực hiện và hiệu quả về tính toán.\n",
            "Nhược điểm:\n",
            "- Có thể làm mất các chi tiết quan trọng, đặc biệt là các chi tiết ở ranh giới giữa các voxel.\n",
            "- Hiệu quả giảm sút với dữ liệu điểm phân bố không đều.\n",
            "Lấy mẫu xa nhất (Farthest Point Sampling - FPS) :\n",
            "Ý tưởng: Lặp lại việc chọn điểm xa nhất so với các điểm đã chọn trước đó.\n",
            "Giảm mẫu: Bắt đầu với một điểm ngẫu nhiên, sau đó chọn điểm có khoảng cách lớn nhất đến tất cả\n",
            "các điểm đã chọn trước đó. Lặp lại quá trình này cho đến khi đạt được số lượng điểm mong muốn.\n",
            "Ưu điểm:\n",
            "- Giữ được phân bố tương đối đều của các điểm trên đám mây 3D, bảo toàn tốt các chi tiết.\n",
            "- Hiệu quả với cả dữ liệu điểm phân bố đều và không đều.\n",
            "Nhược điểm:\n",
            "- Không trực tiếp kiểm soát được mức độ giảm mẫu.\n",
            "- Có thể tính toán tốn thời gian hơn so với phân ô voxel.\n",
            "Kết quả của hai phương pháp sampling được biểu diễn qua hình 2.\n",
            "1def voxel_grid_sampling (pcd , voxel_size =0.05) :\n",
            "2 downpcd = pcd. voxel_down_sample ( voxel_size = voxel_size )\n",
            "3 return downpcd\n",
            "4\n",
            "5def farthest_point_sampling (pcd , num_points = 100) :\n",
            "6 downpcd = pcd. farthest_point_down_sample ( num_samples = num_points )\n",
            "7 return downpcd\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1.4 Noise removal\n",
            "Dữ liệu 3D point clouds đóng vai trò quan trọng trong nhiều lĩnh vực như khảo sát, lập bản đồ, robot,\n",
            "v.v. Tuy nhiên, dữ liệu này thường bị ảnh hưởng bởi nhiễu, gây ra sai sót trong việc xử lý và phân tích.\n",
            "Lọc nhiễu (noise removal) là bước quan trọng để làm sạch dữ liệu, giúp tăng độ chính xác và khai thác\n",
            "tối đa tiềm năng của data.\n",
            "Loại bỏ nhiễu thống kê (Statistic Noise Removal) :\n",
            "Ý tưởng: Sử dụng các tính chất thống kê của dữ liệu điểm đám 3D để phân biệt điểm nhiễu với các\n",
            "điểm thực tế.\n",
            "Thực hiện:\n",
            "1. Tính toán các thống kê của các điểm xung quanh một điểm, chẳng hạn như giá trị trung bình, độ\n",
            "lệch chuẩn, mật độ điểm.\n",
            "2. So sánh các giá trị thống kê của điểm đang xét với các điểm xung quanh.\n",
            "3. Xác định điểm là nhiễu nếu các giá trị thống kê của nó quá khác biệt so với các điểm xung quanh.\n",
            "Ưu điểm:\n",
            "- Có thể loại bỏ nhiễu đa dạng, không phụ thuộc vào dạng hình học của nhiễu.\n",
            "- Hiệu quả với cả nhiễu Gauss (nhiễu theo phân phối chuẩn) và nhiễu xung (nhiễu đột biến).\n",
            "Nhược điểm:\n",
            "- Cần lựa chọn các tham số ngưỡng phù hợp để phân biệt điểm nhiễu.\n",
            "- Có thể loại bỏ nhầm các điểm nằm trên vùng biên của đối tượng.\n",
            "Loại bỏ nhiễu bán kính (Radius Noise Removal) :\n",
            "Ý tưởng: Loại bỏ các điểm nằm xa hơn một khoảng cách nhất định (bán kính) so với các điểm lân cận\n",
            "của chúng.\n",
            "Thực hiện:\n",
            "1. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Xác định một giá trị bán kính nhất định.\n",
            "2. Tìm kiếm các điểm lân cận của mỗi điểm trong đám mây điểm.\n",
            "3. Loại bỏ các điểm có số lượng điểm lân cận trong bán kính quy định nhỏ hơn một giá trị ngưỡng.\n",
            "Ưu điểm:\n",
            "- Đơn giản dễ hiểu và dễ dàng thực hiện.\n",
            "- Hiệu quả với các nhiễu dạng điểm đơn lẻ hoặc cụm nhiễu nhỏ.\n",
            "Nhược điểm:\n",
            "- Khó lựa chọn bán kính phù hợp cho các trường hợp nhiễu khác nhau.\n",
            "- Có thể loại bỏ nhầm các điểm nằm trên chi tiết nhỏ của đối tượng.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình ảnh 3 mô tả hiệu quả của noise removal trên một đám point cloud bị nhiễu.\n",
            "1def statistic_outlier_removal (pcd , nb_neighbors =10 , std_ratio =1.0) :\n",
            "2 _, ind = pcd . remove_statistical_outlier ( nb_neighbors = nb_neighbors ,\n",
            "3 std_ratio = std_ratio )\n",
            "4\n",
            "5 display_inlier_outlier (pcd , ind )\n",
            "6 inlier_cloud = pcd. select_by_index (ind )\n",
            "7 o3d . visualization . draw_geometries ([ inlier_cloud ], \" Statistical oulier removal \")\n",
            "8 return inlier_cloud\n",
            "9\n",
            "10\n",
            "11def radius_outlier_removal (pcd , nb_points =16 , radius =0.05) :\n",
            "12 _, ind = pcd . remove_radius_outlier ( nb_points = nb_points , radius = radius )\n",
            "13 display_inlier_outlier (pcd , ind )\n",
            "14 inlier_cloud = pcd. select_by_index (ind )\n",
            "15 o3d . visualization . draw_geometries ([ inlier_cloud ], \" Radius oulier removal \")\n",
            "16 return inlier_cloud\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 3: Hình ảnh mô tả các phương pháp khử nhiễu trên point cloud. a) Noise, b) Radius noise removal\n",
            "với radius = 0.5, c) Statistical noise removal với standard ratio = 0.5 và number of neighbor = 10.\n",
            "1.5 Nearest neighbor search\n",
            "Đám mây điểm có cấu trúc không đều (irregular). Trong khi đó, vùng lân cận cục bộ của các pixel\n",
            "trong ảnh 2D có thể dễ dàng được xác định bằng cách tạo ra một lưới xung quanh pixel, thì đám mây\n",
            "điểm không có biểu diễn dựa trên lưới tự nhiên và việc xây dựng lưới là không đơn giản. Thay vào\n",
            "đó, tìm kiếm nearest neighbor (NN) đóng vai trò là yếu tố cơ bản để xây dựng các vùng lân cận cục\n",
            "bộ cho các điểm trong đám mây điểm. Tìm kiếm NN được sử dụng trong các tác vụ loại bỏ nhiễu\n",
            "bán kính (radius_outlier_removal), loại bỏ nhiễu thống kê (statistic_outlier_removal)như được mô tả\n",
            "trong Phần 1.4, để tính toán các đặc điểm cục bộ cho mỗi điểm với vùng lân cận cục bộ của nó.\n",
            "Trong lĩnh vực xử lý dữ liệu điểm 3D, hai cấu trúc dữ liệu quan trọng thường được sử dụng để tìm\n",
            "kiếm lân cận (Search Neighbor) hiệu quả là cây KD (KD-Tree) và Octree.\n",
            "Cây KD (KD-Tree)\n",
            "Khái niệm: Cây KD là một cây tìm kiếm nhị phân đa chiều được sử dụng để lưu trữ dữ liệu điểm trong\n",
            "không gian đa chiều (ví dụ như không gian 3D). Nó phân chia lặp lại không gian thành các vùng con\n",
            "dựa trên các trục tọa độ (X, Y, Z).\n",
            "Hoạt động: Khi tìm kiếm điểm lân cận của một điểm truy vấn, cây KD sẽ hướng dẫn tìm kiếm theo các\n",
            "trục tọa độ, loại bỏ hiệu quả các vùng không gian không thể chứa điểm lân cận.\n",
            "Ưu điểm:\n",
            "- Tìm kiếm lân cận nhanh chóng, đặc biệt hiệu quả với dữ liệu điểm phân bố đều.\n",
            "- Sử dụng bộ nhớ hiệu quả.\n",
            "Nhược điểm:\n",
            "- Hiệu quả tìm kiếm có thể giảm với dữ liệu điểm phân bố không đều.\n",
            "- Cấu trúc cây có thể phức tạp đối với dữ liệu chiều cao.\n",
            "Octree\n",
            "Khái niệm: Octree là một cây tìm kiếm nhị phân được sử dụng để lưu trữ dữ liệu điểm trong không\n",
            "gian 3D. Nó phân chia lặp lại không gian thành các khối lập phương (octant) bằng nhau.\n",
            "Hoạt động: Tương tự như cây KD, Octree hướng dẫn tìm kiếm lân cận bằng cách loại bỏ các octant\n",
            "không thể chứa điểm lân cận.\n",
            "Ưu điểm:\n",
            "- Hiệu quả tốt với dữ liệu điểm phân bố không đều.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Cấu trúc đơn giản và dễ dàng truy cập dữ liệu theo vùng.\n",
            "Nhược điểm:\n",
            "- Có thể sử dụng nhiều bộ nhớ hơn so với cây KD cho cùng một lượng dữ liệu điểm.\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 4: Nearest neighbor search bằng KD-Tree và Octree. a) KD-Tree KNN với k = 200, b) KD-Tree\n",
            "Radius với radius = 0.02, c) Octree với max depth = 4.\n",
            "- Không hiệu quả bằng cây KD với dữ liệu điểm phân bố đều.\n",
            "1def kd_tree_nearest_neighbor_knn (pcd , point_index = 5, number_of_neighbor = 200) :\n",
            "2 pcd . paint_uniform_color ([0.5 , 0.5 , 0.5])\n",
            "3 pcd_tree = o3d. geometry . KDTreeFlann (pcd)\n",
            "4 pcd . colors [ point_index ] = [1, 0, 0]\n",
            "5 [k, idx , _] = pcd_tree . search_knn_vector_3d ( pcd. points [ point_index ],\n",
            "number_of_neighbor )\n",
            "6 np. asarray (pcd. colors )[ idx [1:] , :] = [0, 0, 1]\n",
            "7 o3d . visualization . draw_geometries ([ pcd], \" Kd_tree_nearest_neighbor_knn \")\n",
            "8\n",
            "9\n",
            "10def kd_tree_nearest_neighbor_radius (pcd , point_index = 5, radius = 0.02) :\n",
            "11 pcd . paint_uniform_color ([0.5 , 0.5 , 0.5])\n",
            "12 pcd_tree = o3d. geometry . KDTreeFlann (pcd)\n",
            "13 pcd . colors [ point_index ] = [1, 0, 0]\n",
            "14 [k, idx , _] = pcd_tree . search_radius_vector_3d ( pcd. points [ point_index ], radius )\n",
            "15 np. asarray (pcd. colors )[ idx [1:] , :] = [0, 0, 1]\n",
            "16 o3d . visualization . draw_geometries ([ pcd], \" Kd_tree_radius_knn \")\n",
            "17\n",
            "18\n",
            "19def octree_nearest_neighbor (pcd , point_index = 5, max_depth = 4, size_expand =0.01) :\n",
            "20 pcd . colors = o3d . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "utility . Vector3dVector (np. random . uniform (0, 1, size =( np. asarray (\n",
            "pcd . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "points ). shape [0] , 3)))\n",
            "21 octree = o3d. geometry . Octree ( max_depth = max_depth )\n",
            "22 octree . convert_from_point_cloud (pcd , size_expand = size_expand )\n",
            "23 o3d . visualization . draw_geometries ([ octree ] , f\" Octree_depth_ { max_depth }\")\n",
            "24 octree . traverse ( f_traverse )\n",
            "25 octree . locate_leaf_node ( pcd. points [ point_index ])\n",
            "Kết quả sau khi chạy code trên với các tham số như hình 4.\n",
            "1.6 Registration\n",
            "Point cloud registration là một kỹ thuật liên quan đến việc sắp xếp nhiều tập điểm 3D, được gọi là đám\n",
            "mây điểm, vào một hệ tọa độ duy nhất. Hãy tưởng tượng bạn có hai bản quét khác nhau của cùng một\n",
            "căn phòng từ các góc nhìn hơi khác nhau. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Đăng ký đám mây điểm giúp bạn chồng chéo các bản quét\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 5: Hình ảnh so sánh kết quả registration của 2 đám mây điểm. a) Original (inlier_rmse = 1.177e-\n",
            "02), b) Point-to-point ICP (inlier_rmse = 7 76e-03), c) Point-to-plane ICP (inlier_rmse = 6.58e-03)\n",
            "này để tạo ra mô hình 3D hoàn chỉnh và chính xác của căn phòng.\n",
            "Point-to-Point ICP: Đây là cách tiếp cận đơn giản và truyền thống hơn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nó tập trung vào việc\n",
            "tìm điểm gần nhất trong đám mây điểm đích cho mỗi điểm trong đám mây điểm nguồn. Khoảng cách\n",
            "giữa các điểm gần nhất này sau đó được thu nhỏ để tinh chỉnh lặp lại phép biến đổi (quay và dịch\n",
            "chuyển) căn chỉnh hai đám mây.\n",
            "Point-to-plane ICP: Phương pháp này xem xét thông tin bề mặt của đám mây điểm đích. Nó\n",
            "tính toán vectơ pháp tuyến (vuông góc với bề mặt) cho mỗi điểm trong đám mây đích. Thay vì chỉ đơn\n",
            "giản tìm điểm gần nhất, nó chiếu vectơ chênh lệch (giữa điểm nguồn và láng giềng gần nhất của nó) lên\n",
            "vectơ pháp tuyến của điểm đích. Điều này hiệu quả làm giảm khoảng cách vuông góc giữa điểm nguồn\n",
            "và bề mặt đích, dẫn đến sự căn chỉnh chính xác hơn cho các bề mặt cong.\n",
            "1def point_to_point_ICP (source , target , threshold , trans_init ):\n",
            "2 reg_p2p = o3d. pipelines . registration . registration_icp (\n",
            "3 source , target , threshold , trans_init ,\n",
            "4 o3d . pipelines . registration . TransformationEstimationPointToPoint ())\n",
            "5 draw_registration_result ( source , target , reg_p2p . transformation , \" Point to point\n",
            "ICP \")\n",
            "6 return reg_p2p . transformation\n",
            "7\n",
            "8\n",
            "9def point_to_plane_ICP (source , target , threshold , trans_init ):\n",
            "10 reg_p2l = o3d. pipelines . registration . registration_icp (\n",
            "11 source , target , threshold , trans_init ,\n",
            "12 o3d . pipelines . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "registration . TransformationEstimationPointToPlane ())\n",
            "13 draw_registration_result ( source , target , reg_p2l . transformation , \" Point to plane\n",
            "ICP \")\n",
            "14 return reg_p2l . transformation\n",
            "Sau khi registration, hai đám point clouds đạt được độ chồng chéo cao hơn đáng kể so với trước đó.\n",
            "Điều này thể hiện rõ ràng qua việc giảm dần giá trị inlier_rmse từ bản gốc đến Point-to-Point ICP và\n",
            "đạt mức thấp nhất với Point-to-Plane ICP hình 6.\n",
            "1.7 RGB-D Rescontruction\n",
            "RGB-D Reconstruction (Tái tạo 3D từ RGB-D) là kỹ thuật tạo ra mô hình 3D của một cảnh vật sử\n",
            "dụng dữ liệu thu thập từ camera RGB-D.\n",
            "Camera RGB-D là loại camera đặc biệt thu thập đồng thời hai loại dữ liệu:\n",
            "•Ảnh RGB: Ảnh màu thông thường cung cấp thông tin thị giác về cảnh vật.\n",
            "•Ảnh độ sâu: Ảnh này mã hóa khoảng cách đến từng điểm trong cảnh vật từ vị trí camera.\n",
            "Quá trình tái tạo: Ảnh RGB cung cấp chi tiết như màu sắc và kết cấu. Ảnh độ sâu cung cấp thông tin\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "về cấu trúc 3D của cảnh vật. Kết hợp hai nguồn dữ liệu này, các thuật toán có thể ước tính hình học\n",
            "3D của cảnh vật.\n",
            "Lợi ích của RGB-D Reconstruction:\n",
            "•Cung cấp thông tin 3D phong phú: Mang lại hình ảnh toàn diện hơn so với chỉ sử dụng ảnh RGB\n",
            "hoặc ảnh độ sâu riêng lẻ.\n",
            "•Ứng dụng rộng rãi: Được sử dụng trong các lĩnh vực như robot (điều hướng, thao tác), thực tế\n",
            "tăng cường (AR), thực tế ảo (VR) và mô hình 3D.\n",
            "Thách thức của RGB-D Reconstruction:\n",
            "•Hạn chế của cảm biến: Cảm biến độ sâu có thể bị nhiễu, đặc biệt đối với các bề mặt phản xạ hoặc\n",
            "trong suốt.\n",
            "•Độ phức tạp tính toán: Các thuật toán cần kết hợp và giải thích hiệu quả dữ liệu RGB và độ sâu.\n",
            "1def get_xyz_from_pts (u, v, depth , cx =319.5 , cy =239.5 , fx =525.0 , fy =525.0) :\n",
            "2 d = depth [ int(v), int (u)] # height , width in depth image\n",
            "3 x = ((u - cx) / fx) * d\n",
            "4 y = ((v - cy) / fy )* d\n",
            "5 return np. array ([x, y, d]). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "transpose ()\n",
            "6\n",
            "7def show_rgbd (rgb , depth ):\n",
            "8 plt . subplot (1, 2, 1)\n",
            "9 plt . title (’Grayscale image ’)\n",
            "10 plt . imshow (rgb)\n",
            "11 plt . subplot (1, 2, 2)\n",
            "12 plt . title (’Depth image ’)\n",
            "13 plt . imshow ( depth )\n",
            "14 plt . show ()\n",
            "15\n",
            "16def np_to_pc (points , colors ):\n",
            "17 pcd = o3d. geometry . PointCloud ()\n",
            "18 pcd . points = o3d. utility . Vector3dVector ( points )\n",
            "19 pcd . colors = o3d. utility . Vector3dVector ( colors )\n",
            "20 return pcd\n",
            "21\n",
            "22def get_pcl ( name = \"0\"):\n",
            "23 rgb = cv2. cvtColor (cv2. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "imread (f\"./ data / rgbd /{ name }. jpg\", cv2 . IMREAD_UNCHANGED ),\n",
            "cv2 . COLOR_BGR2RGB ) # read rgb\n",
            "24 depth = cv2. imread (f\"./ data / rgbd /{ name }. png\", cv2. IMREAD_UNCHANGED )\n",
            "25 h, w = depth . shape\n",
            "26 N = w*h\n",
            "27 points = np. zeros ((N ,3))\n",
            "28 colors = np. zeros ((N ,3))\n",
            "29 index = 0\n",
            "30 for u in range (w):\n",
            "31 for v in range (h):\n",
            "32 points [index ,:] = get_xyz_from_pts (u, v, depth )\n",
            "33 colors [index ,:] = rgb[v,u ]/255.0\n",
            "34 index += 1\n",
            "35 pcd = np_to_pc (points , colors )\n",
            "36 pcd . transform ([[1 , 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
            "37 show_rgbd (rgb , depth )\n",
            "38 o3d . visualization . draw_geometries ([ pcd], window_name = name )\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 6: Bên trái: Camera RGB-D thu được hai bức ảnh: ảnh màu sắc (RGB) và ảnh chiều sâu (Depth).\n",
            "Bên phải: Từ hai bức ảnh này, ta có thể tái tạo đám mây điểm 3D, mô tả hình dạng và vị trí của các\n",
            "vật thể trong không gian một cách chi tiết.\n",
            "2 Machine Learning with Point Cloud\n",
            "Trong phần này, chúng ta sẽ đi tìm hiểu về bài toán point clouds classification. Chúng ta sẽ sử dụng\n",
            "PointNet làm model để phân loại các vật thể 3D trong tập data ShapeNet.\n",
            "2.1 Data preparation\n",
            "Đầu tiên chúng ta sẽ tải bộ Shapenet bằng câu lệnh sau:\n",
            "1dataset_url = \" https :// git.io/ JiY4i \"\n",
            "2\n",
            "3dataset_path = keras . utils . get_file (\n",
            "4 fname =\" shapenet . zip\",\n",
            "5 origin = dataset_url ,\n",
            "6 cache_subdir =\" datasets \",\n",
            "7 hash_algorithm =\" auto \",\n",
            "8 extract =True ,\n",
            "9 archive_format =\" auto \",\n",
            "10 cache_dir =\" datasets \",\n",
            "11)\n",
            "Trong thí nghiệm này để dễ kiểm chứng kết quả thì ta chỉ lấy 3 classes trong tập Shapenet và mỗi\n",
            "class lấy tối đa 500 vật:\n",
            "1point_clouds = []\n",
            "2dense_labels = []\n",
            "3code_index_mapping = {}\n",
            "4for i, class_name in enumerate ( dict_mapping ):\n",
            "5 point_files = glob (f’/tmp /. keras / datasets / PartAnnotation /{ class_name }/ points /* ’)\n",
            "6 num_object = 0\n",
            "7 for file in point_files :\n",
            "8 point_cloud = np. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "loadtxt ( file )\n",
            "9 if point_cloud . shape [0] < NUM_SAMPLE_POINTS :\n",
            "10 continue\n",
            "11 if num_object == 500:\n",
            "12 break\n",
            "13 shuffle = np. random . choice ( point_cloud . shape [0] , NUM_SAMPLE_POINTS , replace =\n",
            "False )\n",
            "14 point_cloud = point_cloud [ shuffle ]\n",
            "15 point_clouds . append ( point_cloud )\n",
            "16 dense_labels . append (i)\n",
            "17 code_index_mapping [i] = dict_mapping [ class_name ]\n",
            "18 num_object += 1\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 7: Mô hình thiết kế của kiến trúc Pointnet\n",
            "Tạo dataloader:\n",
            "1point_clouds = np. stack ( point_clouds )\n",
            "2dense_labels = np. stack ( dense_labels )\n",
            "3# label_clouds = keras . utils . to_categorical ( dense_labels , num_classes =3)\n",
            "4label_clouds = dense_labels\n",
            "5class PointCloudData ( Dataset ):\n",
            "6 def __init__ (self , point_clouds , label_clouds ):\n",
            "7 self . point_clouds = point_clouds\n",
            "8 self . label_clouds = label_clouds\n",
            "9 def __len__ ( self ):\n",
            "10 return point_clouds . shape [0]\n",
            "11 def __getitem__ (self , idx):\n",
            "12 return {’pointcloud ’: torch . from_numpy ( point_clouds [idx ]) ,\n",
            "13 ’category ’: torch . from_numpy (np. asarray ( label_clouds [idx ]))}\n",
            "14X_train , X_val , y_train , y_val = train_test_split ( point_clouds , label_clouds ,\n",
            "test_size =0.2 , random_state =42)\n",
            "15train_loader = PointCloudData ( X_train , y_train )\n",
            "16val_loader = PointCloudData (X_val , y_val )\n",
            "17train_loader = DataLoader ( dataset = train_loader , batch_size =32 , shuffle = True )\n",
            "18val_loader = DataLoader ( dataset = val_loader , batch_size =32 , shuffle = True )\n",
            "2.2 Model\n",
            "Trong phần này chúng ta sẽ hiện thực lại kiến trúc Pointnet như hình 7.\n",
            "2.2.1 T-Net\n",
            "Trong PointNet, T-net đóng vai trò quan trọng trong việc đạt được tính bất biến hướng của đám mây\n",
            "điểm. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "T-net là một mạng con bên trong PointNet, có chức năng học một ma trận biến đổi. Ma trận\n",
            "biến đổi này sau đó được áp dụng cho từng điểm trong đám mây điểm, về cơ bản là xoay các điểm.\n",
            "Bằng cách học phép biến đổi này, mạng có thể xử lý các đám mây điểm được trình bày từ các góc nhìn\n",
            "khác nhau.\n",
            "Tính ổn định và khởi tạo:\n",
            "Nếu T-net được khởi tạo với các giá trị bằng 0, thì phép biến đổi ban đầu sẽ là phép biến đổi null\n",
            "(không thay đổi). Điều này có thể dẫn đến mất ổn định khi huấn luyện, đặc biệt là trong giai đoạn đầu.\n",
            "Ma trận đơn vị biểu diễn phép biến đổi đồng nhất, về cơ bản giữ nguyên các điểm. Sử dụng ma trận\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "đơn vị để khởi tạo cung cấp một điểm bắt đầu ổn định cho T-net để học các phép biến đổi có ý nghĩa.\n",
            "Nó cho phép T-net dần dần lệch khỏi phép biến đổi đồng nhất khi học. Điều này giúp việc học diễn ra\n",
            "trơn tru hơn và tránh những thay đổi đột ngột trong quá trình huấn luyện.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1class Tnet (nn. Module ):\n",
            "2 def __init__ (self , k=3):\n",
            "3 super (). __init__ ()\n",
            "4 self .k=k\n",
            "5 self . conv1 = nn. Conv1d (k ,64 ,1)\n",
            "6 self . conv2 = nn. Conv1d (64 ,128 ,1)\n",
            "7 self . conv3 = nn. Conv1d (128 ,1024 ,1)\n",
            "8 self . fc1 = nn. Linear (1024 ,512)\n",
            "9 self . fc2 = nn. Linear (512 ,256)\n",
            "10 self . fc3 = nn. Linear (256 ,k*k)\n",
            "11\n",
            "12 self . bn1 = nn. BatchNorm1d (64)\n",
            "13 self . bn2 = nn. BatchNorm1d (128)\n",
            "14 self . bn3 = nn. BatchNorm1d (1024)\n",
            "15 self . bn4 = nn. BatchNorm1d (512)\n",
            "16 self . bn5 = nn. BatchNorm1d (256)\n",
            "17\n",
            "18\n",
            "19 def forward (self , input ):\n",
            "20 # input . shape == (bs ,n ,3)\n",
            "21 bs = input . size (0)\n",
            "22 xb = F. relu ( self .bn1( self . conv1 ( input )))\n",
            "23 xb = F. relu ( self .bn2( self . conv2 (xb)))\n",
            "24 xb = F. relu ( self .bn3( self . conv3 (xb)))\n",
            "25 pool = nn. MaxPool1d (xb. size ( -1))(xb)\n",
            "26 flat = nn. Flatten (1)( pool )\n",
            "27 xb = F. relu ( self .bn4( self .fc1( flat )))\n",
            "28 xb = F. relu ( self .bn5( self .fc2(xb)))\n",
            "29\n",
            "30 # initialize as identity\n",
            "31 init = torch .eye ( self .k, requires_grad = True ). repeat (bs ,1 ,1)\n",
            "32 if xb. is_cuda :\n",
            "33 init = init . cuda ()\n",
            "34 matrix = self .fc3(xb). view (-1, self .k, self .k) + init\n",
            "35 return matrix\n",
            "2.2.2 Transform\n",
            "Module Transform thực hiện thao tác biến đổi bằng T-Net 2.2.1 hai lần. Lần thứ nhất trong không gian\n",
            "3 chiều (coordinate) và lần thứ hai trong không gian 64 chiều (feature).\n",
            "1 class Transform (nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Module ):\n",
            "2 def __init__ ( self ):\n",
            "3 super (). __init__ ()\n",
            "4 self . input_transform = Tnet (k=3)\n",
            "5 self . feature_transform = Tnet (k =64)\n",
            "6 self . conv1 = nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Conv1d (3 ,64 ,1)\n",
            "7\n",
            "8 self . conv2 = nn. Conv1d (64 ,128 ,1)\n",
            "9 self . conv3 = nn. Conv1d (128 ,1024 ,1)\n",
            "10\n",
            "11\n",
            "12 self . bn1 = nn. BatchNorm1d (64)\n",
            "13 self . bn2 = nn. BatchNorm1d (128)\n",
            "14 self . bn3 = nn. BatchNorm1d (1024)\n",
            "15\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "16 def forward (self , input ):\n",
            "17 matrix3x3 = self . input_transform ( input )\n",
            "18 # batch matrix multiplication\n",
            "19 xb = torch .bmm ( torch . transpose (input ,1 ,2) , matrix3x3 ). transpose (1 ,2)\n",
            "20\n",
            "21 xb = F. relu ( self .bn1( self . conv1 (xb)))\n",
            "22\n",
            "23 matrix64x64 = self . feature_transform (xb)\n",
            "24 xb = torch .bmm ( torch . transpose (xb ,1 ,2) , matrix64x64 ). transpose (1 ,2)\n",
            "25\n",
            "26 xb = F. relu ( self .bn2( self . conv2 (xb)))\n",
            "27 xb = self .bn3( self . conv3 (xb))\n",
            "28 xb = nn. MaxPool1d (xb. size ( -1))(xb)\n",
            "29 output = nn. Flatten (1)(xb)\n",
            "30 return output , matrix3x3 , matrix64x64\n",
            "2.2.3 PointNet\n",
            "Mạng PointNet sử dụng module Transform 2.2.2 và các lớp fully connected layer để tổng hợp thông tin\n",
            "và đưa ra dự đoán dựa vào hàm softmax.\n",
            "1 class PointNet (nn. Module ):\n",
            "2 def __init__ (self , classes = 3):\n",
            "3 super (). __init__ ()\n",
            "4 self . transform = Transform ()\n",
            "5 self . fc1 = nn. Linear (1024 , 512)\n",
            "6 self . fc2 = nn. Linear (512 , 256)\n",
            "7 self . fc3 = nn. Linear (256 , classes )\n",
            "8\n",
            "9 self . bn1 = nn. BatchNorm1d (512)\n",
            "10 self . bn2 = nn. BatchNorm1d (256)\n",
            "11 self . dropout = nn. Dropout (p =0.3)\n",
            "12 self . logsoftmax = nn. LogSoftmax (dim =1)\n",
            "13\n",
            "14 def forward (self , input ):\n",
            "15 xb , matrix3x3 , matrix64x64 = self . transform ( input )\n",
            "16 xb = F. relu ( self .bn1( self .fc1(xb)))\n",
            "17 xb = F. relu ( self .bn2( self . dropout ( self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "fc2(xb))))\n",
            "18 output = self .fc3(xb)\n",
            "19\n",
            "20 return self . logsoftmax ( output ), matrix3x3 , matrix64x64\n",
            "2.3 Hàm loss\n",
            "Trong PointNet, việc áp dụng ràng buộc ma trận chuyển đổi học được bởi các mô-đun Tnet gần với ma\n",
            "trận trực giao ( ||X∗XT−I|| ≈ 0) mang lại nhiều lợi ích quan trọng:\n",
            "•Khi ma trận chuyển đổi gần với ma trận trực giao, chúng chủ yếu ảnh hưởng đến việc xoay các\n",
            "điểm, không phải khoảng cách. Điều này đảm bảo rằng các tính năng được mạng trích xuất nắm\n",
            "bắt các mối quan hệ hình học thực sự giữa các điểm, điều cần thiết cho việc nhận dạng đối tượng\n",
            "chính xác.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Ma trận trực giao được điều chỉnh tốt, nghĩa là những thay đổi nhỏ trong đầu vào (đám mây\n",
            "điểm) không dẫn đến những thay đổi lớn trong đầu ra (đám mây điểm được biến đổi). Điều này\n",
            "cải thiện độ ổn định số của mạng trong quá trình đào tạo và giúp nó hội tụ nhanh hơn.\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Ma trận trực giao có một đặc tính đặc biệt: nghịch đảo của chúng đơn giản là chuyển vị của chúng.\n",
            "Điều này đơn giản hóa các phép tính trong mạng. Trong quá trình truyền tiếp, khi đám mây điểm\n",
            "được biến đổi được nhân với chuyển vị của ma trận chuyển đổi, nó trở thành phép nhân ma trận\n",
            "đơn thay vì một phép toán phức tạp hơn liên quan đến nghịch đảo. Điều này làm giảm chi phí\n",
            "tính toán cho việc xử lý đám mây điểm.\n",
            "1def pointnetloss ( outputs , labels , m3x3 , m64x64 , alpha = 0.0001) :\n",
            "2 criterion = torch .nn. NLLLoss ()\n",
            "3 bs= outputs . size (0)\n",
            "4 id3x3 = torch .eye (3, requires_grad = True ). repeat (bs ,1 ,1)\n",
            "5 id64x64 = torch .eye (64 , requires_grad = True ). repeat (bs ,1 ,1)\n",
            "6 if outputs . is_cuda :\n",
            "7 id3x3 = id3x3 . cuda ()\n",
            "8 id64x64 = id64x64 . cuda ()\n",
            "9 diff3x3 = id3x3 - torch . bmm(m3x3 , m3x3 . transpose (1 ,2))\n",
            "10 diff64x64 = id64x64 - torch .bmm( m64x64 , m64x64 . transpose (1 ,2))\n",
            "11 return criterion ( outputs , labels ) + alpha * ( torch . norm ( diff3x3 )+ torch . norm (\n",
            "diff64x64 )) / float (bs)\n",
            "2.4 Training\n",
            "Kết hợp dataloader và model để train:\n",
            "1pointnet = PointNet ( classes = num_classes )\n",
            "2pointnet .to( device );\n",
            "3optimizer = torch . optim . Adam ( pointnet . parameters () , lr =0.001)\n",
            "4def train (model , train_loader , val_loader =None , epochs =5, save = True ):\n",
            "5 for epoch in range ( epochs ):\n",
            "6 pointnet . train ()\n",
            "7 running_loss = 0.0\n",
            "8 for i, data in enumerate ( train_loader , 0):\n",
            "9 inputs , labels = data [’pointcloud ’]. to( device ). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "float () , data [’category ’].\n",
            "to( device )\n",
            "10\n",
            "11 optimizer . zero_grad ()\n",
            "12 outputs , m3x3 , m64x64 = pointnet ( inputs . transpose (1 ,2))\n",
            "13\n",
            "14 loss = pointnetloss ( outputs , labels , m3x3 , m64x64 )\n",
            "15 loss . backward ()\n",
            "16 optimizer . step ()\n",
            "17\n",
            "18 # print statistics\n",
            "19 running_loss += loss . item ()\n",
            "20 if i % 10 == 9: # print every 10 mini - batches\n",
            "21 print (’[ Epoch : %d, Batch : %4d / %4d], loss : %.3f’ %\n",
            "22 ( epoch + 1, i + 1, len( train_loader ), running_loss / 10))\n",
            "23 running_loss = 0.0\n",
            "24\n",
            "25 pointnet . eval ()\n",
            "26 correct = total = 0\n",
            "27\n",
            "28 # validation\n",
            "29 if val_loader :\n",
            "30 with torch . no_grad ():\n",
            "31 for data in val_loader :\n",
            "32 inputs , labels = data [’pointcloud ’]. to( device ). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "float () , data [’\n",
            "category ’]. to( device )\n",
            "33 outputs , __ , __ = pointnet ( inputs . transpose (1 ,2))\n",
            "34 _, predicted = torch .max( outputs .data , 1)\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 8: Kết quả classification của PointNet trên Shapenet\n",
            "35 total += labels . size (0)\n",
            "36 correct += ( predicted == labels ).sum (). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "item ()\n",
            "37 val_acc = 100. * correct / total\n",
            "38 print (’Valid accuracy : %d %% ’ % val_acc )\n",
            "39\n",
            "40\n",
            "41 torch . save ( pointnet . state_dict () , \" save_ \"+str( epoch )+\". pth\")\n",
            "2.5 Inference\n",
            "Sau khi train model xong, inference ta được kết quả như hình 8.\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Câu Hỏi\n",
            "1.When loading a point cloud, what information might be included besides the 3D\n",
            "coordinates (XYZ)?\n",
            "(A). Color information (RGB). (B). Intensity values.\n",
            "(C). Normal vectors. (D). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "All of the above.\n",
            "2.When dealing with 3D point cloud data, which data structure offers faster average-\n",
            "case search time complexity?\n",
            "(A). Kd-Tree. (B). Octree.\n",
            "(C). Both (a) and (b) have similar complexity. (D). The answer depends on the data distribution.\n",
            "3.When dealing with point cloud data containing elongated or anisotropic features,\n",
            "which data structure might be less efficient for nearest neighbor search?\n",
            "(A). Kd-Tree. (B). Octree.\n",
            "(C). Both (a) and (b) can be affected. (D). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Neither (a) nor (b).\n",
            "4.When dealing with point clouds with smooth surfaces, which ICP variant might be\n",
            "more suitable?\n",
            "(A). Point-to-Point ICP. (B). Point-to-Plane ICP.\n",
            "(C). Both (a) and (b) are equally suitable. (D). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Neither (a) nor (b) is suitable.\n",
            "5.When dealing with point clouds with varying surface orientations (not necessarily\n",
            "smooth), which ICP variant might be more robust?\n",
            "(A). Point-to-Point ICP. (B). Point-to-Plane ICP.\n",
            "(C). Both (a) and (b) are equally robust. (D). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Neither (a) nor (b) is suitable.\n",
            "6.What is the main input data format for PointNet?\n",
            "(A). Images. (B). Meshes.\n",
            "(C). Point Clouds. (D). Voxels.\n",
            "7.PointNet utilizes symmetrical functions for processing point clouds. What does this\n",
            "mean?\n",
            "(A). The order of points in the input cloud doesn’t affect the output.\n",
            "(B). The network has the same number of layers in the encoder and decoder.\n",
            "(C). The network can process both 2D and 3D data.\n",
            "(D). The network requires pre-segmented point clouds.\n",
            "8.PointNet++ is an extension of PointNet that addresses a limitation. What is that\n",
            "limitation?\n",
            "(A). Inability to handle large point clouds.\n",
            "(B). Sensitivity to point cloud order.\n",
            "(C). Difficulty capturing local features.\n",
            "(D). Limited number of learnable parameters.\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "9.How does Voxel Net process point cloud data compare to PointNet?\n",
            "(A). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "It directly operates on the point cloud coordinates.\n",
            "(B). It converts the point cloud into a 3D volumetric grid (voxel grid).\n",
            "(C). It requires pre-segmentation of the point cloud.\n",
            "(D). It is computationally less expensive than PointNet.\n",
            "10.What is a potential drawback of using Voxel Net?\n",
            "(A). It can be computationally expensive for high-resolution voxel grids.\n",
            "(B). It requires color information for each point to be effective.\n",
            "(C). It is sensitive to the chosen voxel size.\n",
            "(D). Both (A) and (C).\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "Triển khai mô hình Deep Learning với FastAPI\n",
            "Dinh-Thang Duong, Nguyen-Thuan Duong và Quang-Vinh Dinh\n",
            "PR-Team: Hoàng-Nguyên Vũ, Đăng-Nhã Nguyễn và Minh-Châu Phạm\n",
            "Ngày 28 tháng 3 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Triển khai mô hình Deep Learning (Model Deployment) là một trong những công việc quan\n",
            "trọng trong quy trình đưa mô hình ra sản phẩm thực tế, giúp cho người sử dụng có thể tương tác với\n",
            "trực tiếp với mô hình. Một trong những phương thức giúp chúng ta có thể làm điều này đó là triển khai\n",
            "mô hình thành một API. Theo đó, người dùng có thể thông qua API endpoint để sử dụng mô hình của\n",
            "chúng ta mà không cần phải sở hữu mã nguồn chương trình cũng như tài nguyên tính toán.\n",
            "Hình 1: Triển khai mô hình Deep Learning dưới dạng một API.\n",
            "Trongbàiviếtnày,chúngtasẽtriểnkhaimộtmôhìnhvềImageClassificationbằngthưviệnFastAPI\n",
            "trong Python. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sau khi hoàn thành chương trình, chúng ta sẽ có thể sử dụng mô hình thông qua một\n",
            "địa chỉ web (URL).\n",
            "Hình 2: Logo của thư viện FastAPI.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Nội dung\n",
            "Ở phần này, chúng ta sẽ xây dựng hai thành phần chính của chương trình bao gồm phần xây dựng mô\n",
            "hình và phần FastAPI. Cách thực hiện như sau:\n",
            "A. Xây dựng mô hình\n",
            "Đầu tiên, chúng ta sẽ bắt đầu với giai đoạn đầu như mọi project về Machine Learning đó là\n",
            "xây dựng mô hình. Như đã đề cập trong bài viết, chúng ta sẽ xây dựng một mô hình về Image\n",
            "Classification, cụ thể là bài toán Cat/Dog Classification.\n",
            "Hình 3: Ảnh minh họa bài toán Cat/Dog Classification. Ảnh: link.\n",
            "Ở đây, ta sẽ sử dụng thư viện PyTorch và Google Colab để giải quyết phần này như sau:\n",
            "1.Tải và import các thư viện cần thiết: Đầu tiên, ta cài đặt thư viện datasets để sử dụng\n",
            "trong việc tải dữ liệu Cat Dog về sau:\n",
            "1$ pip install datasets ==2.18.0 -q\n",
            "Sau đó, ta thực hiện import các thư viện cần thiết trong việc huấn luyện mô hình:\n",
            "1import torch\n",
            "2import torch .nn as nn\n",
            "3\n",
            "4from PIL import Image\n",
            "5from datasets import load_dataset\n",
            "6from torch . utils . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "data import Dataset , DataLoader\n",
            "7from torchvision . models import resnet18\n",
            "8from torchvision import transforms\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "2.Tải bộ dữ liệu: Chúng ta sẽ sử dụng bộ dữ liệu Cat Dog có sẵn trên HuggingFace Dataset.\n",
            "Các bạn hãy chạy đoạn code bên dưới để tải cũng như load bộ dữ liệu:\n",
            "1DATASET_NAME = ’ cats_vs_dogs ’\n",
            "2datasets = load_dataset ( DATASET_NAME )\n",
            "3datasets\n",
            "Hình 4: Bộ dữ liệu về Cat Dog Image Classification trên HuggingFace Dataset.\n",
            "3.Chia bộ dữ liệu train, val: Từ bộ dữ liệu gốc, ta sẽ tách thành hai bộ train và val để phục\n",
            "vụ cho việc huấn luyện mô hình như sau:\n",
            "1TEST_SIZE = 0.2\n",
            "2datasets = datasets [’train ’]. train_test_split ( test_size = TEST_SIZE )\n",
            "4.Xây dựng DataLoader: Để thuận tiện trong việc đọc dữ liệu khi thực hiện huấn luyện với\n",
            "PyTorch, chúng ta sẽ xây dựng DataLoader cho hai bộ train và val như sau:\n",
            "(a)Xây dựng hàm tiền xử lý dữ liệu ảnh: Chúng ta sẽ xây dựng hàm transforms trong\n",
            "PyTorch để tiền xử lý dữ liệu ảnh như sau:\n",
            "1IMG_SIZE = 64\n",
            "2img_transforms = transforms . Compose ([\n",
            "3 transforms . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Resize (( IMG_SIZE , IMG_SIZE )),\n",
            "4 transforms . Grayscale ( num_output_channels =3) ,\n",
            "5 transforms . ToTensor () ,\n",
            "6 transforms . Normalize (\n",
            "7 [0.485 , 0.456 , 0.406] ,\n",
            "8 [0.229 , 0.224 , 0.225]\n",
            "9 )\n",
            "10])\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(b)Xây dựng class CatDogDataset: Chúng ta xây dựng class CatDogDataset để đọc dữ\n",
            "liệu cho DataLoader:\n",
            "1class CatDogDataset ( Dataset ):\n",
            "2 def __init__ (self , data , transform = None ):\n",
            "3 self . data = data\n",
            "4 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "transform = transform\n",
            "5\n",
            "6 def __len__ ( self ):\n",
            "7 return len( self . data )\n",
            "8\n",
            "9 def __getitem__ (self , idx):\n",
            "10 images = self . data [ idx ][ ’image ’]\n",
            "11 labels = self . data [ idx ][ ’labels ’]\n",
            "12\n",
            "13 if self . transform :\n",
            "14 images = self . transform ( images )\n",
            "15\n",
            "16 labels = torch . tensor ( labels , dtype = torch . long )\n",
            "17\n",
            "18 return images , labels\n",
            "(c)Khai báo DataLoader: Cuối cùng, ta khai báo hai DataLoader với số batch size phù\n",
            "hợp:\n",
            "1TRAIN_BATCH_SIZE = 512\n",
            "2VAL_BATCH_SIZE = 256\n",
            "3\n",
            "4train_dataset = CatDogDataset ( datasets [’train ’], transform = img_transforms )\n",
            "5test_dataset = CatDogDataset ( datasets [’test ’], transform = img_transforms )\n",
            "6\n",
            "7train_loader = DataLoader ( train_dataset , batch_size = TRAIN_BATCH_SIZE ,\n",
            "shuffle = True )\n",
            "8test_loader = DataLoader ( test_dataset , batch_size = VAL_BATCH_SIZE , shuffle =\n",
            "False )\n",
            "5.Xây dựng mô hình: Ta xây dựng class CatDogModel cho bài toán Cat Dog Classification với\n",
            "backbone là pre-trained resnet18 như sau:\n",
            "1class CatDogModel (nn. Module ):\n",
            "2 def __init__ (self , n_classes ):\n",
            "3 super ( CatDogModel , self ). __init__ ()\n",
            "4\n",
            "5 resnet_model = resnet18 ( weights =’ IMAGENET1K_V1 ’)\n",
            "6 self . backbone = nn. Sequential (* list ( resnet_model . children ()) [: -1])\n",
            "7 for param in self . backbone . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "parameters ():\n",
            "8 param . requires_grad = False\n",
            "9\n",
            "10 in_features = resnet_model .fc. in_features\n",
            "11 self .fc = nn. Linear ( in_features , n_classes )\n",
            "12\n",
            "13 def forward (self , x):\n",
            "14 x = self . backbone (x)\n",
            "15 x = torch . flatten (x, 1)\n",
            "16 x = self .fc(x)\n",
            "17\n",
            "18 return x\n",
            "Sau đó, ta khai báo mô hình và kiểm tra thử mô hình đã hoạt động được hay chưa như sau:\n",
            "1device = ’cuda ’ if torch . cuda . is_available () else ’cpu ’\n",
            "2N_CLASSES = 2\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3model = CatDogModel ( N_CLASSES ).to( device )\n",
            "4test_input = torch . rand (1, 3, 224 , 224) .to( device )\n",
            "5with torch . no_grad ():\n",
            "6 output = model ( test_input )\n",
            "7 print ( output . shape ) # (1, 2)\n",
            "6.Thực hiện huấn luyện mô hình: Với mô hình và dataset đã sẵn sàng, chúng ta sẽ khai\n",
            "báo optimizer, criterion cũng như vòng lặp training để huấn luyện mô hình như sau:\n",
            "1EPOCHS = 10\n",
            "2LR = 1e -3\n",
            "3WEIGHT_DECAY = 1e -5\n",
            "4\n",
            "5optimizer = torch . optim . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Adam ( model . parameters () , lr=LR , weight_decay =\n",
            "WEIGHT_DECAY )\n",
            "6criterion = torch .nn. CrossEntropyLoss ()\n",
            "7\n",
            "8for epoch in range ( EPOCHS ):\n",
            "9 train_losses = []\n",
            "10 model . train ()\n",
            "11 for images , labels in train_loader :\n",
            "12 images = images .to( device )\n",
            "13 labels = labels .to( device )\n",
            "14\n",
            "15 outputs = model ( images )\n",
            "16\n",
            "17 optimizer . zero_grad ()\n",
            "18 loss = criterion ( outputs , labels )\n",
            "19 loss . backward ()\n",
            "20 optimizer . step ()\n",
            "21\n",
            "22 train_losses . append ( loss . item ())\n",
            "23\n",
            "24 train_loss = sum( train_losses ) / len( train_losses )\n",
            "25\n",
            "26 val_losses = []\n",
            "27 model . eval ()\n",
            "28 with torch . no_grad ():\n",
            "29 for images , labels in test_loader :\n",
            "30 images = images .to( device )\n",
            "31 labels = labels .to( device )\n",
            "32\n",
            "33 outputs = model ( images )\n",
            "34 loss = criterion ( outputs , labels )\n",
            "35\n",
            "36 val_losses . append ( loss . item ())\n",
            "37\n",
            "38 val_loss = sum( val_losses ) / len( val_losses )\n",
            "39\n",
            "40 print (f’EPOCH { epoch + 1}:\\ tTrain loss : { train_loss :.3f}\\ tVal loss : {\n",
            "val_loss :.3 f}’)\n",
            "7.Lưu trọng số mô hình: Với mô hình đã được huấn luyện xong, ta sẽ lưu mô hình lại dưới\n",
            "dạng file .pt và tải về máy file này:\n",
            "1SAVE_PATH = ’ catdog_weights .pt ’\n",
            "2torch . save ( model . state_dict () , SAVE_PATH )\n",
            "Như vậy, qua mục này, chúng ta đã có được một mô hình Deep Learning để sử dụng trong\n",
            "API.\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "B. Xây dựng API\n",
            "Sau khi có bộ trọng số mô hình Cat Dog Classification đã huấn luyện ở mục trước, chúng ta\n",
            "sẽ tiến hành xây dựng API để sử dụng mô hình này bằng FastAPI. Nội dung này chúng ta sẽ cài\n",
            "đặt ở máy tính cá nhân. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Demo được thực hiện trên hệ điều hành MacOS. Các bước thực hiện như\n",
            "sau:\n",
            "1.Tổ chức thư mục code: Để mã nguồn trở nên rõ ràng nhằm phục vụ cho mục đích đọc\n",
            "hiểu code, chúng ta sẽ tổ chức thư mục như sau:\n",
            "root/\n",
            "config/\n",
            "catdog_cfg.py\n",
            "logging_cfg.py\n",
            "logs/\n",
            "middleware/\n",
            "__init__.py\n",
            "cors.py\n",
            "http.py\n",
            "models/\n",
            "weights/\n",
            "catdog_weights.pt\n",
            "catdog_model.py\n",
            "catdog_predictor.py\n",
            "routes/\n",
            "base.py\n",
            "catdog_route.py\n",
            "schemas/\n",
            "catdog_schema.py\n",
            "utils/\n",
            "logger.py\n",
            "app.py\n",
            "requirements.txt\n",
            "server.py\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Tổng quan, chúng ta sẽ có thư mục chứa mã nguồn có tên root(các bạn hoàn toàn có thể\n",
            "sử dụng tên gọi khác). Bên trong sẽ có các thư mục con và các file với ý nghĩa như sau:\n",
            "_config/: Thư mục chứa code định nghĩa các tham số liên quan đến các module khác\n",
            "nhau như model, logger...\n",
            "_logs/:Thư mục lưu trữ log. Log có thể bao gồm thông tin trạng thái các request mà\n",
            "API đã nhận được cũng như kết quả trả về của mô hình.\n",
            "_middleware/: Thư mục chứa code tiền và hậu xử lý một request.\n",
            "_models/: Thư mục chứa code của mô hình mà ta đã huấn luyện ở phần A.\n",
            "_routes/: Thư mục chứa code định nghĩa các API endpoints.\n",
            "_schemas/: Thư mục chứa code định nghĩa các cấu trúc dữ liệu input/output của API...\n",
            "_utils/:Thư mục dùng để chứa một số code có các chức năng khác nhau tùy thuộc vào\n",
            "project.\n",
            "_app.py: File code khai báo API.\n",
            "_requirements.txt: File chứa thông tin các gói thư viện cần thiết để chạy mã nguồn.\n",
            "_server.py: File code để thực thi triển khai mô hình.\n",
            "Hình 5: Minh họa cấu trúc cây thư mục của chương trình trong VSCode.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "2.Cập nhật file requirements.txt :Để bắt đầu, chúng ta sẽ liệt kê các gói thư viện cần thiết\n",
            "để chạy được chương trình này. Các bạn hãy cập nhật file requirements.txt với nội dung sau:\n",
            "1fastapi ==0.110.0\n",
            "2uvicorn ==0.27.1\n",
            "3torch ==2.2.1\n",
            "4torchvision ==0.17.1\n",
            "5python - multipart ==0.0.9\n",
            "3.Cập nhật thư mục config/:Mục đích của thư mục này nhằm giúp chúng ta có thể quản\n",
            "lý những tham số của một số tính năng nào đó trong API, có thể kể đến là các tham số của\n",
            "mô hình Deep Learning, một cách thuận tiện và hiệu quả. Vì vậy, chúng ta sẽ khai báo các\n",
            "thông tin tham số cho bài toán Cat Dog Classification vào file config/catdog_cfg.py như sau:\n",
            "1import sys\n",
            "2\n",
            "3from pathlib import Path\n",
            "4sys . path . append (str( Path ( __file__ ). parent ))\n",
            "5\n",
            "6class CatDogDataConfig :\n",
            "7 N_CLASSES = 2\n",
            "8 IMG_SIZE = 64\n",
            "9 ID2DLABEL = {0: ’Cat ’, 1: ’Dog ’}\n",
            "10 LABEL2ID = {’Cat ’: 0, ’Dog ’: 1}\n",
            "11 NORMALIZE_MEAN = [0.485 , 0.456 , 0.406]\n",
            "12 NORMALIZE_STD = [0.229 , 0.224 , 0.225]\n",
            "13\n",
            "14class ModelConfig :\n",
            "15 ROOT_DIR = Path ( __file__ ). parent . parent\n",
            "16 MODEL_NAME = ’resnet18 ’\n",
            "17 MODEL_WEIGHT = ROOT_DIR / ’models ’ / ’weights ’ / ’ catdog_weights .pt ’\n",
            "18 DEVICE = ’cpu ’\n",
            "Ở đây, ta quản lý các tham số bằng Python class. Việc đặt tên class có thể tùy chỉnh khác\n",
            "nhau nhưng nên được đặt tên cho phù hợp với ý nghĩa của chúng.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "4.Xây dựng hàm logger: Khi triển khai API, rất nhiều khả năng chúng ta sẽ bắt gặp lỗi ở\n",
            "một request tại thời điểm nào đó. Để biết chính xác thông tin này, chúng ta cần thực hiện\n",
            "logging. Logging là một kỹ thuật giúp chương trình ghi nhận lại lịch sử của chương trình, có\n",
            "thể bao gồm kết quả dự đoán của mô hình, kết quả request...\n",
            "Hình 6: Minh họa thông tin kết quả các lần request API mà logger ghi nhận được.\n",
            "Trong bài này, chúng ta sẽ sử dụng module logging trong Python để xây dựng một logger.\n",
            "Ta sẽ triển khai code vào file utils/logger.py như sau:\n",
            "1import sys\n",
            "2import logging\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3\n",
            "4from pathlib import Path\n",
            "5sys . path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "append (str( Path ( __file__ ). parent ))\n",
            "6\n",
            "7from logging . handlers import RotatingFileHandler\n",
            "8from config . logging_cfg import LoggingConfig\n",
            "9\n",
            "10class Logger :\n",
            "11 def __init__ (self , name =\"\", log_level = logging .INFO , log_file = None ) ->\n",
            "None :\n",
            "12 self . log = logging . getLogger ( name )\n",
            "13 self . get_logger ( log_level , log_file )\n",
            "14\n",
            "15 def get_logger (self , log_level , log_file ):\n",
            "16 self . log. setLevel ( log_level )\n",
            "17 self . _init_formatter ()\n",
            "18 if log_file is not None :\n",
            "19 self . _add_file_hander ( LoggingConfig . LOG_DIR / log_file )\n",
            "20 else :\n",
            "21 self . _add_stream_hander ()\n",
            "22\n",
            "23 def _init_formatter ( self ):\n",
            "24 self . formatter = logging . Formatter (\n",
            "25 \"%( asctime )s - %( name )s - %( levelname )s - %( message )s\"\n",
            "26 )\n",
            "27 def _add_stream_hander ( self ):\n",
            "28 stream_handler = logging . StreamHandler ( sys. stdout )\n",
            "29 stream_handler . setFormatter ( self . formatter )\n",
            "30 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "log. addHandler ( stream_handler )\n",
            "31\n",
            "32 def _add_file_hander (self , log_file ):\n",
            "33 file_handler = RotatingFileHandler ( log_file , maxBytes =10000 ,\n",
            "backupCount =10)\n",
            "34 file_handler . setFormatter ( self . formatter )\n",
            "35 self . log. addHandler ( file_handler )\n",
            "36\n",
            "37 def log_model (self , predictor_name ):\n",
            "38 self . log. info (f\" Predictor name : { predictor_name }\")\n",
            "39\n",
            "40 def log_response (self , pred_prob , pred_id , pred_class ):\n",
            "41 self . log. info (f\" Predicted Prob : { pred_prob } - Predicted ID: { pred_id\n",
            "} - Predicted Class : { pred_class }\")\n",
            "Đối với việc logging, chúng ta sẽ có tham số về đường dẫn thư mục lưu file log. Vì vậy, ta\n",
            "cũng sẽ cập nhật tham số này trong file config/logging_cfg.py như sau:\n",
            "1from pathlib import Path\n",
            "2\n",
            "3class LoggingConfig :\n",
            "4 ROOT_DIR = Path ( __file__ ). parent . parent\n",
            "5\n",
            "6 LOG_DIR = ROOT_DIR / \" logs \"\n",
            "7\n",
            "8LoggingConfig . LOG_DIR . mkdir ( parents =True , exist_ok = True )\n",
            "5.Cập nhật thư mục models/:Chúng ta sẽ đưa thông tin model đã huấn luyện vào thư mục\n",
            "chuyên dùng để chứa các mô hình đã huấn luyện. Theo đó, chúng ta sẽ lưu file weights\n",
            "catdog_weights.pt vào trong thư mục con models/weights .\n",
            "Tiếp theo, để sử dụng mô hình PyTorch khi inference, chúng ta cần có định nghĩa class\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "của mô hình cũng như hàm prediction. Vậy nên, ta sẽ đưa các thông tin trên thành hai file\n",
            "riêng biệt:\n",
            "_ Với models/catdog_model.py : Dùng để chứa định nghĩa class của mô hình. Ở đây, ta đơn\n",
            "giản copy lại thông tin ở file notebook vào:\n",
            "1import torch\n",
            "2import torch .nn as nn\n",
            "3\n",
            "4from torchvision . models import resnet18\n",
            "5\n",
            "6class CatDogModel (nn. Module ):\n",
            "7 def __init__ (self , n_classes ):\n",
            "8 super ( CatDogModel , self ). __init__ ()\n",
            "9\n",
            "10 resnet_model = resnet18 ( weights =’ IMAGENET1K_V1 ’)\n",
            "11 self . backbone = nn. Sequential (* list ( resnet_model . children ()) [: -1])\n",
            "12 for param in self . backbone . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "parameters ():\n",
            "13 param . requires_grad = False\n",
            "14\n",
            "15 in_features = resnet_model .fc. in_features\n",
            "16 self .fc = nn. Linear ( in_features , n_classes )\n",
            "17\n",
            "18 def forward (self , x):\n",
            "19 x = self . backbone (x)\n",
            "20 x = torch . flatten (x, 1)\n",
            "21 x = self .fc(x)\n",
            "22\n",
            "23 return x\n",
            "_ Với models/catdog_predictor.py : Ta xây dựng class Predictor, dùng trong việc khởi tạo mô\n",
            "hình với bộ trọng số cho trước và cho phép ta thực hiện inference. Ta có thể xây dựng\n",
            "class này như sau:\n",
            "1import sys\n",
            "2import torch\n",
            "3import torchvision\n",
            "4\n",
            "5from pathlib import Path\n",
            "6sys . path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "append (str( Path ( __file__ ). parent . parent ))\n",
            "7\n",
            "8from PIL import Image\n",
            "9from torch .nn import functional as F\n",
            "10from utils . logger import Logger\n",
            "11from config . catdog_cfg import CatDogDataConfig\n",
            "12from . catdog_model import CatDogModel\n",
            "13\n",
            "14LOGGER = Logger ( __file__ , log_file =\" predictor .log\")\n",
            "15LOGGER .log. info (\" Starting Model Serving \")\n",
            "16\n",
            "17class Predictor :\n",
            "18 def __init__ (self , model_name : str , model_weight : str , device : str = \"\n",
            "cpu \"):\n",
            "19 self . model_name = model_name\n",
            "20 self . model_weight = model_weight\n",
            "21 self . device = device\n",
            "22 self . load_model ()\n",
            "23 self . create_transform ()\n",
            "24\n",
            "25 async def predict (self , image ):\n",
            "26 pil_img = Image . open ( image )\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "27\n",
            "28 if pil_img . mode == ’RGBA ’:\n",
            "29 pil_img = pil_img . convert (’RGB ’)\n",
            "30\n",
            "31 transformed_image = self . transforms_ ( pil_img ). unsqueeze (0)\n",
            "32 output = await self . model_inference ( transformed_image )\n",
            "33 probs , best_prob , predicted_id , predicted_class = self . output2pred\n",
            "( output )\n",
            "34\n",
            "35 LOGGER . log_model ( self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "model_name )\n",
            "36 LOGGER . log_response ( best_prob , predicted_id , predicted_class )\n",
            "37\n",
            "38 torch . cuda . empty_cache ()\n",
            "39\n",
            "40 resp_dict = {\n",
            "41 \" probs \":probs ,\n",
            "42 \" best_prob \": best_prob ,\n",
            "43 \" predicted_id \": predicted_id ,\n",
            "44 \" predicted_class \": predicted_class ,\n",
            "45 \" predictor_name \": self . model_name\n",
            "46 }\n",
            "47\n",
            "48 return resp_dict\n",
            "49\n",
            "50 async def model_inference (self , input ):\n",
            "51 input = input .to( self . device )\n",
            "52 with torch . no_grad ():\n",
            "53 output = self . loaded_model ( input .to( self . device )).cpu ()\n",
            "54 return output\n",
            "55\n",
            "56 def load_model ( self ):\n",
            "57 try :\n",
            "58 model = CatDogModel ( CatDogDataConfig . N_CLASSES )\n",
            "59 model . load_state_dict ( torch . load ( self . model_weight ,\n",
            "map_location = self . device ))\n",
            "60 model .to( self . device )\n",
            "61 model . eval ()\n",
            "62\n",
            "63 self . loaded_model = model\n",
            "64\n",
            "65 except Exception as e:\n",
            "66 LOGGER .log. error (f\" Load model failed \")\n",
            "67 LOGGER .log. error (f\" Error : {e}\")\n",
            "68\n",
            "69 return None\n",
            "70\n",
            "71 def create_transform ( self ):\n",
            "72 self . transforms_ = torchvision . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "transforms . Compose ([\n",
            "73 torchvision . transforms . Resize (( CatDogDataConfig . IMG_SIZE ,\n",
            "CatDogDataConfig . IMG_SIZE )),\n",
            "74 torchvision . transforms . ToTensor () ,\n",
            "75 torchvision . transforms . Normalize ( mean = CatDogDataConfig .\n",
            "NORMALIZE_MEAN , std = CatDogDataConfig . NORMALIZE_STD )\n",
            "76 ])\n",
            "77\n",
            "78 def output2pred (self , output ):\n",
            "79 probabilities = F. softmax (output , dim =1)\n",
            "80 best_prob = torch .max( probabilities , 1) [0]. item ()\n",
            "81 predicted_id = torch . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "max( probabilities , 1) [1]. item ()\n",
            "82 predicted_class = CatDogDataConfig . ID2DLABEL [ predicted_id ]\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "83\n",
            "84 return probabilities . squeeze (). tolist () , round ( best_prob , 6) ,\n",
            "predicted_id , predicted_class\n",
            "6.Cập nhật folder middleware/ :Middleware là một thành phần quan trọng API. Có thể hiểu\n",
            "nôm na Middleware là các hàm tiền và hậu xử lý các request mà API nhận được. Trong bài\n",
            "này, chúng ta sẽ triển khai như sau:\n",
            "_middleware/cors.py : Ta cập nhật nội dung file này với CORSMiddleware. Hiểu một cách\n",
            "đơn giản, CORSMiddleware là một tính năng bảo mật cho phép ta định nghĩa một tập\n",
            "các tên miền, URL... (gọi chung là origin) thực hiện request và đọc được response trả về\n",
            "từ API.\n",
            "Hình 7: Minh họa việc bị block khi đọc response từ một server khác tên miền do same-origin policy của\n",
            "các trình duyệt. Ảnh: link.\n",
            "Với demo này, ta sẽ cho phép tất cả origin được quyền request và đọc response. Ta định\n",
            "nghĩa như sau:\n",
            "1from fastapi . middleware . cors import CORSMiddleware\n",
            "2\n",
            "3def setup_cors (app):\n",
            "4 app . add_middleware (\n",
            "5 CORSMiddleware ,\n",
            "6 allow_origins =[\"*\"],\n",
            "7 allow_credentials =True ,\n",
            "8 allow_methods =[\"*\"],\n",
            "9 allow_headers =[\"*\"],\n",
            "10 )\n",
            "Hàm setup_cors() nhận đầu vào là một thực thể (instance) FastAPI. Về sau, khi đã khai\n",
            "báo một thực thể FastAPI, ta sẽ đưa vào hàm này để cập nhật policy này.\n",
            "_middleware/http.py : Ta cập nhật nội dung file này với một định nghĩa Middleware được\n",
            "custom cho việc logging:\n",
            "1import time\n",
            "2import sys\n",
            "3\n",
            "4from pathlib import Path\n",
            "5sys . path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "append (str( Path ( __file__ ). parent . parent ))\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "6\n",
            "7from starlette . middleware . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "base import BaseHTTPMiddleware\n",
            "8from starlette . requests import Request\n",
            "9from utils . logger import Logger\n",
            "10\n",
            "11LOGGER = Logger ( __file__ , log_file =\" http .log\")\n",
            "12\n",
            "13class LogMiddleware ( BaseHTTPMiddleware ):\n",
            "14 async def dispatch (self , request : Request , call_next ):\n",
            "15 start_time = time . time ()\n",
            "16 response = await call_next ( request )\n",
            "17 process_time = time . time () - start_time\n",
            "18 LOGGER .log. info (\n",
            "19 f\"{ request . client . host } - \\\"{ request . method } { request .url. path\n",
            "} { request . scope [’ http_version ’]}\\\" { response . status_code } {\n",
            "process_time :.2f}s\")\n",
            "20\n",
            "21 return response\n",
            "Ta sử dụng class logger đã khai báo trước đó, khi một request đã được thực thi xong,\n",
            "ta sẽ log lại thông tin của response này trước khi trả về cho người dùng. Như đã đề cập\n",
            "trước đó, việc sử dụng class Middleware này sẽ được thực hiện khi ta khai báo một thực\n",
            "thể FastAPI.\n",
            "–middleware/__init__.py : Ta tạo file init để import sẵn các hàm, class của hai file trên để\n",
            "việc import ở các file trong vị trí folder khác thuận tiện hơn như sau:\n",
            "1from . http import LogMiddleware\n",
            "2from . cors import setup_cors\n",
            "7.Cập nhật folder schemas/:Các API thường biểu diễn dữ liệu request/response ở dạng bán\n",
            "cấu trúc như XML, JSON... Trong hầu hết tất cả các trường hợp, các trường thông tin trong\n",
            "dữ liệu sẽ được xác định trước. Vì vậy, sẽ thật tốt nếu chúng ta có một cách thức kiểm tra\n",
            "tự động mà không cần phải thao tác thủ công.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 8: Minh họa dữ liệu request và dữ liệu response.\n",
            "Trong FastAPI, chúng ta có thể sử dụng Pydantic Model, một dạng data validation. Pydantic\n",
            "Model cho phép chúng ta định nghĩa cấu trúc dữ liệu và đảm bảo rằng cấu trúc này sẽ luôn\n",
            "được tuân thủ bởi API. Đối với bài này, chúng ta sẽ cho người dùng gửi một tấm ảnh và API\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "sẽ trả về kết quả dự đoán của tấm ảnh dưới dạng dictionary (JSON). Như vậy, ta sẽ định\n",
            "nghĩa pydantic model cho response này trong file schemas/catdog_schema.py như sau:\n",
            "1from pydantic import BaseModel\n",
            "2\n",
            "3class CatDogResponse ( BaseModel ):\n",
            "4 probs : list = []\n",
            "5 best_prob : float = -1.0\n",
            "6 predicted_id : int = -1\n",
            "7 predicted_class : str = \"\"\n",
            "8 predictor_name : str = \"\"\n",
            "Việc tạo pydantic model gần như tương tự với việc tạo một class trong Python, điểm khác\n",
            "biệt là bạn cần phải cho kế thừa class BaseModel.\n",
            "8.Cập nhật folder routes/:Một API có thể sẽ có nhiều những chức năng khác nhau, từ\n",
            "việc truy vấn dữ liệu trong một database đến inference các Deep Learning model khác nhau.\n",
            "Vì vậy, để phân biệt rõ các chức năng trong một API, chúng ta cần định nghĩa các API\n",
            "endpoints.\n",
            "Hình 9: Minh họa về API Endpoints. Với tên miền API là https://api_domain.com, chúng ta có thể có\n",
            "các endpoints với các chức năng khác nhau.\n",
            "Trong demo này, chúng ta sẽ chỉ có một endpoint với chức năng inference model Cat Dog\n",
            "Classification. Vì vậy, nội dung folder này như sau:\n",
            "(a) routes/catdog_route.py : Định nghĩa router (endpoint) cho phép nhận vào một tấm ảnh\n",
            "upload từ máy tính và trả về kết quả dự đoán của mô hình. Cấu trúc của response sẽ\n",
            "giống với pydantic model mà ta đã định nghĩa trước đó:\n",
            "1import sys\n",
            "2from pathlib import Path\n",
            "3sys . path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "append (str( Path ( __file__ ). parent ))\n",
            "4\n",
            "5from fastapi import File , UploadFile\n",
            "6from fastapi import APIRouter\n",
            "7from schemas . catdog_schema import CatDogResponse\n",
            "8from config . catdog_cfg import ModelConfig\n",
            "9from models . catdog_predictor import Predictor\n",
            "10\n",
            "11router = APIRouter ()\n",
            "12predictor = Predictor (\n",
            "13 model_name = ModelConfig . MODEL_NAME ,\n",
            "14 model_weight = ModelConfig . MODEL_WEIGHT ,\n",
            "15 device = ModelConfig . DEVICE\n",
            "16)\n",
            "17\n",
            "18@router . post (\"/ predict \")\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "19async def predict ( file_upload : UploadFile = File (...) ):\n",
            "20 response = await predictor . predict ( file_upload . file )\n",
            "21\n",
            "22 return CatDogResponse (** response )\n",
            "Trong đây, ta khởi tạo instance router của FastAPI để định nghĩa một endpoint, đồng\n",
            "thời khởi tạo một instance Predictor của model Cat Dog Classification để router này có\n",
            "thể gọi và lấy kết quả dự đoán.\n",
            "(b) routes/base.py : Trong trường hợp các bạn có nhiều router, chúng ta có thể tạo một file\n",
            ".py để import tất cả router của từng file và gom lại thành một router duy nhất. Trong\n",
            "trường hợp này, mặc dù vậy, chúng ta sẽ chỉ import một router:\n",
            "1from fastapi import APIRouter\n",
            "2from . catdog_route import router as catdog_cls_route\n",
            "3\n",
            "4router = APIRouter ()\n",
            "5router . include_router ( catdog_cls_route , prefix =\"/ catdog_classification \")\n",
            "9.Cập nhật app.pyvàserver.py:Cuối cùng, với các thành phần ở trên, ta sẽ khởi tạo một\n",
            "thực thể FastAPI để host API của chúng ta. Đầu tiên, ta code file app.pynhư sau:\n",
            "1import sys\n",
            "2from pathlib import Path\n",
            "3sys . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "path . append (str( Path ( __file__ ). parent ))\n",
            "4\n",
            "5from fastapi import FastAPI\n",
            "6from middleware import LogMiddleware , setup_cors\n",
            "7from routes . base import router\n",
            "8\n",
            "9app = FastAPI ()\n",
            "10\n",
            "11app . add_middleware ( LogMiddleware )\n",
            "12setup_cors (app)\n",
            "13app . include_router ( router )\n",
            "Ta tạo instance FastAPI với tên biến app, sau đó cập nhật middlware cũng như router mà\n",
            "ta đã định nghĩa ở các file khác vào trong biến này. Cuối cùng, để triển khai API, ta sẽ cập\n",
            "nhật đoạn code này vào file server.py :\n",
            "1import uvicorn\n",
            "2\n",
            "3if __name__ == \" __main__ \":\n",
            "4 uvicorn .run(\"app:app \", host =\" 0.0.0.0 \", port =8000 , reload = True )\n",
            "Theo đó, ta sử dụng thư viện uvicornđể host API trên địa chỉ 0.0.0.0 (địa chỉ máy local) trên\n",
            "port 8000. Trong trường hợp các bạn bị lỗi port đã được sử dụng, hãy đổi sang port khác\n",
            "nhé.\n",
            "10.Thực thi chương trình: Để khởi động API, chúng ta hãy cài đặt các gói thư viện cần thiết\n",
            "trong file requirements.txt với lệnh sau trong terminal (các bạn nên cài trong môi trường\n",
            "conda, hướng dẫn cài đặt conda tại đây):\n",
            "1$ pip3 install -r requirements .txt\n",
            "Sau đó, chạy file server.py :\n",
            "1$ python3 server .py\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 10: Nội dung trên màn hình terminal khi API đã được host thành công.\n",
            "Theo đó, nếu cài đặt tương tự như ví dụ trong bài, các bạn có thể truy cập vào địa chỉ\n",
            "http://0.0.0.0:8000/docs trên trình duyệt và sẽ có kết quả như sau:\n",
            "Hình 11: FastAPI docs. Giao diện được khởi tạo tự động cho phép tương tác với các chức năng của\n",
            "API.\n",
            "Từ đây, các bạn có thể sử dụng mô hình của mình bằng cách upload ảnh lên và thực hiện\n",
            "request. Kết quả sẽ được trả về dưới dạng JSON:\n",
            "Hình 12: Mẫu dữ liệu test. Ảnh: link.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 13: Cách bước sử dụng mô hình trên FastAPI docs.\n",
            "Hình 14: Kết quả của mô hình, tương ứng với dữ liệu đầu vào là ví dụ mẫu.\n",
            "Như vậy, chúng ta đã hoàn tất việc host một API với chức năng Cat Dog Classification. Các\n",
            "bạn giờ đây có thể tắt chương trình bằng cách nhấn tổ hợp phím Ctrl + C ở terminal.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Hết -\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "LLMs Series: Cải thiện khả năng giải toán trắc\n",
            "nghiệm của LLMs với Instruction Tuning\n",
            "Dinh-Thang Duong, Nguyen-Thuan Duong và Quang-Vinh Dinh\n",
            "PR-Team: Hoàng-Nguyên Vũ, Đăng-Nhã Nguyễn và Minh-Châu Phạm\n",
            "Ngày 14 tháng 4 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Instruction Tuning (IT) là một trong những kỹ thuật training mô hình ngôn ngữ lớn (LLMs) rất\n",
            "quan trọng. Trong đó, IT giúp chúng ta cải thiện khả năng của mô hình cũng như kiểm soát kết quả\n",
            "đầu ra. Là kiểu huấn luyện mô hình có giám sát từ bộ dữ liệu theo cặp (intruction-output), từ đó giúp\n",
            "mô hình thu hẹp khoảng cách giữa từ kế tiếp được sinh ra và sự chỉ dẫn của con người.\n",
            "Hình 1: Fine-tuning mô hình ngôn ngữ lớn với dữ liệu instruction giải toán trắc nghiệm\n",
            "Trong bài viết này, chúng ta sẽ huấn luyện một mô hình ngôn ngữ lớn tiếng Việt với dữ liệu\n",
            "instruction giải toán trắc nghiệm. Từ đó, mô hình này sẽ có thể phần nào cải thiện khả năng giải toán.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Cài đặt chương trình\n",
            "Trong phần này, chúng ta sẽ xây dựng một Chatbot chuyên giải toán trắc nghiệm tiếng Việt sử dụng\n",
            "Mô hình ngôn ngữ lớn được huấn luyện chủ yếu trên bộ dữ liệu tiếng Việt là VinaLLaMA. Các bước\n",
            "thực hiện như sau:\n",
            "1.Cài đặt thư viện: Chúng ta sẽ cần cài đặt một số thư viện sau để có thể chạy được một mô\n",
            "hình ngôn ngữ lớn từ thư viện HuggingFace:\n",
            "1!pip install -q -U bitsandbytes\n",
            "2!pip install -q -U datasets\n",
            "3!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
            "4!pip install -q -U git+https://github.com/huggingface/peft.git\n",
            "5!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
            "6!pip install -q -U loralib\n",
            "7!pip install -q -U einops\n",
            "8!pip install -q -U googletrans==3.1.0a0\n",
            "2.Import các thư viện cần thiết: Sau khi đã tải xong, chúng ta sẽ thực hiện import các thư viện\n",
            "đã tải cũng như một số thư viện khác để phục vụ cho chương trình:\n",
            "1import json\n",
            "2import os\n",
            "3import bitsandbytes as bnb\n",
            "4import torch\n",
            "5import torch.nn as nn\n",
            "6import transformers\n",
            "7\n",
            "8from googletrans import Translator\n",
            "9from pprint import pprint\n",
            "10from datasets import load_dataset\n",
            "11from huggingface_hub import notebook_login\n",
            "12from peft import (\n",
            "13 LoraConfig,\n",
            "14 PeftConfig,\n",
            "15 PeftModel,\n",
            "16 get_peft_model,\n",
            "17 prepare_model_for_kbit_training\n",
            "18)\n",
            "19from transformers import (\n",
            "20 AutoConfig,\n",
            "21 AutoModelForCausalLM,\n",
            "22 AutoTokenizer,\n",
            "23 BitsAndBytesConfig\n",
            "24)\n",
            "25\n",
            "26os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
            "3.Khởi tạo mô hình: Mô hình ngôn ngữ lớn mà chúng ta sẽ sử dụng trong bài này có tên gọi là\n",
            "VinaLLaMA, một mô hình được nhóm tác giả người Việt thực hiện huấn luyện trên bộ dữ liệu\n",
            "chủ yếu về tiếng Việt. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Để khởi tạo mô hình lên trên file notebook, chúng ta sẽ chạy đoạn code\n",
            "sau:\n",
            "1MODEL_NAME = \"vilm/vinallama-7b-chat\"\n",
            "2\n",
            "3bnb_config = BitsAndBytesConfig(\n",
            "4load_in_4bit=True,\n",
            "5bnb_4bit_use_double_quant=True,\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "6bnb_4bit_quant_type=\"nf4\",\n",
            "7bnb_4bit_compute_dtype=torch.bfloat16\n",
            "8)\n",
            "9\n",
            "10model = AutoModelForCausalLM.from_pretrained(\n",
            "11 MODEL_NAME,\n",
            "12 device_map=\"auto\",\n",
            "13 trust_remote_code=True,\n",
            "14 quantization_config=bnb_config\n",
            "15)\n",
            "16\n",
            "17tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
            "18tokenizer.pad_token = tokenizer.eos_token\n",
            "19\n",
            "20model.gradient_checkpointing_enable()\n",
            "21model = prepare_model_for_kbit_training(model)\n",
            "22\n",
            "23config = LoraConfig(\n",
            "24 r=16,\n",
            "25 lora_alpha=32,\n",
            "26 target_modules=[\n",
            "27 \"q_proj\",\n",
            "28 \"up_proj\",\n",
            "29 \"o_proj\",\n",
            "30 \"k_proj\",\n",
            "31 \"down_proj\",\n",
            "32 \"gate_proj\",\n",
            "33 \"v_proj\"\n",
            "34 ],\n",
            "35 lora_dropout=0.05,\n",
            "36 bias=\"none\",\n",
            "37 task_type=\"CAUSAL_LM\"\n",
            "38)\n",
            "39\n",
            "40model = get_peft_model(model, config)\n",
            "Trong đó:\n",
            "•Dòng 1: Khai báo biến chứa tên của mô hình ngôn ngữ lớn chúng ta mong muốn sử dụng,\n",
            "ở đây sẽ là VinaLLaMA phiên bản 7b-chat.\n",
            "•Dòng 3 - 40: Khởi tạo mô hình và các cài đặt cần thiết.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "4.Sử dụng mô hình (trước khi huấn luyện): Mô hình vừa khởi tạo đã được nhóm tác giả\n",
            "huấn luyện trên một bộ dữ liệu rất lớn, có thể thực hiện được nhiều task khác nhau. Chúng ta có\n",
            "thể tương tác với mô hình ngay lúc này, bằng cách viết một đoạn chat mô tả mệnh lệnh nào đó\n",
            "(prompt) và gửi vào mô hình. Sau một khoảng thời gian tính toán, mô hình sẽ trả về câu trả lời\n",
            "phù hợp. Cách thực hiện như sau:\n",
            "(a) Cài đặt một vài tham số cần thiết cho mô hình, các tham số này sẽ ảnh hưởng đến kết quả\n",
            "trả lời của mô hình ngôn ngữ lớn:\n",
            "1generation_config = model.generation_config\n",
            "2generation_config.max_new_tokens = 200\n",
            "3generation_config.temperature = 0.7\n",
            "4generation_config.top_p = 0.7\n",
            "5generation_config.num_return_sequences = 1\n",
            "6generation_config.pad_token_id = tokenizer.eos_token_id\n",
            "7generation_config.eos_token_id = tokenizer.eos_token_id\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(b)Khai báo prompt: Chúng ta sẽ khởi tạo một biến chứa đoạn prompt, câu mệnh lệnh hoặc\n",
            "một đoạn tin nhắn mà chúng ta muốn gửi vào mô hình. Cụ thể trong VinaLLaMA, chúng ta\n",
            "sẽ có format cố định cho đoạn prompt như sau:\n",
            "Hình 2: Format prompt của VinaLLaMA. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trong đó, {your_task} là một đoạn văn bản mô tả một nhiệm\n",
            "vụ, câu hỏi hay một câu nói bất kì mà bạn mong muốn gửi đến mô hình.\n",
            "Dựa vào format trên, ta có thể thử đặt một yêu cầu xây dựng một hàm Python cho mô hình\n",
            "như trong môi trường code sau:\n",
            "Hình 3: Minh họa về cách xây dựng prompt theo format của mô hình VinaLLaMA\n",
            "(c)Chạy mô hình: Sử dụng đoạn code dưới đây, ta đưa đoạn prompt đã khởi tạo để lấy câu\n",
            "trả lời từ mô hình như sau:\n",
            "1%%time\n",
            "2device = ’cuda’ if torch.cuda.is_available() else ’cpu’\n",
            "3\n",
            "4encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
            "5with torch.inference_mode():\n",
            "6outputs = model.generate(\n",
            "7 input_ids=encoding.input_ids,\n",
            "8 attention_mask=encoding.attention_mask,\n",
            "9 generation_config=generation_config\n",
            "10 )\n",
            "11\n",
            "12print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
            "Khi quá trình tính toán hoàn tất, ta nhận được kết quả in ra màn hình là câu trả lời của mô\n",
            "hình ứng với đoạn prompt:\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 4: Ví dụ về câu trả lời của mô hình về việc viết một hàm Python ứng với mô tả trong prompt\n",
            "Như vậy, có thể thấy chỉ với mô hình gốc (gọi là pre-trained model), chúng ta đã có thể\n",
            "tương tác với mô hình ngôn ngữ lớn và yêu cầu thực hiện một tác vụ nào đó với độ chính\n",
            "xác tương đối. Trong lĩnh vực Machine Learning, chúng ta còn có thể cải thiện kết quả của\n",
            "pre-trained model với một task cụ thể nào đó bằng cách áp dụng một kỹ thuật được gọi là\n",
            "fine-tuning. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cụ thể, chúng ta sẽ tiếp tục thực hiện huấn luyện mô hình, trên một bộ dữ liệu\n",
            "với các task cụ thể hơn (ứng với nhu cầu và mục đich sử dụng của chúng ta).\n",
            "5.Tải bộ dữ liệu fine-tuning: Trong bài này, vì mục tiêu của chúng ta là xây dựng chatbot\n",
            "chuyên dùng để giải toán trắc nghiệm tiếng Việt, nên ở phần sau chúng ta sẽ thực hiện fine-tuning\n",
            "VinaLLaMA trên bộ dữ liệu toán trắc nghiệm để cải thiện chất lượng câu trả lời. Ta thực hiện\n",
            "tải bộ dữ liệu có tên là vi_grade_school_math_mcq như sau:\n",
            "1data = load_dataset(’hllj/vi_grade_school_math_mcq’)\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 5: Minh họa một số mẫu dữ liệu trong bộ dữ liệu vừa tải về\n",
            "Trong đoạn code, ta sử dụng hàm load_data() từ thư viện datasets , hàm này cho phép tải các bộ\n",
            "dữ liệu trong database của thư viện. Bộ dữ liệu được ta lưu vào biến data, khi in biến này, ta có\n",
            "thông tin như sau:\n",
            "Hình 6: Dữ liệu của biến data. Biến có kiểu dữ liệu là DatasetDict , một kiểu dữ liệu riêng biệt của thư\n",
            "việndatasets\n",
            "6.Xây dựng bộ dữ liệu fine-tuning: Với bộ dữ liệu đã tải, chúng ta sẽ sử dụng để thực hiện\n",
            "fine-tuning mô hình, tức sẽ huấn luyện cho mô hình học thêm các dữ liệu từ bộ dữ liệu mới này.\n",
            "Các bước làm như sau:\n",
            "(a)Xây dựng hàm tạo prompt: Trong trường hợp huấn luyện VinaLLaMA, chúng ta cần\n",
            "thay đổi dữ liệu vào đúng format prompt như ở phần trước. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nhận thấy trong format prompt,\n",
            "ô user sẽ nhận input của người dùng, ứng với trường \"prompt\"của bộ dữ liệu. Ô assistant\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "là câu trả lời của mô hình, ứng với trường \"response\"của bộ dữ liệu. Vì vậy, ta sẽ xây dựng\n",
            "hàm để đưa vào đúng khuôn format như sau:\n",
            "1def generate_prompt(question, choices, explanation):\n",
            "2return f\"\"\"\n",
            "3<|im_start|>system\n",
            "4Bạn là một chuyên gia về toán. Bạn sẽ nhận câu hỏi trắc nghiệm kèm theo các l\n",
            "ựa chọn, hãy giải step by step nếu có và chọn phương án đúng.\n",
            "5\n",
            "6<|im_start|>user\n",
            "7### Câu hỏi:\n",
            "8{question}\n",
            "9### Các lựa chọn:\n",
            "10{choices}\n",
            "11### Câu trả lời:\n",
            "12\n",
            "13<|im_start|>assistant\n",
            "14{explanation}\n",
            "15\"\"\".strip()\n",
            "16\n",
            "17def generate_and_tokenize_prompt(question, choices, explanation):\n",
            "18 full_prompt = generate_prompt(question, choices, explanation)\n",
            "19 tokenized_full_prompt = tokenizer(\n",
            "20 full_prompt,\n",
            "21 padding=True,\n",
            "22 truncation=True\n",
            "23 )\n",
            "24\n",
            "25 return tokenized_full_prompt\n",
            "(b)Xây dựng hàm tokenization: Đối với bất kì mô hình ngôn ngữ lớn nào, để xử lý một văn\n",
            "bản nào, trước hết chúng ta cần thực hiện tokenization lên văn bản đó. Hiểu một cách đơn\n",
            "giản, chúng ta sẽ đưa văn bản từ dạng string thành một list (vector) các con số:\n",
            "Ở đây, ta sẽ thiết kế hàm tạo câu prompt với điểm dữ liệu gồm cặp (response, prompt) đầu\n",
            "vào, sau đó thực hiện tokenize câu prompt, code cài đặt như sau:\n",
            "1def generate_and_tokenize_prompt(question, choices, explanation):\n",
            "2full_prompt = generate_prompt(question, choices, explanation)\n",
            "3tokenized_full_prompt = tokenizer(\n",
            "4 full_prompt,\n",
            "5 padding=True,\n",
            "6 truncation=True\n",
            "7)\n",
            "8\n",
            "9return tokenized_full_prompt\n",
            "(c)Áp dụng tokenization vào bộ dữ liệu: Với hàm tokenization vừa xây dựng, ta sử dụng\n",
            "đoạn code sau đây để tách các thông tin về các lựa chọn trắc nghiệm (choices), lời giải thích\n",
            "kèm đáp án (explanation) và câu hỏi (question). Sau đó, đưa các thông tin này vào hàm\n",
            "tokenization để hình thành câu prompt cho mô hình. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sau đó, sử dụng hàm Dataset.from_list\n",
            "()\n",
            "1training_samples = []\n",
            "2for sample in tqdm(data[’train’]):\n",
            "3for quest in sample[’problems’]:\n",
            "4 choices = quest[’choices’]\n",
            "5 explanation = quest[’explanation’].strip()\n",
            "6 question = quest[’question’]\n",
            "7\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "8 if explanation == ’’ or question == ’’ or choices == []:\n",
            "9 continue\n",
            "10\n",
            "11 try:\n",
            "12 question = question.split(’\\n \\n’)[1].strip()\n",
            "13 except:\n",
            "14 continue\n",
            "15\n",
            "16 choices = ’\\n’.join(choices)\n",
            "17 training_sample = generate_and_tokenize_prompt(\n",
            "18 question, choices, explanation\n",
            "19 )\n",
            "20\n",
            "21 training_samples.append(training_sample)\n",
            "22\n",
            "23choices_data = Dataset.from_list(training_samples)\n",
            "Hình 7: Minh họa về mẫu dữ liệu instruction giải toán trắc nghiệm.\n",
            "7.Thực hiện huấn luyện mô hình (fine-tuning): Sau khi đã chuẩn bị xong bộ dữ liệu hoàn\n",
            "tất, chúng ta bắt đầu huấn luyện mô hình ngôn ngữ lớn, chạy các dòng lệnh sau:\n",
            "1training_args = transformers.TrainingArguments(\n",
            "2 per_device_train_batch_size=1,\n",
            "3 gradient_accumulation_steps=4,\n",
            "4 num_train_epochs=1,\n",
            "5 learning_rate=2e-4,\n",
            "6 fp16=True,\n",
            "7 save_total_limit=3,\n",
            "8 logging_steps=1,\n",
            "9 output_dir=\"experiments\",\n",
            "10 optim=\"paged_adamw_8bit\",\n",
            "11 lr_scheduler_type=\"cosine\",\n",
            "12 warmup_ratio=0.05,\n",
            "13)\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "14\n",
            "15trainer = transformers.Trainer(\n",
            "16 model=model,\n",
            "17 train_dataset=data,\n",
            "18 args=training_args,\n",
            "19 data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=\n",
            "False)\n",
            "20)\n",
            "21model.config.use_cache = False\n",
            "22trainer.train()\n",
            "Khi các bạn thấy bảng dưới đây xuất hiện, điều đó chứng tỏ tiến trình huấn luyện đã bắt đầu\n",
            "thành công, việc còn lại của chúng ta sẽ chỉ cần chờ cho tới khi việc thực thi hoàn tất.\n",
            "Hình 8: Ảnh minh họa bảng hiển thị các thông tin trong quá trình thực hiện huấn luyện mô hình ngôn\n",
            "ngữ lớn\n",
            "8.Chạy mô hình đã fine-tuning: Cuối cùng, ta sẽ thử tương tác với mô hình sau khi đã được\n",
            "fine-tuning như sau:\n",
            "1%%time\n",
            "2device = ’cuda’ if torch.cuda.is_available() else ’cpu’\n",
            "3\n",
            "4prompt = \"\"\"\n",
            "5<|im_start|>system\n",
            "6Bạn là một chuyên gia về toán. Bạn sẽ nhận câu hỏi trắc nghiệm kèm theo các lựa\n",
            "chọn, hãy giải step by step nếu có và chọn phương án đúng.\n",
            "7\n",
            "8<|im_start|>user\n",
            "9### Câu hỏi:\n",
            "101 + 1 =\n",
            "11### Các lựa chọn:\n",
            "12A. 1\n",
            "13B. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "2\n",
            "14C. 3\n",
            "15D. 4\n",
            "16### Câu trả lời:\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "17\n",
            "18<|im_start|>assistant\n",
            "19\"\"\".strip()\n",
            "20\n",
            "21encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
            "22with torch.inference_mode():\n",
            "23 outputs = model.generate(\n",
            "24 input_ids=encoding.input_ids,\n",
            "25 attention_mask=encoding.attention_mask,\n",
            "26 generation_config=generation_config\n",
            "27 )\n",
            "28\n",
            "29print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
            "Kết quả trả về của mô hình cho câu prompt trên được mô tả như hình dưới đây:\n",
            "Hình 9: Câu trả lời của mô hình\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. Trong ngữ cảnh về mô hình ngôn ngữ lớn (LLMs), Instruction Tuning được hiểu như thế nào?\n",
            "(a) Huấn luyện mô hình trên task mới mà không cần mẫu dữ liệu nào.\n",
            "(b) Điều chỉnh kết quả của mô hình trong quá trình deploy.\n",
            "(c) Huấn luyện mô hình để tuân theo các yêu cầu cụ thể (instruction).\n",
            "(d) Giảm kích thước của mô hình để tăng độ hiệu quả.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2. Instruction tuning là một dạng của kiểu học\n",
            "(a) Supervised learning.\n",
            "(b) Self-supervised learning.\n",
            "(c) Unsupervised learning.\n",
            "(d) Reinforcement learning.\n",
            "3. Khi thực hiện instruction tuning, hàm loss nào sau đây có thể được sử dụng?\n",
            "(a) Mean Squared Error (MSE)\n",
            "(b) Hinge Loss\n",
            "(c) Kullback-Leibler Divergence\n",
            "(d) Cross-Entropy Loss\n",
            "4. Mệnh đề sau đúng hay sai: \"Ta luôn nên áp dụng instruction tuning để giảm thiểu chi phí tính\n",
            "toán trong quá trình training\"?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(a) Đúng\n",
            "(b) Sai\n",
            "5. Trong LLMs, khái niệm prompt được hiểu như thế nào?\n",
            "(a) Một phần mềm bổ trợ giúp tối ưu hóa hiệu suất của mô hình\n",
            "(b) Một kỹ thuật mã hóa thông tin riêng tư trong quá trình đào tạo mô hình\n",
            "(c) Một câu hỏi hoặc yêu cầu mà người dùng đưa ra cho mô hình\n",
            "(d) Một thuật toán đặc biệt để phân loại dữ liệu đầu vào\n",
            "6. Trong LLMs, ta nên áp dụng kỹ thuật nào sau đây để cải thiện khả năng thực hiện một task cụ\n",
            "thể nào đó của mô hình mà không cần training?\n",
            "(a) Sử dụng kỹ thuật transfer learning.\n",
            "(b) Ứng dụng khả năng zero-shot learning của mô hình.\n",
            "(c) Lập trình thủ công tại bước hậu xử lý cho mỗi task.\n",
            "(d) Mở rộng bộ dữ liệu training.\n",
            "7. Kỹ thuật prompting nào dưới đây cung cấp cho mô hình chỉ một ví dụ về task cần làm?\n",
            "(a) One-shot learning\n",
            "(b) Few-shot learning\n",
            "(c) Continuous learning\n",
            "(d) Transfer learning\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "8. Câu nào sau đây mô tả đúng về kỹ thuật Parameter Efficient Fine-tuning (PEFT)?\n",
            "(a) Một kỹ thuật dùng để huấn luyện mô hình trên bộ dữ liệu cực lớn.\n",
            "(b) Một kỹ thuật liên quan đến việc cập nhật một phần nhỏ tham số của mô hình khi huấn luyện.\n",
            "(c) Một kỹ thuật huấn luyện dành riêng cho các mô hình có kích thước nhỏ (dưới 1 tỷ tham số).\n",
            "(d) Một kỹ thuật để tăng chi phí tính toán của mô hình.\n",
            "9. Mệnh đề sau đúng hay sai: \"Low-Rank Adaptation (LoRA) là một kỹ thuật về PEFT\"?\n",
            "(a) Đúng.\n",
            "(b) Sai.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "10. So với LoRA, QLoRA có điểm gì khác biệt gì trong việc huấn luyện LLMs?\n",
            "(a) QLoRA lượng tử hóa (quantize) tham số mô hình; LoRA thì không.\n",
            "(b) QLoRA sử dụng nhiều tham số mô hình; LoRA ít hơn.\n",
            "(c) QLoRA tối ưu khả năng tổng quát của mô hình; LoRA tối ưu trên một task cụ thể.\n",
            "(d) QLoRA giảm kích thước mô hình; LoRA tăng lên.\n",
            "- Hết -\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "LLMs Series: Xây dựng ứng dụng RAG với\n",
            "LangChain\n",
            "Dinh-Thang Duong, Nguyen-Thuan Duong và Quang-Vinh Dinh\n",
            "Ngày 2 tháng 5 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "LangChain là một framework được thiết kế chuyên biệt cho việc triển khai LLMs trong các ứng dụng\n",
            "thực tế. LangChain hỗ trợ các công cụ và thư viện mạnh mẽ cho phép các nhà phát triển dễ dàng tích\n",
            "hợp các mô hình ngôn ngữ lớn với các ứng dụng của họ, từ các Chatbot thông minh cho đến các hệ\n",
            "thống phân tích dữ liệu phức tạp.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 1: Logo của LangChain\n",
            "Trong bài viết này, chúng ta sẽ xây dựng một ứng dụng về RAG (Retrieval Augmented Generation)\n",
            "trả lời các câu hỏi học thuật tận dụng nguồn tài liệu là các bài báo khoa học mà ta thu thập được (dưới\n",
            "dạng file pdf), sử dụng thư viện LangChain. Tổng quan, pipeline của project như sau:\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 2: Pipeline của project.\n",
            "Theo đó:\n",
            "1. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Từ danh sách các bài báo khoa học, ta tách thành các văn bản nhỏ. Từ đó, xây dựng một hệ cơ\n",
            "sở dữ liệu vector với một embedding model.\n",
            "2. Bên cạnh câu hỏi đầu vào (question), ta truy vấn các mẫu văn bản có liên quan đến đến câu hỏi,\n",
            "dùng làm ngữ cảnh (context) trong câu prompt. Đây là nguồn thông tin mà LLMs có thể dựa vào\n",
            "để trả lời câu hỏi.\n",
            "3. Đưa câu prompt vào mô hình (question và context) để nhận câu trả lời từ mô hình.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Cài đặt chương trình\n",
            "Trong phần này, chúng ta sẽ tiến hành cài đặt nội dung của project. Mã nguồn được xây dựng trên hệ\n",
            "điều hành Ubuntu với GPU 24GB. Các bước thực hiện như sau:\n",
            "1.Tổ chức thư mục code: Để mã nguồn trở nên rõ ràng nhằm phục vụ cho mục đích đọc hiểu\n",
            "code, chúng ta sẽ tổ chức thư mục như sau:\n",
            "rag_langchain/\n",
            "data_source/\n",
            "generative_ai/\n",
            "download.py\n",
            "src/\n",
            "base/\n",
            "llm_model.py\n",
            "rag/\n",
            "file_loader.py\n",
            "main.py\n",
            "offline_rag.py\n",
            "utils.py\n",
            "vectorstore.py\n",
            "app.py\n",
            "requirements.txt\n",
            "Tổng quan, chúng ta sẽ có thư mục chứa mã nguồn có tên rag_langchain (các bạn hoàn toàn\n",
            "có thể sử dụng tên gọi khác). Bên trong sẽ có các thư mục con và các file với ý nghĩa như sau:\n",
            "_data_source/: Thư mục dùng để lưu trữ các tài liệu phục vụ cho việc xây dựng hệ cơ sở\n",
            "dữ liệu vector.\n",
            "_data_source/generative_ai/download.py: File code dùng để tải tự động một số các\n",
            "bài báo khoa học dưới dạng file pdf.\n",
            "_src/base/llm_model: File code dùng để khai báo hàm khởi tạo mô hình ngôn ngữ lớn.\n",
            "_src/rag/: Thư mục dùng để lưu trữ các code liên quan đến xây dựng RAG, bao gồm:\n",
            "(a)src/rag/file_loader.py: File code dùng để khai báo các hàm load file pdf (vì tài liệu\n",
            "của chúng ta thu thập thuộc file pdf).\n",
            "(b)src/rag/main.py: File code dùng để khai báo hàm khởi tạo chains.\n",
            "(c)src/rag/offline_rag.py: File code dùng để khai báo PromptTemplate.\n",
            "(d)src/rag/utils.py: File code dùng để khai báo hàm tách câu trả lời từ model.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(e)src/rag/vectorstore.py: File code dùng để khai báo hàm khởi tạo hệ cơ sở dữ liệu\n",
            "vector.\n",
            "_src/app.py: File code dùng để khởi tạo API.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "_requirements.txt: File code dùng để khai báo các thư viện cần thiết để sử dụng source\n",
            "code.\n",
            "2.Cập nhật file requirements.txt :Để bắt đầu, chúng ta sẽ liệt kê các gói thư viện cần thiết để chạy\n",
            "được chương trình này. Các bạn hãy cập nhật file requirements.txt với nội dung sau:\n",
            "1torch ==2.2.2\n",
            "2transformers ==4.39.3\n",
            "3accelerate ==0.28.0\n",
            "4bitsandbytes ==0.42.0\n",
            "5huggingface -hub ==0.22.2\n",
            "6langchain ==0.1.14\n",
            "7langchain - core ==0.1.43\n",
            "8langchain - community ==0.0.31\n",
            "9pypdf ==4.2.0\n",
            "10sentence - transformers ==2.6.1\n",
            "11beautifulsoup4 ==4.12.3\n",
            "12langserve [all]\n",
            "13chromadb ==0.4.24\n",
            "14langchain - chroma ==0.1.0\n",
            "15faiss -cpu ==1.8.0\n",
            "16rapidocr - onnxruntime ==1.3.16\n",
            "17unstructured ==0.13.2\n",
            "18fastapi ==0.110.1\n",
            "19uvicorn ==0.29.0\n",
            "3.Cập nhật file data_source/generative_ai/download.py :Để tải một vài các bài báo khoa học làm dữ\n",
            "liệu cho hệ cơ sở dữ liệu vector, chúng ta sẽ xây dựng một đoạn code tải tự động các bài báo. Nội\n",
            "dung như sau:\n",
            "1import os\n",
            "2import wget\n",
            "3\n",
            "4file_links = [\n",
            "5 {\n",
            "6 \" title \": \" Attention Is All You Need \",\n",
            "7 \"url\": \" https :// arxiv .org /pdf /1706.03762 \"\n",
            "8 },\n",
            "9 {\n",
            "10 \" title \": \"BERT - Pre - training of Deep Bidirectional Transformers for\n",
            "Language Understanding \",\n",
            "11 \"url\": \" https :// arxiv .org /pdf /1810.04805 \"\n",
            "12 },\n",
            "13 {\n",
            "14 \" title \": \"Chain -of - Thought Prompting Elicits Reasoning in Large Language\n",
            "Models \",\n",
            "15 \"url\": \" https :// arxiv .org /pdf /2201.11903 \"\n",
            "16 },\n",
            "17 {\n",
            "18 \" title \": \" Denoising Diffusion Probabilistic Models \",\n",
            "19 \"url\": \" https :// arxiv .org /pdf /2006.11239 \"\n",
            "20 },\n",
            "21 {\n",
            "22 \" title \": \" Instruction Tuning for Large Language Models - A Survey \",\n",
            "23 \"url\": \" https :// arxiv .org /pdf /2308.10792 \"\n",
            "24 },\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "25 {\n",
            "26 \" title \": \" Llama 2- Open Foundation and Fine - Tuned Chat Models \",\n",
            "27 \"url\": \" https :// arxiv .org /pdf /2307.09288 \"\n",
            "28 }\n",
            "29]\n",
            "30\n",
            "31def is_exist ( file_link ):\n",
            "32 return os. path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "exists (f\"./{ file_link [’ title ’]}. pdf\")\n",
            "33\n",
            "34for file_link in file_links :\n",
            "35 if not is_exist ( file_link ):\n",
            "36 wget . download ( file_link [\" url\"], out=f\"./{ file_link [’ title ’]}. pdf\")\n",
            "Trong file code trên, chúng ta cung cấp một list các đường dẫn bài báo. Từ đó, sử dụng wgetđể\n",
            "tải về. Các bài báo sẽ được lưu ngay tại vị trí của file code. Vì mục đích demo, chúng ta sẽ chỉ tải\n",
            "một số lượng nhỏ các paper. Các bạn có thể tự thêm vào nhiều paper khác để test.\n",
            "Hình 3: Minh họa danh sách các file bài báo khoa học sau khi được tải về.\n",
            "4.Cập nhật file src/base/llm_model.py :Tại file này, ta khai báo hàm get_hf_model() , dùng để thực\n",
            "hiện tải và gọi pre-trained LLM từ HuggingFace về máy. Đồng thời, ta áp dụng kỹ thuật quanti-\n",
            "zation lên model để thực hiện inference trên GPU thấp. Nội dung file như sau:\n",
            "1import torch\n",
            "2from transformers import BitsAndBytesConfig\n",
            "3from transformers import AutoTokenizer , AutoModelForCausalLM , pipeline\n",
            "4from langchain . llms . huggingface_pipeline import HuggingFacePipeline\n",
            "5\n",
            "6\n",
            "7nf4_config = BitsAndBytesConfig (\n",
            "8 load_in_4bit =True ,\n",
            "9 bnb_4bit_quant_type =\"nf4 \",\n",
            "10 bnb_4bit_use_double_quant =True ,\n",
            "11 bnb_4bit_compute_dtype = torch . bfloat16\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "12)\n",
            "13\n",
            "14def get_hf_llm ( model_name : str = \" mistralai / Mistral -7B- Instruct -v0 .2\",\n",
            "15 max_new_token = 1024 ,\n",
            "16 ** kwargs ):\n",
            "17\n",
            "18 model = AutoModelForCausalLM . from_pretrained (\n",
            "19 model_name ,\n",
            "20 quantization_config = nf4_config ,\n",
            "21 low_cpu_mem_usage = True\n",
            "22 )\n",
            "23 tokenizer = AutoTokenizer . from_pretrained ( model_name )\n",
            "24\n",
            "25 model_pipeline = pipeline (\n",
            "26 \"text - generation \",\n",
            "27 model =model ,\n",
            "28 tokenizer = tokenizer ,\n",
            "29 max_new_tokens = max_new_token ,\n",
            "30 pad_token_id = tokenizer . eos_token_id ,\n",
            "31 device_map =\" auto \"\n",
            "32 )\n",
            "33\n",
            "34 llm = HuggingFacePipeline (\n",
            "35 pipeline = model_pipeline ,\n",
            "36 model_kwargs = kwargs\n",
            "37 )\n",
            "38\n",
            "39 return llm\n",
            "Trong project này, mô hình LLM mà chúng ta sử dụng là mô hình Mistral 7B được huấn luyện\n",
            "trên dữ liệu instruction. Các bạn có thể thay thế bằng mô hình khác có cấu hình tương tự.\n",
            "5.Cập nhật file src/rag/file_loader.py :\n",
            "1from typing import Union , List , Literal\n",
            "2import glob\n",
            "3from tqdm import tqdm\n",
            "4import multiprocessing\n",
            "5from langchain_community . document_loaders import PyPDFLoader\n",
            "6from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
            "7\n",
            "8def remove_non_utf8_characters ( text ):\n",
            "9 return ’’. join ( char for char in text if ord( char ) < 128)\n",
            "10\n",
            "11def load_pdf ( pdf_file ):\n",
            "12 docs = PyPDFLoader ( pdf_file , extract_images = True ). load ()\n",
            "13 for doc in docs :\n",
            "14 doc . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "page_content = remove_non_utf8_characters ( doc. page_content )\n",
            "15 return docs\n",
            "16\n",
            "17def get_num_cpu ():\n",
            "18 return multiprocessing . cpu_count ()\n",
            "19\n",
            "20class BaseLoader :\n",
            "21 def __init__ ( self ) -> None :\n",
            "22 self . num_processes = get_num_cpu ()\n",
            "23\n",
            "24 def __call__ (self , files : List [str], ** kwargs ):\n",
            "25 pass\n",
            "26\n",
            "27class PDFLoader ( BaseLoader ):\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "28 def __init__ ( self ) -> None :\n",
            "29 super (). __init__ ()\n",
            "30\n",
            "31 def __call__ (self , pdf_files : List [str ], ** kwargs ):\n",
            "32 num_processes = min( self . num_processes , kwargs [\" workers \"])\n",
            "33 with multiprocessing . Pool ( processes = num_processes ) as pool :\n",
            "34 doc_loaded = []\n",
            "35 total_files = len( pdf_files )\n",
            "36 with tqdm ( total = total_files , desc =\" Loading PDFs \", unit =\" file \") as\n",
            "pbar :\n",
            "37 for result in pool . imap_unordered ( load_pdf , pdf_files ):\n",
            "38 doc_loaded . extend ( result )\n",
            "39 pbar . update (1)\n",
            "40 return doc_loaded\n",
            "41\n",
            "42class TextSplitter :\n",
            "43 def __init__ (self ,\n",
            "44 separators : List [str] = [’\\n\\n’, ’\\n’, ’ ’, ’’],\n",
            "45 chunk_size : int = 300 ,\n",
            "46 chunk_overlap : int = 0\n",
            "47 ) -> None :\n",
            "48\n",
            "49 self . splitter = RecursiveCharacterTextSplitter (\n",
            "50 separators = separators ,\n",
            "51 chunk_size = chunk_size ,\n",
            "52 chunk_overlap = chunk_overlap ,\n",
            "53 )\n",
            "54 def __call__ (self , documents ):\n",
            "55 return self . splitter . split_documents ( documents )\n",
            "56\n",
            "57class Loader :\n",
            "58 def __init__ (self ,\n",
            "59 file_type : str = Literal [\" pdf\"],\n",
            "60 split_kwargs : dict = {\n",
            "61 \" chunk_size \": 300 ,\n",
            "62 \" chunk_overlap \": 0}\n",
            "63 ) -> None :\n",
            "64 assert file_type in [\"pdf\"], \" file_type must be pdf\"\n",
            "65 self . file_type = file_type\n",
            "66 if file_type == \" pdf\":\n",
            "67 self . doc_loader = PDFLoader ()\n",
            "68 else :\n",
            "69 raise ValueError (\" file_type must be pdf \")\n",
            "70\n",
            "71 self . doc_spltter = TextSplitter (** split_kwargs )\n",
            "72\n",
            "73 def load (self , pdf_files : Union [str , List [ str ]], workers : int = 1):\n",
            "74 if isinstance ( pdf_files , str):\n",
            "75 pdf_files = [ pdf_files ]\n",
            "76 doc_loaded = self . doc_loader ( pdf_files , workers = workers )\n",
            "77 doc_split = self . doc_spltter ( doc_loaded )\n",
            "78 return doc_split\n",
            "79\n",
            "80 def load_dir (self , dir_path : str , workers : int = 1):\n",
            "81 if self . file_type == \"pdf\":\n",
            "82 files = glob . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "glob (f\"{ dir_path }/*. pdf\")\n",
            "83 assert len( files ) > 0, f\"No { self . file_type } files found in { dir_path\n",
            "}\"\n",
            "84 else :\n",
            "85 raise ValueError (\" file_type must be pdf \")\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "86 return self . load (files , workers = workers )\n",
            "6.Cập nhật file src/rag/vectorstore.py :Tại file này, ta định nghĩa một class để khởi tạo hệ cơ sở\n",
            "dữ liệu vector. Trong project này, chúng ta sẽ sử dụng Chroma. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Về việc tìm kiếm tài liệu tương\n",
            "đồng, ta sử dụng FAISS. Như vậy, nội dung của file như sau:\n",
            "Hình 4: Minh họa việc sử dụng vector database Chroma để truy vấn các tài liệu có liên quan làm context\n",
            "trong prompt. Ảnh: Link.\n",
            "1from typing import Union\n",
            "2from langchain_chroma import Chroma\n",
            "3from langchain_community . vectorstores import FAISS\n",
            "4from langchain_community . embeddings import HuggingFaceEmbeddings\n",
            "5\n",
            "6class VectorDB :\n",
            "7 def __init__ (self ,\n",
            "8 documents = None ,\n",
            "9 vector_db : Union [Chroma , FAISS ] = Chroma ,\n",
            "10 embedding = HuggingFaceEmbeddings () ,\n",
            "11 ) -> None :\n",
            "12\n",
            "13 self . vector_db = vector_db\n",
            "14 self . embedding = embedding\n",
            "15 self .db = self . _build_db ( documents )\n",
            "16\n",
            "17 def _build_db (self , documents ):\n",
            "18 db = self . vector_db . from_documents ( documents = documents ,\n",
            "19 embedding = self . embedding )\n",
            "20 return db\n",
            "21\n",
            "22 def get_retriever (self ,\n",
            "23 search_type : str = \" similarity \",\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "24 search_kwargs : dict = {\"k\": 10}\n",
            "25 ):\n",
            "26 retriever = self .db. as_retriever ( search_type = search_type ,\n",
            "27 search_kwargs = search_kwargs )\n",
            "28 return retriever\n",
            "7.Cập nhật file src/rag/offline_rag.py :Tại file này, ta khai báo class Offline_RAG để xây dựng một\n",
            "chain về RAG, bao gồm việc sử dụng retriever lấy context, xây dựng prompt và đưa vào model.\n",
            "Nội dung của file như sau:\n",
            "1import re\n",
            "2from langchain import hub\n",
            "3from langchain_core . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "runnables import RunnablePassthrough\n",
            "4from langchain_core . output_parsers import StrOutputParser\n",
            "5\n",
            "6class Str_OutputParser ( StrOutputParser ):\n",
            "7 def __init__ ( self ) -> None :\n",
            "8 super (). __init__ ()\n",
            "9\n",
            "10 def parse (self , text : str) -> str :\n",
            "11 return self . extract_answer ( text )\n",
            "12\n",
            "13 def extract_answer (self ,\n",
            "14 text_response : str ,\n",
            "15 pattern : str = r\" Answer :\\s *(.*) \"\n",
            "16 ) -> str:\n",
            "17\n",
            "18 match = re. search ( pattern , text_response , re. DOTALL )\n",
            "19 if match :\n",
            "20 answer_text = match . group (1). strip ()\n",
            "21 return answer_text\n",
            "22 else :\n",
            "23 return text_response\n",
            "24\n",
            "25class Offline_RAG :\n",
            "26 def __init__ (self , llm ) -> None :\n",
            "27 self . llm = llm\n",
            "28 self . prompt = hub . pull (\"rlm/rag - prompt \")\n",
            "29 self . str_parser = Str_OutputParser ()\n",
            "30\n",
            "31 def get_chain (self , retriever ):\n",
            "32 input_data = {\n",
            "33 \" context \": retriever | self . format_docs ,\n",
            "34 \" question \": RunnablePassthrough ()\n",
            "35 }\n",
            "36 rag_chain = (\n",
            "37 input_data\n",
            "38 | self . prompt\n",
            "39 | self .llm\n",
            "40 | self . str_parser\n",
            "41 )\n",
            "42 return rag_chain\n",
            "43\n",
            "44 def format_docs (self , docs ):\n",
            "45 return \"\\n\\n\". join (doc. page_content for doc in docs )\n",
            "8.Cập nhật file src/rag/utils.py :Tại file này, ta khai báo hàm tách phần trả lời của model từ câu\n",
            "prompt (phần bắt đầu từ \"Answer:\" ):\n",
            "1import re\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "2\n",
            "3def extract_answer ( text_response : str ,\n",
            "4 pattern : str = r\" Answer :\\s *(.*) \"\n",
            "5 ) -> str:\n",
            "6\n",
            "7 match = re. search ( pattern , text_response )\n",
            "8 if match :\n",
            "9 answer_text = match . group (1). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "strip ()\n",
            "10 return answer_text\n",
            "11 else :\n",
            "12 return \" Answer not found .\"\n",
            "9.Cập nhật file src/rag/main.py :Tại file này, ta khởi tạo toàn bộ các instance của các class, các hàm\n",
            "mà ta đã khai báo trước đó và kết nối chúng vào trong một hàm duy nhất gọi là build_rag_chain() :\n",
            "1from pydantic import BaseModel , Field\n",
            "2\n",
            "3from src.rag. file_loader import Loader\n",
            "4from src.rag. vectorstore import VectorDB\n",
            "5from src.rag. offline_rag import Offline_RAG\n",
            "6\n",
            "7class InputQA ( BaseModel ):\n",
            "8 question : str = Field (... , title =\" Question to ask the model \")\n",
            "9\n",
            "10class OutputQA ( BaseModel ):\n",
            "11 answer : str = Field (... , title =\" Answer from the model \")\n",
            "12\n",
            "13def build_rag_chain (llm , data_dir , data_type ):\n",
            "14 doc_loaded = Loader ( file_type = data_type ). load_dir ( data_dir , workers =2)\n",
            "15 retriever = VectorDB ( documents = doc_loaded ). get_retriever ()\n",
            "16 rag_chain = Offline_RAG (llm ). get_chain ( retriever )\n",
            "17\n",
            "18 return rag_chain\n",
            "Như vậy, ta đã hoàn thiện toàn bộ các code cần thiết để xây dựng một ứng dụng về RAG. Để\n",
            "tổng quát hóa toàn bộ quy trình, chúng ta có thể tham khảo qua ảnh sau:\n",
            "Hình 5: Minh họa chuỗi (chain) các bước xây dựng RAG trong LangChain. Ảnh: Link.\n",
            "10.Cập nhật file src/app.py :Cuối cùng, ta tạo file dùng để khai báo API với LangServe để triển\n",
            "khai ứng dụng RAG. Đối với LangServe, cách sử dụng gần như tương tự với việc sử dụng FastAPI.\n",
            "Nội dung file code như sau:\n",
            "1import os\n",
            "2os. environ [\" TOKENIZERS_PARALLELISM \"] = \" false \"\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3\n",
            "4from fastapi import FastAPI\n",
            "5from fastapi . middleware . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "cors import CORSMiddleware\n",
            "6\n",
            "7from langserve import add_routes\n",
            "8\n",
            "9from src. base . llm_model import get_hf_llm\n",
            "10from src.rag. main import build_rag_chain , InputQA , OutputQA\n",
            "11\n",
            "12llm = get_hf_llm ( temperature =0.9)\n",
            "13genai_docs = \"./ data_source / generative_ai \"\n",
            "14\n",
            "15# --------- Chains ----------------\n",
            "16\n",
            "17genai_chain = build_rag_chain (llm , data_dir = genai_docs , data_type =\"pdf\")\n",
            "18\n",
            "19# --------- App - FastAPI ----------------\n",
            "20\n",
            "21app = FastAPI (\n",
            "22 title =\" LangChain Server \",\n",
            "23 version =\"1.0\",\n",
            "24 description =\"A simple api server using Langchain ’s Runnable interfaces \",\n",
            "25)\n",
            "26\n",
            "27app . add_middleware (\n",
            "28 CORSMiddleware ,\n",
            "29 allow_origins =[\"*\"],\n",
            "30 allow_credentials =True ,\n",
            "31 allow_methods =[\"*\"],\n",
            "32 allow_headers =[\"*\"],\n",
            "33 expose_headers =[\"*\"],\n",
            "34)\n",
            "35\n",
            "36# --------- Routes - FastAPI ----------------\n",
            "37\n",
            "38@app . get(\"/ check \")\n",
            "39async def check ():\n",
            "40 return {\" status \": \"ok\"}\n",
            "41\n",
            "42@app . post (\"/ generative_ai \", response_model = OutputQA )\n",
            "43async def generative_ai ( inputs : InputQA ):\n",
            "44 answer = genai_chain . invoke ( inputs . question )\n",
            "45 return {\" answer \": answer }\n",
            "46\n",
            "47# --------- Langserve Routes - Playground ----------------\n",
            "48add_routes (app ,\n",
            "49 genai_chain ,\n",
            "50 playground_type =\" default \",\n",
            "51 path =\"/ generative_ai \")\n",
            "Để khởi động API, chúng ta duy chuyển đến thư mục root của source code trong terminal (trong\n",
            "trường hợp của bài viết sẽ là thư mục rag_langchain/ ), sử dụng lệnh sau (sau khi đã cài đặt các\n",
            "thư viện cần thiết cũng như vector database). Lưu ý, nếu bị lỗi do port đã được sử dụng trong\n",
            "máy của bạn thì có thể thay đổi sang một port khác:\n",
            "1uvicorn src.app:app --host \" 0.0.0.0 \" --port 5000 -- reload\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 6: Minh họa API sau khi ta triển khai thành công.\n",
            "Hình 7: Minh họa một kết quả của model thông qua API mà chúng ta đã xây dựng.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. LangChain được sử dụng nhằm mục đích gì?\n",
            "(a) Web Scraping.\n",
            "(b) Model Quantization.\n",
            "(c) Building language model-powered applications.\n",
            "(d) Database Management.\n",
            "2. Nội dung nào dưới đây là một thành phần cốt lõi của LangChain?\n",
            "(a) Transformers.\n",
            "(b) Agents.\n",
            "(c) Callbacks.\n",
            "(d) Hooks.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3. Trong LangChain, mục đích trong việc sử dụng PromptTemplate là?\n",
            "(a) Tạo các trường thông tin trong hệ cơ sở dữ liệu lưu thông tin người dùng.\n",
            "(b) Định nghĩa các tính năng trong giao diện của người dùng.\n",
            "(c) Tối ưu tốc độ xử lý của mô hình.\n",
            "(d) Chuẩn hóa một cấu trúc phản hồi nhất quán từ mô hình.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "4. Xét đoạn code dưới đây:\n",
            "1from langchain_openai import ChatOpenAI\n",
            "2from langchain_openai import OpenAI\n",
            "3\n",
            "4llm = OpenAI ()\n",
            "5chat_model = ChatOpenAI ( model =\"gpt -3.5 - turbo -0125 \")\n",
            "Ý nghĩa của đoạn code trên là?\n",
            "(a) Khởi tạo model GPT 3.5 Turbo-0125.\n",
            "(b) Tải pre-trained model GPT 3.5 Turbo-0125.\n",
            "(c) Kiểm tra tốc độ đường truyền với ChatGPT API.\n",
            "(d) Các đáp án trên đều sai.\n",
            "5. Ý nghĩa của phương thức from_template() trong class PromptTemplate là?\n",
            "(a) Để khởi tạo prompt template từ một file.\n",
            "(b) Để khởi tạo prompt template từ một string.\n",
            "(c) Để khởi tạo prompt template từ một danh sách các tin nhắn.\n",
            "(d) Để khởi tạo prompt template từ một prompt template có sẵn.\n",
            "6. Trong LangChain, loại OutputParser nào dưới đây có thể được sử dụng để trả về kết quả của mô\n",
            "hình dưới dạng JSON?\n",
            "(a) PydanticOutputParser.\n",
            "(b) RegexOutputParser.\n",
            "(c) JsonOutputParser.\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(d) YamlOutputParser.\n",
            "7. Xét đoạn code dưới đây:\n",
            "1from langchain import HuggingFaceHub\n",
            "2from langchain import PromptTemplate\n",
            "3\n",
            "4template = \"\"\" Question : { question }\n",
            "5\n",
            "6Answer : \"\"\"\n",
            "7prompt = PromptTemplate (\n",
            "8 template = template ,\n",
            "9 input_variables =[ ’question ’]\n",
            "10)\n",
            "11\n",
            "12hub_llm = HuggingFaceHub (\n",
            "13 repo_id =’google /flan -t5 -xl ’\n",
            "14)\n",
            "15\n",
            "16llm_chain = prompt | hub_llm\n",
            "17\n",
            "18print ( llm_chain .run(\" What year was the World Cup first held ?\"))\n",
            "Ý nghĩa của các dòng code 16 là gì?\n",
            "(a) Khai báo hệ cơ sở dữ liệu vector.\n",
            "(b) Khởi tạo LLMChain với LLM và Prompt.\n",
            "(c) Cài đặt ủy quyền và bảo mật cho người dùng.\n",
            "(d) Phân tích và trực quan hóa dữ liệu.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "8. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Xét đoạn code dưới đây:\n",
            "1from langchain_community . document_loaders import PyPDFLoader\n",
            "2\n",
            "3pdf_loader = PyPDFLoader (url , extract_images = True )\n",
            "4\n",
            "5docs = pdf_loader . load ()\n",
            "Tham số extract_images tại dòng code 3 có chức năng gì?\n",
            "(a) Trả về tất cả ảnh từ file pdf.\n",
            "(b) Bỏ qua ảnh, chỉ load text.\n",
            "(c) Phân tích ảnh thành vector.\n",
            "(d) Chuyển đổi ảnh trong file pdf thành text.\n",
            "9. Tại sao chúng ta cần phải chia nhỏ các tài liệu đầu vào thành các tài liệu ngắn hơn? Chọn câu\n",
            "trả lờiSAI.\n",
            "(a) Giúp LLM tập trung tạo ra câu trả lời chỉ dựa trên các thông tin có liên quan.\n",
            "(b) Tiết kiệm bộ nhớ cho phần cứng.\n",
            "(c) Chỉ dựa vào một phần nhỏ tài liệu thì mô hình vẫn trả lời chính xác.\n",
            "(d) Giúp mô hình LLM chạy nhanh hơn.\n",
            "10. Xét đoạn code dưới đây:\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1from langchain_community . document_loaders import PyPDFLoader\n",
            "2from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
            "3from langchain_community . embeddings import HuggingFaceEmbeddings\n",
            "4from langchain_chroma import Chroma\n",
            "5\n",
            "6pdf_url = \" https :// arxiv .org/pdf /2401.18059 v1.pdf\"\n",
            "7\n",
            "8# PDF loader\n",
            "9pdf_loader = PyPDFLoader ( pdf_url , extract_images = True )\n",
            "10pdf_pages = pdf_loader . load ()\n",
            "11\n",
            "12# Splitter\n",
            "13splitter = RecursiveCharacterTextSplitter (\n",
            "14 chunk_size =300 ,\n",
            "15 chunk_overlap =0,\n",
            "16)\n",
            "17docs = splitter . split_documents ( pdf_pages )\n",
            "18\n",
            "19# Embedding model\n",
            "20embedding_model = HuggingFaceEmbeddings ()\n",
            "21\n",
            "22# vector store\n",
            "23chroma_db = Chroma . from_documents (docs , embedding = embedding_model )\n",
            "Nhiệm vụ của embedding_model là gì?\n",
            "(a) Dùng biến đổi chuỗi đầu vào thành các vector cho cơ sở dữ liệu vector.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(b) Dùng để lập chỉ mục cho cơ sở dữ liệu.\n",
            "(c) Dùng để tìm kiếm tài liệu.\n",
            "(d) Dùng để tính toán độ tương đồng.\n",
            "- Hết -\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "BASIC PYTHON - VARIABLE\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 Biến trong Python\n",
            "Biến trong Python là tên được sử dụng để tham chiếu đến một vùng lưu trữ dữ liệu trong bộ nhớ, tên\n",
            "của biến là cách chúng ta đặt cho vùng lưu trữ đó để có thể truy cập và thao tác với dữ liệu trong\n",
            "chương trình của mình. Khi đặt tên biến sẽ có một số quy tắc mà bạn cần chú ý:\n",
            "•Tên biến có thể chứa chữ cái, số, dấu gạch dưới \"_\"nhưng không được là số. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ví dụ: ‘message_1‘,\n",
            "‘_massage‘ nhưng không thể đặt là ‘1_message‘.\n",
            "•Tên biến có thể gồm nhiều từ, nhưng mỗi từ phải được viết liền, không được sử dụng khoảng\n",
            "trắng. Ví dụ ‘fresh_apple‘ nhưng không thể đặt là ‘fresh apple‘\n",
            "•Không được đặt tên biến trùng với những từ khóa và tên hàm trong Python. Ví dụ: Không nên\n",
            "đặt tên biến là ‘list‘, ‘for‘, ‘from‘, ‘if‘, ‘is‘, ‘False‘...\n",
            "•Tên biến chỉ cần ngắn thôi nhưng phải rõ ràng, nếu không thì có thể tạo tên dài hơn mà rõ ràng\n",
            "cũng được. Ví dụ: ‘student_name‘ với ‘s_n‘ thì nên dùng biến tên ‘student_name‘ vì khi đọc sẽ\n",
            "hiểu ngay.\n",
            "•Bạn cũng nên cẩn thận khi sử dụng tên biến chứa chữ ‘l‘ và ‘o‘, vì nó giống số ‘1‘ và ‘0‘ nên có\n",
            "thể gây ra nhầm lẫn nếu quan sát không kỹ.\n",
            "2 Bài tập\n",
            "Viết chương trình với yêu cầu dưới đây, mỗi yêu cầu bạn sẽ viết nó tại một cell trong file jupyter\n",
            "notebook.\n",
            "1. Bạn hãy tạo file và đặt tên file bất kỳ nhưng tên phải được viết thường và mỗi từ cách nhau bởi\n",
            "dấu gạch dưới ‘\"_\"‘, ví dụ như ‘simple_message.ipynb‘. Sau đó hãy lập trình in chuỗi ‘\"Hello\n",
            "world!\"‘ ra màn hình.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2. Gán một chuỗi ‘\"Have a nice day!\"‘ vào biến ‘message‘. Sau đó sử dụng câu lệnh ‘print‘ để hiển\n",
            "thị biến này ra màn hình.\n",
            "3. Bạn hãy tạo một chuỗi ‘\"Let’s have Tet holidays!\"‘ và gán vào biến với tên ‘1_message‘. Sau đó\n",
            "sử dụng câu lệnh ‘print‘ để hiển thị biến này ra màn hình. Nếu kết quả hiển thị thông báo lỗi,\n",
            "hãy xác định lỗi này là gì và sửa như thế nào? Sau đó chạy lại chương trình.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "BASIC PYTHON - STRING\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 String\n",
            "String trong Python là một chuỗi các ký tự, giống như các từ hoặc câu mà chúng ta viết. String có thể\n",
            "chứa chữ cái, số, ký tự đặc biệt và khoảng trắng. Để tạo một string trong Python, ta chỉ cần đặt các\n",
            "ký tự vào trong dấu ngoặc kép. Có thể dùng dấu ngoặc kép đơn (’), ngoặc kép (\") hoặc dùng ba dấu\n",
            "nháy đối với chuỗi dài, nhiều dòng (\"\"\"hoặc ”’). Ví dụ:\n",
            "1page_name = \"AI VIET NAM\"\n",
            "2user_name = ’Tom’\n",
            "3greeting = \"\"\"Xin chào Tom!\n",
            "4 Chào mừng bạn đến AI VIET NAM!\"\"\"\n",
            "2 F-string\n",
            "F-string là một cách đặc biệt để viết các chuỗi ký tự trong Python. Nó giúp chúng ta dễ dàng chèn các\n",
            "biến hoặc kết quả của các phép toán vào trong chuỗi. Chỉ cần đặt chữ ’f’ hoặc ’F’ trước dấu ngoặc kép\n",
            "của chuỗi, rồi đặt các biểu thức hoặc biến trong cặp dấu ngoặc nhọn .\n",
            "1student_name = \"Tom\"\n",
            "2class_name = \"AI VIETNAM\"\n",
            "3message = f\"{student_name} học lập trình tại {class_name}\"\n",
            "4print(message)\n",
            "Trong ví dụ này, student_name sẽ được thay thế bằng giá trị của biến student_name là \"Tom\", và\n",
            "class_name sẽ được thay thế bằng giá trị của biến class_name là \"AI VIETNAM\". Khi chúng ta chạy\n",
            "chương trình, kết quả sẽ là:\n",
            "1Tom học lập trình tại AI VIETNAM\n",
            "3 Chiều dài, chỉ số trong chuỗi\n",
            "Chúng ta có thể sử dụng hàm len() để đếm số ký tự trong một chuỗi. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hàm này sẽ trả về số ký tự có\n",
            "trong chuỗi đó. ví dụ:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "All-in-One Course - 2024 aivietnam.edu.vn\n",
            "1class_name = \"AI VIETNAM\"\n",
            "2length = len(class_name)\n",
            "3print(f\"Số ký tự trong chuỗi là: {length}\")\n",
            "\"Trong ví dụ này, class_name là chuỗi ’Hello’. Khi chúng ta sử dụng len(class_name), Python sẽ đếm\n",
            "số ký tự trong chuỗi này. Kết quả sẽ là:\n",
            "1Số ký tự trong chuỗi là: 10\n",
            "Tương tự, các bạn có thể đếm số ký tự trong bất kỳ chuỗi nào theo cách trên. Tiếp theo chúng ta sẽ\n",
            "học cách truy cập phần tử trong một chuỗi thông qua chỉ số index. Theo chiều từ trái sang phải chỉ số\n",
            "bắt đầu từ 0, có nghĩa là ký tự đầu tiên của chuỗi sẽ có chỉ số là 0. Đối với chiều ngược lại, chỉ số bắt\n",
            "đầu từ -1, có nghĩa là ký tự cuối cùng của chuỗi sẽ có chỉ số là -1. Ví dụ:\n",
            "1class_name = \"AI VIETNAM\"\n",
            "2print(f\"Ký tự đầu tiên trong chuỗi là: {class_name[0]}\")\n",
            "3print(f\"Ký tự cuối cùng trong chuỗi là: {class_name[-1]}\")\n",
            "Trong ví dụ này, class_name[0] sẽ lấy ký tự đầu tiên trong chuỗi, và class_name[-1] sẽ lấy ký tự cuối\n",
            "cùng trong chuỗi. Kết quả sẽ là:\n",
            "1Ký tự đầu tiên trong chuỗi là: A\n",
            "2Ký tự cuối cùng trong chuỗi là: M\n",
            "4 Một số phương thức biến đổi chuỗi\n",
            "Trong phần này, chúng ta sẽ học về ba phương thức phổ biến để biến đổi chuỗi trong Python: lower(),\n",
            "upper(), và title(). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Chúng ta sẽ dùng chuỗi \"tom Holland\"để minh họa.\n",
            "4.1 lower()\n",
            "Phương thức lower() sẽ chuyển tất cả các ký tự trong chuỗi thành chữ thường.\n",
            "1name = \"tom Holland\"\n",
            "2lowercase_name = name.lower()\n",
            "3print(lowercase_name)1================= Output ================\n",
            "2tom holland\n",
            "3=========================================\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "All-in-One Course - 2024 aivietnam.edu.vn\n",
            "Khi chúng ta dùng name.lower(), tất cả các ký tự sẽ được chuyển thành chữ thường. Kết quả sẽ là \"tom\n",
            "holland\"\n",
            "4.2 upper()\n",
            "Phương thức upper() sẽ chuyển tất cả các ký tự trong chuỗi thành chữ hoa.\n",
            "1name = \"tom Holland\"\n",
            "2uppercase_name = name.upper()\n",
            "3print(uppercase_name)1================= Output ================\n",
            "2TOM HOLLAND\n",
            "3=========================================\n",
            "Trong ví dụ này, khi chúng ta dùng name.upper(), tất cả các ký tự sẽ được chuyển thành chữ hoa\n",
            "4.3 title()\n",
            "Phương thức title() sẽ chuyển chữ cái đầu của mỗi từ thành chữ hoa và các ký tự còn lại thành chữ\n",
            "thường.\n",
            "1name = \"tom Holland\"\n",
            "2titlecase_name = name.title()\n",
            "3print(titlecase_name)1================= Output ================\n",
            "2Tom Holland\n",
            "3=========================================\n",
            "Trong ví dụ này, khi chúng ta dùng name.title(), chữ cái đầu của mỗi từ sẽ được chuyển thành chữ hoa\n",
            "và các chữ cái còn lại thành chữ thường.\n",
            "5 Bài Tập\n",
            "Câu 1: Tạo một biến name gán giá trị là tên một người, sau đó hiển thị ra màn hình một thông báo\n",
            "chứa tên đó sử dụng f-string. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ví dụ name = “Alice”, mình sẽ in ra màn hình nội dung là “Alice is a great\n",
            "teacher!”\n",
            "Câu 2: Tạo một biến và gán giá trị “ms Taylor” cho nó, sau đó thực hiện in ra màn hình giá trị biến đó\n",
            "được viết hoa ký tự đầu tiên mỗi từ hoặc viết toàn bộ bằng chữ chữ hoa, hoặc chữ thường.\n",
            "1Input: name = \"ms Taylor\"\n",
            "2Output:\n",
            "3Title case: Ms Taylor\n",
            "4Upper case: MS TAYLOR\n",
            "5Lower case: ms taylor\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "BASIC PYTHON - FOR LOOP\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 Giới thiệu\n",
            "Trong hầu hết các ngôn ngữ lập trình, vòng lặp là một công cụ quan trọng giúp thực hiện lặp đi lặp\n",
            "lại các tác vụ mà không cần viết mã nhiều lần. Trong bài viết này chúng ta sẽ tìm hiểu cách sử dụng\n",
            "vòng lặp for từ cơ bản đến nâng cao, bao gồm cách sử dụng continue, break, vòng lặp lồng nhau và cách\n",
            "duyệt qua các cấu trúc dữ liệu như string, list, tuple và dictionary.\n",
            "2 Vòng lặp for cơ bản\n",
            "Sử dụng vòng lặp for là cách hiệu quả để xử lý các tác vụ lặp đi lặp lại, duyệt qua các phần tử của một\n",
            "danh sách, mảng, hoặc bất kỳ tập hợp nào khác. Cú pháp sử dụng như sau:\n",
            "1for variable in iterable:\n",
            "2# Body of for loop\n",
            "Trong đó:\n",
            "•variable là biến sẽ nhận giá trị từng phần tử trong iterable qua mỗi lần lặp.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•iterable là một đối tượng có thể lặp, ví dụ như list, tuple, string, dictionary, hoặc range.\n",
            "Ví dụ vòng lặp for sau sẽ thực hiện hiển thị giá trị của biến i 5 lần, mỗi lần lặp i sẽ nhận 1 giá trị trong\n",
            "range(5) từ 0 đến 4:\n",
            "1for i in range(5):\n",
            "2print(i)\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7#Vòng lặp for với range================= Output ================\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "==========================================\n",
            "Trong chương trình trên, chúng ta bắt đầu vòng lặp với lệnh for, trong đó range(3) sẽ tạo ra một dãy\n",
            "số từ 0 đến 4 (không bao gồm 5). Tức là, dãy số này sẽ là: [0, 1, 2, 3, 4], i là biến đếm, nó sẽ lần lượt\n",
            "----------------------------------------------------------------------------------------------------\n",
            "All-in-One Course - 2024 aivietnam.edu.vn\n",
            "nhận giá trị từ từng phần tử trong dãy số do range(5) tạo ra. Lệnh print(i) là khối lệnh thực thi trong\n",
            "vòng lặp. Với mỗi giá trị của i trong range(5), lệnh này sẽ in ra giá trị hiện tại của i.\n",
            "Chi tiết hoạt động từng bước của chương trình trên ta có thể hình dung như sau:\n",
            "•Bước đầu tiên: i nhận giá trị đầu tiên từ range(5), tức là 0, sau đó print(i) in ra giá trị 0.\n",
            "•Bước thứ hai: i nhận giá trị tiếp theo từ range(5), tức là 1, sau đó print(i) in ra giá trị 1.\n",
            "•Bước thứ 3 tương tự, i nhận giá trị 2 và in ra 2.\n",
            "•Bước thứ 4 i nhận giá trị 3 và in ra 3\n",
            "•Bước thứ 5 i nhận giá trị 4 và in ra 4 và kết thúc vòng lặp.\n",
            "Như đã đề cập phía trên thì mọi kiểu dữ liệu thuộc loại interable đều có thể dùng vòng lặp for. Theo\n",
            "định nghĩa Iterable là bất kỳ đối tượng Python nào có khả năng trả về từng phần tử của nó cùng một\n",
            "lúc, cho phép nó được lặp lại trong vòng lặp for. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Dưới đây, chúng ta sẽ sử dụng vòng lặp for với string,\n",
            "list, dictionary, tuple.\n",
            "Ví dụ sử dụng vòng lặp for qua từng phần tử trong string:\n",
            "1for i in \"AI VIETNAM\":\n",
            "2print(i)\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12#Vòng lặp for với string================= Output ================\n",
            "A\n",
            "I\n",
            "V\n",
            "I\n",
            "E\n",
            "T\n",
            "N\n",
            "A\n",
            "M\n",
            "==========================================\n",
            "Ví dụ sử dụng vòng lặp for qua từng phần tử trong list:\n",
            "1# Vòng lặp for với danh sách\n",
            "2fruits = [\"apple\", \"banana\", \"cherry\"]\n",
            "3\n",
            "4for fruit in fruits:\n",
            "5print(fruit)================= Output ================\n",
            "apple\n",
            "banana\n",
            "cherry\n",
            "==========================================\n",
            "Ví dụ sử dụng vòng lặp for qua từng phần tử trong tuple:\n",
            "1# Vòng lặp for với tuple\n",
            "2numbers = (1, 2, 3)\n",
            "3\n",
            "4for number in numbers:\n",
            "5print(number)================= Output ================\n",
            "1\n",
            "2\n",
            "3\n",
            "==========================================\n",
            "Ví dụ sử dụng vòng lặp for qua từng phần tử trong dictionary:\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "All-in-One Course - 2024 aivietnam.edu.vn\n",
            "1# Vòng lặp for với từ điển\n",
            "2student_scores = {\n",
            "3 \"Bông\": 90,\n",
            "4 \"Hoa\": 85,\n",
            "5 \"Mai\": 78\n",
            "6 }\n",
            "7for student, score in student_scores.items\n",
            "():\n",
            "8print(f\"{student}: {score}\")================= Output ================\n",
            "Bông: 90\n",
            "Hoa: 85\n",
            "Mai: 78\n",
            "==========================================\n",
            "3 Vòng lặp for trong comprehension\n",
            "Comprehension là một loại cú pháp để viết vòng lặp for ngắn gọn hơn để tạo ra list, dictionary, set mới.\n",
            "Chúng ta sẽ tìm hiểu về cách sử dụng comprehension với list, dictionary còn các kiểu dữ liệu khác thì\n",
            "tương tự.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3.1 List comprehension\n",
            "List comprehension cho phép chúng ta tạo ra một danh sách mới bằng cách áp dụng một biểu thức cho\n",
            "mỗi phần tử trong một iterable.\n",
            "1[expression for item in iterable if condition]\n",
            "Trong đó:\n",
            "•expression: Biểu thức được áp dụng cho mỗi phần tử.\n",
            "•item: Phần tử hiện tại từ iterable.\n",
            "•iterable: Bất kỳ đối tượng nào có thể lặp (như danh sách, chuỗi, range, v.v.).\n",
            "•condition: (Tùy chọn) Điều kiện để lọc các phần tử.\n",
            "Ví dụ: Tạo danh sách bình phương của các số chẵn từ 0 đến 9\n",
            "1squares = [x ** 2 for x in range(10) if x\n",
            "% 2 == 0]\n",
            "2print(squares)================= Output ================\n",
            "[0, 4, 16, 36, 64]\n",
            "==========================================\n",
            "3.2 Dictionary comprehension\n",
            "Dictionary comprehension cho phép ta tạo ra một từ điển mới bằng cách áp dụng một biểu thức cho\n",
            "mỗi phần tử trong một iterable.\n",
            "1{key_expression: value_expression for item in iterable if condition}\n",
            "Trong đó:\n",
            "•key_expression: Biểu thức cho khóa.\n",
            "•value_expression: Biểu thức cho giá trị.\n",
            "•item, iterable, và condition: Tương tự như trong list comprehension.\n",
            "Ví dụ: Tạo dictionary với khóa là số và giá trị là bình phương của số đó.\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "All-in-One Course - 2024 aivietnam.edu.vn\n",
            "1\n",
            "2squares_dict = {x: x ** 2 for x in range\n",
            "(10)}\n",
            "3print(squares_dict)================= Output ================\n",
            "{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6:\n",
            "36, 7: 49, 8: 64, 9: 81}\n",
            "==========================================\n",
            "4 Vòng lặp for với continue\n",
            "Lệnh continue trong vòng lặp for được sử dụng để\n",
            "bỏ qua các lần lặp cụ thể và tiếp tục với lần lặp\n",
            "tiếp theo. Khi gặp lệnh continue, vòng lặp sẽ ngay\n",
            "lập tức bỏ qua các lệnh còn lại trong lần lặp hiện\n",
            "tại và chuyển sang lần lặp tiếp theo. Điều này hữu\n",
            "ích khi ta muốn bỏ qua một số điều kiện nhất định\n",
            "mà không cần kết thúc hoàn toàn vòng lặp.\n",
            "Ví dụ dưới đây minh họa việc sử dụng lệnh con-\n",
            "tinue trong vòng lặp for để bỏ qua việc in ra số\n",
            "2:\n",
            "1# Vòng lặp for với lệnh continue\n",
            "2\n",
            "3for i in range(5):\n",
            "4if i == 2:\n",
            "5 continue\n",
            "6print(i)================= Output ================\n",
            "0\n",
            "1\n",
            "3\n",
            "4\n",
            "==========================================\n",
            "Trong chương trình trên, vòng lặp for được khởi tạo với i nhận các giá trị từ range(5), tức là [0, 1, 2,\n",
            "3, 4]. Khi i là 2, lệnh if i == 2 sẽ được thực thi vì điều kiện lúc đó là True, lệnh continue sẽ được thực\n",
            "thi, bỏ qua phần còn lại của vòng lặp cho giá trị i hiện tại và chuyển sang giá trị tiếp theo của i.\n",
            "Dưới đây là chi tiết từng bước thực hiện:\n",
            "•Khi i là 0, điều kiện i == 2 là sai, lệnh print(i) sẽ in ra 0.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Khi i là 1, điều kiện i == 2 là sai, lệnh print(i) sẽ in ra 1.\n",
            "•Khi i là 2, điều kiện i == 2 là đúng, lệnh continue sẽ được thực thi và vòng lặp bỏ qua việc in ra\n",
            "số 2.\n",
            "•Khi i là 3, điều kiện i == 2 là sai, lệnh print(i) sẽ in ra 3.\n",
            "•Khi i là 4, điều kiện i == 2 là sai, lệnh print(i) sẽ in ra 4.\n",
            "•Sau khi đã duyệt hết các giá trị trong range(5), vòng lặp kết thúc.\n",
            "5 Vòng lặp for với break\n",
            "Lệnh break trong vòng lặp for được sử dụng để kết thúc vòng lặp ngay lập tức, ngay cả khi chưa hoàn\n",
            "thành vòng lặp. Khi gặp lệnh break, chương trình sẽ thoát khỏi vòng lặp và tiếp tục thực hiện các lệnh\n",
            "sau vòng lặp. Chúng ta sẽ sử dụng nó khi muốn dừng vòng lặp với một điều kiện cụ thể.\n",
            "Ví dụ dưới đây minh họa việc sử dụng lệnh break trong vòng lặp for để kết thúc vòng lặp khi gặp số 2:\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "All-in-One Course - 2024 aivietnam.edu.vn\n",
            "1# Vòng lặp for với lệnh break\n",
            "2for i in range(5):\n",
            "3if i == 2:\n",
            "4 break\n",
            "5print(i)================= Output ================\n",
            "0\n",
            "1\n",
            "==========================================\n",
            "Vòng lặp for được khởi tạo với i nhận các giá trị từ range(5), tức là [0, 1, 2, 3, 4]. Khi i là 2, lệnh if i\n",
            "== 2 sẽ được thực thi và lệnh break xảy ra để kết thúc vòng lặp ngay lập tức và không in ra giá trị 2\n",
            "hay các giá trị sau đó.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Khi i là 0, điều kiện i == 2 là sai, lệnh print(i) sẽ in ra 0.\n",
            "•Khi i là 1, điều kiện i == 2 là sai, lệnh print(i) sẽ in ra 1.\n",
            "•Khi i là 2, điều kiện i == 2 là đúng, lệnh break sẽ được thực thi và vòng lặp kết thúc.\n",
            "6 Vòng lặp for lồng\n",
            "Vòng lặp lồng nhau là vòng lặp nằm bên trong một vòng lặp khác. Nó cho phép ta thực hiện các tác\n",
            "vụ phức tạp hơn, chẳng hạn như duyệt qua các ma trận hoặc thực hiện các phép toán trên nhiều chiều\n",
            "dữ liệu.\n",
            "Ví dụ dưới đây minh họa việc sử dụng vòng lặp for lồng nhau để duyệt qua các phần tử của một danh\n",
            "sách 2 chiều và in ra vị trí cũng như giá trị của từng phần tử:\n",
            "1# List 2 chiều\n",
            "2matrix = [\n",
            "3[1, 2, 3],\n",
            "4[4, 5, 6],\n",
            "5[7, 8, 9]\n",
            "6]\n",
            "7\n",
            "8# Vòng lặp for lồng nhau để duyệt và in ra\n",
            "vị trí và giá trị phần tử\n",
            "9for i in range(len(matrix)):\n",
            "10 for j in range(len(matrix[i])):\n",
            "11 print(f\"Vị trí: ({i}, {j}), Giá tr\n",
            "ị: {matrix[i][j]}\")================= Output ================\n",
            "Vị trí: (0, 0), Giá trị: 1\n",
            "Vị trí: (0, 1), Giá trị: 2\n",
            "Vị trí: (0, 2), Giá trị: 3\n",
            "Vị trí: (1, 0), Giá trị: 4\n",
            "Vị trí: (1, 1), Giá trị: 5\n",
            "Vị trí: (1, 2), Giá trị: 6\n",
            "Vị trí: (2, 0), Giá trị: 7\n",
            "Vị trí: (2, 1), Giá trị: 8\n",
            "Vị trí: (2, 2), Giá trị: 9\n",
            "==========================================\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "All-in-One Course - 2024 aivietnam.edu.vn\n",
            "Đầu tiên là khởi tạo vòng lặp ngoài duyệt qua từng hàng của ma trận matrix, với i là chỉ số của hàng.\n",
            "Tiếp theo là vòng lặp trong với mỗi hàng i, vòng lặp for j in range(len(matrix[i])) sẽ duyệt qua từng\n",
            "phần tử trong hàng đó, với j là chỉ số của cột. Với mỗi phần tử matrix[i][j], lệnh print(f\"Vị trí: (i, j),\n",
            "Giá trị: matrix[i][j]\") sẽ in ra vị trí và giá trị của phần tử đó.\n",
            "Chi tiết từng bước được mô tả như sau:\n",
            "•Khi i là 0, j sẽ lần lượt là 0, 1, 2, kết quả in ra là\n",
            "==================================== Output =====================================\n",
            "Vị trí: (0, 0), Giá trị: 1\n",
            "Vị trí: (0, 1), Giá trị: 2\n",
            "Vị trí: (0, 2), Giá trị: 3\n",
            "=================================================================================\n",
            "•Khi i là 1, j vẫn lần lượt là 0, 1, 2\n",
            "==================================== Output =====================================\n",
            "Vị trí: (1, 0), Giá trị: 4\n",
            "Vị trí: (1, 1), Giá trị: 5\n",
            "Vị trí: (1, 2), Giá trị: 6\n",
            "=================================================================================\n",
            "•Khi i là 2, j vẫn lần lượt là 0, 1, 2\n",
            "==================================== Output =====================================\n",
            "Vị trí: (2, 0), Giá trị: 7\n",
            "Vị trí: (2, 1), Giá trị: 8\n",
            "Vị trí: (2, 2), Giá trị: 9\n",
            "=================================================================================\n",
            "7 Kết luận\n",
            "Trong bài viết này chúng ta đã tìm hiểu cách sử dụng vòng lặp for từ cơ bản đến nâng cao. Đây là kiến\n",
            "thức cơ bản nhưng rất quan trọng mà chúng ta cần phải thành thạo nó. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mặc dù bài viết đã cố gắng bao\n",
            "quát các trường hợp sử dụng vòng lặp for, tuy nhiên khi các bạn lập trình sẽ gặp nhiều trường hợp hơn\n",
            "nữa như việc kết hợp với thư viện tqdm, enumerate... nhưng về bản chất thì nó vẫn không thay đổi. Hy\n",
            "vọng các bạn đã nắm được vòng lặp for và sẽ sử dụng nó hiệu quả trong quá trình viết code của mình.\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "BASIC PYTHON - WHILE LOOP\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 Giới thiệu\n",
            "Trong hầu hết các ngôn ngữ lập trình, vòng lặp là một cấu trúc cho phép ta thực thi một khối code\n",
            "nhiều lần. Trong Python, có hai loại vòng lặp chính là for và while. Bài viết này sẽ tập trung vào vòng\n",
            "lặp while, giải thích cách hoạt động qua các ví dụ cụ thể để có thể dễ dàng hiểu và áp dụng.\n",
            "1.1 Vòng lặp while là gì?\n",
            "Vòng lặp while thực thi một khối mã liên tục miễn là điều kiện được chỉ định là đúng. Cú pháp của\n",
            "vòng lặp while như sau:\n",
            "1while điều_kiện:\n",
            "2# Khối code trong while\n",
            "Vòng lặp while bắt đầu bằng việc kiểm tra điều kiện. Nếu điều kiện là True, khối code bên trong vòng\n",
            "lặp sẽ được thực thi. Sau khi khối code kết thúc, điều kiện sẽ được kiểm tra lại. Quá trình này tiếp tục\n",
            "cho đến khi điều kiện trở thành False.\n",
            "Ví dụ chương trình in ra màn hình các số từ 1 đến 5:\n",
            "1i = 1\n",
            "2while i <= 5:\n",
            "3print(i)\n",
            "4i += 1\n",
            "5\n",
            "6\n",
            "7#ai vietnam================= Output ================\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "==========================================\n",
            "Một ví dụ khác để hiểu vòng lặp while, hãy tưởng tượng bạn đang chơi một trò chơi bật nhảy với một\n",
            "quả bóng. Bạn sẽ tiếp tục nhảy và đập bóng xuống đất cho đến khi bạn mệt và không thể nhảy nữa.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ở đây, vòng lặp while hoạt động tương tự như việc bạn bật nhảy. Bạn sẽ tiếp tục thực hiện một hành\n",
            "động (nhảy và đập bóng) cho đến khi một điều kiện nào đó không còn đúng nữa (bạn cảm thấy mệt và\n",
            "không thể nhảy tiếp).\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "1has_energy = True\n",
            "2jump_count = 0\n",
            "3\n",
            "4while has_energy:\n",
            "5jump_count += 1\n",
            "6print(f\"Jump {jump_count} time(s)\")\n",
            "7# Giả sử sau 5 lần nhảy, bạn mệt và dừ\n",
            "ng lại\n",
            "8if jump_count == 5:\n",
            "9 has_energy = False================= Output ================\n",
            "Jump 1 time(s)\n",
            "Jump 2 time(s)\n",
            "Jump 3 time(s)\n",
            "Jump 4 time(s)\n",
            "Jump 5 time(s)\n",
            "==========================================\n",
            "has_energy là biến điều kiện. Mỗi lần vòng lặp chạy, bạn sẽ nhảy một lần và tăng số lần nhảy\n",
            "jump_count lên. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Khi số lần nhảy đạt đến 5, bạn cảm thấy mệt và đặt has_energy thành False, vòng\n",
            "lặp kết thúc.\n",
            "2 Vòng lặp vô hạn\n",
            "Một vòng lặp vô hạn là một vòng lặp tiếp tục thực thi câu lệnh trong vòng lặp đến mãi mãi, vì điều\n",
            "kiện của vòng lặp luôn là True. Mặc dù chúng thường là điều cần tránh, nhưng cũng có những trường\n",
            "hợp chúng ta có thể tạo ra một vòng lặp vô hạn một cách cố ý, chẳng hạn khi xây dựng các chương\n",
            "trình liên tục lắng nghe đầu vào hoặc chạy các tiến trình máy chủ.\n",
            "Ví dụ Vòng lặp vô hạn:\n",
            "1while True:\n",
            "2print(\"This loop will run forever!\")\n",
            "Trong ví dụ trên, điều kiện của vòng lặp while được đặt là True, có nghĩa là vòng lặp sẽ chạy mãi mãi\n",
            "vì điều kiện luôn đúng. Bên trong vòng lặp, câu lệnh print(\"This loop will run forever!\") được thực thi\n",
            "lặp đi lặp lại. Để thoát khỏi vòng lặp, chúng ta cần phải dừng chương trình bằng cách kết thúc quá\n",
            "trình thực thi của nó. Trong hầu hết các môi trường phát triển, chúng ta có thể làm điều này bằng\n",
            "cách nhấn Ctrl + C nếu chúng ta chạy chương trình bằng dòng lệnh hoặc nhấn nút stop trên công cụ\n",
            "lập trình.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "3 Sử dụng break trong while\n",
            "Chúng ta có thể sử dụng lệnh break để thoát khỏi vòng lặp ngay lập tức, bất kể điều kiện của vòng lặp\n",
            "là gì. Sử dụng break khi chúng ta muốn dừng vòng lặp dựa trên một điều kiện khác xảy ra trong quá\n",
            "trình thực thi.\n",
            "Ví dụ sử dụng break để thoát khỏi vòng lặp:\n",
            "1#ai vietnam\n",
            "2i = 1\n",
            "3while i <= 10:\n",
            "4print(i)\n",
            "5if i == 5:\n",
            "6 break\n",
            "7i += 1================= Output ================\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "==========================================\n",
            "Trong ví dụ này vòng lặp while sẽ chạy miễn là i nhỏ hơn hoặc bằng 10. Bên trong vòng lặp, giá trị của\n",
            "i được in ra và sau đó được tăng lên một đơn vị. Khi i đạt giá trị 5, lệnh if i == 5: break sẽ được thực\n",
            "thi, làm cho vòng lặp dừng lại ngay lập tức. Các giá trị từ 1 đến 5 sẽ được in ra, sau đó vòng lặp kết\n",
            "thúc khi i bằng 5.\n",
            "4 Sử dụng continue trong while\n",
            "Chúng ta có thể sử dụng lệnh continue để bỏ qua các lệnh còn lại của khối code trong vòng lặp và bắt\n",
            "đầu lần lặp tiếp theo. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Continue thường được sử dụng khi chúng ta muốn bỏ qua một số bước trong\n",
            "vòng lặp dựa trên một điều kiện nào đó.\n",
            "Ví dụ sử dụng continue để bỏ qua lần lặp của những trường hợp i chia hết cho 2:\n",
            "1#ai vietnam\n",
            "2i = 0\n",
            "3while i < 10:\n",
            "4i += 1\n",
            "5if i % 2 == 0:\n",
            "6 continue\n",
            "7print(i)================= Output ================\n",
            "1\n",
            "3\n",
            "5\n",
            "7\n",
            "9\n",
            "==========================================\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "Trong ví dụ này vòng lặp while sẽ chạy miễn là i nhỏ hơn 10. Mỗi lần vòng lặp chạy, giá trị của i được\n",
            "tăng lên một đơn vị. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nếu i là số chẵn (i % 2 == 0), lệnh continue sẽ được thực thi, bỏ qua câu lệnh\n",
            "print(i) và bắt đầu lần lặp tiếp theo. Kết quả chỉ gồm các số lẻ từ 1 đến 9 được hiển thị ra màn hình.\n",
            "5 Sử dụng while với list\n",
            "Chúng ta cũng có thể sử dụng vòng lặp while để duyệt qua các phần tử của một danh sách. Cachs này\n",
            "thường dùng khi chúng ta cần thực hiện các thao tác lặp lại trên các phần tử của danh sách mà không\n",
            "sử dụng vòng lặp for.\n",
            "Ví dụ sử dụng while để duyệt qua danh sách\n",
            "1#ai vietnam\n",
            "2fruits = [\"apple\", \"banana\", \"cherry\"]\n",
            "3i = 0\n",
            "4while i < len(fruits):\n",
            "5print(fruits[i])\n",
            "6i += 1================= Output ================\n",
            "apple\n",
            "banana\n",
            "cherry\n",
            "==========================================\n",
            "Trong ví dụ trên, chúng ta có một danh sách fruits chứa các phần tử là tên các loại trái cây. Vòng lặp\n",
            "while sẽ chạy khi chỉ số i nhỏ hơn độ dài của danh sách fruits. Trong mỗi lần lặp, phần tử tại vị trí i\n",
            "trong danh sách fruits sẽ được in ra. Chỉ số i sau đó được tăng lên một đơn vị, giúp duyệt qua các phần\n",
            "tử tiếp theo của danh sách. Khi i bằng độ dài của danh sách, vòng lặp sẽ kết thúc. Ngoài ra các bạn có\n",
            "thể thử với dictionary, tuple...\n",
            "6 Kết Luận\n",
            "Vòng lặp while là một công cụ mạnh mẽ trong Python, cho phép ta thực thi một khối code nhiều lần\n",
            "dựa trên điều kiện nào đó. Tuy nhiên, chúng ta cần cẩn thận để tránh vòng lặp vô hạn và sử dụng các\n",
            "lệnh break và continue một cách hợp lý để kiểm soát luồng của vòng lặp.\n",
            "Hy vọng rằng qua bài viết này, các bạn đã hiểu rõ hơn về vòng lặp while và cách sử dụng nó trong\n",
            "Python. Hãy thử áp dụng những gì các bạn đã học vào các bài tập và project trên lớp để nắm vững\n",
            "kiến thức hơn!\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – COURSE 2024\n",
            "Data Structure – Exercise\n",
            "Ngày 8 tháng 6 năm 2024\n",
            "I. Câu hỏi tự luận\n",
            "1.Cho một list các số nguyên num_list và một sliding window có kích thước size k di\n",
            "chuyển từ trái sang phải. Mỗi lần dịch chuyển 1 vị trí sang phải có thể nhìn thấy\n",
            "đươc k số trong num_list và tìm số lớn nhất trong k số này sau mỗi lần trượt k phải\n",
            "lớn hơn hoặc bằng 1\n",
            "Input: num_list = [3, 4, 5, 1, -44 , 5 ,10, 12 ,33, 1] với k=3\n",
            "Output: [5, 5, 5, 5, 10, 12, 33, 33]\n",
            "Ví dụ:\n",
            "[3, 4, 5], 1, -44 , 5 ,10, 12 ,33, 1 => max 5\n",
            "3, [4, 5, 1], -44 , 5 ,10, 12 ,33, 1 => max 5\n",
            "3, 4, [5, 1, -44] , 5 ,10, 12 ,33, 1 => max 5\n",
            "3, 4, 5, [1, -44 , 5] ,10, 12 ,33, 1 => max 5\n",
            "3, 4, 5, 1, [-44 , 5 ,10], 12 ,33, 1 => max 10\n",
            "3, 4, 5, 1, -44 , [5 ,10, 12] ,33, 1 => max 12\n",
            "3, 4, 5, 1, -44 , 5 ,[10, 12 ,33], 1 => max 33\n",
            "3, 4, 5, 1, -44 , 5 ,10, [12 ,33, 1] => max 33\n",
            "2.Thực hiện theo các yêu cầu sau.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Viết function trả về một dictionary đếm số lượng chữ xuất hiện trong một từ, với key là chữ cái\n",
            "và value là số lần xuất hiện\n",
            "•Input:một từ\n",
            "•Output: dictionary đếm số lần các chữ xuất hiện\n",
            "•Note:Giả sử các từ nhập vào đều có các chữ cái thuộc [a-z] hoặc [A-Z]\n",
            "1# Examples\n",
            "2string = ’Happiness ’\n",
            "3count_chars ( string )\n",
            "4>> {’H’: 1, ’a’: 1, ’e’: 1, ’i’: 1, ’n’: 1, ’p’: 2, ’s’: 2}\n",
            "5\n",
            "6string = ’smiles ’\n",
            "7count_chars ( string )\n",
            "8>> {’e’: 1, ’i’: 1, ’l’: 1, ’m’: 1, ’s’: 2}\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3.Thực hiện theo các yêu cầu sau .\n",
            "Viếtfunction đọc cáccâu trongmộtfile txt,đếmsố lượngcáctừ xuấthiệnvàtrảvềmộtdictionary\n",
            "với key là từ và value là số lần từ đó xuất hiện.\n",
            "•Input:Đường dẫn đến file txt\n",
            "•Output: dictionary đếm số lần các từ xuất hiện\n",
            "•Note:\n",
            "–Giả sử các từ trong file txt đều có các chữ cái thuộc [a-z] hoặc [A-Z]\n",
            "–Không cần các thao tác xử lý string phức tạp nhưng cần xử lý các từ đều là viết\n",
            "thường\n",
            "–Các bạn dùng lệnh này để download\n",
            "!gdown https://drive.google.com/uc?id=1IBScGdW2xlNsc9v5zSAya548kNgiOrko\n",
            "1# Examples\n",
            "2! gdown https :// drive . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "google . com/uc?id =1 IBScGdW2xlNsc9v5zSAya548kNgiOrko\n",
            "3file_path = ’/ content / P1_data . txt ’\n",
            "4word_count ( file_path )\n",
            "5>>{’a’: 7,\n",
            "6’again ’: 1,\n",
            "7’and ’: 1,\n",
            "8’are ’: 1,\n",
            "9’at ’: 1,\n",
            "10 ’be ’: 1,\n",
            "11 ’become ’: 2,\n",
            "12 ...}\n",
            "4.Khoảng cách Levenshtein.\n",
            "Viết chương trình tính khoảng cách chỉnh sửa tối thiểu Levenshtein. Khoảng cách Levenshtein thể\n",
            "hiện khoảng cách khác biệt giữa 2 chuỗi ký tự. Khoảng cách Levenshtein giữa chuỗi S và chuỗi T\n",
            "là số bước ít nhất biến chuỗi S thành chuỗi T thông qua 3 phép biến đổi là:\n",
            "•Xoá một ký tự\n",
            "•Thêm một ký tự\n",
            "•Thay thế ký tự này bằng ký tự khác\n",
            "Khoảng cách này được sử dụng trong việc tính toán sự giống và khác nhau giữa 2 chuỗi, như\n",
            "chương trình kiểm tra lỗi chính tả của winword spellchecker. Ví dụ: Khoảng cách Levenshtein\n",
            "giữa 2 chuỗi \"kitten\" và \"sitting\" là 3, vì phải dùng ít nhất 3 lần biến đổi. Trong đó:\n",
            "•kitten -> sitten (thay \"k\" bằng \"s\")\n",
            "•sitten -> sittin (thay \"e\" bằng \"i\")\n",
            "•sittin -> sitting (thêm ký tự \"g\")\n",
            "Để hiểu rõ về thuật toán, chúng ta lấy ví dụ, khoảng cách cần tính giữa hai từ source: ’yu’ và\n",
            "target: ’you’. Chi phí thực hiện cho các phép biến đổi bao gồm: xoá một ký tự, thêm một ký tự\n",
            "và thay thế ký tự này thành ký tự khác đều là 1 (Nếu 2 ký tự giống nhau thì chi phí thực hiện là\n",
            "0).\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Các bước thực hiện như sau:\n",
            "•Bước 1: Xây dựng ma trận lưu trữ có số hàng là M và số cột là N. Trong đó M là số lượng\n",
            "các ký tự trong từ source + 1, N là số lượng các ký tự trong từ target + 1. Vì vậy với ví dụ\n",
            "’yu’ và ’you’, ta có ma trận được biểu diễn như hình 1. Ký hiệu ’#’ đại diện cho chuỗi rỗng.\n",
            "Gọi là ma trận D.\n",
            "Hình 1: Khởi tạo ma trận D\n",
            "•Bước 2: Hoàn thiện hàng và cột đầu tiên. Với hàng đầu tiên, các giá trị đại diện cho chuỗi\n",
            "bắt đầu là chuỗi ’#’ và phép biến đổi là thêm (insert) từ chuỗi ’#’ thành ’#’, ’#y’, ’#yo’,\n",
            "’#you’ lần lượt là 0, 1, 2, 3 tương ứng với ô D[0,0], D[0,1], D[0,2], D[0,3]. Với cột đầu tiên,\n",
            "các giá trị đại diện cho chuỗi ’#’, ’#y’, ’#yu’ và phép biến đổi là xoá (delete) để thu được\n",
            "chuỗi ’#’ lần lượt là: 0, 1, 2 tương ứng với ô D[0,0], D[1,0], D[2,0]. Ta được hình 2.\n",
            "Hình 2: Số phép biến đổi cho hàng đầu tiên (thêm) và cột đầu tiên (xoá).\n",
            "•Bước 3. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tính toán các giá trị với các ô còn lại trong ma trận. Bắt đầu từ D[1,1]được tính\n",
            "dựa vào 3 ô phía trước là D[0,1], D[1,0], D[0,0]như sau:\n",
            "D[1,1] =\n",
            "\n",
            "D[0,1] +del_cost(source [1]) = 1 + 1 = 2\n",
            "D[1,0] +ins_cost(target [1]) = 1 + 1 = 2\n",
            "D[0,0] +sub_cost(source [1], target [1]) = 0 + 0 = 0(1)\n",
            "Vì vậy D[1,1] = 0ta được ma trận Dnhư sau:\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 3: Giá trị tại D[1,1].\n",
            "Tiếp theo chúng ta tính D[2,1], D[1,2]:\n",
            "D[2,1] =\n",
            "\n",
            "D[1,1] +del_cost(source [2]) = 0 + 1 = 1\n",
            "D[2,0] +ins_cost(target [1]) = 2 + 1 = 3\n",
            "D[1,0] +sub_cost(source [2], target [1]) = 1 + 1 = 2(2)\n",
            "D[1,2] =\n",
            "\n",
            "D[0,2] +del_cost(source [1]) = 2 + 1 = 3\n",
            "D[1,1] +ins_cost(target [2]) = 0 + 1 = 1\n",
            "D[0,1] +sub_cost(source [1], target [2]) = 1 + 1 = 2(3)\n",
            "Vì vậy D[2,1] = 1 , D[1,2] = 1ta được ma trận Dnhư sau:\n",
            "Hình 4: Giá trị tại D[2,1], D[1,2].\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cuối cùng, chúng ta tính D[1,3], D[2,2], D[2,3]:\n",
            "D[1,3] =\n",
            "\n",
            "D[0,3] +del_cost(source [1]) = 3 + 1 = 4\n",
            "D[1,2] +ins_cost(target [3]) = 1 + 1 = 2\n",
            "D[0,2] +sub_cost(source [1], target [3]) = 2 + 1 = 3(4)\n",
            "D[2,2] =\n",
            "\n",
            "D[1,2] +del_cost(source [2]) = 1 + 1 = 2\n",
            "D[2,1] +ins_cost(target [2]) = 1 + 1 = 2\n",
            "D[1,1] +sub_cost(source [2], target [2]) = 0 + 1 = 1(5)\n",
            "D[2,3] =\n",
            "\n",
            "D[1,3] +del_cost(source [2]) = 2 + 1 = 3\n",
            "D[2,2] +ins_cost(target [3]) = 1 + 1 = 2\n",
            "D[1,2] +sub_cost(source [2], target [3]) = 1 + 0 = 1(6)\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Vì vậy D[1,3] = 2 , D[2,2] = 1 , D[2,3] = 1ta được ma trận như sau:\n",
            "Hình 5: Giá trị tại D[1,3], D[2,2], D[2,3].\n",
            "•Bước 4: Sau khi hoàn thành ma trận, chúng ta đi tìm đường đi từ ô cuối cùng D[2,3]có giá\n",
            "trị là 1. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Vì vậy khoảng cách chỉnh sửa từ source: ’yu’ sang thành target: ’you’ là 1. Đầu tiên\n",
            "ký tự ’y’ giữ nguyên sau đó thực hiện 1 phép thêm ký tự ’o’ vào sau ký tự ’y’ và cuối cùng\n",
            "ký tự ’u’ được giũ nguyên. Minh hoạ các bước quay lui để tìm đường đi ngắn nhất tưng ứng\n",
            "mũi tên vàng trong hình sau:\n",
            "Hình 6: Quay lui, tìm các bước thực hiện chỉnh sửa từ source ’yu’ sang target: ’you’.\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "II. Câu hỏi trắc nghiệm\n",
            "•Đọc tự luận trước để nắm được idea tổng quát (sẽ không yêu cầu nhưng khuyến khích các\n",
            "bạn tự làm tự luận) và các bài này sẽ được giải trong buổi TA.\n",
            "•Các bạn phải làm phần trắc nghiệm\n",
            "–Các câu hỏi có ký hiệu (Code ): là câu hỏi yêu cầu các bạn phải trực tiếp code vào\n",
            "phần bị khuyết để có thể chọn được đáp án đúng\n",
            "– Lưu ý: Đối với dạng câu hỏi (Code )trong file hint luôn có 1 test casse bắt đầu với\n",
            "từ khóa assert nếu các bạn chạy không báo lỗi có nghĩa các bạn đã vượt qua được test\n",
            "case này và chạy lệnh tiếp theo để trả lời câu hỏi trắc nghiệm\n",
            "– Lưu ý: Đọc kỹ các code gợi ý và code ví dụ mẫu ở tự luận có thể sẽ có ích cho các\n",
            "bạn khi làm trắc nghiệm\n",
            "Câu hỏi 1 :(Code) Hoàn thành chương trình sau với mô tả bài toán từ câu I.1. Đầu ra của chương trình\n",
            "dưới đây là gì?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1def max_kernel ( num_list , k):\n",
            "2 result = []\n",
            "3\n",
            "4 # Your Code Here\n",
            "5\n",
            "6 # End Code Here\n",
            "7\n",
            "8 return result\n",
            "9\n",
            "10assert max_kernel ([3 , 4 , 5 , 1 , -44] , 3) == [5, 5, 5]\n",
            "11num_list = [3, 4, 5, 1, -44 , 5 ,10, 12 ,33, 1]\n",
            "12k = 3\n",
            "13print ( max_kernel ( num_list , k))\n",
            "a) [5, 5, 5, 5, 10, 12, 33, 33]\n",
            "b) [2, 5, 3, 4, 1, 10, 3, 3]\n",
            "c) [0, 9, 5, 1, 0, 12, 3, 33]\n",
            "d) Raise an Error\n",
            "Câu hỏi 2 :(Code) Hoàn thành chương trình sau với mô tả bài toán từ câu I.2. Đầu ra của chương trình\n",
            "dưới đây là gì?\n",
            "1def character_count ( word ):\n",
            "2 character_statistic = {}\n",
            "3\n",
            "4 # Your Code Here\n",
            "5\n",
            "6 # End Code Here\n",
            "7 return character_statistic\n",
            "8\n",
            "9assert character_count (\" Baby \") == {’B’: 1, ’a’: 1, ’b’: 1, ’y’: 1}\n",
            "10print ( character_count (’smiles ’))\n",
            "a) ’s’: 2, ’m’: 1, ’i’: 1, ’l’: 1, ’e’: 1\n",
            "b) ’s’: 0, ’m’: 1, ’i’: 1, ’l’: 1, ’e’: 8\n",
            "c) ’s’: 4, ’m’: 1, ’i’: 2, ’l’: 1, ’e’: 1\n",
            "d) Raise a Error\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Câu hỏi 3 :(Code) Hoàn thành chương trình sau với mô tả bài toán từ câu I.3. Đầu ra của chương trình\n",
            "dưới đây là gì?\n",
            "1! \n",
            "----------------------------------------------------------------------------------------------------\n",
            "gdown https :// drive . google .com/uc?id =1 IBScGdW2xlNsc9v5zSAya548kNgiOrko\n",
            "2\n",
            "3def count_word ( file_path ):\n",
            "4 counter = {}\n",
            "5\n",
            "6 # Your Code Here\n",
            "7\n",
            "8 # End Code Here\n",
            "9\n",
            "10 return counter\n",
            "11file_path = ’/ content / P1_data . txt ’\n",
            "12result = count_word ( file_path )\n",
            "13assert result [’who ’] == 3\n",
            "14print ( result [’man ’])\n",
            "a) 4\n",
            "b) 5\n",
            "c) 6\n",
            "d) 9\n",
            "Câu hỏi 4 :(Code) Hoàn thành chương trình sau với mô tả bài toán từ câu I.4. Đầu ra của chương trình\n",
            "dưới đây là gì?\n",
            "1def levenshtein_distance ( token1 , token2 ):\n",
            "2 # Your Code Here\n",
            "3\n",
            "4 # End Code Here\n",
            "5\n",
            "6 return distance\n",
            "7\n",
            "8assert levenshtein_distance (\"hi\", \" hello \") == 4.0\n",
            "9print ( levenshtein_distance (\" hola \", \" hello \"))\n",
            "a) 1.0\n",
            "b) 2.0\n",
            "c) 3.0\n",
            "d) 4.0\n",
            "Câu hỏi 5 :(Code) Hoàn thành chương trình sau. Đầu ra của chương trình dưới đây là gì?\n",
            "1def check_the_number (N):\n",
            "2 list_of_numbers = []\n",
            "3 result = \"\"\n",
            "4 for i in range (1, 5):\n",
            "5 # Your code here\n",
            "6 #Su dung append them i vao trong list_of_number\n",
            "7 if N in list_of_numbers :\n",
            "8 results = \" True \"\n",
            "9 if N not in list_of_numbers :\n",
            "10 results = \" False \"\n",
            "11 return results\n",
            "12\n",
            "13N = 7\n",
            "14assert check_the_number (N) == \" False \"\n",
            "15\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "16N = 2\n",
            "17results = check_the_number (N)\n",
            "18print ( results )\n",
            "a) True ==\n",
            "b) False\n",
            "c) None\n",
            "d) Raise an Error\n",
            "Câu hỏi 6 :(Code) Hãy hoàn thành chương trình dưới đây. Đầu ra của chương trình là gì?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1def my_function (data , max , min):\n",
            "2 result = []\n",
            "3 for i in data :\n",
            "4 # Your code here\n",
            "5 #Neu i < min thi them min vao result\n",
            "6 elif i > max :\n",
            "7 result . append (max )\n",
            "8 else :\n",
            "9 result . append (i)\n",
            "10 return result\n",
            "11my_list = [5, 2, 5, 0, 1]\n",
            "12max = 1\n",
            "13min = 0\n",
            "14assert my_function (max = max , min = min , data = my_list ) == [1, 1, 1, 0, 1]\n",
            "15my_list = [10 , 2, 5, 0, 1]\n",
            "16max = 2\n",
            "17min = 1\n",
            "18print ( my_function (max = max , min = min , data = my_list ))\n",
            "a) [10, 2, 5, 1, 1]\n",
            "b) [0, 2, 2, 0, 0]\n",
            "c) [2, 2, 2, 1, 1] ==\n",
            "d) Raise an Error\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Câu hỏi 7 :(code) Hãy hoàn thành chương trình dưới đây. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Đầu ra của chương trình là gì?\n",
            "1def my_function (x, y):\n",
            "2 # Your code here\n",
            "3 #Su dung extend de noi y vao x\n",
            "4 # return x\n",
            "5\n",
            "6list_num1 = [’a’, 2, 5]\n",
            "7list_num2 = [1, 1]\n",
            "8list_num3 = [0, 0]\n",
            "9\n",
            "10assert my_function ( list_num1 , my_function ( list_num2 , list_num3 )) == [’a’, 2, 5, 1, 1,\n",
            "0, 0]\n",
            "11\n",
            "12list_num1 = [1, 2]\n",
            "13list_num2 = [3, 4]\n",
            "14list_num3 = [0, 0]\n",
            "15\n",
            "16print ( my_function ( list_num1 , my_function ( list_num2 , list_num3 )))\n",
            "a) [1, 2, 3, 4, 0, 0] ==\n",
            "b) [1, 2, [3, 4, 0, 0]]\n",
            "c) [[1, 2, 3, 4, 0, 0]]\n",
            "d) Raise an Error\n",
            "Câu hỏi 8 :(code) Hãy hoàn thành chương trình tìm phần tử có giá trị nhỏ nhất trong một list dưới\n",
            "đây. Đầu ra của chương trình là gì?\n",
            "1def my_function (n):\n",
            "2 # Your code here\n",
            "3\n",
            "4my_list = [1, 22, 93, -100]\n",
            "5assert my_function ( my_list ) == -100\n",
            "6\n",
            "7my_list = [1, 2, 3, -1]\n",
            "8print ( my_function ( my_list ))\n",
            "a) None\n",
            "b) Raise an Error\n",
            "c) -1 ==\n",
            "d) 3\n",
            "Câu hỏi 9 :(code) Hãy hoàn thành chương trình tìm phần tử có giá trị lớn nhất trong một list dưới\n",
            "đây. Đầu ra của chương trình là gì?\n",
            "1def my_function (n):\n",
            "2 # Your code here\n",
            "3\n",
            "4my_list = [1001 , 9, 100 , 0]\n",
            "5assert my_function ( my_list ) == 1001\n",
            "6\n",
            "7my_list = [1, 9, 9, 0]\n",
            "8print ( my_function ( my_list ))\n",
            "a) None\n",
            "b) Raise an Error\n",
            "c) 0\n",
            "d) 9 ==\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Câu hỏi 10 :(code) Hãy hoàn thành chương trình dưới đây. Đầu ra của chương trình là gì?\n",
            "1def My_function ( integers , number = 1):\n",
            "2 return any(# Your code here : Thuc hien duyet tung phan tu trong integers , so sanh\n",
            "tung phan tu voi number , neu bang nhau tra ve True , khac nhau tra ve false\n",
            "3 #vi du: integers = [1, 2, 3], number = 2, ban se tao ra list [False ,\n",
            "True , False ] )\n",
            "4\n",
            "5my_list = [1, 3, 9, 4]\n",
            "6assert My_function ( my_list , -1) == False\n",
            "7\n",
            "8my_list = [1, 2, 3, 4]\n",
            "9print ( My_function ( my_list , 2))\n",
            "a) 1\n",
            "b) 4\n",
            "c) True ==\n",
            "d) False\n",
            "Câu hỏi 11 :(code) Hãy hoàn thành chương trình dưới đây. Đầu ra của chương trình là gì?\n",
            "1def my_function ( list_nums = [0, 1, 2]):\n",
            "2 var = 0\n",
            "3 for i in list_nums :\n",
            "4 var += i\n",
            "5 return # Your code here : Tra ve gia tri trung binh cua list bang cach chia var cho\n",
            "so luong phan tu trong list_mums\n",
            "6\n",
            "7assert my_function ([4 , 6, 8]) == 6\n",
            "8print ( my_function ())\n",
            "a) 1.0 ==\n",
            "b) 2.0\n",
            "c) Raise an Error\n",
            "d) A and C\n",
            "Câu hỏi 12 :(code) Hãy hoàn thành chương trình dưới đây. Đầu ra của chương trình dưới đây là gì?\n",
            "1def my_function ( data ):\n",
            "2 var = []\n",
            "3 for i in data :\n",
            "4 # Your code here\n",
            "5 #Neu i chia het cho 3 thi them i vao list var\n",
            "6 return var\n",
            "7\n",
            "8assert my_function ([3 , 9, 4, 5]) == [3, 9]\n",
            "9print ( my_function ([1 , 2, 3, 5, 6]))\n",
            "a) [3, 6] ==\n",
            "b) [1, 2, 3, 5, 6]\n",
            "c) a and d\n",
            "d) [5, 1]\n",
            "Câu hỏi 13 :(code) Hãy hoàn thành chương trình sau đây thực hiện tính giai thừa của 1 số. Đầu ra\n",
            "của chương trình dưới đây là gì?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1def my_function (y):\n",
            "2 var = 1\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3 while (y > 1):\n",
            "4 # Your code here\n",
            "5 return var\n",
            "6assert my_function (8) == 40320\n",
            "7print ( my_function (4))\n",
            "a) 0\n",
            "b) 20\n",
            "c) 24 ==\n",
            "d) Raise an Error\n",
            "Câu hỏi 14 :(code) Hãy hoàn thành chương trình đảo ngược chuỗi dưới đây. Đầu ra của chương trình\n",
            "là gì?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1def my_function (x):\n",
            "2 # your code here\n",
            "3\n",
            "4x = ’I can do it ’\n",
            "5assert my_function (x)==\"ti od nac I\"\n",
            "6\n",
            "7x = ’apricot ’\n",
            "8print ( my_function (x))\n",
            "a) apricot\n",
            "b) tocirpa ==\n",
            "c) Raise a Error\n",
            "d) None\n",
            "Câu hỏi 15 :(code) Hãy hoàn thành chương trình dưới đây. Đầu ra của chương trình là gì?\n",
            "1def function_helper (x):\n",
            "2 # Your code here\n",
            "3 #Neu x >0 tra ve ’T ’, nguoc lai tra ve ’N’\n",
            "4\n",
            "5def my_function ( data ):\n",
            "6 res = [ function_helper (x) for x in data ]\n",
            "7 return res\n",
            "8\n",
            "9data = [10 , 0, -10, -1]\n",
            "10assert my_function ( data ) == [’T’, ’N’, ’N’, ’N’]\n",
            "11\n",
            "12data = [2, 3, 5, -1]\n",
            "13print ( my_function ( data ))\n",
            "a) [’N’, ’T’, ’T’, ’N’]\n",
            "b) [’T’, ’N’, ’T’, ’N’]\n",
            "c) [’T’, ’T’, ’T’, ’N’] ==\n",
            "d) Raise an Error\n",
            "Câu hỏi 16 :(code) Hãy hoàn thành chương trình dưới đây để loại bỏ những phần tử trùng nhau. Đầu\n",
            "ra của chương trình là gì?\n",
            "1def function_helper (x, data ):\n",
            "2 for i in data :\n",
            "3 # Your code here\n",
            "4 #Neu x == i thi return 0\n",
            "5 return 1\n",
            "6\n",
            "7def my_function ( data ):\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "8 res = []\n",
            "9 for i in data :\n",
            "10 if function_helper (i, res):\n",
            "11 res . append (i)\n",
            "12\n",
            "13 return res\n",
            "14\n",
            "15lst = [10 , 10, 9, 7, 7]\n",
            "16assert my_function (lst) ==[10 , 9, 7]\n",
            "17\n",
            "18lst = [9, 9, 8, 1, 1]\n",
            "19print ( my_function (lst))\n",
            "a) [9, 8, 1] ==\n",
            "b) [1, 1, 1]\n",
            "c) [9, 9, 8, 1, 1]\n",
            "d) Raise an Error\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AIO Course\n",
            "Mamba for Vision\n",
            "Minh-Duc Bui và Quang-Vinh Dinh\n",
            "PR-Team: Đăng-Nhã Nguyễn, Minh-Châu Phạm và Hoàng-Nguyên Vũ\n",
            "Ngày 23 tháng 2 năm 2024\n",
            "1 Introduction\n",
            "Mamba, tên gọi khác là S6 ( Structured StateSpace for Sequence Modeling with Selective Scan), là\n",
            "một kiến trúc mới xuất hiện gần đây. Điểm khác biệt chính giữa Mamba và các mô hình hiện tại như\n",
            "Transformer là Mamba không sử dụng cơ chế attention. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nhờ vậy, Mamba có độ phức tạp thấp hơn\n",
            "nhiều so với Transformer, chỉ O(n)so với O(n2)của Transformer (với nlà chiều dài sequence). Bên\n",
            "cạnh đó, Mamba cho độ chính xác cao khi chiều dài sequence tăng (lên đến hàng triệu).\n",
            "Trong bài viết này, ta sẽ tìm hiểu cách các nhà nghiên cứu đã áp dụng kiến trúc Mamba vào data dạng\n",
            "ảnh, thông qua các bài paper sau:\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Title Link Github\n",
            "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State\n",
            "Space Modelhere here\n",
            "VMamba: Visual State Space Model here here\n",
            "U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation here here\n",
            "Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining here here\n",
            "2 Text vs. Image\n",
            "Điểm khác biệt chính giữa text và image chính là thông tin về dimension, text chỉ có 1D trong khi image\n",
            "là 2D. Điều này gây ra khó khăn khi áp dụng các model từ NLP (ví dụ Mamba, Transformer) sang CV.\n",
            "Hình 1: Pixel-level và Patch-level khi sử dụng mô hình Transformer cho data dạng ảnh.\n",
            "Hình 1 mô tả 2 cách chuyển đổi từ data 2D sang data 1D. Nếu ta chia ảnh đầu vào theo pixel-level\n",
            "thì với ví dụ như hình (ảnh 224x224) ta sẽ có hơn 50ktoken, nếu ánh xạ tương ứng sang text là 1 câu\n",
            "có50ktừ. Điều này cực kì khó khăn đối với các GPU để tính toán. Cách phổ biến được sử dụng đối\n",
            "với Transformer chính là chia ảnh đầu vào thành các patch nhỏ (ví dụ 16x16pixel), ảnh có kích thước\n",
            "224x224sau khi chia sẽ có tổng cộng 14*14=196 patch (hoặc token). 196token là hoàn toàn hợp lý so với\n",
            "50kvà các GPU vẫn có thể hoạt động bình thường.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3 Vision Mamba\n",
            "Vision Mamba (Vim) là bài paper đầu tiên áp dụng Mamba vào data dạng ảnh. Các tác giả đã thay\n",
            "thế Transformer Encoder trong Vision Transformer (ViT) bằng Vision Mamba Encoder , và thay\n",
            "đổi kiến trúc SSM thành Bidirectional SSM (tương tự Bidirectional LSTM). Kiến trúc của Vim và\n",
            "Vision Mamba Encoder được mô tả như hình 2. Từng Vision Mamba Encoder block sẽ có 2 block SSM là\n",
            "Forward SSM vàBackward SSM . Giả sử ta đánh số các token theo thứ tự từ 1đếnN, thì Forward\n",
            "SSM sẽ tính SSM theo chiều thuận từ 1đếnN, Backward SSM sẽ tính theo chiều ngược lại từ Nđến\n",
            "1. Tương tự trong data dạng text, Forward là từ đầu câu đến cuối câu, và Backward là từ cuối câu đến\n",
            "đầu câu. Việc tính toán như vậy giúp model học được thông tin từ 2 hướng khác nhau.\n",
            "Hình 2: Kiến trúc Vision Mamba (Vim) và Vision Mamba Encoder.\n",
            "Hình 3 mô tả kết quả giữa Transformer (DeiT) và Vision Mamba (Vim). Ta thấy, Vim vượt trội hơn\n",
            "DeiT ở tất cả các task bao gồm: image classification, object detection, và instance segmentation. Hơn\n",
            "nữa, khi kích thước ảnh đầu vào tăng, Vim outperform DeiT ở cả speed và memory. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cụ thể, Vim nhanh\n",
            "hơn và tiết kiệm bộ nhớ hơn DeiT lần lượt là 2.8xvà86.8%. Khi công nghệ ngày càng phát triển, kích\n",
            "thước ảnh 224x224 -> 512x512 dần trở nên lỗi thời, con người luôn muốn sử dụng ảnh có kích thước lớn\n",
            "hơn để các model có thể đạt độ chính xác cao hơn. Điều này càng chứng tỏ Mamba sẽ có khả năng cao\n",
            "trở thành backbone được sử dụng trong tương lai.\n",
            "Hình 3: Kết quả so sánh giữa Transformer (DeiT) và Vision Mamba.\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4 Visual Mamba\n",
            "Sau khi Vim được công bố chỉ 1 ngày thì ta tiếp tục có bài paper thứ 2 sử dụng Mamba vào data dạng\n",
            "ảnh mang tên Visual Mamba (VMamba). Xuất phát từ Swin Transformer (một model cải tiến của ViT)\n",
            "các tác giả đã thay thế Transformer block bằng Visual State Space (VSS) block (hình 4).\n",
            "Hình 4: Kiến trúc VMamba và VSS Block.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Khác với Vim sử dụng Bidirectional, VMamba sử dụng Four-Directional (4 hướng) để tính SSM và sử\n",
            "dụng tên gọi Cross-Scan. 4 hướng này bao gồm:\n",
            "1.trái->phải->trên->dưới\n",
            "2.phải->trái->dưới->trên\n",
            "3.trên->dưới->trái->phải\n",
            "4.dưới->trên->phải->trái\n",
            "Hình 5: So sánh giữa Attention (hình a) và Cross-Scan (hình b).\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 5 mô tả cách hoạt động của Cross-Scan, và hình 6 mô tả cách tính toán với Cross-Scan trong SSM\n",
            "block. Cross-Scan giúp VMamba đạt được độ phức tạp linear O(n)mà không bị mất bất kỳ thông tin\n",
            "global nào. Ví dụ, token ở vị trí chính giữa trong hình 5 được tổng hợp thông tin từ tất cả các token\n",
            "khác theo nhiều hướng khác nhau. Cross-Scan được tính toán thông qua 3 bước chính:\n",
            "1.Scan expand : các token đầu vào được chia thành 4 sequence khác nhau (theo 4 hướng).\n",
            "2.S6 block : 4 sequence được đưa vào S6 block để tính toán.\n",
            "3.Scan merge : cuối cùng, 4 sequence sẽ được tổng hợp lại để tiếp tục expand ở block tiếp theo.\n",
            "Hình 6: Cách tính toán với Cross-Scan.\n",
            "Hình 7 so sánh kết quả giữa VMamba và các model Transformer, CNN khác. Ta thấy VMamba là model\n",
            "sở hữu cả 3 tính chất là:\n",
            "•Độ phức tạp O(n)(Linear Complexity).\n",
            "•Tổng hợp thông tin global (Global ERF).\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Tạo ra param phụ thuộc vào input (Dynamic weights).\n",
            "Hình 7: So sánh VMamba và các model Transformer, CNN khác.\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Tương tự Vim, các tác giả của VMamba cũng đánh giá backbone Mamba dưới nhiều size ảnh khác\n",
            "nhau (tham khảo hình 8). Ta thấy, VMamba vượt trội hơn hầu hết các model khác khi kích thước ảnh\n",
            "tăng dần.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 8: So sánh VMamba và các model Transformer và CNN khác dưới nhiều size ảnh khác nhau.\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "5 U-Mamba\n",
            "Hơn 1 tháng sau khi Mamba được công bố, các tác giả tại Đại học Toronto, Canada đã hưởng ứng trend\n",
            "này với bài paper: “U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation”,\n",
            "một bài paper về bài toán Segmentation trong lĩnh vực Y Sinh. U-Mamba là model theo hướng encoder-\n",
            "decoder tương tự U-Net, nhưng các block nhỏ trong encoder và decoder được thay bằng CNN và SSM\n",
            "block (các tác giả gọi là U-Mamba block). Kiến trúc U-Mamba block và U-Mamba hoàn chỉnh được mô\n",
            "tả như hình 9.\n",
            "Hình 9: Kiến trúc U-Mamba block và model U-Mamba hoàn chỉnh.\n",
            "Sự kết hợp giữa CNN và SSM tạo nên hybrid CNN-SSM model, model hybrid này vừa có khả năng\n",
            "tổng hợp thông tin local nhờ vào CNN và thông tin global nhờ vào SSM. Từ đó giúp model tổng hợp\n",
            "được 2 khía cạnh khác nhau trong ảnh đầu vào.\n",
            "U-Mamba block hoạt động bằng cách đưa input đầu vào sang CNN block, sau đó output từ CNN block\n",
            "này sẽ được đưa vào SSM block. Tùy thuộc vào CNN block thuộc phần encoder hay decoder thì sẽ được\n",
            "thiết kế khác nhau. Đối với encoder, CNN block sẽ có tác dụng giảm kích thước feature map và tăng\n",
            "chiều sâu, ngược lại đối với decoder, CNN làm nhiệm vụ tăng kích thước feature map và giảm chiều sâu.\n",
            "Bàn luận về hybrid model : Các model CNN thuần túy (AlexNet, Resnet, VGG,...) là những model\n",
            "chỉ dùng CNN để trích xuất thông tin, nói cách khác chỉ tổng hợp được thông tin local. Ngược lại, các\n",
            "model Transformer (ViT) chỉ trích xuất thông tin global. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Và Transformer cho performance vượt trội\n",
            "hơn CNN. Nhưng không vì thế mà ta khẳng định rằng thông tin global luôn luôn tốt hơn local, dẫn tới\n",
            "tình huống chỉ tập trung vào global. Đây là một hiểu lầm phổ biến, cả thông tin local và global đều\n",
            "có những tính chất khác nhau, model mang cả 2 thông tin này sẽ cho performance cao hơn model chỉ\n",
            "mang 1 trong 2. Ví dụ một số paper về Transformer sử dụng thông tin hybrid:\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Neighborhood Attention Transformer\n",
            "•Dilated Neighborhood Attention Transformer\n",
            "•MaxViT: Multi-Axis Vision Transformer\n",
            "Hình 10 mô tả kết quả so sánh giữa U-Mamba và các model CNN, Transformer khác. Ta thấy U-Mamba\n",
            "vượt trội hoàn toàn so với các model này, khoảng cách rất lớn ≈10%.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 10: Bảng so sánh kết quả U-Mamba và các model khác trên dataset ảnh 2D.\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "6 Swin-UMamba\n",
            "Ngay sau khi U-Mamba được công bố được chưa đầy 1 tháng thì các tác giả tại Chinese Academy of\n",
            "Sciences, Peng Cheng Laboratory, và một số phòng Lab khác đã tiếp tục cải tiến U-Mamba và công\n",
            "bố Swin-UMamba. Swin-UMamba là sự kết hợp giữa việc tận dụng pretrained model (VMamba ở phần\n",
            "2) và kết hợp với kiến trức U-Net để giải quyết bài toán Medical image segmentation . Kiến trúc\n",
            "Swin-UMamba được mô tả như hình 11.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 11: Kiến trúc Swin-UMamba.\n",
            "Nhìn vào hình 11 ta thấy phần Encoder được sử dụng theo kiến trúc Swin Transformer với các Visual\n",
            "State Space (VSS) block tương tự bài paper Visual Mamba (VMamba). Chính vì tận dụng kiến trúc\n",
            "Encoder như VMamba như thế, ta có thể tận dụng pretrained VMamba để khởi tạo. Đối với phần\n",
            "Decoder, các tác giả đã thiết kế đơn giản như những model U-Net truyền thống: Transpose Convolution\n",
            "+ Skip-Connection.\n",
            "Hình 12 mô tả kết quả của Swin-UMamba và các model Transformer-, Mamba-based khác. Ta thấy khi\n",
            "sử dụng pretrained model từ VMamba thì performance đã tăng từ 4->6%. Swin-UMamba dù sử dụng\n",
            "ít số lượng parameter hơn so với U-Mamba ≈30->40\\% nhưng vẫn cho kết quả cao hơn. Về tổng quát,\n",
            "Swin-UMamba vượt trội hoàn toàn so với các model CNN, Transformer, và các model Mamba trước đó.\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 12: Bảng so sánh kết quả Swin-UMamba và các model khác.\n",
            "7 Conclusion\n",
            "Như vậy, trong bài viết này ta đã tìm hiểu về kiến trúc Mamba được áp dụng cho data dạng ảnh thông\n",
            "qua nhiều bài toán khác nhau. Ta thấy rằng, các model Mamba-based này hoàn toàn vượt trội so với\n",
            "Transformer về cả 3 tiêu chí: tốc độ, tài nguyên tiết kiệm, và độ chính xác cao. Các tiêu chí này đã\n",
            "đúng đối với data dạng text và dạng ảnh, vốn là 2 loại data phổ biến nhất. Từ đó, ta có thể mường\n",
            "tượng được rằng Mamba cũng sẽ tốt ở hầu hết các loại data còn lại.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "References\n",
            "[1] Gu, Albert, and Tri Dao. “Mamba: Linear-time sequence modeling with selective state spaces.” arXiv\n",
            "preprint arXiv:2312.00752 (2023)\n",
            "[2] Zhu, Lianghui, et al. “Vision mamba: Efficient visual representation learning with bidirectional state\n",
            "space model.” arXiv preprint arXiv:2401.09417 (2024).\n",
            "[3] Liu, Yue, et al. “Vmamba: Visual state space model.” arXiv preprint arXiv:2401.10166 (2024).\n",
            "[4] Ma, Jun, Feifei Li, and Bo Wang. “U-mamba: Enhancing long-range dependency for biomedical\n",
            "image segmentation.” arXiv preprint arXiv:2401.04722 (2024).\n",
            "[5] Liu, Jiarun, et al. “Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining.” arXiv\n",
            "preprint arXiv:2402.03302 (2024).\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – 2024\n",
            "Text Classification with Mamba - Project\n",
            "Minh-Duc Bui, Khai-Xuan Trinh, và Quang-Vinh Dinh\n",
            "Ngày 25 tháng 2 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Gần đây, Mamba là kiến trúc mới ra mắt và được sự hưởng ứng mạnh mẽ từ cộng đồng các nhà nghiên\n",
            "cứu. Mamba trở thành trend vì khả năng vượt trội hơn Transformer (kiến trúc phổ biến ở thời điểm\n",
            "hiện tại). Sự vượt trội được thể hiện ở cả 3 tiêu chí chính để đánh giá 1 model: accuracy, speed, và\n",
            "computional cost.\n",
            "Trong project này, ta sẽ tìm hiểu cơ bản về kiến trúc Mamba và áp dụng Mamba vào bài toán text\n",
            "classification.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Nội dung\n",
            "1.Mô tả dataset IMDB\n",
            "IMDB dataset là bộ data bao gồm 50,000 đánh giá về phim. Đây là bộ dữ liệu được sử dụng cho\n",
            "việc phân loại đánh giá tiêu cực và tích cực. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bộ dữ liệu được chia làm 2 phần bằng nhau, 25,000\n",
            "mẫu để train, và 25,000 mẫu để kiểm thử. Bên cạnh đó, bộ dữ liệu cũng cung cấp 50,000 mẫu dữ\n",
            "liệu chưa đánh nhãn để hỗ trợ quá trình train. Tuy nhiên trong project này ta chỉ sử dụng phần\n",
            "dữ liệu đã được đánh nhãn để train model.\n",
            "Hình 1: Ví dụ minh họa về dataset IMDB.\n",
            "2.Model Mamba cho bài toán Text classification\n",
            "(a)Install and import libraries: Đầu tiên ta sẽ install một số thư viện cần thiết của Hug-\n",
            "gingface và Mamba:\n",
            "1!pip install datasets evaluate accelerate\n",
            "2!pip install causal-conv1d>=1.1.0\n",
            "3!pip install mamba-ssm\n",
            "Sau đó ta sẽ tiến hành login vào HuggingFace để download dataset và model có sẵn. Khi\n",
            "chạy block code này thì HuggingFace sẽ đưa ra một đường dẫn đến trang HuggingFace để\n",
            "lấy mã token. Lưu ý để thuận tiện cho quá trình train và đưa model lên Huggingface Hub\n",
            "thì ta nên sử dụng token có quyền ghi của Huggingface.\n",
            "1from huggingface_hub import notebook_login\n",
            "2notebook_login()\n",
            "Cuối cùng ta sẽ import các thư viện chính được sử dụng trong phần này:\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1import os\n",
            "2import random\n",
            "3import json\n",
            "4import torch\n",
            "5import torch.nn as nn\n",
            "6from collections import namedtuple\n",
            "7from dataclasses import dataclass, field, asdict\n",
            "8from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
            "9from mamba_ssm.utils.hf import load_config_hf, load_state_dict_hf\n",
            "10\n",
            "11import evaluate\n",
            "12import numpy as np\n",
            "13from datasets import load_dataset\n",
            "14from transformers import Trainer\n",
            "15from transformers import AutoTokenizer, TrainingArguments\n",
            "(b)Download dataset:\n",
            "1# Tải bộ dataset\n",
            "2imdb = load_dataset(\"imdb\")\n",
            "(c)Build Custom Mamba Model: Xây dựng model Mamba để phân loại văn bản.\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Setup config:\n",
            "1# Config class của Mamba\n",
            "2class MambaConfig:\n",
            "3d_model: int = 2560\n",
            "4n_layer: int = 64\n",
            "5vocab_size: int = 50277\n",
            "6ssm_cfg: dict = field(default_factory=dict)\n",
            "7rms_norm: bool = True\n",
            "8residual_in_fp32: bool = True\n",
            "9fused_add_norm: bool = True\n",
            "10 pad_vocab_size_multiple: int = 8\n",
            "11\n",
            "12 def to_json_string(self):\n",
            "13 return json.dumps(asdict(self))\n",
            "14\n",
            "15 def to_dict(self):\n",
            "16 return asdict(self)\n",
            "•Định nghĩa class head (classifier) để phục vụ cho việc phân loại văn bản:\n",
            "1# Định nghĩa class head để phân loại\n",
            "2class MambaClassificationHead(nn.Module):\n",
            "3def __init__(self, d_model, num_classes, **kwargs):\n",
            "4 super(MambaClassificationHead, self).__init__()\n",
            "5 # Sử dụng một lớp tuyến tính để thực hiện phân loại dựa trên\n",
            "đầu vào có kích thước d_model và num_classes cần phân loại.\n",
            "6 self.classification_head = nn.Linear(d_model, num_classes,\n",
            "**kwargs)\n",
            "7\n",
            "8def forward(self, hidden_states):\n",
            "9 return self.classification_head(hidden_states)\n",
            "•Định nghĩa model Mamba:\n",
            "1class MambaTextClassification(MambaLMHeadModel):\n",
            "2def __init__(\n",
            "3 self,\n",
            "4 config: MambaConfig,\n",
            "5 initializer_cfg=None,\n",
            "6 device=None,\n",
            "7 dtype=None,\n",
            "8) -> None:\n",
            "9 super().__init__(config, initializer_cfg, device, dtype)\n",
            "10\n",
            "11 # Tạo một đầu phân loại sử dụng MambaClassificationHead với\n",
            "kích thước đầu vào là d_model và số lớp là 2.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "12 self.classification_head = MambaClassificationHead(d_model=\n",
            "config.d_model, num_classes=2)\n",
            "13\n",
            "14 del self.lm_head\n",
            "15\n",
            "16 def forward(self, input_ids, attention_mask=None, labels=None):\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "17 # Truyền input_ids qua model gốc để nhận hidden_states.\n",
            "18 hidden_states = self.backbone(input_ids)\n",
            "19\n",
            "20 # Lấy trung bình của hidden_states theo chiều thứ 2 để tạo\n",
            "ra [CLS] feature đại điện\n",
            "21 mean_hidden_states = hidden_states.mean(dim=1)\n",
            "22\n",
            "23 # Đưa mean_hidden_states qua đầu phân loại để nhận logits.\n",
            "24 logits = self.classification_head(mean_hidden_states)\n",
            "25\n",
            "26 if labels is None:\n",
            "27 ClassificationOutput = namedtuple(\"ClassificationOutput\",\n",
            "[\"logits\"])\n",
            "28 return ClassificationOutput(logits=logits)\n",
            "29 else:\n",
            "30 ClassificationOutput = namedtuple(\"ClassificationOutput\",\n",
            "[\"loss\", \"logits\"])\n",
            "31\n",
            "32 # Sử dụng hàm mất mát CrossEntropyLoss để tính loss.\n",
            "33 loss_fct = nn.CrossEntropyLoss()\n",
            "34 loss = loss_fct(logits, labels)\n",
            "35\n",
            "36 return ClassificationOutput(loss=loss, logits=logits)\n",
            "37\n",
            "38 def predict(self, text, tokenizer, id2label=None):\n",
            "39 input_ids = torch.tensor(tokenizer(text)[’input_ids’],\n",
            "device=’cuda’)[None]\n",
            "40 with torch.no_grad():\n",
            "41 logits = self.forward(input_ids).logits[0]\n",
            "42 label = np.argmax(logits.cpu().numpy())\n",
            "43\n",
            "44 if id2label is not None:\n",
            "45 return id2label[label]\n",
            "46 else:\n",
            "47 return label\n",
            "48\n",
            "49 @classmethod\n",
            "50 def from_pretrained(cls, pretrained_model_name, device=None,\n",
            "dtype=None, **kwargs):\n",
            "51 # Tải cấu hình từ model đã được train trước đó.\n",
            "52 config_data = load_config_hf(pretrained_model_name)\n",
            "53 config = MambaConfig(**config_data)\n",
            "54\n",
            "55 # Khởi tạo model từ cấu hình và chuyển nó đến thiết bị và ki\n",
            "ểu dữ liệu mong muốn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "56 model = cls(config, device=device, dtype=dtype, **kwargs)\n",
            "57\n",
            "58 # Tải trạng thái model đã được train trước đó.\n",
            "59 model_state_dict = load_state_dict_hf(pretrained_model_name,\n",
            "device=device, dtype=dtype)\n",
            "60 model.load_state_dict(model_state_dict, strict=False)\n",
            "61\n",
            "62 # In ra các tham số embedding mới được khởi tạo.\n",
            "63 print(\"Newly initialized embedding:\", set(model.state_dict()\n",
            ".keys()) - set(model_state_dict.keys()))\n",
            "64 return model\n",
            "•Cuối cùng ta sẽ tải trọng số và tokenizer của model Mamba đã được pretrain từ trước.\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Trọng số của model Mamba pretrain sẽ không bao gồm các tham số của phần head\n",
            "(classifier) MambaClassificationHead mà ta tự định nghĩa. Do đó, phần head này sẽ được\n",
            "khởi tạo tham số từ đầu:\n",
            "1# Tải model Mamba từ model đã được train trước đó.\n",
            "2model = MambaTextClassification.from_pretrained(\"state-spaces/mamba\n",
            "-130m\")\n",
            "3model.to(\"cuda\")\n",
            "4\n",
            "5# Tải tokenizer của model Mamba từ model gpt-neox-20b.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "6tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
            "7# Đặt id của token pad bằng id của token eos trong tokenizer.\n",
            "8tokenizer.pad_token_id = tokenizer.eos_token_id\n",
            "(d)Preprocess dataset: Trong phần này ta sẽ tiến hành tokenize dataset cho tập train và tập\n",
            "test. Vì số lượng sample của tập test khá lớn nên để thuận tiện cho quá trình train ta sẽ lấy\n",
            "ra 1 phần nhỏ của tập test để đánh giá model.\n",
            "1# Tạo chức năng tiền xử lý để mã hóa văn bản và cắt bớt các chuỗi không\n",
            "dài hơn độ dài đầu vào tối đa của mã thông báo\n",
            "2def preprocess_function(examples):\n",
            "3samples = tokenizer(examples[\"text\"], truncation=True)\n",
            "4# Không cần attention_mask\n",
            "5# Cụ thể hơn về token masking của mamba có thể tham khảo: https://\n",
            "github.com/state-spaces/mamba/issues/49\n",
            "6samples.pop(’attention_mask’)\n",
            "7return samples\n",
            "8\n",
            "9# Thực hiện mã hóa văn bản\n",
            "10tokenized_imdb = imdb.map(preprocess_function, batched=True)\n",
            "11\n",
            "12# Set seed cho hàm random\n",
            "13random.seed(42)\n",
            "14\n",
            "15# Tạo tập train và test\n",
            "16train_dataset = tokenized_imdb[\"train\"]\n",
            "17test_dataset = tokenized_imdb[\"test\"]\n",
            "18\n",
            "19# Tạo tập evaluation để đánh giá trong lúc train\n",
            "20# Do số lượng tập test lớn nên chỉ lấy mẫu 1% tập dữ liệu test để đánh\n",
            "giá\n",
            "21total_samples = len(test_dataset)\n",
            "22eval_samples = int(0.1 * total_samples)\n",
            "23eval_indices = random.sample(range(total_samples), eval_samples)\n",
            "24eval_dataset = test_dataset.select(eval_indices)\n",
            "(e)Evaluation metric: Để đánh giá performance của model ta sẽ sử dụng metric accuracy từ\n",
            "thư viện evaluate:\n",
            "1# Tải module \"accuracy\" từ thư viện evaluate.\n",
            "2accuracy = evaluate.load(\"accuracy\")\n",
            "3\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4# Định nghĩa hàm compute_metrics để tính các độ đo hiệu suất (metrics)\n",
            "cho việc đánh giá model.\n",
            "5def compute_metrics(eval_pred):\n",
            "6predictions, labels = eval_pred\n",
            "7\n",
            "8# Lấy chỉ số của lớp có xác suất cao nhất trong predictions.\n",
            "9predictions = np.argmax(predictions, axis=1)\n",
            "10\n",
            "11 # Sử dụng module \"accuracy\" để tính độ chính xác dựa trên\n",
            "predictions và labels.\n",
            "12 return accuracy.compute(predictions=predictions, references=labels)\n",
            "(f)Train model: Sau khi đã chuẩn bị xong dataset, ta sẽ tiến hành setup một số tham số trong\n",
            "quá trình train và tiến hành train model.\n",
            "•Trước hết, ta sẽ định nghĩa một số hyper-parameter mà ta sẽ sử dụng để train model:\n",
            "1# Định nghĩa tên project để log thông tin quá trình train trên wandb\n",
            "2# os.environ[\"WANDB_PROJECT\"] = \"mamba_tutorial\"\n",
            "3\n",
            "4# Định nghĩa các tham số train trong class TrainingArguments.\n",
            "5# Cụ thể hơn về các tham số hỗ trợ có thể tham khảo: https://\n",
            "huggingface.co/docs/transformers/main_classes/trainer\n",
            "6training_args = TrainingArguments(\n",
            "7output_dir=\"mamba_text_classification\", # Tên folder output\n",
            "8learning_rate=5e-5,\n",
            "9per_device_train_batch_size=4, # Số lượng train sample trên mỗi\n",
            "device\n",
            "10 per_device_eval_batch_size=16, # Số lượng eval sample trên mỗi\n",
            "device\n",
            "11 num_train_epochs=1, # Số epoch train\n",
            "12 warmup_ratio=0.01, # Tỉ lệ tăng dần lr trong giai đoạn warmup\n",
            "13 lr_scheduler_type=\"cosine\", # Loại scheduler để giảm lr\n",
            "14 report_to=\"none\", # \"wandb\" nếu muốn log kết quả\n",
            "15 evaluation_strategy=\"steps\", # Xác định metric đánh giá sau mỗi\n",
            "số bước\n",
            "16 eval_steps=0.1, # Số bước giữa các đợt đánh giá\n",
            "17 save_strategy=\"steps\", # Xác định khi nào lưu checkpoint\n",
            "18 save_steps=0.1, # Số bước giữa các lần lưu checkpoint\n",
            "19 logging_strategy=\"steps\", # Xác định khi nào in thông tin log\n",
            "20 logging_steps=1, # Số bước giữa các lần in thông tin log\n",
            "21 push_to_hub=True, # Đẩy kết quả lên Hub\n",
            "22 load_best_model_at_end=True, # Load model có kết quả evaluation\n",
            "tốt nhất trong quá trình train\n",
            "23)\n",
            "•Sau đó ta sẽ khởi tạo class MambaTrainer kế thừa từ class Trainer. Đầu tiên, ta sẽ tạo hàm\n",
            "compute_loss() để định nghĩa hàm loss sử dụng trong quá trình train. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Vì ta đã triển khai\n",
            "hàm loss là cross-entropy trong hàm forward của model, nên ta chỉ cần trích xuất giá trị\n",
            "mất mát từ kết quả trả về của hàm forward. Sau đó ta sẽ tiếp tục code hàm save_model()\n",
            "để định nghĩa cách lưu model. Để lưu model, ta cần ghi lại các tham số, tokenizer, và\n",
            "cấu hình (config) của model.\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1# Định nghĩa một class MambaTrainer kế thừa từ class Trainer.\n",
            "2class MambaTrainer(Trainer):\n",
            "3\n",
            "4# Định nghĩa hàm compute_loss để tính toán hàm mất mát trong quá\n",
            "trình train.\n",
            "5def compute_loss(self, model, inputs, return_outputs=False):\n",
            "6 # Lấy giá trị input_ids và labels từ inputs.\n",
            "7 input_ids = inputs.pop(\"input_ids\")\n",
            "8 labels = inputs.pop(’labels’)\n",
            "9\n",
            "10 # Gọi hàm forward của model với input_ids và labels để nhận\n",
            "các kết quả.\n",
            "11 outputs = model(input_ids=input_ids, labels=labels)\n",
            "12\n",
            "13 # Lấy giá trị loss từ kết quả của model.\n",
            "14 loss = outputs.loss\n",
            "15\n",
            "16 # Trả về cả loss và outputs nếu return_outputs là True, ngượ\n",
            "c lại chỉ trả về loss.\n",
            "17 return (loss, outputs) if return_outputs else loss\n",
            "18\n",
            "19 # Định nghĩa hàm save_model để lưu model trong quá trình train.\n",
            "20 def save_model(self, output_dir = None, _internal_call = False):\n",
            "21 # Kiểm tra nếu thư mục lưu trữ không được chỉ định, sử dụng\n",
            "thư mục mặc định từ đối số ’args’.\n",
            "22 if output_dir is None:\n",
            "23 output_dir = self.args.output_dir\n",
            "24\n",
            "25 # Nếu thư mục đầu ra không tồn tại, tạo mới nó.\n",
            "26 if not os.path.exists(output_dir):\n",
            "27 os.makedirs(output_dir)\n",
            "28\n",
            "29 # Lưu trạng thái của model PyTorch vào file ’pytorch_model.\n",
            "bin’ trong thư mục đầu ra.\n",
            "30 torch.save(self.model.state_dict(), f\"{output_dir}/\n",
            "pytorch_model.bin\")\n",
            "31\n",
            "32 # Lưu trạng thái của tokenizer vào thư mục đầu ra.\n",
            "33 self.tokenizer.save_pretrained(output_dir)\n",
            "34\n",
            "35 # Lưu cấu hình của model vào file ’config.json’ trong thư mụ\n",
            "c đầu ra.\n",
            "36 with open(f’{output_dir}/config.json’, ’w’) as f:\n",
            "37 json.dump(self.model.config.to_dict(), f)\n",
            "•Cuối cùng ta sẽ khởi tạo class MambaTrainer , đây là class chính để train model. Sau khi đã\n",
            "khởi tạo thì ta chỉ cần gọi trainer.train() thì quá trình train model sẽ được tiến hành:\n",
            "1# Khởi tạo classs MambaTrainer để thực hiện quá trình train của\n",
            "model.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2trainer = MambaTrainer(\n",
            "3model=model, # Model cần train\n",
            "4train_dataset=train_dataset, # Dữ liệu train\n",
            "5eval_dataset=eval_dataset, # Dữ liệu đánh giá\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "6tokenizer=tokenizer, # Tokenizer sử dụng để mã hóa dữ liệu\n",
            "7args=training_args, # Các tham số train đã được định nghĩa trước\n",
            "đó\n",
            "8compute_metrics=compute_metrics # Hàm tính các độ đo hiệu suất (\n",
            "metrics) cho đánh giá\n",
            "9)\n",
            "10# Bắt đầu quá trình train bằng cách gọi hàm train() trên classs\n",
            "trainer.\n",
            "11trainer.train()\n",
            "•Sau khi quá trình train hoàn tất, ta sẽ đưa weight, config của model lên HuggingFace\n",
            "Hub để lưu lại:\n",
            "1# Đẩy model lên huggingface hub\n",
            "2trainer.push_to_hub(commit_message=\"Training complete\")\n",
            "3\n",
            "4>> Output: CommitInfo(commit_url=’https://huggingface.co/\n",
            "trinhxuankhai/mamba_text_classification/commit/816827\n",
            "ae91a91dd9006a9ef66ecefd837382998b’, commit_message=’Training\n",
            "complete’, commit_description=’’, oid=’816827\n",
            "ae91a91dd9006a9ef66ecefd837382998b’, pr_url=None, pr_revision=\n",
            "None, pr_num=None)\n",
            "(g)Run Testing: Sau khi đã hoàn tất quá trình train, ta sẽ đánh giá model trên tập test và in\n",
            "ra kết quả đánh giá của model:\n",
            "1# Thực hiện dự đoán trên tập dữ liệu validation\n",
            "2outputs = trainer.predict(test_dataset)\n",
            "3print(outputs.metrics)\n",
            "4\n",
            "5>> Output: {’test_loss’: 0.21128389239311218, ’test_accuracy’: 0.94708,\n",
            "’test_runtime’: 1308.2019, ’test_samples_per_second’: 19.11, ’\n",
            "test_steps_per_second’: 1.195}\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(h)Load and inference model from Hub: Ở phần trước, sau khi ta đưa model lên Hugging-\n",
            "face Hub, nếu muốn inference model ta có thể gọi hàm from_pretrained của model Mambata\n",
            "đã định nghĩa ở trước để load pretrain model. Sau đó ta sẽ truyền văn bản cần phân loại,\n",
            "tokenize và id của từng class vô hàm predictcủa model để thực hiện dự đoán kết quả.\n",
            "1# Tải model Mamba từ model đã được train trước đó.\n",
            "2model = MambaTextClassification.from_pretrained(\"trinhxuankhai/\n",
            "mamba_text_classification\")\n",
            "3model.to(\"cuda\")\n",
            "4\n",
            "5# Tải tokenizer của model Mamba từ model đã được train trước đó.\n",
            "6tokenizer = AutoTokenizer.from_pretrained(\"trinhxuankhai/\n",
            "mamba_text_classification\")\n",
            "7# Đặt id của token pad bằng id của token eos trong tokenizer.\n",
            "8tokenizer.pad_token_id = tokenizer.eos_token_id\n",
            "Sau đây ta sẽ chạy thử một sample trên tập test:\n",
            "1id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
            "2text = imdb[’test’][0][’text’]\n",
            "3label = imdb[’test’][0][’label’]\n",
            "4response = model.predict(text, tokenizer, id2label)\n",
            "5print(f’Classify: {text}\\nGT: {id2label[label]}\\nPredict: {response}’)\n",
            "6\n",
            "7>> Output:\n",
            "8- Classify: I love sci-fi and am willing to put up with a lot. Sci-fi\n",
            "movies/TV are usually underfunded, under-appreciated and\n",
            "misunderstood. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "I tried to like this, I really did, but it is to good\n",
            "TV sci-fi as Babylon 5 is to Star Trek (the original).\n",
            "9- GT: NEGATIVE\n",
            "10- Predict: NEGATIVE\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. Trong state space model, dạng recurrent phù hợp cho quá trình inference vì?\n",
            "(a) Khả năng tính toán song song.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(b) Độ phức tạp O(n2).\n",
            "(c) Độ phức tạp O(n).\n",
            "(d) Khả năng xử lý long sequence.\n",
            "2. Trong state space model, dạng convolutional có tính chất nào sau đây?\n",
            "(a) Độ phức tạp O(n2).\n",
            "(b) Không thể tính toán song song.\n",
            "(c) Khả năng tính toán song song.\n",
            "(d) Khả năng attention.\n",
            "3. Trong structured state space model (S4), ma trận HiPPO được sử dụng để khởi tạo ma trận A vì:\n",
            "(a) Khả năng tính toán song song.\n",
            "(b) Tăng tham số để model học.\n",
            "(c) Giảm tham số để model học.\n",
            "(d) Tăng khả năng ghi nhớ sequence.\n",
            "4. Trong state space model, biểu thức Dx ttrong công thức yt=Ch t+Dx tđóng vai trò gì?\n",
            "(a) Activation function.\n",
            "(b) LayerNorm.\n",
            "(c) Skip-connection.\n",
            "(d) BatchNorm.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "5. Trong state space model, ta chỉ có thể sử dụng dạng recurrent để inference là nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "6. Trong state space model, dạng convolutional phù hợp để train vì độ phức tạp O(n)so với O(n2)\n",
            "của dạng recurrent là nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "7. Trong state space model, dạng convolutional phù hợp để train vì khả năng tính toán song song là\n",
            "nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "8. Trong state space model, dạng recurrent phù hợp để inference vì có khả năng tính toán song song\n",
            "là nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "9. Trong state space model, dạng recurrent phù hợp để inference vì độ phức tạp O(1)khi tạo ra từng\n",
            "token là nhận định:\n",
            "(a) True\n",
            "(b) False\n",
            "10. Đâu là contribution của Mamba?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(a) Khả năng tính toán song song ở dạng convolutional.\n",
            "(b) Khả năng tính toán song song ở dạng recurrent.\n",
            "(c) Khả năng tính toán song song ở 2 dạng convolutional và recurrent.\n",
            "(d) Khả năng tính toán song song khi inference.\n",
            "11. Đâu là contribution của Mamba?\n",
            "(a) Khả năng tạo ra trọng số phụ thuộc vào input\n",
            "(b) Khả năng tạo ra trọng số không dựa vào input.\n",
            "(c) Khả năng tạo ra trọng số phụ thuộc vào label.\n",
            "(d) Khả năng tạo ra trọng số không phụ thuộc vào label.\n",
            "- Hết -\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Foundation of Prompt Engineering\n",
            "Team GenAIO\n",
            "Hoang-Bach Ngo Minh-Hung An\n",
            "Ngày 6 tháng 3 năm 2024\n",
            "Phần I: Tổng quan về Prompt Engineering\n",
            "1 LLM Settings\n",
            "Khi tương tác với các mô hình ngôn ngữ lớn, bạn sẽ thường xuyên điều chỉnh một loạt các tham\n",
            "số và cài đặt. Việc tinh chỉnh những tham số này là bước không thể thiếu để làm cho các phản\n",
            "hồi trở nên đáng tin cậy và phù hợp hơn với yêu cầu của bạn, và điều này đôi khi đòi hỏi phải thử\n",
            "nghiệm để xác định được cách cấu hình tối ưu. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Dưới đây là một số tham số cơ bản bạn thường gặp\n",
            "trong quá trình sử dụng các mô hình LLM.\n",
            "Temperature - Như chúng ta có thể đã biết thì Large Language Model (LLM) hoạt động theo\n",
            "cơ chế phân loại từ tiếp theo, và như bao bài toán phân loại khác thì output đầu ra của LLM sẽ\n",
            "áp dụng thêm một hàm softmax để tạo ra phân phối xác suất từ tiếp theo sao cho tổng xác suất\n",
            "cộng lại bằng 1. Temperature thật ra là một tham số điều khiển độ “mượt mà” của hàm softmax\n",
            "đó bằng cách lấy logits output ra từ LLM chia cho tham số temperature.\n",
            "P(i) =exp(logit i/T)P\n",
            "jexp(logit j/T)(1)\n",
            "Công thức trên là công thức hàm softmax, trong đó tham số temperature được kĩ hiệu bằng\n",
            "chữT, vàlogit nkí hiệu output thứ nở lớp cuối của mô hình LLM. Để giúp bạn dễ hình dung,\n",
            "sau đây là một visualization nho nhỏ với hàm sigmoid - một hàm có những đặc điểm tương tự như\n",
            "softmax.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 1: Khi temperature được set bằng 1.0, tức là không có một sự thay đổi nào so với hàm softmax\n",
            "bình thường, lúc này sẽ là như apply một hàm softmax bình thường.\n",
            "Hình 2: Khi temperature được đặt thành giá trị lớn hơn 1.0, nó sẽ \"làm mượt\" lại phân bố xác\n",
            "suất, làm cho phân bố xác suất trở nên phẳng hơn. Điều này có nghĩa là các từ có xác suất thấp\n",
            "hơn sẽ có cơ hội được chọn cao hơn, dẫn đến output model có tính ngẫu nhiên cao hơn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 3: Ngược lại, khi temperature được đặt thành giá trị nhỏ hơn 1.0 (ví dụ: 0,5), nó sẽ \"làm sắc\n",
            "nét\" phân bố xác suất. Điều này làm cho mô hình có nhiều khả năng chọn các từ có xác suất cao\n",
            "hơn, dẫn đến kết quả đầu ra tập trung và mang tính xác định hơn. Khi temperature bằng 0 (hình\n",
            "4), phân bố xác suất sẽ được đẩy từ có logits cao nhất bằng 1 và tất cả các từ còn lại bằng 0, dẫn\n",
            "đến output của model sẽ luôn là từ có xác suất cao nhất.\n",
            "top_p- Tham số này được áp dụng trong kỹ thuật sampling gọi là nucleus sampling , giúp\n",
            "điều chỉnh độ đa dạng trong kết quả mà mô hình sinh ra. Theo phương pháp này, chúng ta sẽ chọn\n",
            "ra nhóm các từ có xác suất cao nhất, đảm bảo rằng tổng xác suất của nhóm này vượt qua một\n",
            "ngưỡng nhất định, ngưỡng này là top_p. Cách làm này giúp mở rộng khả năng chọn từ của mô\n",
            "hình, tạo ra kết quả phong phú hơn. Nếu chúng ta cần câu trả lời chính xác, dựa trên dữ liệu cụ\n",
            "thể, giá trị top_p nên được giữ ở mức thấp. Trong trường hợp muốn nhận được đầu ra đa dạng\n",
            "hơn, có thể tăng giá trị này. Tuy nhiên, lưu ý chỉ điều chỉnh hoặc tham số temperature hoặc top_p,\n",
            "không nên cùng lúc thay đổi cả hai để tránh gây rối loạn cho mô hình.\n",
            "Max Length - Chúng ta có thể dễ dàng điều chỉnh số lượng từ tối đa mà mô hình sinh ra bằng\n",
            "cách thiết lập giới hạn Max Length. Việc này giúp hạn chế những kết quả quá dài hoặc không mấy\n",
            "liên quan, đồng thời cũng giúp chúng ta kiểm soát được chi phí tốt hơn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Stop Sequences - Đây là cách thiết lập một chuỗi dừng giúp ngăn mô hình sinh thêm từ. Khi\n",
            "mô hình nhận diện một từ trong chuỗi dừng này, nó sẽ ngừng việc tạo thêm nội dung. Xác định\n",
            "stop sequences là một phương pháp hữu ích để kiểm soát chiều dài và bố cục của đầu ra mô hình.\n",
            "Chẳng hạn, nếu muốn mô hình chỉ tạo ra danh sách tối đa 10 mục, ta có thể đặt từ \"11.\" vào trong\n",
            "danh sách stop sequences.\n",
            "Frequency Penalty - Tham số này giúp chúng ta có thể áp dụng một hình phạt lên từ tiếp\n",
            "theo dựa trên số lần từ đó xuất hiện trong kết quả và prompt. frequency penalty càng cao, từ đó\n",
            "càng ít có cơ hội xuất hiện lại. Cơ chế này giúp giảm thiểu việc lặp lại các từ trong kết quả mà mô\n",
            "hình tạo ra, bằng cách áp đặt mức phạt lớn hơn cho những từ thường xuyên xuất hiện.\n",
            "Presence Penalty - Tham số này giúp ta có thể áp dụng hình phạt cho các từ lặp lại, nhưng\n",
            "khác với frequency penalty, mức phạt này được áp dụng như nhau cho mọi từ lặp lại, không phân\n",
            "biệt một từ xuất hiện hai lần hay mười lần, chúng đều nhận mức phạt giống nhau. Cách làm này\n",
            "giúp hạn chế việc mô hình lặp đi lặp lại một cụm từ nhiều lần trong kết quả của mình. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Để tạo ra\n",
            "nội dung đa dạng và sáng tạo hơn, chúng ta có thể tăng mức độ phạt này lên. Ngược lại, nếu muốn\n",
            "mô hình tập trung hơn vào một số ý tưởng nhất định, chúng ta có thể giảm mức phạt xuống.\n",
            "Để tổng kết lại, sau đây là một số đề xuất của nhóm khi khởi tạo các tham số này:\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Temperature : Ban đầu khi nhìn vào tham số này, chúng ta sẽ dễ bị lầm tưởng đây là tham\n",
            "số chạy từ 0 đến 1. Thực tế thì như giải thích ở trên thì ta có thể thấy là temperature không\n",
            "hề là một biến chạy từ 0 đến 1. Vậy ta nên chọn tham số này như thế nào để tối ưu nhất?\n",
            "– Chọn temperature = 0.0 nếu chúng ta muốn kết quả model không có tính ngẫu nhiên\n",
            "và luôn giống nhau với những input giống nhau. Lúc nào mô hình LLM luôn chọn từ có\n",
            "xác suất cao nhất.\n",
            "– Chọn temperature = 0.7, 0.8 nếu chúng ta muốn kết quả model “sắc nét” hơn nhưng\n",
            "vẫn có tính random, đây cũng là khoảng các “cao nhân” trên mạng hay truyền tai nhau\n",
            "để model ra kết quả tốt và vẫn có tính sáng tạo.\n",
            "– Chọn temperature > 1 nếu chúng ta muốn model có tính sáng tạo cao, tuy nhiên\n",
            "điều này cũng đem lại rủi ro là kết quả model có thể không quá tốt, và nếu set quá cao\n",
            "thì kết quả từ model sẽ là ngẫu nhiên hoàn toàn.\n",
            "•Top P\n",
            "– Tìm câu trả lời chính xác : Giữ giá trị Top P thấp (0.1 - 0.5).\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "– Tìm câu trả lời sáng tạo : Tăng giá trị Top P (0.6 - 0.9).\n",
            "•Max Length\n",
            "– Điều chỉnh tùy theo nhu cầu của task : đối với phản hồi ngắn, giới hạn số lượng\n",
            "token (ví dụ: 100-200 tokens); đối với bài viết dài hơn, tăng số lượng token tối đa.\n",
            "•Stop Sequences\n",
            "– Đặt các chuỗi cụ thể để kết thúc kết quả trả về : nếu bạn muốn mô hình chỉ tạo\n",
            "ra một danh sách với 10 item, bạn có thể thêm \"11\" làm Stop Sequences.\n",
            "•Frequency Penalty\n",
            "– Để giảm sự lặp lại của từ : Sử dụng giá trị trung bình đến cao (0.5 - 1.0).\n",
            "– Nếu không quan tâm đến sự lặp lại : Giữ giá trị thấp (0.0 - 0.4).\n",
            "•Presence Penalty\n",
            "– Để tạo kết quả đa dạng : Sử dụng giá trị cao (0.6 - 1.0).\n",
            "– Để duy trì độ chính xác của mô hình :Sử dụng giá trị thấp (0.0 - 0.4).\n",
            "2 Prompt Engineering\n",
            "Chất lượng của các câu trả lời được tạo ra bởi LLM đã qua huấn luyện và điều chỉnh phụ thuộc trực\n",
            "tiếp vào chất lượng của prompts, hay cấu trúc của prompt (instructions prompt) do người dùng\n",
            "cung cấp. Vì vậy, việc thiết kế prompts mà LLM có thể hiểu và trả lời một cách hiệu quả là rất\n",
            "quan trọng. Prompts đóng vai trò như một phương tiện để lập trình cuộc tương tác giữa người dùng\n",
            "và LLM, giúp nâng cao khả năng xử lý đa dạng các nhiệm vụ. Điều này đòi hỏi phải hiểu biết sâu\n",
            "rộng về cách hoạt động và hành vi của LLMs, cơ chế đằng sau chúng và các nguyên tắc điều khiển\n",
            "phản ứng của chúng. Dựa vào bài báo:\"Principled Instructions Are All You Need for Questioning\n",
            "LLaMA-1/2, GPT-3.5/4\" Bsharat et al., 2024, nhóm sẽ trích dẫn lại một số instructions prompt\n",
            "hữu ích giúp tăng chất lượng trả lời của LLM.\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Principle Prompt Principle for Instructions\n",
            "1Nếu bạn muốn một câu trả lời ngắn gọn, không cần phải lịch sự với mô hình\n",
            "LLM, không cần thêm những cụm từ như \"please\", \"if you don’t mind\", \"thank\n",
            "you\", \"I would like to\", v.v. Ta nên đi thẳng vào vấn đề\n",
            "2Nên đề cập đến đối tượng của câu trả lời ở trong prompt, ví dụ: những người\n",
            "đọc này là chuyên gia trong lĩnh vực của họ\n",
            "3Chia nhỏ các tác vụ phức tạp thành một chuỗi prompt đơn giản hơn trong cuộc\n",
            "trò chuyện tương tác với mô hình.\n",
            "4Sử dụng các chỉ thị khẳng định như “do”, đồng thời tránh dùng ngôn ngữ phủ\n",
            "định như “don’t”.\n",
            "5Khi bạn cần xác nhận hoặc hiểu biết sâu sắc hơn về một chủ đề, ý tưởng hoặc\n",
            "bất kỳ thông tin nào, hãy sử dụng những prompt sau:\n",
            "•Explain [insert specific topic] in simple terms.\n",
            "•Explain to me like I’m 11 years old.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Explain to me as if I’m a beginner in [field].\n",
            "•Write the [essay/text/paragraph] using simple English like you’re explain-\n",
            "ing something to a 5-year-old.\n",
            "6Thêm “I’m going to tip $xxx“ (tôi sẽ bo cho bạn $xxx) để kết quả cho ra tốt\n",
            "hơn\n",
            "7Triển khai prompt dựa trên ví dụ (Dùng few-shot prompting).\n",
            "8Khi soạn prompt của bạn, bắt đầu với “###Instruction###”, theo sau đó\n",
            "bằng “###Example###” hoặc “###Question###” nếu cần thiết. Sau đó,\n",
            "trình bày ngữ cảnh của bạn. Sử dụng một hoặc nhiều dấu ngắt dòng để phân\n",
            "tách các hướng dẫn, ví dụ, câu hỏi, ngữ cảnh và dữ liệu đầu vào.\n",
            "9Kết hợp các cụm từ sau: “Your task is” và “You MUST”.\n",
            "10 Kết hợp các cụm từ sau: “You will be penalized”. (bạn sẽ bị phạt nếu)\n",
            "11Sử dụng những cụm như “Answer a question given in a natural, human-like\n",
            "manner” (trả lời câu hỏi theo các tự nhiên, giống con người) trong prompt của\n",
            "bạn.\n",
            "12Sử dụng những từ dẫn đầu như viết “think step by step” (Hãy suy nghĩ theo\n",
            "từng bước).\n",
            "13Thêm vào prompt của bạn cụm sau “Ensure that your answer is unbiased and\n",
            "avoids relying on stereotypes.” (Đảm bảo rằng câu trả lời của bạn không thiên\n",
            "vị và tránh dựa vào khuôn mẫu.)\n",
            "14Cho phép mô hình gợi ra các chi tiết và yêu cầu chính xác từ bạn bằng cách\n",
            "đặt câu hỏi cho bạn cho đến khi mô hình có đủ thông tin để cung cấp kết quả\n",
            "đầu ra cần thiết (ví dụ: “From now on, I would like you to ask me questions to\n",
            "...” (từ bây giờ tôi muốn bạn hỏi câu hỏi cho đến khi ...)).\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "15Để hỏi về một chủ đề hoặc ý tưởng cụ thể hoặc bất kỳ thông tin nào và bạn\n",
            "muốn kiểm tra sự hiểu biết của mình, bạn có thể sử dụng cụm sau: “Teach\n",
            "me any [theorem/topic/rule name] and include a test at the end, and let me\n",
            "know if my answers are correct after I respond, without providing the answers\n",
            "beforehand.” (Hãy dạy tôi bất kỳ [định lý/chủ đề/tên quy tắc] nào và kèm theo\n",
            "một bài kiểm tra ở cuối, đồng thời cho tôi biết liệu câu trả lời của tôi có đúng\n",
            "sau khi tôi trả lời mà không cần cung cấp câu trả lời trước hay không.)\n",
            "16 Gán vai trò cho các mô hình ngôn ngữ lớn.\n",
            "17 Sử dụng các dấu phân cách.\n",
            "18 Lặp lại một từ hoặc cụm từ cụ thể nhiều lần trong prompt.\n",
            "19 Kết hợp Chain-of-thought với few-Shot prompts.\n",
            "20Sử dụng đoạn mở đầu đầu ra, bao gồm việc kết thúc lời nhắc của bạn với phần\n",
            "đầu của đầu ra mong muốn. Sử dụng đoạn mồi đầu ra bằng cách kết thúc\n",
            "prompt của bạn bằng phần bắt đầu phản hồi bạn muốn nhận được\n",
            "21Để viết một bài luận/văn bản/đoạn/bài viết hoặc bất kỳ loại văn bản nào cần\n",
            "chi tiết: “Write a detailed [essay/text/paragraph] for me on [topic] in detail by\n",
            "adding all the information necessary\" (Viết một [bài luận/văn bản/đoạn văn]\n",
            "chi tiết cho tôi về [chủ đề] một cách chi tiết bằng cách thêm tất cả thông tin\n",
            "cần thiết).\n",
            "22Để sửa/thay đổi văn bản cụ thể mà không thay đổi văn phong: “Try to revise\n",
            "every paragraphsentby users. You should onlyimprovethe user’sgrammar and\n",
            "vocabulary and make sure it sounds natural. You should maintain the original\n",
            "writing style, ensuring that a formal paragraph remains formal.” (Cố gắng sửa\n",
            "lại mọi đoạn văn do người dùng gửi. Bạn chỉ nên cải thiện ngữ pháp và từ vựng\n",
            "của người dùng và đảm bảo rằng nó nghe tự nhiên. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bạn nên giữ nguyên phong\n",
            "cách viết ban đầu, đảm bảo rằng đoạn văn trang trọng vẫn giữ được hình thức\n",
            "trang trọng.)\n",
            "23Khi bạn có một prompt về lập trình phức tạp và có thể nằm trong các tệp khác\n",
            "nhau: “From now and on whenever you generate code that spans more than one\n",
            "file, generate a [programming language ] script that can be run to automatically\n",
            "create the specified files or make changes to existing files to insert the generated\n",
            "code. [your question]”.\n",
            "24Khi bạn muốn bắt đầu hoặc tiếp tục một văn bản bằng các từ, cụm từ hoặc\n",
            "câu cụ thể, hãy sử dụng những prompt sau:\n",
            "•I’m providing you with the beginning [song lyrics/story/paragraph/es-\n",
            "say...]: [Insert lyrics/words/sentence].\n",
            "Finish it based on the words provided. Keep the flow consistent.\n",
            "25Nêu rõ các yêu cầu mà mô hình phải tuân theo để tạo sinh nội dung, dưới dạng\n",
            "từ khóa, quy định, gợi ý hoặc hướng dẫn\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "26Để viết bất kỳ văn bản nào, chẳng hạn như một bài luận hoặc đoạn văn, và bạn\n",
            "muốn văn phong tương tự như mẫu được cung cấp, hãy bao gồm các prompt\n",
            "sau:\n",
            "•Use the same language based on the provided paragraph[/title/text /es-\n",
            "say/answer].\n",
            "Phần II: Prompt Techniques\n",
            "3 Zero-Shot Prompting\n",
            "Zero-Shot Prompting là một phương pháp nhằm cải thiện zero-shot learning trong LLMs. Học\n",
            "zero-shot giúp mô hình có khả năng nắm bắt và thực hiện những nhiệm vụ mà nó chưa từng được\n",
            "huấn luyện một cách cụ thể. Phương pháp này bao gồm việc tinh chỉnh các mô hình ngôn ngữ đã\n",
            "được huấn luyện trước trên một loạt các nhiệm vụ NLP được mô tả trong prompt bằng ngôn ngữ\n",
            "tự nhiên. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cách tiếp cận này đã được chứng minh là cải thiện đáng kể khả năng của mô hình trong\n",
            "việc thực hiện các nhiệm vụ chưa được nhìn thấy (unseen tasks). Hiệu quả của việc tinh chỉnh\n",
            "prompt được thể hiện qua sự cải thiện hiệu suất đáng kể so với các mô hình ngôn ngữ, lợi ích càng\n",
            "trở nên rõ rệt khi số lượng nhiệm vụ tăng lên và khi được áp dụng với LLM. Trong nghiên cứu\n",
            "\"Finetuned Language Models Are Zero-shot learners\" Wei et al., n.d. kết luận rằng việc tinh chỉnh\n",
            "prompt là một kỹ thuật triển vọng để cải thiện khả năng tổng quát hóa và hiệu suất của LLMs\n",
            "trong các tình huống zero-shot learning.\n",
            "Hình 4: Ví dụ minh họa về áp dụng zero-shot prompting trong việc phân tích, đánh giá thái độ\n",
            "nhân viên chăm sóc khách hàng qua email.\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4 Few-Shot Prompting\n",
            "Khi zero-shot learning không mang lại kết quả như mong đợi, việc đưa ra các mẫu ví dụ cụ thể\n",
            "trong prompt sẽ là phương pháp khuyến khích được lựa chọn tiếp theo, từ đó tiến tới kỹ thuật gợi\n",
            "ý với một số lượng nhỏ ví dụ. Đây cũng chính là cơ sở cho kỹ thuật Few-Shot Prompting.\n",
            "Trong paper \"Language Models are Few-Shot Learners\" Brown et al., 2020 - Few-shot learning\n",
            "được giới thiệu như một cách để mô hình hóa các mô hình ngôn ngữ có thể thích nghi và thực hiện\n",
            "các nhiệm vụ dựa trên một số ít ví dụ cụ thể được cung cấp trong quá trình suy luận, mà không\n",
            "cần cập nhật trọng số mô hình hay tinh chỉnh cụ thể cho nhiệm vụ đó. Điều này cho phép mô hình\n",
            "hoạt động gần giống với cách con người học: chúng ta thường có thể học và thực hiện tác vụ mới\n",
            "với chỉ vài hướng dẫn cụ thể. Kết quả từ paper cho thấy mô hình GPT-3 có khả năng thực hiện\n",
            "khá tốt trên nhiều tập dữ liệu với few-shot, thỉnh thoảng ngang bằng hoặc thậm chí vượt qua hiệu\n",
            "suất của các mô hình được tinh chỉnh cụ thể (fine-tuning). Điều này cho thấy tiềm năng lớn của\n",
            "việc sử dụng few-shot learning để cải thiện khả năng tổng quát hóa và thích ứng nhanh của các\n",
            "mô hình ngôn ngữ lớn với các nhiệm vụ mới mà chúng không được tinh chỉnh trực tiếp.\n",
            "Hình 5: Few shot giúp chúng ta phân loại nhanh một số vấn đề trong bài đánh giá bình luận của\n",
            "người dùng\n",
            "Với Few-Shot Prompting chúng ta có thể một ví dụ duy nhất (nghĩa là học 1-shot) đối với một\n",
            "số tác vụ dễ. Đối với một số tác vụ khó khăn hơn, chúng ta có thể thử nghiệm bằng cách tăng số\n",
            "lượng mẫu lên (3-shot, 5-shot, 10-shot,...). Dựa vào paper \"Rethinking the Role of Demonstrations:\n",
            "What Makes In-Context Learning Work?\" chúng ta có một số tricks để giúp few-shot prompting\n",
            "hiệu quả hơn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Không chỉ việc lựa chọn nhãn một cách chính xác mới quan trọng, mà cả không gian nhãn\n",
            "và cách phân phối văn bản đầu vào từ những ví dụ cũng đóng một vai trò quan trọng.\n",
            "•Cách thức chúng ta trình bày dữ liệu cũng có ảnh hưởng đáng kể đến kết quả, thậm chí việc\n",
            "sử dụng nhãn một cách ngẫu nhiên cũng tốt hơn là không sử dụng nhãn.\n",
            "•Ngoài ra, việc lựa chọn nhãn một cách ngẫu nhiên nhưng phản ánh đúng phân phối thực tế\n",
            "của nhãn (không theo phân phối đều) cũng đem lại lợi ích rõ rệt.\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "5 Chain-of-Thought Prompting\n",
            "Phương pháp \"Chain of Thought\" (COT) được giới thiệu này như một cách để cải thiện hiệu suất\n",
            "của các mô hình ngôn ngữ lớn (LLMs) trong việc giải quyết các bài toán đòi hỏi suy luận phức tạp.\n",
            "Phương pháp này dựa trên việc kích thích mô hình tạo ra một chuỗi các bước suy nghĩ trung gian\n",
            "tự nhiên, giúp dẫn đến kết quả cuối cùng. Điều này cho phép mô hình phân rã các vấn đề thành\n",
            "các bước nhỏ hơn, làm cho quá trình suy luận trở nên minh bạch và dễ hiểu hơn. Từ kết quả thực\n",
            "nghiệm trong paper \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\"\n",
            "Wei et al., 2022 cho thấy rằng việc sử dụng COT cải thiện đáng kể hiệu suất của mô hình trên các\n",
            "tác vụ toán học, suy luận thông thường và suy luận biểu tượng. Phương pháp này mở ra hướng\n",
            "mới trong việc tối ưu hóa các mô hình ngôn ngữ lớn, giúp chúng có khả năng giải quyết các tác vụ\n",
            "phức tạp hơn mà không cần tinh chỉnh cụ thể cho từng tác vụ.\n",
            "Hình 6: COT giúp các mô hình ngôn ngữ lớn giải quyết các nhiệm vụ suy luận số học phức tạp,\n",
            "suy luận thông thường và suy luận biểu tượng.\n",
            "6 Zero-shot Chain-of-Thought Prompting\n",
            "Zero-shot Chain of Thought (Zero-shot COT) là một cách tiếp cận giúp cải thiện khả năng suy\n",
            "luận của các mô hình ngôn ngữ lớn (LLMs) mà không cần hướng dẫn cụ thể từ một số ví dụ mẫu\n",
            "từ dữ liệu(few-shot). Phương pháp này cho phép mô hình tạo ra chuỗi suy nghĩ một cách tự nhiên\n",
            "và logic để giải quyết các bài toán, mà không cần dựa trên các ví dụ cụ thể đã được cung cấp\n",
            "trước đó. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Zero-shot COT thể hiện sự linh hoạt và khả năng áp dụng rộng rãi trong các tác vụ suy\n",
            "luận khác nhau, từ toán học đến suy luận thông thường, mở ra hướng mới trong việc khám phá và\n",
            "tận dụng tiềm năng sẵn có của các LLMs. Trong bài báo \"Large Language Models are Zero-Shot\n",
            "Reasoners\" Kojima et al., 2022 chỉ ra rằng chúng ta chỉ cần đơn giản thêm cụm \"Let’s think step\n",
            "by step\" vào prompt gốc sẽ giúp model đưa ra kết quả tốt hơn.\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "7 Automatic Chain-of-Thought Prompting\n",
            "Auto-CoT: Automatic Chain-of-Thought Prompting (Auto-COT) được đề xuất trong paper \"Au-\n",
            "tomatic Chain of Thought Prompting in Large Language Models\" Zhang et al., 2023a là một cách\n",
            "tiếp cận để tự động tạo ra các chuỗi suy nghĩ trong các mô hình ngôn ngữ lớn (LLMs). Auto-CoT\n",
            "tận dụng khả năng của LLMs để tự sinh ra các chuỗi suy nghĩ, từ đó xây dựng các ví dụ minh họa.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Phương pháp này giảm bớt sự cần thiết của việc tạo ví dụ minh họa thủ công, mở ra khả năng áp\n",
            "dụng rộng rãi trong việc giải quyết các bài toán suy luận phức tạp mà không cần tới sự can thiệp\n",
            "thủ công từ người dùng. Auto-CoT hứa hẹn sẽ cải thiện hiệu suất và khả năng tự học của LLMs,\n",
            "đặc biệt trong các tác vụ đòi hỏi suy luận nhiều bước.\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "8 Self-Consistency\n",
            "Self-Consistencyđượcđềxuấttrongpaper\"Self-ConsistencyImprovesChainofThoughtReasoning\n",
            "in Language Models\" Wang et al., 2022 giúp cải thiện khả năng suy luận của LLMs bằng cách sử\n",
            "dụng COT. Nó hoạt động bằng cách tạo ra nhiều hướng suy nghĩ đa dạng và sau đó chọn câu trả\n",
            "lời phổ biến nhất từ những hướng suy nghĩ đó. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Điều này giúp tăng cường khả năng suy luận chính\n",
            "xác của mô hình, đồng thời cung cấp cái nhìn sâu sắc và dễ hiểu về quá trình suy nghĩ của mô\n",
            "hình, giúp người dùng có thể kiểm tra và hiểu rõ cách mô hình đưa ra kết quả.\n",
            "Trong paper nhóm tác giả đề xuất thay thế cho chiến lược giải mã tham lam (greedy decoding)\n",
            "thường được sử dụng trong COT. Chiến lược này khắc phục một số nhược điểm của COT như:\n",
            "•Đa dạng hóa hướng suy nghĩ : Self-Consistency sinh ra một tập hợp đa dạng các hướng\n",
            "suy nghĩ, thay vì chỉ chọn một suy nghĩ duy nhất. Điều này dựa trên quan điểm rằng một\n",
            "bài toán suy luận phức tạp thường có nhiều cách suy nghĩ khác nhau dẫn đến một câu trả\n",
            "lời đúng duy nhất.\n",
            "•Cải thiện hiệu suất suy luận : Self-Consistency đã được chứng minh là cải thiện hiệu suất\n",
            "của COT một cách đáng kể trên các bài toán suy luận thông thường và toán học.\n",
            "•Khắc phục hạn chế của COT : Nghiên cứu cho thấy rằng COT có thể làm giảm hiệu suất\n",
            "so với gợi ý thông thường trong một số trường hợp. Self-Consistency giúp khắc phục điểm\n",
            "yếu này, đặc biệt trong các tác vụ few-shot learning.\n",
            "•Ứng dụng rộng rãi : Self-Consistency được ứng dụng trong nhiều tác vụ NLP, như trả lời\n",
            "câu hỏi không dựa trên nguồn thông tin (Closed-Book Question Answering) và suy luận ngôn\n",
            "ngữ tự nhiên (Natural Language Inference)\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 7: Self-Consistency gồm 3 bước: (1) Kỹ thuật prompt sử dụng COT, (2) Thay thế “greedy\n",
            "decode” trong COT bằng cách lấy mẫu từ language model’s decoder để tạo ra một tập hợp đa dạng\n",
            "các đường suy luận, (3) loại bỏ các đường suy luận và tổng hợp bằng cách chọn câu trả lời nhất\n",
            "quán nhất trong câu trả lời cuối cùng.\n",
            "9 Generated Knowledge Prompting\n",
            "Trong paper \"Generated Knowledge Prompting for Commonsense Reasoning\" Liu et al., 2021,\n",
            "Generated Knowledge Prompting được giới thiệu là một cách tiếp cận mới để cải thiện hiệu suất\n",
            "của các mô hình ngôn ngữ lớn trong các tác vụ suy luận thông thường. Phương pháp này bao gồm\n",
            "hai bước chính: sinh ra các phát biểu kiến thức liên quan đến câu hỏi từ một mô hình ngôn ngữ,\n",
            "sau đó sử dụng kiến thức này như một phần của đầu vào khi trả lời câu hỏi. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Điều này giúp tăng\n",
            "cường khả năng suy luận của mô hình mà không cần truy cập vào một cơ sở kiến thức có cấu trúc\n",
            "hay tinh chỉnh cụ thể cho việc tích hợp kiến thức. Phương pháp này được chứng minh là hiệu quả\n",
            "thông qua việc cải thiện hiệu suất trên nhiều bài toán suy luận thông thường và đạt kết quả hàng\n",
            "đầu trên một số tác vụ.\n",
            "Sau đây là chi tiết 2 bước của Generated Knowledge Prompting để trả lời các câu hỏi thông\n",
            "thường:\n",
            "•Bước Tạo Kiến Thức (Knowledge Generation) : Sử dụng mô hình ngôn ngữ để sinh ra\n",
            "các phát biểu kiến thức dựa trên câu hỏi Kq={km:km∼pG(k|q), m= 1. . . M},với mỗi\n",
            "phát biểu kiến thức kmlà một chuỗi văn bản có độ dài biến đổi. Bản chất, mỗi phát biểu\n",
            "chứa thông tin hữu ích cho việc trả lời câu hỏi. Khi tạo kiến thức cho một câu hỏi mới, câu\n",
            "hỏi được chèn vào vị trí dành cho câu hỏi mới và lấy mẫu liên tục các tiếp nối của prompt\n",
            "này để thu được một tập hợp các phát biểu kiến thức K|q.\n",
            "•Bước Tích Hợp Kiến Thức (Knowledge Integration) : Trong bước này, kiến thức sinh\n",
            "ra được tích hợp vào quá trình đưa ra quyết định của mô hình ngôn ngữ sử dụng cho suy\n",
            "luận ˆa= arg max a∈Aqmax 0≤m≤MpI(a|qm),Điều này được thực hiện bằng cách sử dụng\n",
            "từng phát biểu kiến thức để gợi ý cho mô hình, tạo ra M câu hỏi được bổ sung kiến thức:\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "q0=q, q1= [k1||q], . . . , q M= [kM||q],với [·||·] biểu thị sự kết hợp văn bản. Điểm tổng hợp\n",
            "cho mỗi lựa chọn trả lời được tính dựa trên câu hỏi bổ sung hỗ trợ tốt nhất lựa chọn đó dưới\n",
            "mô hình suy luận. Câu trả lời dự đoán cuối cùng là lựa chọn được hỗ trợ nhiều nhất từ một\n",
            "trong các phát biểu kiến thức. Mô hình suy luận có thể là một mô hình ngôn ngữ hiện có\n",
            "hoặc được tinh chỉnh cụ thể cho tác vụ. Không cần tinh chỉnh thêm với kỹ thuật gợi ý kiến\n",
            "thức.\n",
            "Hình 8: Generated Knowledge Prompting bao gồm 2 bước: (1) sử dụng few-shot để tạo ra các phát\n",
            "biểu liên quan đến câu hỏi từ một mô hình ngôn ngữ, (2) sử dụng một mô hình ngôn ngữ khác để\n",
            "đưa ra dự đoán với mỗi phát biểu, sau đó chọn dự đoán có độ tin cậy cao nhất.\n",
            "10 Tree of Thoughts\n",
            "Tree of Thoughts (TOT) là phương pháp mở rộng cách tiếp cận COT bằng cách cho phép khám\n",
            "phá trên các đơn vị văn bản nhất quán (\"thoughts\") mà phục vụ như những bước trung gian hướng\n",
            "tới giải quyết vấn đề. Nó cho phép mô hình ngôn ngữ thực hiện quá trình ra quyết định một cách\n",
            "cẩn trọng, bằng cách xem xét nhiều hướng suy nghĩ khác nhau và tự đánh giá các lựa chọn để quyết\n",
            "định hành động tiếp theo, cũng như nhìn về phía trước hoặc lùi lại (forward and backward) khi\n",
            "cần thiết để đưa ra các quyết định. Trong paper \"Tree of Thoughts: Deliberate Problem Solving\n",
            "with Large Language Models\" Yao et al., 2023a, TOT đã được chứng minh là cải thiện đáng kể\n",
            "khả năng giải quyết vấn đề của các mô hình ngôn ngữ trên ba nhiệm vụ mới đòi hỏi kế hoạch hoặc\n",
            "tìm kiếm không đơn giản: Game of 24, Creative Writing, and Mini Crosswords.\n",
            "ToT giải quyết vấn đề bằng cách trả lời bốn câu hỏi:\n",
            "•Làm thế nào để phân rã quá trình trung gian thành các bước suy nghĩ?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Làm thế nào để sinh ra các suy nghĩ tiềm năng từ mỗi trạng thái?\n",
            "•Làm thế nào để đánh giá các trạng thái một cách có hệ thống?\n",
            "•Sử dụng thuật toán tìm kiếm nào?\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Thought decomposition : khi các mẫu COT có thể tạo ra suy nghĩ mà không cần phân rã\n",
            "rõ ràng, TOT tận dụng đặc tính của vấn đề để thiết kế và phân rã các bước suy nghĩ trung gian.\n",
            "Tùy thuộc vào từng vấn đề cụ thể, một suy nghĩ có thể là một vài từ, một dòng của phương trình,\n",
            "hoặc một đoạn văn mô tả. Điều quan trọng là suy nghĩ phải đủ nhỏ để có thể quản lý được, nhưng\n",
            "cũng phải đủ \"lớn\" để có thể đánh giá tiến trình giải quyết vấn đề một cách có ý nghĩa.\n",
            "Thought generator : với mục đích tạo ra các suy nghĩ mới, khi có một trạng thái cây s=\n",
            "[x, z 1...zi]có hai cách để sinh ra k ứng viên cho bước suy nghĩ tiếp theo:\n",
            "•Sample: Đầu tiên chúng ta lấy mẫu độc lập và phân phối đồng đều theo COT prompt. Đây\n",
            "là việc chọn ra các suy nghĩ tiếp theo mà không phụ thuộc lẫn nhau và mỗi suy nghĩ đều có\n",
            "cùng khả năng xuất hiện. Đề xuất theo COT prompt là một dạng câu hỏi hoặc mệnh đề mà\n",
            "từ đó, mô hình có thể phát sinh ra các suy nghĩ tiếp theo. Một CoT prompt có thể là một\n",
            "nhiệm vụ mở ra cho mô hình, như yêu cầu mô tả một cảnh hoặc tạo ra một câu chuyện dựa\n",
            "trên các thông tin đã cho. Kết quả bước này là k suy nghĩ tiếp theo mà không cần các suy\n",
            "nghĩ đó phải liên quan mật thiết với nhau. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mỗi suy nghĩ tiếp theo có thể hoàn toàn độc lập\n",
            "với nhau, đảm bảo sự đa dạng trong chuỗi suy nghĩ. Chiến lược này được cho là hoạt\n",
            "động tốt khi không gian suy nghĩ rất phong phú, ví dụ như khi mỗi suy nghĩ là\n",
            "một đoạn văn dài. Điều này cho phép mô hình tạo ra nhiều suy nghĩ tiềm năng\n",
            "và đa dạng mà không bị giới hạn bởi các suy nghĩ trước đó.\n",
            "•Propose : Đầu tiên chúng ta đề xuất các suy nghĩ một cách tuần tự tức thay vì lấy mẫu ngẫu\n",
            "nhiên các suy nghĩ như trong sample thì propose đề xuất các suy nghĩ tiếp theo dựa trên suy\n",
            "nghĩ hiện tại. Điều này giúp cho các suy nghĩ được tạo ra có mối liên kết logic và tuần tự\n",
            "với nhau. Việc đề xuất này là đặt ra một khuôn khổ hoặc hướng dẫn cho mô hình về cách\n",
            "tạo ra suy nghĩ tiếp theo. Một điều đáng lưu ý là khi không gian suy nghĩ bị hạn chế việc sử\n",
            "dụng đề xuất prompt giúp tránh tạo ra các suy nghĩ trùng lặp, bởi vì mô hình sẽ cân nhắc\n",
            "đến bối cảnh hiện tại để tạo ra suy nghĩ mới. Kết quả là k suy nghĩ tiếp theo một cách có\n",
            "trật tự, mỗi suy nghĩ tiếp nối từ suy nghĩ trước đó, tạo ra một chuỗi suy nghĩ có cấu trúc và\n",
            "liền mạch hơn. Chiến lược này phù hợp khi không gian suy nghĩ bị hạn chế và cần\n",
            "một cách tiếp cận có cấu trúc để tạo ra các suy nghĩ mới mà khôn g bị lặp lại ý\n",
            "đã nêu trước đó.\n",
            "State evaluator hoạt động như một hàm heuristic giúp thuật toán tìm kiếm quyết định trạng\n",
            "thái nào cần được khám phá thêm và thứ tự ưu tiên. Có hai chiến lược để đánh giá các trạng thái:\n",
            "•Đánh giá từng trạng thái độc lập : Mỗi trạng thái được đánh giá độc lập để tạo ra một\n",
            "giá trị vô hướng (ví dụ từ 1 đến 10) hoặc một phân loại. Cách tiếp cận này sử dụng suy luận\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "đánh giá để chuyển đổi một heuristic thành một giá trị. Sự suy luận đánh giá có thể thay đổi\n",
            "tùy thuộc vào vấn đề và các bước suy nghĩ.\n",
            "•Bầu chọn các trạng thái : Đánh giá dựa trên việc so sánh và bầu chọn giữa các trạng thái\n",
            "khác nhau, nơi \"trạng thái tốt\" là trạng thái nhận được nhiều phiếu bầu nhất từ việc so sánh\n",
            "cẩn thận giữa các trạng thái. Khi đánh giá bằng cách bầu chọn, LM sẽ xem xét các trạng\n",
            "thái khác nhau và bầu chọn cho trạng thái \"ưu tú\" nhất.\n",
            "Cả hai chiến lược này đều nhằm mục đích tăng cường linh hoạt cho việc sử dụng heuristic trong\n",
            "thuật toán tìm kiếm, đặc biệt là khi sử dụng các mô hình ngôn ngữ để suy nghĩ một cách có chủ\n",
            "đích về các trạng thái.\n",
            "Search algorithm có hai loại tìm kiếm cơ bản trong TOT là: Tìm kiếm theo chiều rộng\n",
            "(Breadth-first search - BFS) và Tìm kiếm theo chiều sâu (Depth-first search - DFS).\n",
            "Một số lợi ích của TOT:\n",
            "•Generalizability: Các cách tiếp cận khác như IO, CoT, CoT-SC, và tự tinh chỉnh có thể được\n",
            "coi là trường hợp đặc biệt của TOT.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Modularity: cũng như việc phân rã suy nghĩ, đánh giá và thuật toán tìm kiếm có thể được\n",
            "thay đổi độc lập.\n",
            "•Adaptability: TOT có thể thích ứng với các tính chất vấn đề khác nhau và khả năng của LM.\n",
            "•Convenience: Không cần đào tạo thêm, chỉ cần một LM đã được đào tạo sẵn.\n",
            "11 Automatic Prompt Engineer (APE)\n",
            "Automatic Prompt Engineer là một kĩ thuật được đề xuất trong paper \"Large Language Models\n",
            "Are Human-Level Prompt Engineers\" Zhou et al., 2022. Paper này đề xuất một phương pháp tự\n",
            "động hóa việc prompt engineer bằng cách sử dụng các mô hình ngôn ngữ lớn để tự động tạo sinh\n",
            "và đánh giá prompt trong một không gian tìm kiếm.\n",
            "Phương pháp APE hoạt động như sau:\n",
            "•Đầu tiên, sử dụng một mô hình LLMs để tạo sinh ra một tập instruction đề xuất.\n",
            "•Chọn một subset từ tập train, sau đó đánh giá score của từng prompt đề xuất trên subset\n",
            "đó.\n",
            "•Lọc ra top k prompt có kết quả cao nhất, có thể sử dụng mô hình LLM để resample lại từ\n",
            "top k đó.\n",
            "•Lặp lại các bước trên đến khi hội tụ.\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 9: Thuật toán của APE\n",
            "Hình 10: Phương pháp APE, các bước được đánh số từ 1 đến 5\n",
            "APE giúp tìm kiếm những prompt cho ra kết quả tốt hơn khi sử dụng trong zero-shot CoT so\n",
            "với prompt được định nghĩa bởi con người như \"Let’s think step by step\" được đề xuất bởi Kojima\n",
            "et al., 2022.\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 11: Prompt được tạo sinh bằng phương pháp APE và prompt được định nghĩa bởi con người.\n",
            "Lợi ích của việc sử dụng APE:\n",
            "•tự động hóa quá trình prompt engineering.\n",
            "•APE đạt được kết quả ngang hoặc hơn con người trong một số task nhất định, bao gồm\n",
            "zero-shot và few-shot learning.\n",
            "12 Active-Prompt\n",
            "Một trong những nhược điểm của Chain-of-Thought là phương pháp này phụ thuộc vào một tập ví\n",
            "dụ giống nhau cho tất cả các task, tuy nhiên tập ví dụ này có thể không phải là tập thích hợp nhất\n",
            "cho các task khác nhau. Phương pháp Active-Prompt được đề xuất trong bài \"Active Prompting\n",
            "with Chain-of-Thought for Large Language Models\" Diao et al., 2023. Phương pháp này hoạt động\n",
            "theo các bước như sau.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Đầu tiên sử dụng mô hình LLM để gấn nhãn cho data train, có thể có hoặc không sử dụng\n",
            "CoT với một số ví dụ ở bước này.\n",
            "•k câu trả lời được tạo ra cho mỗi câu hỏi trong tập train. Sau đó ta sẽ sử dụng một số phương\n",
            "pháp khác nhau để tính độ bất định cho từng câu hỏi.\n",
            "•Những câu hỏi bất định nhất sẽ được lựa chọn để gấn nhãn thủ công bởi con người. Những\n",
            "câu hỏi này sẽ được lựa chọn để làm ví dụ cho CoT trong quá trình inference.\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 12: Các bước trong Active-Prompting\n",
            "Các thang đo để tính độ bất định được sử dụng trong paper bao gồm:\n",
            "•Disagreement : Ta có kết quả cho k câu hỏi A=a1, a2, ...a k. Thang đo disagreement được\n",
            "tính bằng số đáp án trả lời riêng biệt chia cho tổng số đáp án.\n",
            "•Entropy : Sử dụng hàm entropy để tính độ bất định. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "vời hàm entropy được định nghĩa như\n",
            "sau:\n",
            "u= arg max\n",
            "i−kX\n",
            "j=1Pθ(aj|qi) lnPθ(aj|qi) (2)\n",
            "Trong đó Pθ(aj|qi)là tần số xuất hiện của một câu trả lời j nhất định trong tập tất cả các\n",
            "dự đoán. Entropy càng cao chứng tỏ độ bất định càng lớn.\n",
            "•Variance : Sử dụng variance cho các câu hỏi liên quan đến toán học. Các tác giả nhận ra\n",
            "rằng độ variance trong các câu trả lời là rất lớn. Vì độ variance trong các câu trả lời là rất\n",
            "lớn, ta cần phải normalize các câu trả lời lại.\n",
            "•Self-Confidence : Sử dụng một mô hình LLM để tạo sinh ra thang điểm cho độ bất định\n",
            "của các câu trả lời. Thang điểm này hoạt động không quá tốt do các mô hình LLM có xu hứ\n",
            "tự tin thái quá vào các câu trả lời.\n",
            "Nhìn chung disagreement và entropy là 2 phương pháp tính độ bất định cho ra kết quả tốt nhất.\n",
            "Trong đó disagreement cho ra kết quả tốt hơn entropy trong nhiều task.\n",
            "13 Directional Stimulus Prompting\n",
            "Đây là một kĩ thuật prompting giúp LLM có thể tóm tắt văn bản theo ý muốn. Kĩ thuật này được\n",
            "giới thiệu trong paper \"Guiding Large Language Models via Directional Stimulus Prompting\" Li\n",
            "et al., 2023. DSP sử dụng các kích thích/chỉ dẫn hướng (directional stimulus, trong trường hợp này\n",
            "là các từ khóa), để cung cấp hướng dẫn cụ thể cho từng trường hợp cho các mô hình ngôn ngữ lớn\n",
            "18\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(LLMs) trong việc tạo ra các bản tóm tắt phù hợp hơn với bản tóm tắt tham khảo mong muốn.\n",
            "Hình 13 minh họa cách hoạt động của DSP.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 13: So sánh giữa DSP và Prompting truyền thống cho tác vụ tóm tắt văn bản. DSP sử dụng\n",
            "các kích thích/chỉ dẫn hướng, trong trường hợp này là các keyword được đánh dấu bằng màu cam,\n",
            "để các mô hình LLM có thể sinh ra bản tóm tắt phù hợp với mong muốn.\n",
            "Trong paper này, một mô hình language model nhỏ và có thể tune được (chẳng hạn như T5)\n",
            "được sử dụng để tạo sinh các kích thích/chỉ dẫn. Hướng tiếp cận này cho phép tránh việt phải\n",
            "fine-tune một mô hình ngôn ngữ lớn, thay vào đó ta có thể fine-tune một mô hình chỉ dẫn nhỏ hơn\n",
            "một cách dễ dàng hơn. Hướng tiếp cận này được mô tả trong hình 14.\n",
            "Hình 14: DSP sử dụng một mô hình ngôn ngữ nhỏ hơn để tạo sinh ra các kích thích/chỉ dẫn\n",
            "định hướng, trong trường hợp này là keyword. Mô hình này có thể được huấn luyện bằng SFT\n",
            "(supervised fine-tuning) và/hoặc là RL.\n",
            "19\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "14 PAL: Program-aided Language Models\n",
            "Điểm đặc biệt của PAL là việc giải quyết vấn đề được chuyển giao cho trình thông dịch, như\n",
            "Python, giúp tận dụng sức mạnh tính toán và độ chính xác cao của máy tính. Được đề xuất trong\n",
            "bài báo \"PAL: Program-aided Language Models\" Gao et al., 2023, phương pháp này tập trung vào\n",
            "việc phân tách vấn đề thành các bước có thể thực thi, giải phóng LLM khỏi trách nhiệm giải quyết\n",
            "vấn đề mà thay vào đó, giao cho trình thông dịch. Qua việc áp dụng PAL trong 13 nhiệm vụ suy\n",
            "luận toán học, biểu tượng, và thuật toán từ các bài kiểm tra khó như BIG-Bench Hard và các tiêu\n",
            "chuẩn khác.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 15: Sơ đồ PAL: Đối với một câu hỏi suy luận toán học, Chain-of-Thought tạo ra các bước\n",
            "suy luận trung gian dưới dạng văn bản tự do. Ngược lại, PAL tạo ra các bước trung gian và mã\n",
            "Python. Điều này chuyển vai trò thực thi các bước suy luận từ mô hình ngôn ngữ sang trình thông\n",
            "dịch Python. Câu trả lời cuối cùng được thu bằng cách chạy chuỗi suy luận đã tạo.\n",
            "PAL là một phương pháp độc đáo và sáng tạo trong việc giải quyết các vấn đề ngôn ngữ tự\n",
            "nhiên bằng cách kết hợp mạch lạc giữa ngôn ngữ tự nhiên (Natural Language - NL) và ngôn ngữ\n",
            "lập trình (Programming Language - PL). Trong tác vụ này, một vấn đề được đặt ra trong ngôn\n",
            "ngữ tự nhiên được biến đổi thành một loạt các câu lệnh xen kẽ giữa NL và PL, tạo ra một dạng\n",
            "hợp nhất giữa hai loại ngôn ngữ này. Điều này cho phép mô hình không chỉ phân tích và hiểu vấn\n",
            "đề mà còn tự động tạo ra mã lập trình như một phần của quy trình giải quyết vấn đề, mà không\n",
            "cần cung cấp trực tiếp các câu trả lời cuối cùng trong prompt của mình.\n",
            "Điểm đặc biệt của PAL là việc giải quyết vấn đề được chuyển giao cho một trình thông dịch, ví\n",
            "dụ như trình thông dịch Python, cho phép mô hình tập trung vào việc xây dựng và tối ưu hóa các\n",
            "20\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "bước giải quyết vấn đề một cách logic và hiệu quả. Các bước trung gian và câu lệnh lập trình được\n",
            "mô hình tạo ra sau đó được thực thi bởi trình thông dịch để thu được kết quả cuối cùng. Điều này\n",
            "không chỉ tăng cường khả năng của mô hình trong việc xử lý các vấn đề phức tạp mà còn mở rộng\n",
            "khả năng tương tác của nó với các ngôn ngữ lập trình thực tế.\n",
            "Trong quá trình thiết lập PAL, việc tận dụng các prompt có sẵn từ các nghiên cứu trước đây\n",
            "và bổ sung vào đó các ví dụ ngẫu nhiên để tạo nên một prompt đa dạng và phong phú, được tối\n",
            "ưu hóa bằng cách sử dụng các cấu trúc lập trình phổ biến như vòng lặp và dictionary. Quá trình\n",
            "này không chỉ giúp tạo ra các prompts chất lượng cao mà còn đảm bảo rằng các biến trong code\n",
            "được tạo ra có tên phản ánh chính xác vai trò và ý nghĩa của chúng trong vấn đề được giải quyết.\n",
            "PAL mở ra một hướng đi mới trong việc sử dụng trí tuệ nhân tạo để giải quyết vấn đề, nơi\n",
            "sự kết hợp giữa suy luận ngôn ngữ tự nhiên và lập trình cung cấp một cách tiếp cận linh hoạt và\n",
            "mạnh mẽ trong việc xử lý các thách thức phức tạp, từ đó thúc đẩy sự phát triển của các hệ thống\n",
            "AI thông minh và có khả năng thích ứng cao.\n",
            "15 ReAct Prompting\n",
            "ReAct Prompting được giới thiệu trong paper \"ReAct: Synergizing Reasoning and Acting in Lan-\n",
            "guage Models\" Yao et al., 2023b, là một kỹ thuật để tạo ra cả dấu vết suy luận và hành động cụ\n",
            "thể cho nhiệm vụ một cách xen kẽ, cho phép sự kết hợp chặt chẽ hơn giữa hai phần: theo vết suy\n",
            "luận giúp mô hình khởi tạo, theo dõi và cập nhật kế hoạch hành động cũng như xử lý ngoại lệ,\n",
            "trong khi hành động cho phép nó tương tác với và thu thập thông tin bổ sung từ các nguồn bên\n",
            "ngoài như cơ sở dữ liệu tri thức hoặc môi trường. ReAct cho một tập hợp đa dạng các nhiệm vụ về\n",
            "ngôn ngữ và ra quyết định, đã đạt hiệu quả so với các tiêu chuẩn hàng đầu cũng như cải thiện tính\n",
            "dễ hiểu và đáng tin cậy đối với con người. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cụ thể, trên các nhiệm vụ trả lời câu hỏi (HotpotQA)\n",
            "và xác minh sự thật (Fever), ReAct giải quyết các vấn đề phổ biến về ảo giác và lan truyền lỗi\n",
            "trong COT bằng cách tương tác với API Wikipedia đơn giản, và tạo ra quỹ đạo giải quyết nhiệm\n",
            "vụ giống như con người dễ hiểu hơn so với các tiêu chuẩn không có dấu vết suy luận.\n",
            "Thông qua việc sử dụng một số ít ví dụ điển hình trong prompt, với mỗi quỹ đạo bao gồm\n",
            "nhiều bước suy nghĩ-hành động-quan sát. ReAct khai thác sức mạnh của suy nghĩ tự do cho nhiều\n",
            "mục đích, từ phân rã câu hỏi, trích xuất thông tin từ Wikipedia, suy luận thông thường và toán\n",
            "học, đến hướng dẫn cải tiến tìm kiếm và tổng hợp câu trả lời cuối cùng. Đối với các tiêu chuẩn so\n",
            "sánh, loại bỏ từng phần trong quỹ đạo ReAct để xây dựng các lời nhắc cho nhiều cơ sở so sánh, từ\n",
            "CoT chỉ tập trung vào suy luận, đến hành động duy nhất mà không cần suy nghĩ, và kết hợp cả\n",
            "hai để tạo ra quyết định dựa trên cả kiến thức nội bộ và bên ngoài.\n",
            "21\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 16: So sánh 4 phương pháp prompting, standard, Chain-of-thought (CoT, Reason Only), Act-\n",
            "only và ReAct (Reason+Act)\n",
            "16 Reflexion\n",
            "Reflexion được đề xuất trong bài báo \"Reflexion: Language Agents with Verbal Reinforcement\n",
            "Learning\" Shinn et al., 2023, đánh dấu bước tiến trong việc cải thiện khả năng của các language\n",
            "agents - những mô hình ngôn ngữ lớn được sử dụng ngày càng nhiều để tương tác với môi trường\n",
            "bên ngoài như trò chơi, trình biên dịch, API với vai trò là các đại diện có mục tiêu. Mặc dù việc áp\n",
            "dụng các phương pháp học tăng cường truyền thống đang đối mặt với thách thức lớn, do yêu cầu\n",
            "lượng dữ liệu huấn luyện rộng lớn và việc tinh chỉnh mô hình tốn kém, Reflexion mở ra một hướng\n",
            "đi mới. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Thay vì cập nhật trọng số, Reflexion tăng cường khả năng của language agents thông qua\n",
            "phản hồi ngôn ngữ. Cụ thể, Reflexion agents phản ánh về tín hiệu phản hồi công việc thông qua\n",
            "lời nói, sau đó duy trì văn bản phản ánh của chính nó trong một bộ đệm theo dõi để thúc đẩy\n",
            "quyết định tốt hơn trong các lần thử tiếp theo. Reflexion đủ linh hoạt để kết hợp các loại (giá trị\n",
            "vô hướng hoặc ngôn ngữ tự do) và nguồn (bên ngoài hoặc mô phỏng nội bộ) tín hiệu phản hồi, và\n",
            "đạt được những cải thiện đáng kể so với một đại diện cơ sở trên nhiều nhiệm vụ đa dạng (quyết\n",
            "định tuần tự, lập trình, suy luận ngôn ngữ).\n",
            "22\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 17: Quá trình hoạt động của Reflexion qua 3 tác vụ decision-making, programming và rea-\n",
            "soning.\n",
            "Reflexion là một khái niệm đột phá trong lĩnh vực trí tuệ nhân tạo, tạo ra một cách tiếp cận\n",
            "mới cho việc tăng cường khả năng tự học của các language agents thông qua ba thành phần chính:\n",
            "Actor, Evaluator và Self-Reflection. Actor sử dụng mô hình ngôn ngữ lớn để tạo ra văn bản và\n",
            "hành động dựa trên quan sát. Evaluator đánh giá chất lượng của các kết quả này và cung cấp điểm\n",
            "thưởng, trong khi Self-Reflection tạo ra phản hồi ngôn từ để hỗ trợ Actor phát triển qua từng lần\n",
            "thử. Phản hồi này sau đó được lưu trữ trong bộ nhớ, giúp Actor điều chỉnh hành động trong các\n",
            "lần thử tiếp theo. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Quy trình này không chỉ tối ưu hóa việc học từ kinh nghiệm mà còn cho phép\n",
            "các đại diện nhanh chóng cải thiện quyết định của mình thông qua việc sử dụng phản hồi có giá\n",
            "trị, tạo ra một cơ chế học tập mạnh mẽ và linh hoạt.\n",
            "Hình 18: Diagram và Pseudo-Code của Reflexion\n",
            "23\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "17 Multimodal CoT Prompting\n",
            "Các mô hình ngôn ngữ lớn đã thể hiện hiệu suất ấn tượng trong việc giải quyết các bài toán suy\n",
            "luận phức tạp bằng cách sử dụng COT để tạo ra các chuỗi suy luận trung gian như rationale (lý do)\n",
            "để suy luận ra câu trả lời. Tuy nhiên, các nghiên cứu về COT trước đó đã tập trung vào mô hình\n",
            "ngôn ngữ. Multimodal-CoT được đề xuất trong paper \"Multimodal Chain-of-Thought Reasoning\n",
            "in Language Models\" Zhang et al., 2023b, là một phương pháp kết hợp cả hai mô hình ngôn ngữ\n",
            "và hình ảnh vào một two-stage framework tách biệt việc tạo lý do và suy luận câu trả lời. Nhờ\n",
            "đó, việc suy luận câu trả lời có thể tận dụng tốt hơn các lý do được tạo ra dựa trên thông tin đa\n",
            "phương tiện.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 19: Multimodal-CoT bao gồm hai giai đoạn: (i) tạo lập lý do và (ii) suy luận câu trả lời. Cả\n",
            "hai giai đoạn đều sử dụng cùng một kiến trúc mô hình nhưng khác nhau về đầu vào và đầu ra.\n",
            "Trong giai đoạn đầu tiên, cung cấp cho mô hình đầu vào ngôn ngữ và hình ảnh để tạo ra lý do.\n",
            "Trong giai đoạn thứ hai, thêm đầu vào ngôn ngữ ban đầu với lý do được tạo ra từ giai đoạn đầu\n",
            "tiên. Sau đó, cung cấp đầu vào ngôn ngữ đã được cập nhật cùng với đầu vào hình ảnh ban đầu cho\n",
            "mô hình để suy luận ra câu trả lời.\n",
            "Multimodal-CoT hoạt động với 2-stage kết hợp giữa ngôn ngữ và thị giác để cải thiện suy luận\n",
            "và đưa ra câu trả lời cho các mô hình ngôn ngữ lớn. Giai đoạn đầu tiên, tạo các lý do, nhận đầu\n",
            "vào là dữ liệu ngôn ngữ và hình ảnh để sinh ra chuỗi lý do. Giai đoạn thứ hai, suy luận câu trả lời,\n",
            "bắt đầu bằng việc thêm chuỗi lý do vào đầu vào ngôn ngữ gốc, và sau đó kết hợp với đầu vào thị\n",
            "giác ban đầu để mô hình có thể suy luận ra câu trả lời. Cả hai giai đoạn này sử dụng chung kiến\n",
            "trúc mô hình nhưng khác biệt về dữ liệu đầu vào và đầu ra.\n",
            "Trong cả hai giai đoạn, mô hình được huấn luyện để xử lý thông tin đa phương tiện: đầu vào\n",
            "ngôn ngữ được mã hóa bởi một bộ mã hóa ngôn ngữ, trong khi đầu vào hình ảnh được xử lý bởi\n",
            "một bộ trích xuất đặc trưng hình ảnh và sau đó được kết hợp thông qua một single-head attention\n",
            "network để tạo đầu ra hợp nhất. Đầu ra này sau đó được đưa vào Transformer decoder để sinh ra\n",
            "dự đoán cuối cùng. Cách tiếp cận này không chỉ tận dụng được sức mạnh của cả văn bản và hình\n",
            "ảnh mà còn cho phép mô hình tạo ra các lý do suy luận phong phú và đa dạng, tăng cường khả\n",
            "năng đưa ra câu trả lời chính xác và có cơ sở\n",
            "24\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "18 Synthetic Prompting\n",
            "Bài báo \"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language\n",
            "Models\" Shao et al., 2023, khám phá ý tưởng sử dụng kỹ thuật chain-of-thought (CoT) để hướng\n",
            "dẫn các mô hình ngôn ngữ lớn (LLMs) giải quyết các nhiệm vụ suy luận khác nhau. Ý tưởng chính\n",
            "là LLMs có thể tìm ra câu trả lời tốt hơn bằng cách theo dõi một loạt các bước giải thích từng\n",
            "bước. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tuy nhiên, việc tạo ra những bước giải thích này một cách thủ công là tốn thời gian và đắt\n",
            "đỏ. Bài báo giới thiệu một phương pháp gọi là Synthetic Prompting, sử dụng một vài ví dụ thủ\n",
            "công để gợi ý cho mô hình tự tạo ra thêm ví dụ. Phương pháp này bao gồm một quá trình ngược\n",
            "để tạo ra các câu hỏi phù hợp với chuỗi suy nghĩ được lấy mẫu, đảm bảo các câu hỏi rõ ràng và có\n",
            "thể giải quyết, và một quá trình để tạo ra chuỗi suy nghĩ chi tiết hơn, từ đó cải thiện chất lượng\n",
            "của các ví dụ. Việc đánh giá phương pháp này trên các nhiệm vụ suy luận toán học, biểu tượng và\n",
            "thuật toán cho thấy nó vượt trội hơn các kỹ thuật prompting hiện có.\n",
            "Với phương pháp này, thay vì đưa trực tiếp các ví dụ về chuỗi suy luận cho từng câu hỏi như\n",
            "chain-of-thought, phương pháp này lại sử dụng những ví dụ này như những ví dụ mồi để mô hình\n",
            "LLM tự động sinh ra các ví dụ khác qua 2 quá trình backward-forward.\n",
            "25\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Ở quá trình backward, câu hỏi sẽ được LLM tạo ra dựa trên những câu hỏi mồi, cộng với\n",
            "một topic cho trước, một độ phức tạp dự kiến và một chuỗi suy luận được tạo tự động. Có\n",
            "một điểm cần lưu ý là chuỗi suy luận sẽ được tạo ra trước dựa trên từ chủ đề và đô phức tạp\n",
            "dự kiến, sau đó mô hình LLM sẽ tạo ra câu hỏi dựa trên chuỗi suy luận đó.\n",
            "•Quá trình forward có mục đích là tạo ra chuỗi suy luận dựa vào câu hỏi vừa được tạo ra. Các\n",
            "tác giả nhận ra rằng chuỗi suy luận được tạo ra trong quá trình forward sẽ phù hợp và chính\n",
            "xác hơn cái được tạo ra trong quá trình backward, vì nó trực tiếp phụ thuộc vào câu hỏi.\n",
            "Cuối cùng một ví dụ mới được hình thành bằng cách sử dụng chuỗi suy luận từ quá trình\n",
            "forward và câu hỏi từ quá trình backward.\n",
            "Cuối cùng, trong quá trình inference, một tập nhỏ các câu hỏi được tạo sinh ra sẽ được sử dụng\n",
            "để làm ví dụ mẫu cho mô hình. Phương pháp này nhìn chung cho thấy sự vượt trội trong các task\n",
            "liên quan đến lập trình, toán học, và suy luận dựa trên biểu tượng.\n",
            "Phần III: Tổng kết\n",
            "Prompt engineering là yếu tố then chốt để khai thác hết khả năng của các mô hình ngôn ngữ tiên\n",
            "tiến. Sự hiệu quả và độ chính xác của các phản hồi từ mô hình ngôn ngữ lớn phụ thuộc rất nhiều\n",
            "vào cách thức ta thiết kế và cung cấp các prompt. Việc tinh chỉnh và tạo ra những prompts thông\n",
            "minh và sáng tạo không chỉ giúp các mô hình ngôn ngữ lớn hiểu rõ hơn yêu cầu của người dùng\n",
            "mà còn tối ưu hóa khả năng phản hồi của nó. Bài viết này mang lại cái nhìn tổng quan về những\n",
            "kỹ thuật prompt engineering đang được áp dụng hiện nay, mở ra những khả năng mới trong việc\n",
            "tương tác với các hệ thống trí tuệ nhân tạo.\n",
            "References\n",
            "Bsharat, S. M., Myrzakhan, A., & Shen, Z. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "(2024). Principled instructions are all you need for\n",
            "questioning llama-1/2, gpt-3.5/4.\n",
            "Wei, J., Bosma, M., Zhao, V., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., & Le, Q. V. Fine-\n",
            "tuned language models are zero-shot learners. In: In International conference on learning\n",
            "representations .\n",
            "Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam,\n",
            "P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child,\n",
            "R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., ... Amodei, D. Language models are\n",
            "few-shot learners (H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, & H. Lin, Eds.). In:\n",
            "Advances in neural information processing systems (H. Larochelle, M. Ranzato, R. Hadsell,\n",
            "M. Balcan, & H. Lin, Eds.). Ed. by Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.,\n",
            "& Lin, H. 33. Curran Associates, Inc., 2020, 1877–1901. https://proceedings.neurips.cc/\n",
            "paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n",
            "Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou,\n",
            "D. (2022). Chain-of-thought prompting elicits reasoning in large language models [cite\n",
            "arxiv:2201.11903]. http://arxiv.org/abs/2201.11903\n",
            "Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. Large language models are zero-shot\n",
            "reasoners. In: In Advances in neural information processing systems .35. 2022, 22199–22213.\n",
            "Zhang, Z., Zhang, A., Li, M., & Smola, A. Automatic chain of thought prompting in large language\n",
            "models. In: In The eleventh international conference on learning representations (iclr 2023) .\n",
            "2023.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "26\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Wang, X., Wei, J., Schuurmans, D., Le, Q., hsin Chi, E. H., & Zhou, D. (2022). Self-consistency\n",
            "improves chain of thought reasoning in language models. ArXiv,abs/2203.11171 . https:\n",
            "//api.semanticscholar.org/CorpusID:247595263\n",
            "Liu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi, H. (2021). Gen-\n",
            "erated knowledge prompting for commonsense reasoning. arXiv preprint arXiv:2110.08387 .\n",
            "Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., & Narasimhan, K. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "(2023a). Tree of\n",
            "thoughts: Deliberate problem solving with large language models.\n",
            "Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2022). Large language\n",
            "models are human-level prompt engineers.\n",
            "Diao, S., Wang, P., Lin, Y., & Zhang, T. (2023). Active prompting with chain-of-thought for large\n",
            "language models.\n",
            "Li, Z., Peng, B., He, P., Galley, M., Gao, J., & Yan, X. (2023). Guiding large language models via\n",
            "directional stimulus prompting. arXiv preprint arXiv:2302.11520 .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., & Neubig, G. (2023). Pal:\n",
            "Program-aided language models.\n",
            "Yao,S.,Zhao,J.,Yu,D.,Du,N.,Shafran,I.,Narasimhan,K.,&Cao,Y.(2023b).React:Synergizing\n",
            "reasoning and acting in language models.\n",
            "Shinn, N., Cassano, F., Berman, E., Gopinath, A., Narasimhan, K., & Yao, S. (2023). Reflexion:\n",
            "Language agents with verbal reinforcement learning.\n",
            "Zhang, Z., Zhang, A., Li, M., Zhao, H., Karypis, G., & Smola, A. (2023b). Multimodal chain-of-\n",
            "thought reasoning in language models.\n",
            "Shao, Z., Gong, Y., Shen, Y., Huang, M., Duan, N., & Chen, W. (2023). Synthetic prompting:\n",
            "Generating chain-of-thought demonstrations for large language models.\n",
            "- Hết -\n",
            "27\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "Xây dựng hệ thống hỏi-đáp mở với hệ cơ sở dữ\n",
            "liệu vector\n",
            "Dinh-Thang Duong, Minh-Duc Bui và Quang-Vinh Dinh\n",
            "PR-Team: Minh-Châu Phạm, Hoàng-Nguyên và Vũ Đăng-Nhã Nguyễn\n",
            "Ngày 13 tháng 2 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Trong project này, chúng ta sẽ tập trung vào việc phát triển một hệ thống end-to-end hỏi đáp tự động,\n",
            "với khả năng trả lời một câu hỏi với nội dung bất kì. Hệ thống mà chúng ta cài đặt trong project này\n",
            "bao gồm hai phần chính là Retriever và Reader, với mục tiêu xây dựng một hệ thống toàn diện có khả\n",
            "năng rút trích thông tin từ văn bản và cung cấp câu trả lời cho các câu hỏi dựa trên nội dung của đoạn\n",
            "văn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cụ thể, ta sẽ xây dựng chương trình dựa vào dataset SQuAD2.0, một bộ dữ liệu về đọc hiểu, vector\n",
            "database là FAISS và mô hình BERT để thực hiện các nhiệm vụ cụ thể trong chương trình. Input và\n",
            "output của chương trình như sau:\n",
            "•Input:Một câu hỏi.\n",
            "•Output: Câu trả lời tương ứng.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Nội dung\n",
            "Để xây dựng một chương trình End-to-end Question Answering, chúng ta cần hoàn thiện hai module\n",
            "chính bao gồm Retriever và Reader:\n",
            "Hình 1: Ảnh minh hoạt tổng quát về một hệ thống End-to-end QA.\n",
            "Theo đó, nội dung của bài viết sẽ trình bày chương trình cài đặt cho từng thành phần như sau:\n",
            "1.Dataset description: SQuAD2.0 Stanford Question Answering Dataset (SQuAD) là bộ data\n",
            "theo hướng đọc hiểu, bao gồm các đoạn văn (passage) khác nhau về nhiều chủ đề, ứng với mỗi\n",
            "đoạn văn sẽ có một các câu hỏi ngắn kèm theo. Bảng 1 miêu tả cấu trúc chi tiết về dataset\n",
            "SQuAD2.0:\n",
            "Hình 2: Ví dụ minh họa về dataset SQuAD2.0.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "SQuAD 2.0\n",
            "Train\n",
            "Total examples 130,319\n",
            "Negative examples 43,498\n",
            "Total articles 442\n",
            "Articles with negatives 285\n",
            "Development\n",
            "Total examples 11,873\n",
            "Negative examples 5,945\n",
            "Total articles 35\n",
            "Articles with negatives 35\n",
            "Test\n",
            "Total examples 8,862\n",
            "Negative examples 4,332\n",
            "Total articles 28\n",
            "Articles with negatives 28\n",
            "Bảng 1: Thống kê số lượng sample của dataset SQuAD2.0.\n",
            "Câu trả lời cho các câu hỏi ngắn là những từ/cụm từ có sẵn trong đoạn văn cho trước (không\n",
            "yêu cầu suy luận phức tạp), hoặc các câu hỏi không trả lời được dựa vào đoạn văn (answer là no\n",
            "answer). Bảng 2 thống kê về dataset SQuAD2.0:\n",
            "Answer type Percentage Example\n",
            "Date 8.9% 19 October 2023\n",
            "Other Numeric 10.9% 12\n",
            "Person 12.9% Thomas Coke\n",
            "Location 4.4% Germany\n",
            "Other Entity 15.3% ABC Sports\n",
            "Common Noun Phrase 31.8% property damage\n",
            "Adjective Phrase 3.9% second-largest\n",
            "Verb Phrase 5.5% returned to Earth\n",
            "Clause 3.7% to avoid trivialization\n",
            "Other 2.7% quietly\n",
            "Bảng 2: Thống kê các loại câu trả lời khác nhau của dataset SQuAD2.0.\n",
            "2.Reader: DistilBERT Đầu tiên ta sẽ xây dựng model Reader hay chính là model QA trong\n",
            "project này.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(a)Install and import bibraries: Đầu tiên ta sẽ install một số thư viện cần thiết mà Colab\n",
            "chưa hỗ trợ.\n",
            "1!pip install -qq datasets==2.16.1 evaluate==0.4.1 transformers[sentencepiece\n",
            "]==4.35.2\n",
            "2!pip install -qq accelerate==0.26.1\n",
            "3!apt install git-lfs\n",
            "Sau đó ta sẽ tiến hành login vào HuggingFace để download dataset và model có sẵn. Khi\n",
            "chạy block code này thì HuggingFace sẽ đưa ra một đường dẫn đến trang HuggingFace để\n",
            "lấy mã token.\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1from huggingface_hub import notebook_login\n",
            "2\n",
            "3notebook_login()\n",
            "Cuối cùng ta sẽ import các thư viện chính được sử dụng trong phần này:\n",
            "1import numpy as np\n",
            "2from tqdm.auto import tqdm\n",
            "3import collections\n",
            "4\n",
            "5import torch\n",
            "6\n",
            "7from datasets import load_dataset\n",
            "8from transformers import AutoTokenizer\n",
            "9from transformers import AutoModelForQuestionAnswering\n",
            "10from transformers import TrainingArguments\n",
            "11from transformers import Trainer\n",
            "12import evaluate\n",
            "13\n",
            "14device = torch.device(\"cuda\") if torch.cuda.is_available() else \\\n",
            "15 torch.device(\"cpu\")\n",
            "(b)Setup config: Tiếp theo ta sẽ setup một số config cơ bản:\n",
            "1# Sử dụng mô hình \"distilbert-base-uncased\" làm mô hình checkpoint\n",
            "2MODEL_NAME = \"distilbert-base-uncased\"\n",
            "3\n",
            "4# Độ dài tối đa cho mỗi đoạn văn bản sau khi được xử lý\n",
            "5MAX_LENGTH = 384\n",
            "6\n",
            "7# Khoảng cách giữa các điểm bắt đầu của các đoạn văn bản liên tiếp\n",
            "8STRIDE = 128\n",
            "(c)Setup Dataset:\n",
            "•Download dataset:\n",
            "1# Download squad dataset từ HuggingFace\n",
            "2DATASET_NAME = ’squad_v2’\n",
            "3raw_datasets = load_dataset(DATASET_NAME)\n",
            "•Load tokenizer and run some examples:\n",
            "1# Load tokenizer để run một số example\n",
            "2tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
            "(d)Tokenize dataset: Trong phần này ta sẽ tiến hành tokenize dataset cho tập train và tập\n",
            "val.\n",
            "•Tokenize train set: Hàm preprocess_training_examples nhận dữ liệu đào tạo làm đầu\n",
            "vào và tiền xử lý để chuẩn bị cho việc huấn luyện mô hình hỏi đáp. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trong quá trình này,\n",
            "hàm trích xuất danh sách câu hỏi, mã hóa thông tin đầu vào bằng tokenizer, và trích\n",
            "xuất offset_mapping và sample_map để ánh xạ vị trí từ mã hóa về văn bản gốc. Hàm\n",
            "cũng xác định vị trí bắt đầu và kết thúc của câu trả lời trong ngữ cảnh và thêm thông\n",
            "tin về vị trí này vào biến inputs.\n",
            "1# Định nghĩa hàm preprocess_training_examples và nhận tham số examples\n",
            "2# là dữ liệu training\n",
            "3def preprocess_training_examples(examples):\n",
            "4# Trích xuất danh sách câu hỏi từ examples và\n",
            "5# loại bỏ các khoảng trắng dư thừa\n",
            "6questions = [q.strip() for q in examples[\"question\"]]\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "7\n",
            "8# Tiến hành mã hóa thông tin đầu vào sử dụng tokenizer\n",
            "9inputs = tokenizer(\n",
            "10 questions,\n",
            "11 examples[\"context\"],\n",
            "12 max_length=MAX_LENGTH,\n",
            "13 truncation=\"only_second\",\n",
            "14 stride=STRIDE,\n",
            "15 return_overflowing_tokens=True,\n",
            "16 return_offsets_mapping=True,\n",
            "17 padding=\"max_length\",\n",
            "18 )\n",
            "19\n",
            "20 # Trích xuất offset_mapping từ inputs và loại bỏ nó ra khỏi inputs\n",
            "21 offset_mapping = inputs.pop(\"offset_mapping\")\n",
            "22\n",
            "23 # Trích xuất sample_map từ inputs và loại bỏ nó ra khỏi inputs\n",
            "24 sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
            "25\n",
            "26 # Trích xuất thông tin về câu trả lời (answers) từ examples\n",
            "27 answers = examples[\"answers\"]\n",
            "28\n",
            "29 # Khởi tạo danh sách các vị trí bắt đầu và kết thúc câu trả lời\n",
            "30 start_positions = []\n",
            "31 end_positions = []\n",
            "32\n",
            "33 # Duyệt qua danh sách offset_mapping\n",
            "34 for i, offset in enumerate(offset_mapping):\n",
            "35 # Xác định index của mẫu (sample) liên quan đến offset hiện tại\n",
            "36 sample_idx = sample_map[i]\n",
            "37\n",
            "38 # Trích xuất sequence_ids từ inputs\n",
            "39 sequence_ids = inputs.sequence_ids(i)\n",
            "40\n",
            "41 # Xác định vị trí bắt đầu và kết thúc của ngữ cảnh\n",
            "42 idx = 0\n",
            "43 while sequence_ids[idx] != 1:\n",
            "44 idx += 1\n",
            "45 context_start = idx\n",
            "46 while sequence_ids[idx] == 1:\n",
            "47 idx += 1\n",
            "48 context_end = idx - 1\n",
            "49\n",
            "50 # Trích xuất thông tin về câu trả lời cho mẫu này\n",
            "51 answer = answers[sample_idx]\n",
            "52\n",
            "53 if len(answer[’text’]) == 0:\n",
            "54 start_positions.append(0)\n",
            "55 end_positions.append(0)\n",
            "56 else:\n",
            "57 # Xác định vị trí ký tự bắt đầu và kết thúc của câu trả lời\n",
            "58 # trong ngữ cảnh\n",
            "59 start_char = answer[\"answer_start\"][0]\n",
            "60 end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
            "61\n",
            "62 # Nếu câu trả lời không nằm hoàn toàn trong ngữ cảnh,\n",
            "63 # gán nhãn là (0, 0)\n",
            "64 if offset[context_start][0] > start_char\n",
            "65 or offset[context_end][1] < end_char:\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "66 start_positions.append(0)\n",
            "67 end_positions.append(0)\n",
            "68 else:\n",
            "69 # Nếu không, gán vị trí bắt đầu và kết thúc dựa trên\n",
            "70 # vị trí của các mã thông tin\n",
            "71 idx = context_start\n",
            "72 while idx <= context_end and offset[idx][0] <= start_char:\n",
            "73 idx += 1\n",
            "74 start_positions.append(idx - 1)\n",
            "75\n",
            "76 idx = context_end\n",
            "77 while idx >= context_start and offset[idx][1] >= end_char:\n",
            "78 idx -= 1\n",
            "79 end_positions.append(idx + 1)\n",
            "80\n",
            "81 # Thêm thông tin vị trí bắt đầu và kết thúc vào inputs\n",
            "82 inputs[\"start_positions\"] = start_positions\n",
            "83 inputs[\"end_positions\"] = end_positions\n",
            "84\n",
            "85 return inputs\n",
            "Sau đó ta sẽ chạy đoạn hàm trên với từng dòng trong raw_dataset của tập train:\n",
            "1# Tạo một biến train_dataset và gán cho nó giá trị sau khi áp dụng\n",
            "2# hàm preprocess_training_examples lên tập dữ liệu \"train\"\n",
            "3#\n",
            "4# Bật chế độ xử lý theo từng batch bằng cách đặt batched=True\n",
            "5#\n",
            "6# Loại bỏ các cột không cần thiết trong\n",
            "7# tập dữ liệu \"train\" bằng cách sử dụng remove_columns\n",
            "8\n",
            "9train_dataset = raw_datasets[\"train\"].map(\n",
            "10 preprocess_training_examples,\n",
            "11 batched=True,\n",
            "12 remove_columns=raw_datasets[\"train\"].column_names,\n",
            "13)\n",
            "14\n",
            "15# In ra độ dài của tập dữ liệu \"train\" ban đầu và\n",
            "16# độ dài của tập dữ liệu đã được xử lý (train_dataset)\n",
            "17len(raw_datasets[\"train\"]), len(train_dataset)\n",
            "•Tokenize val set: Ta sẽ làm tương tự với tập val, hàm preprocess_validation_examples\n",
            "thực hiện việc tiền xử lý dữ liệu cho quá trình đánh giá mô hình. Hàm chuẩn bị danh\n",
            "sách câu hỏi, mã hóa các câu hỏi và văn bản liên quan bằng cách sử dụng tokenizer. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sau\n",
            "đó xác định ví dụ tham chiếu cho từng dòng đầu vào và điều chỉnh ánh xạ offset để loại\n",
            "bỏ các offset không phù hợp với sequence_ids. Cuối cùng là thêm thông tin về ví dụ\n",
            "tham chiếu vào đầu vào.\n",
            "1def preprocess_validation_examples(examples):\n",
            "2# Chuẩn bị danh sách câu hỏi bằng cách\n",
            "3# loại bỏ khoảng trắng ở đầu và cuối mỗi câu hỏi\n",
            "4questions = [q.strip() for q in examples[\"question\"]]\n",
            "5\n",
            "6# Sử dụng tokenizer để mã hóa các câu hỏi và văn bản liên quan\n",
            "7inputs = tokenizer(\n",
            "8 questions,\n",
            "9 examples[\"context\"],\n",
            "10 max_length=MAX_LENGTH,\n",
            "11 truncation=\"only_second\",\n",
            "12 stride=STRIDE,\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "13 return_overflowing_tokens=True,\n",
            "14 return_offsets_mapping=True,\n",
            "15 padding=\"max_length\",\n",
            "16 )\n",
            "17\n",
            "18 # Lấy ánh xạ để ánh xạ lại ví dụ tham chiếu cho từng dòng trong inputs\n",
            "19 sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
            "20 example_ids = []\n",
            "21\n",
            "22 # Xác định ví dụ tham chiếu cho mỗi dòng đầu vào và\n",
            "23 # điều chỉnh ánh xạ offset\n",
            "24 for i in range(len(inputs[\"input_ids\"])):\n",
            "25 sample_idx = sample_map[i]\n",
            "26 example_ids.append(examples[\"id\"][sample_idx])\n",
            "27\n",
            "28 sequence_ids = inputs.sequence_ids(i)\n",
            "29 offset = inputs[\"offset_mapping\"][i]\n",
            "30\n",
            "31 # Loại bỏ các offset không phù hợp với sequence_ids\n",
            "32 inputs[\"offset_mapping\"][i] = [\n",
            "33 o if sequence_ids[k] == 1 else None \\\n",
            "34 for k, o in enumerate(offset)\n",
            "35 ]\n",
            "36\n",
            "37 # Thêm thông tin ví dụ tham chiếu vào đầu vào\n",
            "38 inputs[\"example_id\"] = example_ids\n",
            "39\n",
            "40 return inputs\n",
            "Ta sẽ chạy đoạn hàm trên với từng dòng trong raw_dataset của tâp validation:\n",
            "1# Tạo một biến validation_dataset và gán giá trị bằng việc sử dụng dữ liệu\n",
            "2# từ raw_datasets[\"validation\"] sau khi áp dụng một hàm xử lý trước.\n",
            "3\n",
            "4validation_dataset = raw_datasets[\"validation\"].map(\n",
            "5preprocess_validation_examples,\n",
            "6batched=True,\n",
            "7remove_columns=raw_datasets[\"validation\"].column_names,\n",
            "8)\n",
            "9\n",
            "10# In ra độ dài của raw_datasets[\"validation\"]\n",
            "11# và validation_dataset để so sánh.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "12len(raw_datasets[\"validation\"]), len(validation_dataset)\n",
            "(e)Train model: Sau khi đã chuẩn bị xong dataset, ta sẽ tiến hành load model từ HuggingFace\n",
            "để chuẩn bị cho quá trình training:\n",
            "1# Load model\n",
            "2model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
            "Tiếp theo ta sẽ định nghĩa một số parameter mà ta sẽ sử dụng để training model:\n",
            "1# Tạo đối tượng args là các tham số cho quá trình huấn luyện\n",
            "2args = TrainingArguments(\n",
            "3output_dir=\"distilbert-finetuned-squadv2\", # Thư mục lưu output\n",
            "4evaluation_strategy=\"no\", # Chế độ đánh giá không tự động sau mỗi epoch\n",
            "5save_strategy=\"epoch\", # Lưu checkpoint sau mỗi epoch\n",
            "6learning_rate=2e-5, # Tốc độ học\n",
            "7num_train_epochs=3, # Số epoch huấn luyện\n",
            "8weight_decay=0.01, # Giảm trọng lượng mô hình để tránh overfitting\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "9fp16=True, # Sử dụng kiểu dữ liệu half-precision để tối ưu tài nguyên\n",
            "10 push_to_hub=True, # Đẩy kết quả huấn luyện lên HuggingFace Hub\n",
            "11)\n",
            "Cuối cùng ta sẽ khởi tạo class Trainer, đây là class chính để training model, ta sẽ không cần\n",
            "phải định nghĩa hàm train, đưa input vào mode, tính toán loss, update gradient nữa, hàm\n",
            "class này sẽ tự động làm giúp chúng ta. Sau khi đã khởi tạo thì chỉ cần gọi trainner.train()\n",
            "thì quá trình training model sẽ được tiến hành:\n",
            "1# Khởi tạo một đối tượng Trainer để huấn luyện mô hình\n",
            "2trainer = Trainer(\n",
            "3model=model, # Sử dụng mô hình đã tạo trước đó\n",
            "4args=args, # Các tham số và cấu hình huấn luyện\n",
            "5train_dataset=train_dataset, # Sử dụng tập dữ liệu huấn luyện\n",
            "6eval_dataset=validation_dataset, # Sử dụng tập dữ liệu đánh giá\n",
            "7tokenizer=tokenizer, # Sử dụng tokenizer để xử lý văn bản\n",
            "8)\n",
            "9\n",
            "10# Bắt đầu quá trình huấn luyện\n",
            "11trainer.train()\n",
            "Sau khi quá trình training hoàn tất, ta sẽ đưa weight, config của model lên HuggingFace Hub\n",
            "để lưu lại:\n",
            "1# Gửi dữ liệu đào tạo lên Hub\n",
            "2trainer.push_to_hub(commit_message=\"Training complete\")\n",
            "(f)Evaluate model: Để đánh giá performance của model ta sẽ sử dụng metric squad từ thư\n",
            "viện evaluate:\n",
            "1# Tải metric \"squad\" từ thư viện evaluate\n",
            "2metric = evaluate.load(\"squad_v2\")\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hàm compute_metrics nhận các đầu vào như start_logits, end_logits, features, và examples,\n",
            "và thực hiện các bước sau để tính toán các độ đo và kết quả đánh giá mô hình hỏi đáp. Trong\n",
            "quá trình tính toán, hàm này tạo một danh sách các câu trả lời dự đoán dựa trên các logits\n",
            "được dự đoán bởi mô hình. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Điều này bao gồm việc xác định vị trí bắt đầu và kết thúc tốt\n",
            "nhất cho các câu trả lời và đánh giá xem chúng có hợp lệ hay không dựa trên độ dài tối đa\n",
            "cho câu trả lời. Cuối cùng, hàm tính toán các độ đo và trả về kết quả đánh giá mô hình hỏi\n",
            "đáp dựa trên các câu trả lời dự đoán và câu trả lời lý thuyết từ ví dụ.\n",
            "1N_BEST = 20 # Số lượng kết quả tốt nhất được lựa chọn sau khi dự đoán\n",
            "2MAX_ANS_LENGTH = 30 # Độ dài tối đa cho câu trả lời dự đoán\n",
            "3\n",
            "4def compute_metrics(start_logits, end_logits, features, examples):\n",
            "5# Tạo một từ điển mặc định để ánh xạ mỗi ví dụ\n",
            "6# với danh sách các đặc trưng tương ứng\n",
            "7example_to_features = collections.defaultdict(list)\n",
            "8for idx, feature in enumerate(features):\n",
            "9 example_to_features[feature[’example_id’]].append(idx)\n",
            "10\n",
            "11 predicted_answers = []\n",
            "12 for example in tqdm(examples):\n",
            "13 example_id = example[’id’]\n",
            "14 context = example[’context’]\n",
            "15 answers = []\n",
            "16\n",
            "17 # Lặp qua tất cả các đặc trưng liên quan đến ví dụ đó\n",
            "18 for feature_index in example_to_features[example_id]:\n",
            "19 start_logit = start_logits[feature_index]\n",
            "20 end_logit = end_logits[feature_index]\n",
            "21 offsets = features[feature_index][’offset_mapping’]\n",
            "22\n",
            "23 # Lấy các chỉ số có giá trị lớn nhất cho start và end logits\n",
            "24 start_indexes = np.argsort(start_logit)[-1:-N_BEST-1:-1].tolist()\n",
            "25 end_indexes = np.argsort(end_logit)[-1:-N_BEST-1:-1].tolist()\n",
            "26 for start_index in start_indexes:\n",
            "27 for end_index in end_indexes:\n",
            "28 # Bỏ qua các câu trả lời\n",
            "29 # không hoàn toàn nằm trong ngữ cảnh\n",
            "30 if offsets[start_index] is None or \\\n",
            "31 offsets[end_index] is None:\n",
            "32 continue\n",
            "33 # Bỏ qua các câu trả lời có độ dài > max_answer_length\n",
            "34 if end_index - start_index + 1 > MAX_ANS_LENGTH:\n",
            "35 continue\n",
            "36\n",
            "37 # Tạo một câu trả lời mới\n",
            "38 text = context[\n",
            "39 offsets[start_index][0]:offsets[end_index][1]\n",
            "40 ]\n",
            "41 logit_score = start_logit[start_index] + \\\n",
            "42 end_logit[end_index]\n",
            "43 answer = {\n",
            "44 ’text’: text,\n",
            "45 ’logit_score’: logit_score,\n",
            "46 }\n",
            "47 answers.append(answer)\n",
            "48\n",
            "49 # Chọn câu trả lời có điểm số tốt nhất\n",
            "50 if len(answers) > 0:\n",
            "51 best_answer = max(answers, key=lambda x: x[’logit_score’])\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "52 answer_dict = {\n",
            "53 ’id’: example_id,\n",
            "54 ’prediction_text’: best_answer[’text’],\n",
            "55 ’no_answer_probability’: 1 - best_answer[’logit_score’]\n",
            "56 }\n",
            "57 else:\n",
            "58 answer_dict = {\n",
            "59 ’id’: example_id,\n",
            "60 ’prediction_text’: ’’,\n",
            "61 ’no_answer_probability’: 1.0\n",
            "62 }\n",
            "63 predicted_answers.append(answer_dict)\n",
            "64\n",
            "65 # Tạo danh sách câu trả lời lý thuyết từ các ví dụ\n",
            "66 theoretical_answers = [\n",
            "67 {’id’: ex[’id’], ’answers’: ex[’answers’]} for ex in examples\n",
            "68 ]\n",
            "69 # Sử dụng metric.compute để tính toán các độ đo và trả về kết quả\n",
            "70 return metric.compute(\n",
            "71 predictions=predicted_answers,\n",
            "72 references=theoretical_answers\n",
            "73 )\n",
            "Sau khi đã định nghĩa hàm evaluation, ta sẽ tiến hành predict model trên tập validation rồi\n",
            "đưa vào hàm compute_metrics:\n",
            "1# Thực hiện dự đoán trên tập dữ liệu validation\n",
            "2predictions, _, _ = trainer.predict(validation_dataset)\n",
            "3\n",
            "4# Lấy ra thông tin về các điểm bắt đầu và\n",
            "5# điểm kết thúc của câu trả lời dự đoán\n",
            "6start_logits, end_logits = predictions\n",
            "7\n",
            "8# Tính toán các chỉ số đánh giá sử dụng hàm compute_metrics\n",
            "9results = compute_metrics(\n",
            "10 start_logits,\n",
            "11 end_logits,\n",
            "12 validation_dataset,\n",
            "13 raw_datasets[\"validation\"]\n",
            "14)\n",
            "15results\n",
            "(g)Load model from hub: Ở phần trước, xong khi training model xong thì ta đã đưa model\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "lên HuggingFace, nếu muốn sử dụng thì ta chỉ cần dùng class pipeline có sẵn của HuggingFace\n",
            "là đã có thể load model và tiến hành inference:\n",
            "1# Use a pipeline as a high-level helper\n",
            "2from transformers import pipeline\n",
            "3\n",
            "4PIPELINE_NAME = ’question-answering’\n",
            "5MODEL_NAME = ’thangduong0509/distilbert-finetuned-squadv2’\n",
            "6pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)\n",
            "Sau đây ta sẽ chạy thử một example để test model:\n",
            "1INPUT_QUESTION = ’What is my name?’\n",
            "2INPUT_CONTEXT = ’My name is AI Vietnam and I live in Vietnam.’\n",
            "3pipe(question=INPUT_QUESTION, context=INPUT_CONTEXT)\n",
            "4\n",
            "5## >> Output: {’score’: 0.97179114818573, ’start’: 11, ’end’: 21, ’answer’: ’\n",
            "AI Vietnam’}\n",
            "3.Retriever: Faiss (Facebook AI Similarity Search) là một thư viện được phát triển bởi Facebook\n",
            "AI Research Team, hỗ trợ trong việc tìm kiếm tương đồng và phân cụm (clustering) các vector\n",
            "với tốc độ và độ chính xác cao. Các bạn có thể đọc thêm về Faiss tại đây.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 3: Source\n",
            "Tại đây, chúng ta sẽ ứng dụng Faiss để làm module Retriever cho hệ thống E2E QA của chúng\n",
            "ta. Với nhiệm vụ tìm kiếm các context phù hợp nhất cho câu hỏi đầu vào, ta sẽ cài đặt Faiss theo\n",
            "cách thức như sau:\n",
            "(a) Với bộ dữ liệu SQuAD2.0, ta sẽ xây dựng một database chứa thêm cột đại diện cho vector\n",
            "embedding của câu hỏi.\n",
            "(b) Thực hiện embedding các câu hỏi sử dụng DistilBERT.\n",
            "(c) Thực hiện tìm kiếm tương đồng giữa các vector trong cột mới và vector câu hỏi đầu vào, từ\n",
            "đó tìm ra nội dung context có liên quan nhất.\n",
            "Quy trình xử lý của Faiss trong bài có thể được tóm gọn qua ảnh sau:\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 4: Minh họa các bước xây dựng một vector database với Faiss\n",
            "Để cài đặt Faiss phục vụ cho việc tìm kiếm các văn bản context của các câu hỏi có nội dung giống\n",
            "với câu hỏi đầu vào, ta thực hiện như sau:\n",
            "(a)Cài đặt và import các thư viện cần thiết:\n",
            "1!pip install -qq transformers[sentencepiece]==4.35.2 datasets==2.16.1\n",
            "evaluate==0.4.1\n",
            "2!sudo apt-get install libomp-dev\n",
            "3!pip install -qq faiss-gpu\n",
            "1import numpy as np\n",
            "2import collections\n",
            "3import torch\n",
            "4import faiss\n",
            "5import evaluate\n",
            "6\n",
            "7from datasets import load_dataset\n",
            "8from transformers import AutoTokenizer, AutoModel\n",
            "9from transformers import AutoModelForQuestionAnswering\n",
            "10from transformers import TrainingArguments\n",
            "11from transformers import Trainer\n",
            "12from tqdm.auto import tqdm\n",
            "13\n",
            "14device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
            "\"cpu\")\n",
            "(b)Tải bộ dữ liệu: Ta tải bộ dữ liệu SQuAD2.0:\n",
            "1DATASET_NAME = ’squad_v2’\n",
            "2raw_datasets = load_dataset(DATASET_NAME, split=’train+validation’)\n",
            "3raw_datasets\n",
            "Để tận dụng toàn bộ ngữ liệu, chúng ta sẽ gom hai bộ dữ liệu train và validation trong bước\n",
            "tạo vector database này.\n",
            "(c)Loại bỏ các mẫu không có đáp án: Các mẫu dữ liệu không có đáp án thường chứa các\n",
            "câu hỏi không liên quan đến đoạn văn ngữ cảnh. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Vì vậy, ta sẽ loại bỏ các trường hợp này ra\n",
            "khỏi bộ dữ liệu:\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1raw_datasets = raw_datasets.filter(\n",
            "2lambda x: len(x[’answers’][’text’]) > 0\n",
            "3)\n",
            "(d)Khởi tạo mô hình: Để tạo vector embedding cho các câu hỏi, ta sẽ sử dụng mô hình\n",
            "pre-trained DistilBERT:\n",
            "1MODEL_NAME = \"distilbert-base-uncased\"\n",
            "2tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
            "3model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
            "(e)Xây dựng hàm lấy vector embedding: Ở đây, ta sẽ xây dựng một hàm trả về vector\n",
            "embedding cho một đoạn text đầu vào, cụ thể ở đây sẽ là câu hỏi. Để tạo vector embedding\n",
            "đại diện cho câu hỏi, ta sẽ sử dụng vector hidden state từ token [CLS] trong kết quả output\n",
            "của mô hình DistilBERT:\n",
            "Hình 5: Ảnh minh họa vị trí của final hidden state của token CLS.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Đầu tiên, ta xây dựng hàm lấy final hidden state của token CLS:\n",
            "1def cls_pooling(model_output):\n",
            "2return model_output.last_hidden_state[:, 0]\n",
            "Sau đó, xây dựng hàm đưa một văn bản vào model để từ đó có thể gọi hàm cls_pooling():\n",
            "1def get_embeddings(text_list):\n",
            "2encoded_input = tokenizer(\n",
            "3 text_list,\n",
            "4 padding=True,\n",
            "5 truncation=True,\n",
            "6 return_tensors=’pt’\n",
            "7)\n",
            "8encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
            "9model_output = model(**encoded_input)\n",
            "10\n",
            "11 return cls_pooling(model_output)\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(f)Xây dựng vector database: Với hàm tạo vector embedding đã triển khai, ta sẽ sử dụng nó\n",
            "để tạo một cột trong bảng dữ liệu dùng để chứa kết quả lời gọi hàm get_embeddings() với input\n",
            "là các câu hỏi của từng mẫu dữ liệu. Cụ thể, ta tạo cột mới tên là question_embedding\n",
            "và lưu vector embedding của câu hỏi như sau:\n",
            "1EMBEDDING_COLUMN = ’question_embedding’\n",
            "2embeddings_dataset = raw_datasets.map(\n",
            "3lambda x: {\n",
            "4 EMBEDDING_COLUMN: get_embeddings(\n",
            "5 x[’question’]\n",
            "6 ).detach().cpu().numpy()[0]\n",
            "7}\n",
            "8)\n",
            "Sau đó, để có thể tìm kiếm các vector tương đồng, ta sẽ tạo một cấu trúc dữ liệu đặc biệt là\n",
            "Faiss Index như sau:\n",
            "1embeddings_dataset.add_faiss_index(column=EMBEDDING_COLUMN)\n",
            "Cuối cùng, chúng ta đã có một vector database lưu trữ vector embedding của các câu hỏi\n",
            "trong bộ dữ liệu. Từ đây, ta sẽ tiến hành thử thực hiện truy vấn với một câu hỏi đầu vào\n",
            "bất kì như sau:\n",
            "1input_question = ’When did Beyonce start becoming popular?’\n",
            "2\n",
            "3input_quest_embedding = get_embeddings([input_question])\n",
            "4input_quest_embedding = input_quest_embedding.cpu().detach().numpy()\n",
            "5\n",
            "6TOP_K = 5\n",
            "7scores, samples = embeddings_dataset.get_nearest_examples(\n",
            "8EMBEDDING_COLUMN, input_quest_embedding, k=TOP_K\n",
            "9)\n",
            "10\n",
            "11for idx, score in enumerate(scores):\n",
            "12 print(f’Top {idx + 1}\\tScore: {score}’)\n",
            "13 print(f’Question: {samples[\"question\"][idx]}’)\n",
            "14 print(f’Context: {samples[\"context\"][idx]}’)\n",
            "15 print()\n",
            "Khi chạy xong đoạn lệnh trên, ta được kết quả trả về như sau:\n",
            "Hình 6: Kết quả truy vấn được in ra màn hình\n",
            "Có thể thấy, vì câu hỏi đầu vào có tồn tại trong vector database của chúng ta nên mẫu dữ\n",
            "liệu tương đồng nhất cũng chính là mẫu có câu hỏi tương tự.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(g)Áp dụng mô hình hỏi-đáp để trả lời câu hỏi: Như vậy, chúng ta đã có hai thành\n",
            "phần Retriever và Reader. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Chúng ta sẽ viết một đoạn code ngắn để thực hiện chương trình\n",
            "End-to-End QA. Đầu tiên, khởi tạo mô hình hỏi-đáp đã huấn luyện:\n",
            "1from transformers import pipeline\n",
            "2\n",
            "3PIPELINE_NAME = ’question-answering’\n",
            "4MODEL_NAME = ’thangduong0509/distilbert-finetuned-squadv2’\n",
            "5pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)\n",
            "Tận dụng kết quả truy vấn vừa rồi (nằm ở biến scoresvàsamples), chúng ta sẽ truyền vào\n",
            "mô hình QA hai thông tin gồm question và context:\n",
            "1print(f’Input question: {input_question}’)\n",
            "2for idx, score in enumerate(scores):\n",
            "3question = samples[\"question\"][idx]\n",
            "4context = samples[\"context\"][idx]\n",
            "5answer = pipe(\n",
            "6 question=question,\n",
            "7 context=context\n",
            "8)\n",
            "9print(f’Top {idx + 1}\\tScore: {score}’)\n",
            "10 print(f’Context: {context}’)\n",
            "11 print(f’Answer: {answer}’)\n",
            "12 print()\n",
            "Hình 7: Kết quả E2E QA được in ra màn hình\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. So với QA, chương trình End-to-end QA có điểm gì khác biệt?\n",
            "(a) Mô hình trích xuất câu hỏi tốt hơn.\n",
            "(b) Sử dụng kiến trúc transformer.\n",
            "(c) Có sử dụng mô hình tìm kiếm context.\n",
            "(d) Tốc độ xử lý nhanh hơn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2. Tại sao mô hình Transformer được sử dụng phổ biến trong bài toán Question Answering (QA)?\n",
            "(a) Do Transformer có khả năng tự học đặc trưng từ văn bản tự nhiên.\n",
            "(b) Do Transformer chứa nhiều kiến thức về dữ liệu.\n",
            "(c) Có sử dụng mô hình tìm kiếm context.\n",
            "(d) Do Transformer có khả năng xử lý dữ liệu dạng sequence.\n",
            "3. Trong QA, tại sao phải sử dụng Transfer learning?\n",
            "(a) Transfer learning giúp mô hình học được kiến thức từ dữ liệu lớn.\n",
            "(b) Mô hình QA không cần sử dụng transfer learning.\n",
            "(c) Transfer learning làm gia tăng khả năng xử lý của CPU.\n",
            "(d) Transfer learning giúp mô hình bị overfitting.\n",
            "4. Mô hình End-to-end QA khác biệt với QA truyền thống ở điểm nào?\n",
            "(a) Mô hình End-to-end QA sử dụng mô hình tìm kiếm context.\n",
            "(b) Mô hình End-to-end QA có khả năng tự động xây dựng câu hỏi.\n",
            "(c) Mô hình End-to-end QA sử dụng RNN để trích xuất câu trả lời.\n",
            "(d) Mô hình End-to-end QA chỉ hoạt động trên dữ liệu có cấu trúc.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "5. Tham số stride có nghĩa là gì trong đoạn code sau:\n",
            "1inputs = tokenizer(\n",
            "2question, # Danh sách các câu hỏi\n",
            "3context, # Nội dung liên quan đến câu hỏi\n",
            "4max_length=MAX_LENGTH, # Độ dài tối đa cho đầu ra mã hóa\n",
            "5truncation=\"only_second\", # Cắt bớt dữ liệu chỉ cho phần thứ hai (context)\n",
            "6stride=STRIDE,\n",
            "7return_overflowing_tokens=True, # Trả về các tokens vượt quá độ dài tối đa\n",
            "8return_offsets_mapping=True, # Trả về bản đồ vị trí của các tokens trong văn\n",
            "bản gốc\n",
            "9padding=\"max_length\" # Điền vào dữ liệu để có cùng độ dài max_length\n",
            "10)\n",
            "(a) Độ dài bước nhảy trong trường hợp dữ liệu dài hơn max_length\n",
            "(b) Độ dài bước nhảy trong trường hợp dữ liệu ngắn hơn max_length\n",
            "(c) Độ dài bước nhảy trong trường hợp dữ liệu bằng max_length\n",
            "(d) Độ dài bước nhảy trong trường hợp bất kỳ\n",
            "6. Tham số fp16=True có nghĩa là gì trong đoạn code sau:\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1# Tạo đối tượng args là các tham số cho quá trình huấn luyện\n",
            "2args = TrainingArguments(\n",
            "3output_dir=\"distilbert-finetuned-squadv2\", # Thư mục lưu trữ kết quả huấn\n",
            "luyện\n",
            "4evaluation_strategy=\"no\", # Chế độ đánh giá không tự động sau mỗi epoch\n",
            "5save_strategy=\"epoch\", # Lưu checkpoint sau mỗi epoch\n",
            "6learning_rate=2e-5, # Tốc độ học\n",
            "7num_train_epochs=3, # Số epoch huấn luyện\n",
            "8weight_decay=0.01, # Giảm trọng lượng mô hình để tránh overfitting\n",
            "9fp16=True,\n",
            "10 push_to_hub=True, # Đẩy kết quả huấn luyện lên một nơi chia sẻ trực tuyến (\n",
            "Hub)\n",
            "11)\n",
            "(a) Sử dụng kiểu dữ liệu 32-bit để tối ưu hóa tài nguyên\n",
            "(b) Sử dụng kiểu dữ liệu double để tối ưu hóa tài nguyên\n",
            "(c) Sử dụng kiểu dữ liệu float để tối ưu hóa tài nguyên\n",
            "(d) Sử dụng kiểu dữ liệu half-precision để tối ưu hóa tài nguyên\n",
            "7. Trong đoạn code sau đây, biến PIPELINE_NAME dùng để làm gì?\n",
            "1# Use a pipeline as a high-level helper\n",
            "2from transformers import pipeline\n",
            "3\n",
            "4PIPELINE_NAME = ’question-answering’\n",
            "5MODEL_NAME = ’thangduong0509/distilbert-finetuned-squadv2’\n",
            "6pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)\n",
            "(a) Xác định tên của task hiện tại, người dùng có thể đặt tên bất kỳ\n",
            "(b) Xác định tên của task hiện tại, người dùng phải đặt đúng tên quy định của HuggingFace\n",
            "(c) Tên của model, người dùng phải đặt tên đúng yêu cầu\n",
            "(d) Tên của model, người dùng có thể đặt bất kỳ\n",
            "8. Ưu điểm của vector database khi xử lý các loại dữ liệu phức tạp như hình ảnh, âm thanh và văn\n",
            "bản so với cơ sở dữ liệu quan hệ truyền thống là gì?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(a) Nó cung cấp khả năng chuẩn hóa dữ liệu và ràng buộc tính toàn vẹn tốt hơn.\n",
            "(b) Nó cho phép tìm kiếm và truy vấn dữ liệu dựa trên nội dung một cách hiệu quả.\n",
            "(c) Nó cung cấp các cơ chế kiểm soát giao dịch mạnh mẽ hơn.\n",
            "(d) Nó tăng cường khả năng truy vấn SQL cho phân tích dữ liệu có cấu trúc.\n",
            "9. Để tính sự tương đồng giữa hai vector, độ đo nào sau đây không thể áp dụng?\n",
            "(a) Cosine Similarity\n",
            "(b) Euclidean Distance\n",
            "(c) Pearson Correlation Coefficient\n",
            "(d) Maximum Likelihood Estimation\n",
            "10. Khi ứng dụng BERT để tạo vector embedding trong vector database, final hidden state của token\n",
            "nào thường được sử dụng trong output của BERT?\n",
            "(a)[CLS]token\n",
            "(b)[SEP]token\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(c)[EOS]token\n",
            "(d) Final token\n",
            "11. Trong các vector database như Faiss, kỹ thuật nào thường được sử dụng để tối ưu hiệu quả tìm\n",
            "kiếm trên dữ liệu đa chiều?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(a) Linear Search\n",
            "(b) Indexing\n",
            "(c) Quantization\n",
            "(d) Encryption\n",
            "12. Trong đoạn code dưới đây:\n",
            "1TOP_K = 5\n",
            "2scores, samples = embeddings_dataset.get_nearest_examples(\n",
            "3EMBEDDING_COLUMN, input_quest_embedding, k=TOP_K\n",
            "4)\n",
            "BiếnTOP_Kcòn được hiểu là?\n",
            "(a) Số lượng cluster\n",
            "(b) Số lượng kết quả trả về\n",
            "(c) Số epochs\n",
            "(d) Số chiều trong không gian embedding\n",
            "- Hết -\n",
            "18\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – COURSE 2023\n",
            "Foundation of Prompt Engineering\n",
            "Ngày 19 tháng 3 năm 2024\n",
            "Phần I: Tổng quan về RAG\n",
            "Phần II: Retrieval Augmented Generation\n",
            "(RAG)\n",
            "Trong bối cảnh các mô hình ngôn ngữ lớn (LLM) phát triển mạnh mẽ, sự xuất hiện của các mô hình\n",
            "GPT (OpenAI), LLama (Meta), Gemini (Google) đã thể hiện khả năng ấn tượng trong việc sinh ngôn\n",
            "ngữ, thực hiện tác tác vụ với ngôn ngữ tự nhiên. Cho dù vậy, các mô hình ngôn ngữ lớn vẫn cho thấy\n",
            "còn nhiều điểm yếu như dữ liệu thiếu tính cập nhật, thiếu dữ liệu chuyên môn cho các lĩnh vực cụ thể\n",
            "hay sinh ngôn ngữ thiếu chính xác (hay được biết đến với thuật ngữ \"hallucination\").\n",
            "Bên cạnh đó, nhu cầu sử dụng mô hình ngôn ngữ để tương tác với dữ liệu riêng, dữ liệu doanh\n",
            "nghiệp cũng gặp nhiều khó khăn với việc các giải pháp fine-tuning, training LLM bởi chi phí lớn và yêu\n",
            "cầu kỹ thuật cao. RAG ra đời cung cấp giải pháp nhanh chóng, tiện lợi cho phép LLM sử dụng thông\n",
            "tin bổ sung để giao tiếp, ...\n",
            "1 Khái niệm RAG\n",
            "Retrieval Augmented Generation (RAG) lần đầu được giới thiệu bởi nhóm kỹ sư thuộc Meta AI là một\n",
            "kỹ thuật trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) nhằm nâng cao độ chính xác và tin cậy của các\n",
            "mô hình tạo văn bản (Generative language models - LLMs). RAG kết hợp hai thành phần chính: cấu\n",
            "phần truy xuất thông tin (Retriever) và mô hình sinh ngôn ngữ (Generator):\n",
            "•Truy xuất thông tin (Retrieval): RAG không chỉ dựa vào dữ liệu đào tạo ban đầu của LLM\n",
            "mà còn truy cập một nguồn kiến thức bên ngoài, thường là các văn bản được xác định trước và\n",
            "có độ tin cậy cao. Khi nhận được yêu cầu, RAG sẽ phân tích nó và tìm kiếm thông tin liên quan\n",
            "trong nguồn kiến thức bên ngoài.\n",
            "•Tạo văn bản (Generation): Dựa trên thông tin đã truy xuất, LLM sẽ tạo ra văn bản phản hồi\n",
            "phù hợp với yêu cầu. Quá trình này có thể bao gồm tóm tắt, giải thích, trả lời câu hỏi, viết văn\n",
            "bản sáng tạo, v.v.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trong bài báo của Lewis et al. (2021), khi lần đầu đề cấp đến hệ thống RAG, Lewis đã sử dụng một\n",
            "mô hình seq2seq huấn luyện trước ...\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 1: Giải pháp RAG cung cấp bởi Lewis (2020). Giải pháp kết hợp một mô hình truy vấn được huấn\n",
            "luyện trước (Query Encoder + Document Index) và một mô hình seq2seq huấn luyện trước (Generator).\n",
            "Với đầu vào là truy vấn x, Maximum Inner Product Search (MIPS) được sử dụng để tìm ra top-k tài\n",
            "liệu liên quan. Tài liệu tìm thấy được sử dụng trong phần dự báo của mô hình seq2seq.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 2: Hệ thống RAG cơ bản với các cấu phần: Nguồn thông tin tra cứu (Knowledge Base), Truy vấn\n",
            "(Retriever), Mô hình sinh (Generator), Truy vấn đầu vào và Kết quả đầu ra.\n",
            "Hệ thống RAG cho phép tìm kiếm và nhận về các tài liệu liên quan đến câu hỏi truy vấn của người\n",
            "dùng. Các tài liệu này được sử dụng như nguồn thông tin kết hợp với câu hỏi truy vấn để tạo ra câu\n",
            "trả lời cuối cùng thông qua một mô hình sinh ngôn ngữ. Phương pháp này cho phép RAG thích ứng với\n",
            "các yêu cầu mà nguồn thông tin thay đổi theo thời gian thực, truy cập thông tin mới nhất, tạo ra kết\n",
            "quả đáng tin câỵ mà không cần phải huấn luyện lại mô hình. Đây cũng là lý do giúp RAG trở thành\n",
            "giải pháp hữu hiệu giải quyết nhược điểm \"hallucination\" của các mô hình ngôn ngữ huấn luyện trước.\n",
            "2 Cấu trúc tổng quan\n",
            "Tương tự như các giải pháp LLM khác, hệ thống RAG tiếp nhận yêu cầu người dùng (User Query) và\n",
            "xử lý để đưa ra kết quả trả về (Output). Ngoài ra hai cấu phần chính của hệ thống RAG là bộ truy\n",
            "vấn (Retriever) và mô hình sinh (Generator). Thông thường, bên cạnh Retriever, một cơ sở dữ liệu phi\n",
            "cấu trúc (Knowledge Base) cần được được thiết lập và xử lý trước.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 3: Ví dụ chi tiết hoạt động của hệ thống RAG. Nguồn: Gao et al. (2024)\n",
            "Các thành phần trong ví dụ có thể giải thích như sau:\n",
            "•Input:Câu hỏi đầu vào, thường được cung cấp/yêu cầu bởi người dùng nhằm truy vấn và tương\n",
            "tác với mô hình ngôn ngữ.\n",
            "•Indexing: Trong hệ thống RAG, để xây dựng Knowledge Base, các văn bản/tài liệu cần được xử\n",
            "lý (indexing) và lưu trữ dưới các định dạng dễ dàng truy vấn như vector. Các thao tác cần xử\n",
            "lý có thể kể đến như phân đoạn (chunking), vector hoá (embedding), lưu trữ trên cơ sở dữ liệu\n",
            "vector (vector store database). Trong quá trình truy vấn, câu hỏi người dùng sẽ được embedded\n",
            "để sẵn sàng cho các thuật toán tìm kiếm.\n",
            "•Retrieval: Quá trình tìm kiếm các đoạn tài liệu (chunks) liên quan đến câu hỏi truy vấn. Công\n",
            "tác tìm kiếm thường được thực hiện thông qua phép tìm kiếm mức độ tương đồng (similarity), so\n",
            "sánh vector truy vấn và vector đã được xử lý (index) trong cơ sở dữ liệu vector. Các kết quả có\n",
            "similarity score cao thể hiện mức độ tương quan tốt với câu hỏi truy vấn. Giá trị top-k cũng được\n",
            "thiết lập tại bước này nhằm thể hiện số lượng k tài liệu có score cao nhất được lấy ra từ bước này.\n",
            "•Generation: Khái niệm thể hiện cho các mô hình sinh ngôn ngữ, có thể biết đến như các mô\n",
            "hình ngôn ngữ lớn (từ các mô hình thương mại như GPT - OpenAI, Gemini - Google, Claude\n",
            "- Anthropic cho đến các mô hình mã nguồn mở như Llama - MetaAI, BLOOM, BERT, Falcon,\n",
            "Mixtral, Vicuna, PhoGPT,...). Trong hệ thống RAG, các tài liệu liên quan được đưa vào mô hình\n",
            "ngôn ngữ cùng câu hỏi dưới dạng prompt (ngữ cảnh bổ sung thông tin). Kết quả từ mô hình ngôn\n",
            "ngữ được đưa về người dùng như câu trả lời.\n",
            "3 Phân loại RAG\n",
            "Theo Yunfan Gao et al, một khảo sát tổng hợp chi tiết về sự phát triển của các hệ thống RAG đã được\n",
            "thực hiện và ra công bố vào những ngày đầu năm dương lịch 2024 Gao et al. (2024). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Theo đó, các hệ\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "thống RAG có thể được phân loại theo các bước phát triển của mô hình từ RAG cơ bản (Naive) đến\n",
            "RAG nâng cao (Advanced) và Mô-đun RAG (Modular). Các mô hình có sự cập nhật và giải quyết được\n",
            "các giới hạn của mô hình trước về các mặt mức độ thể hiện (performance), thời gian và hiệu quả (cost\n",
            "and efficiency).\n",
            "Hình 4: Phân loại hệ thống RAG. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nguồn: Gao et al. (2024)\n",
            "(a)RAG cơ bản bao gồm các bước thực hiện truyền thống từ: xử lý dữ liệu nguồn (indexing), truy\n",
            "vấn (retrieval) và sinh câu trả lời (generation). RAG cơ bản tồn tại các giới hạn như chỉ lệ chính\n",
            "xác chưa cao đén từ việc truy vấn thiếu chính xác các phân đoạn tài liệu (chunks) liên quan. Điều\n",
            "này cũng là nguyên nhân khiến các vấn đề về \"tự cho mình đúng\" (hallucination) từ các mô hình\n",
            "LLM còn tồn tại.\n",
            "(b)RAG nâng cao cung cấp các giải pháp giải quyết nhược điểm của RAG cơ bản như cải thiện\n",
            "chất lượng truy vấn bằng cách thực thi các giải pháp tiền truy vấn, trong truy vấn và sau truy\n",
            "vấn.\n",
            "•Giải pháp tiền truy vấn: bao gồm tối ưu quá trình xử lý dữ liệu nguồn như tối ưu cấu\n",
            "trúc tài liệu đã xử lý bằng các phương pháp tách tài liệu (chunking khác nhau: sentence\n",
            "splitter, sentence window, semantic splitter, hierarchical,...), bổ sung metadata, tối ưu mô\n",
            "hình embedding bằng embedding fine-tuning,...\n",
            "•Giải pháp truy vấn: Quá trình truy vấn có thể được cải thiện bằng các giải pháp viết lại\n",
            "câu hỏi truy vấn (Sub-queries), truy vấn mở rộng (sử dụng bộ lọc metadata), truy vấn với\n",
            "các phương pháp khác nhau (full-text search, semantic-search, hybrid-search).\n",
            "•Giải pháp sau truy vấn: Các kết quả sau khi truy vấn với nhiều phương pháp được xếp\n",
            "hạng lại nhằm đánh giá lại mức độ tương quan trước khi chọn ra top-k tài liệu liên quan\n",
            "nhất.\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(c)Mô-đun RAG: Một cách hệ thống, giải pháp RAG bao gồm nhiều cấu phần, mỗi cấu phần thực\n",
            "hiện các chức năng khác nhau. Mô-đun RAG được thiết kế với các mô đun chức năng nhằm cải\n",
            "thiện chất lượng của các cấu phần thuộc hệ thống RAG. Một cách tổng quan, RAG cơ bản là một\n",
            "giải pháp thuộc RAG nâng cao, RAG nâng cao là một trường hợp của Mô-đun RAG với các chức\n",
            "năng cố định. Các mô đun RAG bao gồm tìm kiếm (Search), bộ nhớ (Memory), kết hợp (Fusion),\n",
            "(Routing), (Predict), (Task Adaptable Module). Các mô đun này được sắp xếp để giải quyết các\n",
            "vấn đề cụ thể.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nhằm tăng tính linh hoạt của hệ thống RAG, một số kỹ thuật có thể áp dụng như:\n",
            "•Hybrid Search Exploration: Là giải pháp kết hợp hai giải pháp tìm kiếm là tìm kiếm với\n",
            "từ khoá (keyword) và tìm kiếm theo ngữ nghĩa (semantic). Giải pháp này tối ưu được kết\n",
            "quả chính xác từ việc tìm theo từ khoá và việc linh hoạt tìm kiếm với các từ cùng ngữ cảnh.\n",
            "Kết hợp với giải pháp này thường là các thuật toán xếp hạng (reranker) để phân hạng lại\n",
            "các kết quả có được từ hai phương pháp tìm kiếm.\n",
            "•Recursive Retrieval and Query Engine: Giải pháp cung cấp phương pháp phân chia\n",
            "tài liệu hiệu quả với các cấp phân chia. Cấp nhỏ để phân chia thành các đoạn tài liệu ngắn\n",
            "nhằm gia tăng khả năng tìm kiếm các nội dung tương đồng. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sau đó, cấp lớn chứa đoạn tài\n",
            "liệu dài hơn, bao chùm ngữ cảnh tốt hơn (chứa đoạn nhỏ) được trả về như kết quả tìm kiếm.\n",
            "Giải pháp cho phép tìm kiếm chính xác hơn mà vẫn giữ được ngữ cảnh của tài liệu.\n",
            "•Sub-Queries: Trong bối cảnh thực tế, rất nhiều loại truy vấn được thực hiện. Nhằm tối ưu\n",
            "việc truy vấn, các giải pháp về truy vấn được đề xuất, từ việc đơn giản hoá truy vấn, truy\n",
            "vấn nhiều cấp hay xác định chủ đích truy vấn. Các giải pháp này nhằm tăng cường mức độ\n",
            "hoàn thiện của đầu vào truy vấn, cũng như nâng cao mức độ chính xác của kết quả truy vấn.\n",
            "•Hypotherical Document Embeddings: Gao et al. (2022) đã đưa ra giải pháp mới với\n",
            "quan điểm tìm kiếm dựa trên một câu trả lời giả thuyết sẽ cho kết quả tốt hơn tìm kiếm\n",
            "trực tiếp với câu hỏi truy vấn. Giải pháp HyDE sử dụng một LLM để tạo ra một câu trả lời\n",
            "giả thuyết cho câu hỏi truy vấn. Sau đó câu trả lời này được sử dụng làm đầu vào cho việc\n",
            "tìm kiếm thông tin liên quan. Kết quả tìm kiếm sẽ được đưa trở lại LLM cùng câu hỏi truy\n",
            "vấn để tạo ra câu trả lời cuối cùng. Trên thực tế, giải pháp này không phải lúc nào cũng\n",
            "hiệu quả do phụ thuộc hoàn toàn vào câu trả lời giả thuyết. Khi chủ đề của câu hỏi không\n",
            "có sẵn trong dữ liệu được huấn luyện trước của LLM, kết quả nhận về thường không được\n",
            "như mong đợi.\n",
            "4 Cấu phần RAG\n",
            "Trong nội dung này, chi tiết các giải pháp cho từng cấu phần của hệ thống RAG: Retrieval, Augmented,\n",
            "Generation sẽ được đề cập. Mỗi giải pháp có điểm mạnh riêng và phù hợp với các trường hợp cụ thể.\n",
            "4.1 Tăng cường (Augmented) và Truy vấn (Retrieval) dữ liệu\n",
            "Tăng cường và truy vấn là cấu phần quan trọng trong việc tổ chức và tìm kiếm tài liệu liên quan với\n",
            "yêu cầu người dùng (user query). Việc xây dựng một quy trình truy vấn hiệu quả luôn là vấn đề then\n",
            "chốt trong mọi hệ thống RAG.\n",
            "Trong các mô hình RAG, công tác tổ chức truy vấn bao gồm cả nhiệm vụ tăng cường (augmented)\n",
            "tổ chức cơ sở dữ liệu (xử lý dữ liệu thô, lưu trữ, duy trì ngữ nghĩa,...) và nhiệm vụ tìm kiếm tài liệu\n",
            "(tra cứu thông tin liên quan theo yêu cầu của người dùng). Dưới góc nhìn của người viết, ba cấu phần\n",
            "chính của công tác Truy vấn được phân loại bao gồm: Xử lý dữ liệu đầu vào (Data Structure), Xử lý\n",
            "lưu trữ và đại diện ngữ nghĩa (Semantic Representation), Truy vấn - tìm kiếm (Searching).\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 5: Các nhiệm vụ trong công tác Truy vấn - Retrieval\n",
            "4.1.1 Xử lý dữ liệu\n",
            "Các mô hình RAG tốt thường thích ứng với đa dạng các định dạng dữ liệu đầu vào. Tuy nhiên, một số\n",
            "bài toán cho dữ liệu riêng cần được thiết kế công cụ đọc và bóc tách dữ liệu hiệu quả.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Về phía các mô hình ngôn ngữ lớn (LLM) ở thời điểm hiện tại đều gặp giới hạn về độ dài ngữ cảnh\n",
            "(context) văn bản mà LLM có thể xử lý. Ví dụ: giới hạn 128k với GPT4 phiên bản mới nhất, 16k với\n",
            "GPT3.5, 32k với Gemini, 32k Llama-2, 8k Mixtral 8x7b,...\n",
            "Ngoài ra, việc đưa lượng lớn dữ liệu vào ngữ\n",
            "cảnh cho LLM được chứng minh là không hiệu quả\n",
            "với một số vị trí. Liu et al. (2023) bằng cách thử\n",
            "nghiệm với các ngữ cảnh dài đã chỉ ra rằng việc sử\n",
            "dụng ngữ cảnh dài sẽ gặp khó khăn với các câu hỏi\n",
            "mà thông tin liên quan nằm giữa ngữ cảnh. Các\n",
            "câu hỏi sử dụng thông tin nằm ở đầu và cuối của\n",
            "ngữ cảnh thường cho kết quả tốt hơn.\n",
            "Để giải quyết vấn đề này, việc chia nhỏ dữ liệu\n",
            "đầu vào với tham số độ dài và chiến lược phân\n",
            "chia (chunking) phù hợp là giải pháp vô cùng quan\n",
            "trọng. Đề bài đặt ra là xây dựng phép chia tài liệu\n",
            "mà ở đó kết quả sau khi phân chia, các thông tin\n",
            "nằm trong một đoạn phải có ý nghĩa liên quan với\n",
            "nhau và việc phân tách không được làm mất thông\n",
            "tin.\n",
            "Đi từ giải pháp RAG cơ bản, việc phân đoạn đơn\n",
            "giản là phân chia đoạn theo độ dài (chunk size) với\n",
            "đơn vị là tokens, hay bổ sung phân đoạn chồng lấn\n",
            "(overlap chunk) nhằm giữ lại thông tin giữa các\n",
            "chunks, phân chia theo câu (Sentence Splitter).\n",
            "Hình 6: Hiện tượng Lost in the Middle chỉ ra các\n",
            "mô hình LLM thể hiện kém với việc hỏi đáp liên\n",
            "quan đến thông tin nằm ở giữa ngữ cảnh dài.\n",
            "Tuy nhiên các giải pháp phân chia cơ bản thường gặp nhiều vấn đề như không các đoạn chia (chunk)\n",
            "không chứa thông tin liên quan. Độ dài của các phân đoạn thường là cố định nên không phù hợp. Nếu\n",
            "độ dài quá lớn sẽ dẫn đến khó tìm kiếm với thông tin chi tiết. Nếu độ dài quá ngắn sẽ dẫn đến khó có\n",
            "được bối cảnh tổng quan.\n",
            "Với giải pháp RAG nâng cao, các hướng tiếp cận hiệu quả hơn được đề cập nhằm đưa ra các phương\n",
            "án chia nhỏ tối ưu để có thể vừa nâng cao khả năng tìm kiếm chi tiết mà vẫn có được thông tin bối\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "cảnh. Độ dài của các phân đoạn có thể linh hoạt ấn định cho phù hợp với nội dung ngữ nghĩa. Một số\n",
            "giải pháp có thể kể đến như sau:\n",
            "•Sentence Window: là giải pháp phân chia theo câu kết hợp cửa sổ mở rộng. Dữ liệu được ngữ\n",
            "nghĩa hoá (word2vec) là đơn vị câu, tuy nhiên dữ liệu trả về là dữ liệu mở rộng cho câu lân cận.\n",
            "Tham số độ rộng cửa sổ được khai báo cho phép người dùng tuỳ chỉnh độ dài văn bản trả về.\n",
            "•Hierarchical Splitter: là giải pháp chia nhỏ dữ liệu theo nhiều cấp. Trong đó, các cấp được\n",
            "phân loại theo độ dài và được ví như các đoạn mẹ (parent) và các đoạn con (child). Các đoạn mẹ\n",
            "có độ dài lớn hơn sẽ bao gồm nhiều đoạn con, đoạn mẹ mang thông tin về ngữ cảnh. Ngược lại,\n",
            "các đoạn con có độ dài ngắn hơn sẽ chứa thông tin chi tiết về các đối tượng, phù hợp hơn cho các\n",
            "phép tìm kiếm chi tiết. Giải pháp này cho phép việc truy vấn có thể tìm kiếm với thông tin chi\n",
            "tiết mà không bị mất đi dữ kiện bối cảnh.\n",
            "•Semantic Splitter: Kamradt (2024) đã giới\n",
            "thiệu giải pháp phân đoạn thông minh nhằm tối\n",
            "ưu sự liên quan của các câu trong văn bản. Giải\n",
            "pháp sử dụng một mô hình embedding để đại\n",
            "diện ngữ nghĩa cho các phân đoạn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tác giả coi\n",
            "mỗi câu văn như một đơn vị trong một bài toán\n",
            "chuỗi thời gian (Time Series). Một thuật toán\n",
            "chạy lặp qua các cửa sổ được thực hiện để tìm\n",
            "ra điểm ngắt của các phân đoạn không liên quan\n",
            "với nhau về mặt ngữ nghĩa. Theo cách tiếp cận\n",
            "này, việc phân chia văn bản được thực hiện tự\n",
            "động mà vẫn giữ được thông tin liên quan giữa\n",
            "các câu văn trong cùng một phân đoạn (chunk).\n",
            " Hình 7: Giải pháp Semantic Splitter.\n",
            "•Agentic Splitter: Cũng trong phần trình bày của mình Kamradt (2024) đã giới thiệu giải pháp\n",
            "chia nhỏ Agentic dựa trên bài báo Chen et al. (2023).\n",
            "•EnhancingSemanticRepresentations,AligningQueriesandDocuments,AligningRe-\n",
            "triever and LLM\n",
            "Xử lý dữ liệu dạng bảng: Bên cạnh các giải pháp xử lý dữ liệu chữ, thông tin từ hệ thống bảng biểu\n",
            "cũng được cân nhắc. Bởi việc bóc tách xử lý chữ thông thường không giữ lại được cấu trúc và mối quan\n",
            "hệ trong các bảng biểu. Các phương pháp đơn giản sẽ chuyển đổi cấu trúc bảng thành các cấu trúc dễ\n",
            "hiểu hơn với máy như markdown hoặc html.\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 8: Xử lý thông tin dạng bảng với phép biến đổi markdown và html. Thông tin trích xuất trực tiếp\n",
            "với Raw-text cho thấy cấu trúc bảng không rõ ràng. Cấu trúc bảng của markdown và html cho phép\n",
            "các LLM dễ hiểu hơn nội dung trong bảng.\n",
            "Dữ liệu có cấu trúc: Một số giải pháp coi dữ liệu dạng bảng như một nguồn dữ liệu cung cấp\n",
            "các thông tin chính xác. Các giải pháp này tập trung vào việc nâng cao khả năng suy luận và truy vấn\n",
            "thông tin từ các cơ sở dữ liệu có cấu trúc.Wang et al. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "(2024) đề cập giải pháp có tên gọi Chain of Table,\n",
            "trong đó phương pháp thiết lập một chuỗi các lập luận với LLM để thực thi các truy vấn nhằm đạt\n",
            "được kết quả liên quan nhất với câu hỏi đầu vào.\n",
            "Hình 9: So sánh giải pháp truy vấn thông tin bảng biểu (a) generic reasoning, (b) program-aided\n",
            "reasoning, and (c) CHAIN-OF-TABLE..\n",
            "Knowledge Graph: Bên cạnh các kiến trúc lưu trữ dữ liệu truyền thống, Graph database hay\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Knowledge Graph được cân nhắc như một giải pháp hiệu quả để quản lý kiến thức. Bởi sự phát triển\n",
            "mối quan hệ theo chiều ngang, việc thiết lập các lập luận (reasoning) được thực hiện dễ dàng hơn. Tuy\n",
            "nhiên, các mô hình Knowledge Graph thường tốn công sức để xây dựng hơn các kiến trúc dữ liệu khác.\n",
            "4.1.2 Embedding Models\n",
            "Trong các tác vụ xử lý ngôn ngữ, embeddings đóng vai trò chuyển đổi, đại diện thông tin từ các các\n",
            "chủ thể như hình ảnh, âm thanh hay chữ. Trong giải pháp RAG, embeddings được sử dụng trong thuật\n",
            "toán tìm kiếm theo ngữ nghĩa (semantic search).\n",
            "Về mặt toán học, kết quả embeddings được lưu trữ dưới dạng các vector. Mỗi vector là một chuỗi\n",
            "các số, trong đó mỗi số tương ướng với một chiều không gian. Tại các chiều không gian đó, thuật toán\n",
            "tìm kiếm tương đồng (similar) được thực thi để tìm ra các vector gần nhau trong cơ sở dữ liệu vector.\n",
            "Như vậy, mục tiêu của embeddings là việc đại diện hoá thông tin từ ngữ cảnh (chữ) sang không gian\n",
            "vector sao cho các thông tin có nghĩa giống nhau sẽ có khoảng cách gần nhau.\n",
            "Hình 10: Embedding đại diện thông tin văn bản dưới dạng vector.\n",
            "Các mô hình embedding: Muennighoff et al. (2023) đã thực hiện đánh giá 08 tác vụ embedding\n",
            "trên 15 tập dataset, phủ 112 ngôn ngữ. Kết quả của đánh giá được thể hiện trên một bảng xếp hạng\n",
            "chất lượng của các mô hình embeddings.\n",
            "Hình 11: Kết quả đánh giá mô hình embeddings dựa trên mức độ thể hiện, tốc độ, số chiều, kích thước\n",
            "dữ liệu. Đánh giá được thực hiện trên phần cứng Nvidia A100 80GB, CUDA 11.6.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Dựa trên kết quả đánh giá, một bảng xếp hạng các mô hình embedding đã được xây dựng dựa vào\n",
            "các tiêu chí.\n",
            "Hình 12: Bảng xếp hạng các mô hình embeddings dựa trên kết quả đánh giá của Muennighoff et al.\n",
            "(2023)\n",
            "Hiệuchỉnh(fine-tuning)môhìnhembedding: TrongcácgiảiphápRAG,hiệuchỉnhembedding\n",
            "là một cách được cân nhắc để cải thiện chất lượng truy vấn. Các mô hình embedding gốc không được\n",
            "huấn luyện với dữ liệu riêng của người dùng nên việc đại diện ngữ nghĩa có thể không hoàn toàn tốt.\n",
            "Công tác hiệu chỉnh mô hình embedding là quá trình cập nhật lại tham số của mô hình với nhằm đưa\n",
            "thêm thông tin dữ liệu riêng vào mô hình.\n",
            "Các bước thực hiện hiệu chỉnh mô hình bao gồm:\n",
            "•Tạo dữ liệu huấn luyện: Bên cạnh việc xây dựng các tập dữ liệu huấn luyện một cách thủ công,\n",
            "nhiều giải pháp sử dụng các mô hình ngôn ngữ lớn để tạo dataset được sử dụng. Trong đó, LLM\n",
            "tạo ra câu hỏi giả thuyết tương ứng với thông tin chứa trong đoạn văn bản để tạo ra bộ câu hỏi -\n",
            "đoạn chứa thông tin liên quan.\n",
            "•Hiệu chỉnh mô hình embedding: Sử dụng tập dữ liệu được chuẩn bị trước và một mô hình\n",
            "embedding mã nguồn mở với thuật toán SentenceTransformers, việc huấn luyện hiệu chỉnh mô\n",
            "hình được thực hiện cùng các phép đánh giá đảm bảo mô hình đầu ra phù hợp với các tác vụ truy\n",
            "vấn. Code tham khảo cho hiệu chỉnh embedding model được viết bởi Jerry Liu.\n",
            "•Đánh giá mô hình: Đánh giá được thực thi để kiểm tra chất lượng mô hình sau khi hiệu chỉnh.\n",
            "Thông thường, việc hiệu chỉnh tốt sẽ tăng cường chất lượng của mô hình hỏi đáp từ 5-10 phần\n",
            "trăm.\n",
            "4.1.3 Giải pháp truy vấn (Retrieval)\n",
            "Dữ liệu sau khi xử lý được lưu trữ trên các cơ sở dữ liệu như Vector database, Knowledge graph hay\n",
            "non-sql (Mongodb). Công việc tiếp theo là thực thi các truy vấn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mục tiêu là truy vấn được các thông\n",
            "tin liên quan nhất với câu hỏi đầu vào. Một số giải pháp có thể đề cập đến như:\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Viết lại câu hỏi: Trong quá trình hỏi đáp, việc làm rõ câu hỏi đầu vào giúp cho việc tổ chức\n",
            "truy vấn hiệu quả. Việc sử dụng một LLM có hướng dẫn (instruction) để viết lại câu hỏi đầu vào\n",
            "của người dùng là giải pháp phù hợp với những câu hỏi quá đơn giản hoặc quá phức tạp.\n",
            "•Hypothetical Document Embedding: Tạo ra câu hỏi giả thuyết để phục vụ embedding và\n",
            "tìm kiếm thông tin liên quan.\n",
            "•Hybrid Search and Reranker: Áp dụng tìm kiếm với từ khoá và ngữ nghĩa sau đó thực hiện\n",
            "xếp hạng lại kết quả tìm kiếm giúp nâng cao kết quả so với việc tìm kiếm đơn thuần với một\n",
            "phương pháp.\n",
            "•Metadata Filter: Giải pháp sử dụng thông tin bổ sung để tạo bộ lọc được sử dụng khi nắm rõ\n",
            "được cấu trúc của cơ sở dữ liệu cũng như nắm được các trường hợp truy vấn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bộ lọc tìm kiếm\n",
            "giúp thu gọn phạm vi tìm kiếm, nâng cao chất lượng truy vấn.\n",
            "4.2 Mô hình sinh ngôn ngữ (Generation)\n",
            "Generation là công đoạn cuối trong chu trình RAG với nhiệm vụ chuyển đổi thông tin nhận được từ\n",
            "bối cảnh thành câu trả lời cho câu hỏi đầu vào của người dùng thông qua một mô hình ngôn ngữ lớn.\n",
            "Quá trình sinh câu trả lời cần đảm bảo câu trả lời đầu ra sử dụng thông tin từ ngữ cảnh được cung\n",
            "cấp, hạn chế câu trả lời sai (hallucination).\n",
            "Với các yêu cầu về chất lượng, các giải pháp có thể tiếp cận để nâng cao kết quả bao gồm tối ưu\n",
            "hoá kết quả tìm kiếm từ khâu truy vấn (retrieval) bằng các giải pháp hậu truy vấn. Quá trình sinh văn\n",
            "bản có thể được tác đông bằng các phương thức:\n",
            "•Prompt Engineering: Prompt Engineering là giải pháp can thiệp vào cách trả lời của LLM mà\n",
            "không cần hiệu chỉnh lại bộ tham số gốc. Prompt Engineering đóng vai trò như một bộ lọc trong\n",
            "quá trình sinh ngôn ngữ đảm bảo kết quả đầu ra theo phong cách trình bày mong muốn. Ngoài\n",
            "ra, một số giải pháp như yêu cầu LLM không tạo ra câu trả lời nếu không có đủ thông tin sẽ giúp\n",
            "hạn chế việc hallucination. Trong trường hợp khác khi ngữ cảnh không đủ dữ kiện, hãy sử dụng\n",
            "dữ liệu được huấn luyện cũng là giải pháp tốt. Bên cạnh đó, trong các kiến trúc RAG kết hợp\n",
            "Multi-Agents, prompt engineering đóng vai trò cốt lõi trong việc điều hướng Agents để tạo ra sự\n",
            "mượt mà ở giải pháp cuối.\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 13: Kojima et al. (2023) sử dụng Zero-Shot-CoT để cải thiện chất lượng câu trả lời của LLM\n",
            "•Hiệu chỉnh mô hình ngôn ngữ lớn (Fine-tuning LLM): Công tác hiệu chỉnh mô hình ngôn\n",
            "ngữ lớn thực hiện việc huấn luyện lại một phần tham số của mô hình LLM gốc. Các dữ liệu huấn\n",
            "luyện được chuẩn bị trước từ nguồn dữ liệu riêng, chưa được học bởi LLM. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Công tác huấn luyện\n",
            "sẽ ghi đè một phần tham số trong bộ tham số gốc. Giải pháp Fine-tuning được đánh giá là giải\n",
            "pháp hiệu quả cho chất lượng kiểm soát tốt khi lượng dữ liệu huấn luyện đầy đủ, phủ khắp các\n",
            "trường hợp hỏi đáp. Điểm trừ của giải pháp là giải pháp yêu cầu nhiều công sức cho việc chuẩn\n",
            "bị dữ liệu, nhiều tài nguyên cho việc huấn luyên bổ sung cho mô hình ngôn ngữ lớn. Bên cạnh đó,\n",
            "người xây dựng cũng cần có kiến thức và kỹ thuật làm việc với mô hình tốt, tránh trường hợp kết\n",
            "quả sau khi fine-tuning tệ hơn trước khi fine-tuning.\n",
            "4.3 Đánh giá hệ thống RAG\n",
            "Giống với các loại mô hình khác, việc đánh giá mô hình luôn là yếu tố quan trọng để đánh giá chất\n",
            "lượng của giải pháp. Thông thường, hệ thống RAG được đánh giá bằng việc đo lường mức độ thể hiện\n",
            "trong các tác vụ cuối (hỏi đáp). Hệ thống đánh giá RAG đo lường hai yếu tố chính là khả năng truy\n",
            "vấn dữ liệu (retrieval) và khả năng sinh câu trả lời (generation).\n",
            "Công tác đánh giá RAG tập trung vào ba yếu tố đo lường và bốn khả năng. Ba yếu tố đo lường gồm\n",
            "\"context relevance\" (sự chính xác của kết quả tìm kiếm), \"answer faithfulness\" (sự thành thực của câu\n",
            "trả lời với ngữ cảnh), \"answer relevance\" (sự liên quan giữa câu trả lời và câu hỏi). Bên cạnh đó, bốn\n",
            "khả năng được cân nhắc bao gồm: \"noise robustness\", \"negative rejection\", \"information integration\",\n",
            "và \"counterfactual robustness\".\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 14: Gao et al. (2024) đã hệ thống các giải pháp đánh giá hệ thống RAG và danh sách các công cụ\n",
            "sử dụng để đánh giá.\n",
            "Việc tự động hoá công tác đánh giá các hệ thống RAG ngày càng phổ biến với sự xuất hiện của các\n",
            "công cụ như RAGAS, ARES, TruLens.\n",
            "Phần III: Advanced RAG\n",
            "Ở phần này chúng ta sẽ cùng tìm hiểu về vấn đề của Naive RAG và một số kỹ thuật RAG nâng cao\n",
            "nhằm nâng cao chất lượng cho một hệ thống sử dụng RAG.\n",
            "5 Vấn đề của Naive RAG\n",
            "RAG đã nhanh chóng được ứng dụng rộng rãi trong nhiều sản phẩm và dịch vụ, nó đóng vai trò quan\n",
            "trọng trong việc cải thiện khả năng tương tác và trải nghiệm người dùng bằng cách cung cấp câu trả\n",
            "lời chính xác và tức thời cho các truy vấn phức tạp. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tuy nhiên, sự phổ biến và tính ứng dụng rộng rãi\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "của RAG cũng dẫn đến một loạt thách thức cần giải quyết. Vấn đề chính mà RAG đối mặt là việc tối\n",
            "ưu hóa hiệu suất của nó, cụ thể là làm thế nào để quá trình truy xuất thông tin diễn ra nhanh chóng\n",
            "hơn và kết quả thu được chính xác hơn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bây giờ chúng ta sẽ tìm hiểu một số lý do mà một hệ thống\n",
            "Naive RAG sẽ gặp phải làm ảnh hưởng tới hiệu suất của nó.\n",
            "Hình 15: Một số vấn đề của Naive RAG\n",
            "Với hình trên chúng ta thấy rằng cả ba quá trình Indexing, Retrieval và Generation đều gặp phải\n",
            "những vấn đề riêng của chúng. Những vấn đề này có thể là độc lập hoặc liên quan với nhau để \"cùng\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "nhau\" làm giảm hiệu suất của hệ thống RAG.\n",
            "Với quá trình Indexing:\n",
            "•Quá trình Indexing còn chưa hoàn thiện, vì nó chưa xử lý hiệu quả thông tin hữu ích trong hình\n",
            "ảnh, biểu đồ và bảng biểu trong các tệp dữ liệu không cấu trúc như PDF.\n",
            "•Quá trình chunking sử dụng chiến lược “one-size-fits-all” thay vì chọn lựa các chiến lược tối ưu\n",
            "dựa trên đặc điểm của các loại tệp khác nhau. Điều này đã dẫn đến việc mỗi phần chứa thông tin\n",
            "ngữ nghĩa chưa đầy đủ. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hơn nữa, nó không xem xét các chi tiết quan trọng, như các tiêu đề hiện\n",
            "có trong văn bản.\n",
            "•Cấu trúc indexing chưa được tối ưu hóa đủ mức, dẫn đến chức năng truy xuất chưa hiệu quả.\n",
            "•Khả năng biểu diễn ngữ nghĩa của embedding model chưa đủ mạnh.\n",
            "Đối với quá trình Retrieval\n",
            "•Mức độ liên quan của các ngữ cảnh được ghi nhớ không đủ và độ chính xác thấp.\n",
            "•Recall Rate thấp ngăn cản việc truy vấn tất cả các đoạn văn bản liên quan, do đó cản trở khả\n",
            "năng của LLMs trong việc tạo ra các câu trả lời toàn diện.\n",
            "•Truy vấn có thể không chính xác hoặc khả năng biểu diễn ngữ nghĩa của embedding model có thể\n",
            "yếu, dẫn đến khả năng không thể truy vấn thông tin có giá trị.\n",
            "•Thuật toán truy vấn bị hạn chế vì nó không kết hợp các loại phương pháp hoặc thuật toán truy\n",
            "vấn khác nhau, như kết hợp truy vấn từ khóa, ngữ nghĩa và vector.\n",
            "•Sự trùng lặp thông tin xảy ra khi nhiều ngữ cảnh được truy vấn chứa thông tin tương tự, dẫn đến\n",
            "nội dung lặp lại trong các câu trả lời được tạo ra.\n",
            "Đối với quá trình Generation\n",
            "•Việc tích hợp hiệu quả giữa hai tác vụ retrieved context và generation có thể không khả thi, dẫn\n",
            "đến kết quả không nhất quán.\n",
            "•Sự phụ thuộc quá mức vào thông tin được cải thiện trong quá trình generation mang lại rủi ro\n",
            "cao. Điều này có thể dẫn đến việc tạo ra những kết quả chỉ đơn giản lặp lại nội dung đã truy vấn\n",
            "mà không cung cấp thông tin có giá trị.\n",
            "•LLM có thể tạo ra các phản hồi sai, không liên quan, có hại, hoặc thiên vị.\n",
            "6 Unveiling PDF Parsing\n",
            "Việc trích xuất thông tin từ tài liệu, đặc biệt là từ các tệp PDF không cấu trúc, đã trở thành một yếu\n",
            "tố không thể thiếu trong việc cải thiện chất lượng và hiệu suất của các hệ thống tự động như RAG.\n",
            "Quá trình này yêu cầu một sự chú ý đặc biệt với mục tiêu đảm bảo rằng nội dung được trích xuất một\n",
            "cách chính xác và hiệu quả, từ đó nâng cao giá trị của sản phẩm cuối cùng. Việc ứng dụng công nghệ\n",
            "phân tích cú pháp thông tin từ những tài liệu này là cực kỳ quan trọng, bởi vì dữ liệu không cấu trúc\n",
            "chiếm một tỷ lệ lớn trong dữ liệu được tạo ra và lưu trữ hằng ngày.\n",
            "Tài liệu PDF, vốn là một trong những dạng phổ biến nhất của dữ liệu không cấu trúc, yêu cầu các\n",
            "phương pháp tiếp cận đặc thù để có thể khai thác trọn vẹn giá trị thông tin bên trong vì vậy việc trích\n",
            "xuất thông tin từ tài liệu PDF lại là một quá trình đầy thách thức. Thay vì là một định dạng dữ liệu,\n",
            "PDF chính xác hơn khi được mô tả là một tập hợp các hướng dẫn in ấn. Một tệp PDF bao gồm một\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "loạt hướng dẫn cho máy đọc hoặc máy in PDF biết cách hiển thị các ký tự trên màn hình hoặc giấy.\n",
            "Điều này trái ngược với các định dạng tệp như HTML và docx, sử dụng các thẻ như <p>, <w:p>,\n",
            "<table>, và <w:tbl> để tổ chức các cấu trúc logic khác nhau. Thách thức trong việc phân tích cú pháp\n",
            "tài liệu PDF nằm ở việc chính xác trích xuất bố cục của toàn bộ trang và dịch nội dung, bao gồm bảng,\n",
            "tiêu đề, đoạn văn, và hình ảnh, thành một biểu diễn văn bản của tài liệu. Quá trình này đòi hỏi phải\n",
            "xử lý những không chính xác trong trích xuất văn bản, nhận dạng hình ảnh, và sự nhầm lẫn về mối\n",
            "quan hệ hàng-cột trong bảng.\n",
            "Hình 16: HTML và PDF\n",
            "Thông thường chúng ta sẽ có ba cách tiếp cận cơ bản để parse tài liệu PDF:\n",
            "•Rule-based approach: nơi mà phong cách và nội dung của từng phần được xác định dựa trên đặc\n",
            "điểm tổ chức của tài liệu.\n",
            "•Deep learning models: Sử dụng một số model kết hợp như Optical Character Recognition, Docu-\n",
            "ment Layout Analysis, Key Information Extraction,...\n",
            "•Phân tích cấu trúc phức tạp hoặc trích xuất thông tin chính trong PDF dựa trên các multimodal\n",
            "large models.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 17: Hình minh họa cho việc kết hợp nhiều Deep learning Model cho quá trình parse PDF\n",
            "7 Re-ranking\n",
            "Re-ranking đóng vai trò quan trọng trong RAG. Trong naive RAG, một số lượng lớn ngữ cảnh có thể\n",
            "được truy vấn, nhưng không phải tất cả đều cần thiết liên quan đến câu hỏi. Re-ranking cho phép sắp\n",
            "xếp lại và lọc các tài liệu, đặt những cái liên quan lên hàng đầu, từ đó nâng cao hiệu quả của RAG.\n",
            "Nhiệm vụ của re-ranking là đánh giá mức độ liên quan của các ngữ cảnh này và ưu tiên những cái có\n",
            "khả năng cung cấp câu trả lời chính xác và liên quan nhất. Điều này cho phép LLM ưu tiên những ngữ\n",
            "cảnh được xếp hạng cao này khi tạo ra câu trả lời, từ đó cải thiện độ chính xác và chất lượng của phản\n",
            "hồi.\n",
            "Các phương pháp re-ranking chủ yếu được chia thành hai loại:\n",
            "•Re-ranking models: những mô hình này xem xét các đặc điểm tương tác giữa tài liệu và truy vấn\n",
            "để đánh giá mức độ liên quan một cách chính xác hơn.\n",
            "•Large Language Model: sự xuất hiện của mô hình ngôn ngữ lớn đã mở ra những khả năng mới\n",
            "cho việc re-ranking. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bằng cách hiểu sâu toàn bộ tài liệu và truy vấn, có thể nắm bắt thông tin\n",
            "ngữ nghĩa một cách toàn diện hơn.\n",
            "8 Exploring Semantic Chunking\n",
            "9 Exploring Query Rewriting\n",
            "Phần VI: Research in RAG\n",
            "9.1 FLARE\n",
            "https://arxiv.org/pdf/2305.06983.pdf\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Trong bài báo \"Active Retrieval Augmented Generation\" Jiang et al., 2023, các tác giả giới thiệu\n",
            "phươngphápmớicótênFLARE,viếttắtcủaForward-LookingActiveRetrievalAugmentedGeneration.\n",
            "Phương pháp này cho phép các mô hình ngôn ngữ lớn tích cực lựa chọn thời điểm và loại thông tin cần\n",
            "truy vấn trong suốt quá trình tạo ra văn bản. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "FLARE hoạt động bằng cách tạo ra các câu tạm thời,\n",
            "và nếu nhận thấy có từ nào trong câu đó không chắc chắn, nó sẽ tìm kiếm thông tin liên quan để cải\n",
            "thiện câu tiếp theo. Điều này tiếp tục diễn ra cho đến khi hoàn thành văn bản. Một ưu điểm đáng chú\n",
            "ý là FLARE có thể áp dụng cho bất kỳ mô hình ngôn ngữ nào mà không cần phải huấn luyện lại từ\n",
            "đầu. Bài báo cũng trình bày hai cách thức truy vấn chủ động khác nhau: phương pháp đầu tiên, gọi là\n",
            "FLARE instruct, tạo ra truy vấn dựa trên một chỉ dẫn đặc biệt để khuyến khích việc truy vấn thông tin,\n",
            "trong khi phương pháp thứ hai, FLARE direct, sử dụng kết quả tạo sinh trực tiếp từ mô hình ngôn ngữ\n",
            "làm truy vấn, đặc biệt khi có từ không chắc chắn trong câu đó.\n",
            "FLARE ntruct: Một phương pháp đơn giản để tạo ra thông tin truy vấn trong quá trình tạo nội dung\n",
            "là sử dụng token đặc biệt \"[Search(query)]\" mỗi khi cần thông tin bổ sung. Khi mô hình ngôn ngữ sinh\n",
            "ra token này, quá trình tạo nội dung tạm thời dừng lại, và câu truy vấn bên trong token sẽ được dùng\n",
            "để tìm kiếm thông tin liên quan. Phương pháp này được lấy cảm hứng từ nghiên cứu \"Toolformer:\n",
            "Language Models Can Teach Themselves to Use Tools\" Schick et al., 2023.\n",
            "18\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "FLARE directTrong phương pháp FLARE instruct, có lúc các câu truy vấn được tạo ra không chính\n",
            "xác, làm giảm độ tin cậy của quá trình truy vấn. Để giải quyết vấn đề này, bài báo đề xuất một cách\n",
            "tiếp cận truy vấn chủ động khác, dựa vào việc xem xét câu tiếp theo để quyết định thời điểm truy vấn.\n",
            "Cụ thể, mô hình ngôn ngữ sẽ trước tiên tạo ra một câu tiếp theo mà không dựa vào kết quả truy vấn.\n",
            "Nếu mô hình tự tin về câu trả lời đó, câu trả lời sẽ được chấp nhận mà không cần truy vấn thêm. Trong\n",
            "trường hợp mô hình không tự tin, một câu truy vấn sẽ được tạo dựa trên câu tiếp theo để tìm kiếm\n",
            "thông tin cần thiết, và sau đó câu trả lời sẽ được tạo ra lại. Cách tiếp cận này hiệu quả bởi vì thường\n",
            "xuyên từ có độ tự tin thấp thì liên quan đến việc thiếu thông tin.\n",
            "9.2 Self RAG: Learning to retrieve, generate, and critique through self-reflection\n",
            "https://arxiv.org/pdf/2310.11511.pdf https://www.youtube.com/watch?v=i4V9iJcxzZ4\n",
            "Bài báo \"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection\" giới thiệu\n",
            "một framework mới có tên là Self-Reflective Retrieval-Augmented Generation (Self-RAG). Framework\n",
            "này nhằm mục đích cải thiện chất lượng và độ chính xác về thông tin của các mô hình ngôn ngữ lớn\n",
            "(LLMs) bằng cách cho phép chúng tự động tìm kiếm thông tin và phản ánh về nội dung được trích xuất\n",
            "cũng như phản hồi của chính mình. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Khác với các mô hình RAG truyền thống có thể trích xuất thông\n",
            "tin không liên quan, Self-RAG sử dụng các mã token đặc biệt gọi là token phản ánh để làm cho mô hình\n",
            "có thể kiểm soát và thích nghi với nhiều nhiệm vụ khác nhau. Các tác giả chứng minh rằng Self-RAG\n",
            "vượt trội hơn các mô hình LLM hiện tại và các mô hình tăng cường tìm kiếm trong các nhiệm vụ như\n",
            "QA miền mở, suy luận, xác minh sự thật và tạo ra văn bản dài, làm nổi bật những cải thiện đáng kể\n",
            "về tính chính xác và độ chính xác của trích dẫn.\n",
            "19\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Trong nghiên cứu này, các tác giả huấn luyện mô hình LLM để tự sinh ra 4 loại token phải ứng\n",
            "(reflection token) để hỗ trợ cho quá trình trả lời, bao gồm:\n",
            "•Retrieve: Cho mô hình biết có nên truy vấn/tiếp tục truy vấn hay không.\n",
            "•IsRel: Đánh giá xem kết quả truy vấn có cung cấp thông tin hữu dụng cho quá trình trả lời câu\n",
            "hỏi hay không.\n",
            "•IsSup: Cho biết mực độ kết quả truy vấn cung cấp dẫn chứng hỗ trợ cho câu trả, bao gồm: support\n",
            "hoàn toàn, support một phần, và hoàn toàn không support cho câu trả lời.\n",
            "•IsUse: Đánh giá xem mức độ hữu dụng của câu trả lời, trên thang điểm từ 1-5.\n",
            "Ở quá trình inference, thuật toán Self-RAG hoạt động như sau:\n",
            "•Đầu tiên ta có một câu hỏi prompt từ người dùng và câu trả lời từ bước trước đó (nếu có). Model\n",
            "sẽ tự tạo ra token Retrieve để dự đoán xem có cần truy vấn thông tin từ cơ sở dữ liệu hay không.\n",
            "•Nếu cần Retrieve thì:\n",
            "–Truy vấn thông tin cần thiết từ cơ sở dữ liệu.\n",
            "–Mô hình dự đoán token IsRel để dự đoán kết quả truy vấn có cung cấp thông tin cần thiết.\n",
            "–Mô hình dự đoán token IsSup và IsUse để đánh giá từng kết quả truy vấn.\n",
            "–Rerank lại kết quả truy vấn dựa trên 3 token IsRel, IsSup và IsUse.\n",
            "•Nếu không cần Retrieve, mô hình sẽ trả lời mà không cần retrieve, sau đó dự đoán độ hữu ích của\n",
            "câu trả lời qua token IsUse.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "20\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "9.3 SELF-DISCOVER: Large Language Models Self-Compose Reasoning Struc-\n",
            "tures\n",
            "https://arxiv.org/pdf/2402.03620.pdf 52 y Trong các nghiên cứu, các phương pháp prompting khác\n",
            "nhau thường được đề xuất để giải quyết một vấn đề hết sức cụ thể, chẳng hạn như giải toán, suy luận\n",
            "theo từng bước, hay suy luận số học. Tuy nhiên các phương pháp prompting này lại không thật sự\n",
            "phù hợp với tất cả các task, chẳng hạn những phương pháp prompting chuyên về giải toán sẽ không\n",
            "tốt bằng những phương pháp khác khi được ứng dụng trong tác vụ trả lời câu hỏi suy luận logic. Vì\n",
            "vậy nghiên cứu \"SELF-DISCOVER: Large Language Models Self-Compose Reasoning Structures\" Zhou\n",
            "et al., 2024 nhắm đến tự tìm kiếm những cấu trúc suy luận phù hợp nahast cho từng task, trong khi\n",
            "vẫn giữ tính hiệu quả về mặt tính toán.\n",
            "Phương pháp này được lấy cảm hứng từ cách con người chúng ta suy luận một vấn đề. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Phương pháp\n",
            "này được chia thành 2 gai đoạn. Ở giai đoạn đầu tiên, phương pháp self-discover sẽ tìm ra những cấu\n",
            "trúc prompt suy luận phù hợp nhất cho từng task. Sau đó các cấu trúc này sẽ được format về dạng\n",
            "JSON, bới cấu trúc này được chứng minh là tăng cường khả năng suy luận của mô hình Zhou et al.,\n",
            "2023. Bước này có mục tiêu là tìm những cấu trúc suy luận hợp lý nhất cho từng tác vụ, và không chỉ\n",
            "một tác vụ trong một lần. Ở giai đoạn thứ 2, phương pháp này sử dụng những cấu trúc suy luận ở bước\n",
            "trước và tìm ra cấu trúc phù hợp nhất với mỗi câu hỏi của người dùng.\n",
            "Giai 1 bao gồm 3 hành động chính:\n",
            "•SELECT: Những cấu trúc suy luận có thể cần thiết để giải quyết tác vụ được chọn từ một tập\n",
            "mô tả các cấu trúc suy luân.\n",
            "•ADAPT: Cấu trúc suy luận ở bước trước sẽ được viết lại để phù hợp hơn với tác vụ mà mô hình\n",
            "đang muốn giải quyết.\n",
            "•IMPLEMENT: cấu trúc vừa được tạo ra sẽ được tiến hành thành một cấu trúc từng bước các\n",
            "hành động để giải quyết tác vụ.\n",
            "Sau 3 bước ở giai đoạn 1, ta đã tìm được cấu trúc phù hợp để giải 1 tác vụ cụ thể. Sau đó ta sẽ\n",
            "prompt mô hình ngôn ngữ lớn để làm theo cấu trúc đó, từ đó tạo ra câu trả lời chính xác cho người\n",
            "dùng.\n",
            "9.4 Corrective RAG\n",
            "https://arxiv.org/abs/2401.15884 https://www.youtube.com/watch?v=pbAd8O1Lvm4\n",
            "21\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Trong các ứng dụng RAG thông thường, thông tin ngữ cảnh truy vấn sẽ được đưa vào mô hình để\n",
            "sinh ra kết quả, bất kết rằng thông tin đó có liên quan hay không. Điều này làm cho kết quả sinh ra\n",
            "bởi mô hình trở nên nhiễu và làm chậm tốc độ tạo sinh đi rất nhiều. Vì vậy nghiên cứu \"Corrective\n",
            "Retrieval Augmented Generation\" Yan et al., 2024 được đưa ra nhằm giải quyết vấn đề này. Bài báo này\n",
            "đi vào nghiên cứu những trường hợp khi những thông tin truy vấn được không liên quan hoặc không\n",
            "chính xác, đồng thời đề xuất 1 cơ chế tự động điều chỉnh và tối ưu những văn bản truy vấn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cụ thể, phương pháp này hoạt động như sau. Cho một câu query và nhiều văn bản được truy vấn.\n",
            "Một mô hình đánh giá gọn nhẹ sẽ được sử dụng để đánh giá độ phù hợp của các văn bản với câu query\n",
            "đầu vào, quy thành 3 mức độ: Đúng, Không đúng và không rõ ràng, tương ứng với những hành động\n",
            "khác nhau. Nếu những văn bản truy vấn được là Đúng, những văn bản đó sẽ được chắt lọc lại thành\n",
            "những thông tin liên quan. Quá trình này bao gồm: phân rã kiến thức, chắt lọc và sắp xếp lại kiến thức.\n",
            "Nếu những văn bản truy vấn được là không chính xác, những văn bản này sẽ được bỏ đi, thay vào đó\n",
            "là bước tìm kiếm trên internet. Khi những thông tin truy vấn là không rõ ràng, cả 2 quá trình chắt lọc\n",
            "và tìm kiếm trên web sẽ đồng thời được diễn ra.\n",
            "Một trong những thành phần quan trọng nhất trong phương pháp này là mô hình đánh giá văn bản\n",
            "truy vấn. Trong nghiên cứu này, mô hình T5-Large được sử dụng để fine-tune cho tác vụ này. Với mỗi\n",
            "câu query, sẽ có 10 văn bản được truy vấn. Từng câu sẽ kết hợp với câu query để thành input đầu vào\n",
            "đưa vào mô hình T5, từ đó đưa ra một thang điểm độ liên quan. Dựa trên thang điểm này, ta sẽ phân\n",
            "loại văn bản đầu vào thành 3 loại: Đúng, Không Đúng, hoặc không liên quan.\n",
            "Khi những văn bản truy vấn được là Đúng, quá trình chắt lọc kiến thức sẽ được bắt đầu. Đầu tiên,\n",
            "những văn bản này sẽ được cắt ra thành những đoạn kiến thức. Lúc này mô hình đánh giá truy vấn ở\n",
            "bước trên sẽ được sử dụng lại độ liên quan của những dải kiến thức này, và những dải không quá liên\n",
            "22\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "quan sẽ được loại bỏ đi, trong khi những dải có liên quan sẽ được giữ lại.\n",
            "Khi những văn bản truy vấn là Không Đúng, quá trình tìm kiếm trên web sẽ được bắt đầu. Cụ thể\n",
            "câu đầu vào sẽ được viết lại thành những keyword để mô phỏng quá trình tìm kiếm trên web. Sau đó\n",
            "quá trình chắt lọc thông tin tương tự như bước trên sẽ được sử dụng để đưa ra những dải kiến thức\n",
            "liên quan nhất.\n",
            "9.5 WikiChat\n",
            "https://arxiv.org/pdf/2305.14292v2.pdf Đây là một phương pháp được nghiên cứu trong paper \"Wi-\n",
            "kiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on\n",
            "Wikipedia\" Semnani et al., 2023, nhằm giải quyết vấn đền câu trả lời đưa ra bởi mô hình ngôn ngữ lớn\n",
            "có độ trung thực không cao và có tỉ lệ tưởng tượng (hallucination) lớn. Phương pháp này bao gồm 7\n",
            "bước chính, với mỗi bước sử dụng few-shot prompting để hướng mô hình trả lời theo ý muốn của người\n",
            "dùng. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nhìn tổng quan, WikiChat bao gồm 2 giai đoạn chính, giai đoạn đầu là thu thập thông tin dựa\n",
            "trên đoạn chat với người dùng, và giai đoạn hai đưa ra câu trả lời dựa trên thông tin thu thập được. 5\n",
            "bước đầu của phương pháp này thuộc về giai đoạn 1, và 2 bước sau thuộc về giai đoạn 2, sau đây chúng\n",
            "ta đi chi tiết từng giai đoạn.\n",
            "Giai đoạn 1: Thu thập thông tin Trong quá trình giao tiếp với người dùng, WikiChat sẽ tự\n",
            "nhận biết lúc nào nên thu thập thông tin, (khi người dùng đưa ra câu hỏi trực tiếp). Giai đoạn này bao\n",
            "gồm 5 bước chính\n",
            "•Bước1:WikiChatsẽtựtạomộtcâuquerycóthểbaohàmđượcýmuốncủangườidùng,cộngthêm\n",
            "một mốc thời gian chẳng hạn như \"recent\" nếu câu trả lời cần cập nhật nhất có thể, \"year=xxxx\"\n",
            "cho một năm cụ thể, hoặc là none nếu thời gian là không quan trọng.\n",
            "•Bước 2: WikiChat trích xuất những thông tin liên quan từ những văn bản truy vấn được thành\n",
            "dạng những gạch đầu dòng tóm tắt, và những thông tin không liên quan sẽ được lọc đi.\n",
            "•Bước 3: Mô hình LLM sẽ được sử dụng để tạo ra câu trả lời, câu trả lời này thường sẽ đề cập\n",
            "những thông tin liên quan và thú vị, tuy nhiên thường không đáng tin cậy.\n",
            "•Bước 4: Câu trả lời của mô hình sẽ được chia nhỏ ra thành từng câu khẳng định một. Sau đó một\n",
            "hệ thống truy vấn thông tin sẽ được sử dụng để truy vấn những bằng chứng cho khẳng định đó.\n",
            "•Bước 5: Sử dụng một mô hình LLM khác, từng câu khẳng định sẽ được chia thành 3 nhóm chính,\n",
            "những bằng chứng truy vấn được ủng hộ khẳng định, phủ định, hoặc không đủ thông tin để kết\n",
            "luận. Chỉ những khẳng định được ủng hộ bởi bằng chứng mới được giữ lại.\n",
            "23\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Giai đoạn 2: Tạo ra câu trả lời Bước tiếp theo là dùng những thông tin đã thu thập được tạo ra\n",
            "câu trả lời chính xác. Nghiên cứu này chỉ ra rằng việc trực tiếp tạo ra câu trả lời sẽ gây khó khăn trong\n",
            "việc duy trì tính hội thoại cho câu trả lời của mô hình. Vì vậy, giai đoạn này sẽ chia thành 2 bước nhỏ.\n",
            "•Bước 6: WikiChat tạo ra một câu trả lời tạm dựa trên những gạch đầu dòng được truy vấn từ\n",
            "bước trước.\n",
            "•Bước 7: Sau đó WikiChat sẽ tạo ra nhận xét và chỉnh sửa lại câu trả lời dựa trên các yếu tố tính\n",
            "phù hợp, tính tự nhiên, tính không lặp lại và tính đúng đắn về mặt thời gian.\n",
            "Chắt lọc kiến thức sáng các mô hình nhỏ hơn Để giảm độ trễ, chi phí và đảm bảo tính riêng\n",
            "tư, nghiên cứu này để xuất phương pháp để chắt lọc kiến thức từ một mô hình lớn và mã nguồn đóng\n",
            "(chẳng hạn như GPT-4) sang một mô hình nhỏ hơn và mã nguồn mở (chẳng hạn như Llama-7B). Một\n",
            "mô hình ngôn ngữ giả lập người dùng sẽ được sử dụng để hội thọai với WikiChat về những chủ đề\n",
            "được lấy từ Wikipedia, và ghi lại những đầu vào và đầu ra của mô hình. Dữ liệu này sẽ được giữ lại để\n",
            "fine-tune mô hình Llama nhỏ. Kết quả thu được cho thấy mô hình nhỏ này có khả năng trả lời tiệm\n",
            "cận so với mô hình lớn, trong khi giảm đi độ trễ, chi phí và vẫn đảm bảo được tính riêng tư cho dữ liệu\n",
            "người dùng.\n",
            "References\n",
            "Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K¨ uttler, H., Lewis, M., tau\n",
            "Yih, W., Rockt¨ aschel, T., Riedel, S., & Kiela, D. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "(2021). Retrieval-augmented generation for\n",
            "knowledge-intensive nlp tasks.\n",
            "Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Guo, Q., Wang, M., & Wang, H.\n",
            "(2024). Retrieval-augmented generation for large language models: A survey.\n",
            "Gao, L., Ma, X., Lin, J., & Callan, J. (2022). Precise zero-shot dense retrieval without relevance labels.\n",
            "Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., & Liang, P. (2023). Lost in\n",
            "the middle: How language models use long contexts.\n",
            "24\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Kamradt, G. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "(2024). The 5 levels of text splitting for retrieval . https://youtu.be/8OJC21T2SL4\n",
            "Chen, T., Wang, H., Chen, S., Yu, W., Ma, K., Zhao, X., Zhang, H., & Yu, D. (2023). Dense x retrieval:\n",
            "What retrieval granularity should we use?\n",
            "Wang, Z., Zhang, H., Li, C.-L., Eisenschlos, J. M., Perot, V., Wang, Z., Miculicich, L., Fujii, Y., Shang,\n",
            "J., Lee, C.-Y., & Pfister, T. (2024). Chain-of-table: Evolving tables in the reasoning chain for\n",
            "table understanding.\n",
            "Muennighoff, N., Tazi, N., Magne, L., & Reimers, N. (2023). Mteb: Massive text embedding benchmark.\n",
            "Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2023). Large language models are zero-shot\n",
            "reasoners.\n",
            "Jiang, Z., Xu, F. F., Gao, L., Sun, Z., Liu, Q., Dwivedi-Yu, J., Yang, Y., Callan, J., & Neubig, G.\n",
            "(2023). Active retrieval augmented generation.\n",
            "Schick, T., Dwivedi-Yu, J., Dessi, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., &\n",
            "Scialom, T. Toolformer: Language models can teach themselves to use tools. In: 2023.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Zhou, P., Pujara, J., Ren, X., Chen, X., Cheng, H.-T., Le, Q. V., Chi, E. H., Zhou, D., Mishra, S., &\n",
            "Zheng, H. S. (2024). Self-discover: Large language models self-compose reasoning structures.\n",
            "Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2023). Large language\n",
            "models are human-level prompt engineers.\n",
            "Yan, S.-Q., Gu, J.-C., Zhu, Y., & Ling, Z.-H. (2024). Corrective retrieval augmented generation.\n",
            "Semnani, S. J., Yao, V. Z., Zhang, H. C., & Lam, M. S. (2023). Wikichat: Stopping the hallucination\n",
            "of large language model chatbots by few-shot grounding on wikipedia.\n",
            "- Hết -\n",
            "25\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Switch-case Alternatives in Python\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 Switch Case\n",
            "Switch case là một cấu trúc điều khiển trong lập trình giúp kiểm tra giá trị của một biến, biểu thức\n",
            "và thực hiện các hành động khác nhau tùy thuộc vào giá trị đó. Để đơn giản thì hãy tưởng tượng bạn\n",
            "có một chiếc hộp điều khiển với nhiều nút bấm. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mỗi nút bấm trên chiếc hộp này sẽ làm một việc khác\n",
            "nhau. Khi bạn nhấn vào một nút, chiếc hộp sẽ biết cần phải làm gì tiếp theo. Đó chính là cách mà\n",
            "switch case hoạt động.\n",
            "Trong biểu đồ trên thể hiện các thành phần và cách switch case hoạt động, trong đó:\n",
            "•Switch Expression (Biểu thức kiểm tra): Chúng ta bắt đầu với việc kiểm tra biểu thức. Ví dụ:\n",
            "Hôm nay bạn muốn ăn món gì?\n",
            "•Case 1: Kiểm tra trường hợp đầu tiên. Nếu biểu thức khớp với trường hợp này, chúng ta thực hiện\n",
            "\"Statement 1\"và sau đó kết thúc. Ví dụ: Case bạn muốn ăn Táo thì thực hiện Statement 1: Lấy\n",
            "trong tủ lạnh.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AIO2024 aivietnam.edu.vn\n",
            "•Case 2: Nếu biểu thức không khớp với trường hợp đầu tiên, chúng ta kiểm tra trường hợp thứ hai.\n",
            "Nếu biểu thức khớp với trường hợp này, chúng ta thực hiện \"Statement 2\"và sau đó kết thúc. Ví\n",
            "dụ: Case bạn muốn ăn chuối thì thực hiện Statement 1: Lấy trên bàn ăn.\n",
            "•Case n: Tiếp tục kiểm tra các trường hợp khác cho đến khi tìm thấy một trường hợp khớp hoặc\n",
            "đến trường hợp cuối cùng.\n",
            "•Default Statement: Nếu không có trường hợp nào khớp, chúng ta thực hiện hành động mặc định.\n",
            "Đây là điều sẽ xảy ra nếu tất cả các trường hợp trên đều không đúng. ví dụ: statement mặc định\n",
            "khi bạn chọn một loại trái cây không khớp với bất kỳ trường hợp nào, giả sử bạn chọn bưởi mà\n",
            "nhà bạn không có bưởi thì giá trị mặc định trả về sẽ là: \"Hãy ra chợ mua\".\n",
            "•End: Sau khi thực hiện một hành động (dù là từ một trường hợp cụ thể hay hành động mặc định),\n",
            "quá trình kết thúc.\n",
            "Và đó là cấu trúc và cách switch case hoạt động, tuy nhiên trong python không có cấu trúc này. Thay\n",
            "vào đó, chúng ta có thể sử dụng các phương pháp khác như if-elif-else ,dictionary hoặc từ Python\n",
            "3.10 trở đi, chúng ta có thể sử dụng match case để làm điều tương tự.\n",
            "2 Các phương pháp thay thế switch case trong python\n",
            "Chúng ta sẽ tìm hiểu các phương pháp thay thế switch case qua ví dụ về thói quen vào buổi sáng của\n",
            "Tom. Buổi sáng, Tom thường thức dậy vào lúc 5 giờ, đến 6 giờ thì cậu ấy bắt đàu tập yoga, sau đó\n",
            "7 giờ cậu ấy bắt đầu làm việc, và các thời gian còn lại thì cậu ấy làm các công việc khác. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ta sẽ viết\n",
            "chương trình nhập đầu vào là thời gian để xem hoạt động của Tom.\n",
            "Input Output\n",
            "5 AM Wake up\n",
            "6 AM Yoga\n",
            "7 AM Work\n",
            "Giá trị khác Do something else\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AIO2024 aivietnam.edu.vn\n",
            "2.1 If-elif-else\n",
            "Cách phổ biến nhất để thay thế switch case trong python là sử dụng cấu trúc if-elif-else. Cấu trúc này\n",
            "bắt đầu bằng câu lệnh if và điều kiện condition, nếu điều kiện này đúng khối lệnh trong if(statement)\n",
            "sẽ được thực hiện. Nếu điều kiện sai sẽ chuyển sang câu lệnh elif và tiếp tục kiểm tra điều kiện. Nếu\n",
            "không có điều kiện nào đúng thì thực hiện khối lệnh trong else.\n",
            "Sau đây là cách sử dụng if-elif-else để xây dựng chương trình :\n",
            "1time = input (\" Input time : \")\n",
            "2if time == \"5 AM\":\n",
            "3 print (\" Wake up\")\n",
            "4elif time == \"6 AM\":\n",
            "5 print (\" Yoga \")\n",
            "6elif time == \"7 AM\":\n",
            "7 print (\" Work \")\n",
            "8else :\n",
            "9 print (\"Do something else \")\n",
            "10\n",
            "Chương trình trên bắt đầu bằng cách yêu cầu người dùng nhập thời gian. Người dùng sẽ nhập một giá\n",
            "trị thời gian cụ thể (ví dụ: \"5 AM\", \"6 AM\", hoặc \"7 AM\"). Sau đó chương trình kiểm tra giá trị của\n",
            "biến thời gian với các lệnh if, elif, và else, nếu điều kiện đúng thì sẽ thực hiện câu lệnh print. Nếu người\n",
            "dùng nhập các giá trị khác thì thực hiện khối lệnh trong else in ra màn hình \"Do something else\".\n",
            "2.2 Dictionary\n",
            "Phương pháp thứ hai có thể thay thế switch case trong python là sử dụng Dictionary, đây là kiểu dữ\n",
            "liệu được lưu trữ dưới dạng các cặp khóa và giá trị. Mỗi khóa là duy nhất và liên kết với một giá trị.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sau đây là cách sử dụng dictionary để xây dựng chương trình theo dõi hoạt động của Tom.\n",
            "1todo = {\"5 AM\": \" Wake up\",\n",
            "2 \"6 AM\": \" Yoga \",\n",
            "3 \"7 AM\": \" Work \"}\n",
            "4time = input (\" Input time : \")\n",
            "5todo . get(time , \"Do something else \")\n",
            "Đầu tiên chúng ta tạo một từ điển todo với các cặp khóa-giá trị. Mỗi khóa là một thời gian cụ thể (ví\n",
            "dụ: \"5 AM\", \"6 AM\", \"7 AM\") và mỗi giá trị là haotj động của Tom vào thời gian đó (ví dụ: \"Wake\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AIO2024 aivietnam.edu.vn\n",
            "up\", \"Yoga\", \"Work\"). Tiếp theo chương trình yêu cầu người dùng nhập thời gian. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cuối cùng chúng\n",
            "ta sử dụng phương thức get của từ điển để tìm công việc tương ứng với thời gian nhập vào. Nếu thời\n",
            "gian nhập vào có trong từ điển, phương thức get sẽ trả về công việc tương ứng. Nếu thời gian nhập vào\n",
            "không có trong từ điển, phương thức get sẽ trả về giá trị mặc định là \"Do something else\".\n",
            "2.3 Mactch case\n",
            "Cấu trúc match case trong Python cung cấp một cách tiếp cận mạnh mẽ và trực quan để xử lý các điều\n",
            "kiện phức tạp. So với if-else, dictionary, và switch case từ các ngôn ngữ khác, match case giúp mã dễ\n",
            "đọc hơn, dễ bảo trì hơn, và linh hoạt hơn trong việc kiểm tra các mẫu dữ liệu phức tạp. Cú pháp sử\n",
            "dụng tương tự switch case, bắt đầu bằng match và biểu thức cần kiểm tra. Bên trong khối match gồm\n",
            "các case, với trường hợp các case đều sai thì sử dụng cú pháp \"case _\".\n",
            "Dưới đây là cách sử dụng match case để xây dựng chương trình theo dõi hoạt động của Tom:\n",
            "1time = input (\" Input time : \")\n",
            "2match time :\n",
            "3 case \"5 AM\":\n",
            "4 print (\" Wake up\")\n",
            "5 case \"6 AM\":\n",
            "6 print (\" Yoga \")\n",
            "7 case \"7 AM\":\n",
            "8 print (\" Work \")\n",
            "9 case _:\n",
            "10 print (\"Do something else \")\n",
            "11\n",
            "Trong chương trình trên, đầu tiên chúng ta sử dụng lệnh input để yêu cầu người dùng nhập thời gian\n",
            "và lưu giá trị đó vào biến time. Tiếp theo chúng ta kiểm tra giá trị biến time này với cấu trúc match\n",
            "case. Một chú ý nhỏ ở đây là dấu gạch dưới _ đại diện cho trường hợp mặc định, khi giá trị của time\n",
            "không khớp với bất kỳ trường hợp nào đã liệt kê.\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Text-to-Video Generation Guide\n",
            "Hoang-Bach Ngo Minh-Hung An\n",
            "Ngày 28 tháng 2 năm 2024\n",
            "Phần I: Giới thiệu tổng quan\n",
            "Trong những năm gần đây, sự phát triển không ngừng của công nghệ đã mở đường cho một bước đột\n",
            "phá đáng kinh ngạc trong lĩnh vực tạo sinh nội dung: khả năng chuyển đổi văn bản thành video, một\n",
            "tiến bộ mới nhất trong chuỗi các thành tựu công nghệ. Điều này không chỉ là một bước tiến trong việc\n",
            "tạo ra nội dung đa phương tiện từ văn bản mô tả mà còn mở ra cánh cửa mới cho nhiều ngành công\n",
            "nghiệp khác nhau. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mô hình Sora, phát triển bởi OpenAI, hay Genie, phát triển bởi Google, là những\n",
            "minh chứng nổi bật cho tiến trình này, đánh dấu một cột mốc quan trọng trong việc mô hình hóa và\n",
            "tạo sinh video dựa trên văn bản, giúp biến những mô tả văn bản thành video sinh động với mạch lạc\n",
            "thời gian và không gian cao.\n",
            "Lý do phía sau việc nghiên cứu và phát triển text-to-video không chỉ là để mở rộng biên giới của thị\n",
            "giác máy tính mà còn nhằm giải quyết những thách thức liên quan đến việc mô hình hóa video, một\n",
            "tác vụ phức tạp hơn đáng kể so với tạo sinh hình ảnh từ văn bản. Sự phức tạp này đến từ việc cần phải\n",
            "hiểu và tái tạo được sự liên kết thời gian và không gian trong video, đòi hỏi những phương pháp tiếp\n",
            "cận sáng tạo và tiên tiến. Bài viết này nhằm mục đích giới thiệu về cách thức hoạt động của các mô\n",
            "hình tạo sinh video, phân biệt chúng với mô hình tạo sinh hình ảnh, và khám phá các nghiên cứu hàng\n",
            "đầu trong lĩnh vực hấp dẫn nhưng cũng đầy thách thức này.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Các thách thức cho bài toán\n",
            "text-to-video\n",
            "Trước hết, chúng ta hãy cùng nhau khám phá những thách thức lớn mà công nghệ tạo sinh video phải\n",
            "đối mặt. Những thách thức này chủ yếu liên quan đến việc giữ cho video có sự nhất quán về không gian\n",
            "và liên kết mạch lạc theo thời gian, đồng thời cũng cần phải quan tâm đến yếu tố tài nguyên tính toán\n",
            "và sự khan hiếm của dữ liệu dataset chất lượng cao.\n",
            "1 Sự nhất quán trong không gian và sự liên kết về mặt thời gian\n",
            "Duy trì sự nhất quán trong không gian và sự liên kết về mặt thời gian giữa các vật thể, nhân vật và\n",
            "bối cảnh là một trong những thử thách lớn nhất trong bài toán tạo sinh video [8], [11]. Sự nhất quán\n",
            "về không gian yêu cầu mô hình phải có sự hiểu biết về không gian ba chiều trong video và theo sát vị\n",
            "trí, phương hướng và sự tương tác giữa các vật thể trong video. Vấn đề này trở nên khó khăn khi câu\n",
            "văn bản mô tả những phân cảnh có tính phức tạp cao, với nhiều vật thể tương tác với nhau, yêu cầu\n",
            "mô hình phải có hiểu biết phức tạp về bối cảnh.\n",
            "Bên cạnh đó, sự nhất quán về thời gian yêu cầu video được tạo ra không chỉ tuân theo mạch tường\n",
            "thuật được mô tả trong văn bản mà chuyển động và chuyển tiếp giữa các khung hình cũng mượt mà\n",
            "và chân thực. Để đạt được sự mạch lạc về mặt thời gian đòi hỏi mô hình phải hiểu được mối quan hệ\n",
            "nhân quả và trình tự của các sự kiện trong câu text prompt, chuyển chúng thành một chuỗi khung hình\n",
            "mạch lạc về mặt trực quan.\n",
            "2 Độ phức tạp trong tính toán\n",
            "Nhu cầu duy trì đồng thời sự nhất quán về không gian và tính liên kết về thời gian làm tăng đáng kể\n",
            "yêu cầu tính toán của việc tạo văn bản thành video. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mỗi khung hình trong video được tạo ra đều phải\n",
            "liến kết đến tất cả các khung hình trước đó, đến từng chi tiết để đảm bảo độ chính xác về không gian\n",
            "và quá trình chuyển đổi giữa các khung hình phải được mô hình hóa cẩn thận để duy trì dòng thời gian.\n",
            "Quá trình này yêu cầu tài nguyên tính toán khổng lồ [8] [11], đặc biệt đối với các video có độ phân giải\n",
            "cao trong đó độ trung thực của từng pixel có thể ảnh hưởng đến chất lượng tổng thể và độ chân thực\n",
            "của video.\n",
            "Hơn nữa, các mô hình tổng hợp được sử dụng để tổng hợp văn bản thành video, chẳng hạn như\n",
            "Mạng GAN, VAE hay mạng Diffusion,đều cần một lượng tính toán khổng lồ. Khi được giao nhiệm vụ\n",
            "tạo video, các mô hình này phải hoạt động trên không gian đầu ra lớn hơn nhiều so với việc tạo hình\n",
            "ảnh, xử lý nhiều khung hình thậm chí chỉ trong vài giây video. Điều này không chỉ đòi hỏi sức mạnh\n",
            "xử lý đáng kể mà còn đặt ra những thách thức về bộ nhớ và lưu trữ, vì mô hình phải duy trì và xử lý\n",
            "lượng lớn dữ liệu để tạo ra đầu ra video cuối cùng.\n",
            "3 Thiếu các datasets có chất lượng cao\n",
            "Trong việc chuyển đổi văn bản thành video, một trong những khó khăn lớn nhất chính là việc tìm kiếm\n",
            "và sử dụng dữ liệu phù hợp. Có một sự thiếu hụt rõ ràng về các bộ dữ liệu lớn, nơi mô tả văn bản chi\n",
            "tiết đi kèm với video tương ứng [9], [7] [3] khiến việc thu thập dữ liệu trở nên cực kỳ phức tạp. Cần\n",
            "phải có những mô tả rất cụ thể và chính xác về nội dung video, điều này làm tăng thêm độ khó trong\n",
            "việc tạo ra những bộ dữ liệu đa dạng và chất lượng cao.\n",
            "Để giải quyet vấn đề này, các nhà nghiên cứu đang áp dụng nhiều phương pháp như tạo dữ liệu\n",
            "giả, phương pháp tăng cường dữ liệu, sử dụng crowdsourcing để thu thập mô tả video, và áp dụng kỹ\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "thuật học chuyển giao từ các nhiệm vụ có liên quan. Mặc dù đã có nhiều cố gắng, việc vượt qua những\n",
            "trở ngại liên quan đến việc tiếp cận dữ liệu vẫn là một bước tiến quan trọng để phát triển công nghệ\n",
            "chuyển đổi văn bản thành video.\n",
            "Nhìn chung đó là những thách thức chính cho bài toán tạo sinh video từ văn bản. Ở phần sau, chúng\n",
            "ta hãy cùng đi vào tìm hiểu xem có những phương pháp nào được sử dụng để vượt qua những thách\n",
            "thức trên.\n",
            "Phần III: Các Dataset phổ biến\n",
            "Việc sử dụng các bộ dữ liệu gồm video kèm theo mô tả (caption) để huấn luyện các mô hình tạo sinh\n",
            "video là một phần không thể thiếu trong quá trình phát triển công nghệ này. Những bộ dữ liệu này\n",
            "cung cấp cho mô hình một cơ sở dữ liệu phong phú, giúp mô hình học cách hiểu và tái tạo lại các sự\n",
            "kiện, hành động, và mối liên kết giữa các nhân vật trong video dựa trên mô tả văn bản. Qua đó, mô\n",
            "hình có thể tăng cường khả năng nhận thức về không gian và thời gian, cũng như cách các yếu tố trong\n",
            "video tương tác với nhau. Việc này đòi hỏi bộ dữ liệu phải đa dạng về nội dung, cảnh quay và phong\n",
            "cách kể chuyện, giúp mô hình có khả năng áp dụng vào nhiều tình huống và bối cảnh khác nhau, từ đó\n",
            "mở rộng khả năng ứng dụng của công nghệ tạo sinh video trong thực tế. Sau đây là một số bộ dữ liệu\n",
            "phổ biến, thường xuyên được sử dụng để huấn luyện các mô hình tạo sinh video\n",
            "3.1 HowTo100M\n",
            "HowTo100M ( https://www.di.ens.fr/willow/research/howto100m ) là một tập dữ liệu quy mô lớn\n",
            "bao gồm 136 triệu đoạn clip video được thu thập từ 1.22 triệu video hướng dẫn có lời bình trên web,\n",
            "mô tả con người thực hiện và mô tả hơn 23 nghìn nhiệm vụ trực quan khác nhau. Tập dữ liệu được tạo\n",
            "ra bằng cách sử dụng WikiHow để xác định 23,611 nhiệm vụ trực quan từ các hoạt động tương tác với\n",
            "thế giới vật lý, loại trừ các nhiệm vụ trừu tượng. Các video hướng dẫn được tìm kiếm trên YouTube\n",
            "dựa trên các tiêu chí như có phụ đề tiếng Anh và thu hút ít nhất 100 lượt xem, đồng thời loại bỏ video\n",
            "quá dài hoặc thiếu nội dung. Tập dữ liệu được tinh lọc để loại bỏ trùng lặp và cải thiện chất lượng,\n",
            "mặc dù vẫn có khả năng chứa bản sao do tải lên nhiều lần, nhưng điều này không ảnh hưởng lớn đến\n",
            "quy mô dự án của tập dữ liệu này.\n",
            "Hình 1: Ví dụ về các cặp clip-caption được chọn dựa trên sự tương đồng giữa ảnh và mô tả tương ứng.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3.2 WebVid\n",
            "WebVid ( https://maxbain.com/webvid-dataset )là tập dữ liệu được thu thập từ web, bao gồm 2.5\n",
            "triệu cặp video-text, vượt trội hơn hẳn so với các tập dữ liệu trước đó. Quá trình thu thập dữ liệu này\n",
            "tuân thủ một phương pháp tương tự như Google Conceptual Captions, với việc nhận thấy một phần\n",
            "đáng kể các hình ảnh từ CC3M thực chất là hình thu nhỏ của video, WebVid khai thác các nguồn\n",
            "video tương tự để tạo ra tập dữ liệu phong phú. Tập dữ liệu video này, mặc dù nhỏ hơn đáng kể so\n",
            "với HowTo100M về thời lượng và số lượng cặp clip-caption, nhưng lại nổi bật với chất lượng caption\n",
            "thủ công cao, tạo ra câu văn rõ ràng và mô tả chính xác nội dung hình ảnh. Bên cạnh đó, tập dữ liệu\n",
            "Google Conceptual Captions cho hình ảnh của WebVid, với 3.3 triệu cặp text-image, mở rộng phạm vi\n",
            "đa dạng phong cách mô tả và hình ảnh, phản ánh một cách chân thực hơn các nguồn thông tin đa dạng\n",
            "từ web.\n",
            "Hình 2: Ví dụ minh họa về cặp video và văn bản mô tả trong WebVid dataset:\n",
            "3.3 CelebV-Text\n",
            "CelebV-Text ( https://celebv-text.github.io ), một tập dữ liệu lớn, đa dạng và chất lượng cao của\n",
            "cặp video về khuôn mặt và văn bản mô tả, nhằm hỗ trợ nghiên cứu về nhiệm vụ tạo video từ văn bản\n",
            "mô tả cho khuôn mặt. CelebV-Text bao gồm 70,000 đoạn clip video về khuôn mặt trong môi trường tự\n",
            "nhiên với nội dung hình ảnh đa dạng, mỗi đoạn được ghép nối với 20 đoạn văn bản mô tả được tạo ra\n",
            "thông qua chiến lược tạo văn bản bán tự động. Các văn bản mô tả được cung cấp có chất lượng cao, mô\n",
            "tả chính xác cả các thuộc tính tĩnh và động. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sự vượt trội của CelebV-Text so với các tập dữ liệu khác\n",
            "được thể hiện qua phân tích thống kê toàn diện về video, văn bản mô tả và mối liên quan text-video.\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 3: CelebV-Text bao gồm (a) 70,000 mẫu video và (b) 1,400,000 văn bản mô tả. Mỗi mẫu video\n",
            "được ghi chú với hình dáng tổng quát, hình dáng chi tiết, điều kiện ánh sáng, hành động, cảm xúc, và\n",
            "hướng ánh sáng.\n",
            "Phần IV: Các hướng tiếp cận chính\n",
            "Khi nói đến việc tạo video từ văn bản, có hai phương pháp tiếp cận chính mà các nhà nghiên cứu thường\n",
            "theo đuổi. Một là sử dụng mô hình dựa trên cấu trúc Transformer, vốn nổi tiếng với khả năng hiểu và\n",
            "xử lý ngôn ngữ tự nhiên một cách hiệu quả. Phương pháp thứ hai là áp dụng kỹ thuật diffusion, một\n",
            "cách tiếp cận mới mẻ và đầy hứa hẹn trong việc tạo ra hình ảnh và video từ văn bản.\n",
            "Gần đây, một số nghiên cứu đã bắt đầu kết hợp những ưu điểm của cả hai mô hình này, tích hợp\n",
            "cấu trúc Transformer vào bên trong mô hình diffusion để tạo ra những kết quả còn ấn tượng hơn. Một\n",
            "ví dụ điển hình cho sự kết hợp này là mô hình Sora của OpenAI, được kỳ vọng sẽ mở ra những khả\n",
            "năng mới trong lĩnh vực tạo sinh video từ văn bản.\n",
            "4 Transformer-based Pretraining\n",
            "Transformer, kể từ khi được giới thiệu, đã tạo ra một cuộc cách mạng trong nhiều lĩnh vực của trí tuệ\n",
            "nhân tạo, từ xử lý ngôn ngữ tự nhiên đến nhận dạng hình ảnh. Gần đây, nhiều sự chú ý đã được hướng\n",
            "tới việc áp dụng kiến trúc transformer trong tác vụ tạo sinh video, một lĩnh vực đầy thách thức nhưng\n",
            "cũng rất hứa hẹn. Trong bối cảnh này, transformer được sử dụng để hiểu và dự đoán các mô hình thời\n",
            "gian không gian phức tạp trong dữ liệu video, cho phép chúng tạo ra những đoạn video mới mẻ và độc\n",
            "đáo từ mô tả văn bản. Sau đây là những công trình nghiên cứu nổi bật với hướng tiếp cận này.\n",
            "4.1 VideoGPT:\n",
            "Trong nghiên cứu tiên phong về việc áp dụng công nghệ Transformer vào việc tạo video, bài báo khoa\n",
            "học \"VideoGPT: Video Generation using VQ-VAE and Transformers\" [10] đưa ra một kiến trúc độc\n",
            "đáo nhằm khai thác tiềm năng của các mô hình tạo sinh dựa trên xác suất. Kiến trúc này được thiết\n",
            "kế để mở rộng và tối ưu hóa quá trình tạo video, làm cho nó trở nên mạnh mẽ và linh hoạt hơn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trong\n",
            "VideoGPT, có một số thành phần chính được đưa ra, mỗi thành phần đều đóng vai trò quan trọng\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "trong việc tạo ra các video chất lượng cao và đa dạng từ văn bản hoặc các dạng đầu vào khác. Một số\n",
            "thành phần chính của VideoGPT được thể hiện trong Hình 7 bao gồm:\n",
            "Hình 4: Kiến trúc của VideoGPT bao gồm 2 thành phần: khối VQ-VAE và khối GPT\n",
            "•VQ-VAE (Vector Quantized Variational AutoEncoder) : được đề xuất bởi [4], là một dạng\n",
            "mô hình nén các điểm dữ liệu ở không gian nhiều chiều về không gian latent rời rạc và tái tạo lại\n",
            "những điểm dữ liệu đó. Thành phần này có chức năng chính là học những biểu diễn của các video\n",
            "trong không gian latent, cụ thể như sau:\n",
            "–Đầu tiên một khối encoder E(x)−→hmã hóa video x thành một chuỗi các vector h. Sau\n",
            "đó chuỗi vector này sẽ được rời rạc hóa bằng cách sử dụng phương pháp nearest neighbor để\n",
            "map về các vector codebook có sẵn.\n",
            "–Sau đó một khối D(e)−→ˆxhọc để tái tạo lại xtừ những vector đã được rời rạc hóa.\n",
            "Để có thể học mô hình hóa được data dạng video, VideoGPT sử dụng một chuỗi các khối 3D\n",
            "convolutions để lấy mẫu xuống (downsample) thông tin không gian và thời gian, theo sau đó bằng\n",
            "một khối attention residual. Khối attention residual được thiết kế như hình 5:\n",
            "Hình 5: Khối attention residual\n",
            "•GPT:Ở giai đoạn tiếp theo, sau khi đã có những vector rời rạc trong không gian latent ở bước\n",
            "trước, tác giả dùng một kiểu kiến trúc tương tự GPT (Generative pretrained transformer) để mô\n",
            "hình hóa những vector này thành một chuỗi liên tục. Và train bằng cách dự đoán vector của frame\n",
            "kế tiếp.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tóm lại, videoGPT giới thiệu một kiến trúc đơn giản và hiệu quả cho bài toán tạo sinh video, sử dụng\n",
            "2 thành phần chính là khối VQ-VAE có chức năng học không gian latent rời rạc của các video và khối\n",
            "kiến trúc tương tự như GPT để mô hình hóa và tạo sinh chuỗi. Sự đơn giản của phương pháp này cùng\n",
            "với tính hiệu quả của nó mang đến một hướng nghiên cứu về các mô hình tạo video.\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4.2 Make-A-Video\n",
            "Được giới thiệu trong [7], đây là một phương pháp tạo video từ văn bản mà không cần dữ liệu video\n",
            "đi kèm văn bản mô tả, từ đó giải quyết vấn đề về thiếu hụt data trong tác vụ tạo sinh video. Phương\n",
            "pháp này mở rộng từ mô hình tạo hình ảnh từ văn bản mô tả (Text to Image-T2I) bằng cách thêm vào\n",
            "các mô-đun spatialtemporal, cho phép tạo video có độ phân giải cao và tốc độ khung hình cao từ văn\n",
            "bản đầu vào. Make-A-Video không yêu cầu dữ liệu video có kèm theo văn bản mô tả và có thể tạo ra\n",
            "video với chất lượng và mức độ chi tiết cao, mở ra khả năng áp dụng trong nhiều lĩnh vực khác nhau.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 6: Make-A-Video high-level architecture\n",
            "Make-A-Video bao gồm ba thành phần chính:\n",
            "•Một mô hình cơ sở T2I được huấn luyện trên các cặp text-image : Sử dụng 3 networks để\n",
            "tạo ra hình ảnh độ phân giải cao từ văn bản. Prior network P trong quá trình inference tạo ra\n",
            "các image embedding từ text embedding và các BPE encoded text tokens. Decoder network D\n",
            "tạo ảnh RGB với low-resolution (64 ×64) dựa trên các image embedding. Hai super-resolution\n",
            "networks SR1, SR htăng độ phân giải của ảnh lên thành 256 ×256 và 768 ×768.\n",
            "•Spatiotemporal network sử dụng các spatiotemporal convolution và attention layers\n",
            "để mở rộng các blocks. Điều này đòi hỏi phải điều chỉnh các lớp tích chập và các lớp attention.\n",
            "Ngoài ra, spatiotemporal decoder network tạo ra những khung hình RGB độ phân giải thấp ban\n",
            "đầu. Các khung hình này sau đó được cải thiện bởi interpolation network và các super-resolution\n",
            "networks đảm bảo sự nhất quán giữa các khung hình để tránh flickering artifacts. Super-resolution\n",
            "được sử dụng do hạn chế về bộ nhớ và khả năng tính toán cùng với sự khởi tạo consistent noise\n",
            "giữa các khung hình để duy trì nội dung chi tiết giữa chúng.\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 7: Kiến trúc và cơ chế khởi tạo của Pseudo-3D convolutional và attention layers, cho phép chuyển\n",
            "đổi mô hình T2I đã được huấn luyện trước sang chiều không gian thời gian.\n",
            "– Pseudo-3D convolutional layers : Việc sử dụng Pseudo-3D convolutional layers nhằm\n",
            "nâng cao 2D convolutional network cho temporal learning mà không cần đến tính toán của\n",
            "3D convolutions. Xếp 1D convolution sau 2D convolution layer nhằm thúc đẩy việc chia sẻ\n",
            "thông tin giữa không gian và thời gian đồng thời duy trì sự tách biệt giữa 2D convolution đã\n",
            "huấn luyện trước và 1D convolution mới. Lớp này được định nghĩa theo mặt toán học, với\n",
            "tensor được biểu diễn trong không gian đa chiều nơi mà B, C, F, H, và W lần lượt ký hiệu\n",
            "cho batch, channels, frames, height, width. Nó cũng lưu ý rằng khi khởi tạo, mạng có khả\n",
            "năng tạo ra nhiều hình ảnh chính xác về mặt văn bản nhưng không nhất quán về thời gian\n",
            "do nhiễu ngẫu nhiên.\n",
            "– Pseudo-3D attention layers : với mục đích là chèn thông tin văn bản vào network mà\n",
            "không tốn nhiều tài nguyên tính toán như sử dụng full 3D convolutions. Việc này được thực\n",
            "hiện bằng cách xếp chồng các 1D attention layer lên trên pre-trained spatial attention layer.\n",
            "Những lớp này cho phép network duy trì sự chú ý trong không gian đồng thời kết hợp thông\n",
            "tin thời gian. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cách tiếp cận này giúp khả thi về quản lý tài nguyên bộ nhớ và tính toán,\n",
            "đồng thời giải quyết thách thức tích hợp thời gian vào tạo ảnh và video.\n",
            "•Spatiotemporal network còn có thêm một thành phần quan trọng cho việc tạo video là frame\n",
            "interpolation network nhằm cải thiện tốc độ tạo khung hình. Network có thể tăng số lượng\n",
            "khung hình của video được tạo ra thông qua nội suy khung hình để tạo ra các chuỗi smooth hơn\n",
            "hoặc ngoại suy khung hình trước/sau để kéo dài video. Để quản lý giới hạn về bộ nhớ và tính\n",
            "toán, network tinh chỉnh một spatiotemporal decoder cho nhiệm vụ nội suy khung hình với mask\n",
            "để nâng cao chất lượng video. Quá trình này bao gồm việc thêm các channels bổ sung vào input\n",
            "và sử dụng zero-padding cho các masked frames. Network cũng có khả năng bỏ qua một số khung\n",
            "hình biến đổi và điều kiện fps trong thời gian suy luận, cho phép linh hoạt trong việc nâng cao\n",
            "chất lượng thời gian từ một số lượng khung hình nhất định sang một số lượng lớn hơn.\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4.3 Phenaki\n",
            "Hình 8: Kiến trúc chung của mô hình Phenaki\n",
            "Mô hình Phenaki, được trình bày trong công trình \"Phenaki: Variable Length Video Generation From\n",
            "Open Domain Textual Description\" [8], mở ra một hướng mới trong việc tạo video từ văn bản. Được\n",
            "thiết kế để tạo ra những đoạn video chân thực từ các mô tả văn bản, Phenaki giải quyết nhiều thách\n",
            "thức đáng kể trong lĩnh vực này. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Đó là việc tối ưu hóa hiệu suất tính toán, đối mặt với tình trạng thiếu\n",
            "hụt nguồn dữ liệu văn bản-video chất lượng cao và duy trì sự nhất quán trong không gian cũng như\n",
            "tính liên kết về thời gian cho các video dài. Bằng cách biến đổi các đoạn văn bản thành những câu\n",
            "chuyện video liền mạch, Phenaki không chỉ đặt ra một tiêu chuẩn mới mà còn cho thấy khả năng ứng\n",
            "dụng rộng rãi của nó trong thực tế.\n",
            "4.3.1 Kiến trúc Encoder-Decoder cho video: C-ViVIT\n",
            "Để có thể làm được những điều trên, Phenaki giới thiệu một kiến trúc encoder-decodcer mới, đặt tên\n",
            "là C-ViViT, được mô tả trong Hình 8. Kiến trúc này có 2 khả năng chính.\n",
            "•Kiến trúc này có thể khai thác sự dư thừa thời gian trong video để cải thiện chất lượng tái tạo\n",
            "mỗi khung hình đồng thời nén số lượng video token từ 40% trở lên.\n",
            "•Cho phép mã hóa và giải mã các video có độ dài thay đổi dựa trên cấu trúc của nó.\n",
            "Một trong những thách thức lớn nhất đối với các mô hình tạo sinh video từ văn bản đó chính là\n",
            "quá trình nén video thành các vector biểu diễn. Các công trình trước đó đi theo 2 hướng chính để làm\n",
            "việc này, đó là sử dụng các image encoder theo từng frame một, hoặc là sử dụng một video encoder có\n",
            "số frame cố định. Hướng thứ nhất cho phép tạo sinh video với độ dài tùy thích, tuy nhiên trên thực tế\n",
            "thì việc tạo sinh video với độ dài lớn là rất khó khăn và tốn nhiều tài nguyên. Phương pháp thứ 2 có\n",
            "thể giúp giảm tài nguyên tính toán, tuy nhiên lại không thể tạo sinh video với độ dài tùy thích. Mục\n",
            "tiêu của Phenaki là giải quyết 2 vấn đề này: tạo sinh video với độ dài tùy thích, đồng thời nén số lượng\n",
            "token video về mức tối thiểu. Kiến trúc C-ViViT, là một biến thể của mô hình ViViT có khả năng tạo\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "sinh video và nén video trong các chiều thời gian và không gian, trong khi vẫn có tính hồi quy theo thời\n",
            "gian.\n",
            "Khối Encoder:\n",
            "Hình 9: Kiến trúc của khối encoder\n",
            "Khối encoder chuyển chuỗi video thành các token biểu diễn nhỏ gọn phù hợp để xử lý bởi các lớp\n",
            "transformers của mô hình.Quy trình bắt đầu với một chuỗi video ban đầu ở không gian bốn chiều biểu\n",
            "diễn thời gian, chiều cao, chiều rộng và kênh màu. Chuỗi này sau đó được nén thành biểu diễn token\n",
            "nhỏ hơn phân biệt giữa khung hình đầu tiên và các token video không gian-thời gian tiếp theo, phụ\n",
            "thuộc vào các khung hình trước.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Quá trình nén được thực hiện bằng cách trích xuất các patches không chồng lấn từ khung hình đầu\n",
            "tiên và các khung hình video tiếp theo, sau đó được làm phẳng và chiếu vào không gian chiều thấp hơn.\n",
            "Các chiều không gian và thời gian của các patches này được sắp xếp lại thành định dạng tensor phân\n",
            "biệt rõ ràng giữa chiều không gian và chiều thời gian. Quá trình này được biểu diễn trong hình 8.\n",
            "Hình 10: Quá trình trích xuất các patches không chồng lấn sau đó làm phẳng và giảm chiều.\n",
            "Bộ mã hóa áp dụng nhiều lớp transformer trên các chiều không gian sử dụng Spatial Transformer\n",
            "với attention toàn cục. Khối transformer này có nhiệm vụ học thông tin về không gian. Tiếp theo là\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "các lớp transformer bổ sung trên chiều thời gian sử dụng causal attention. Các lớp này có nhiệm vụ\n",
            "học thông tin về thời gian. Điều này đảm bảo rằng mỗi token không gian chỉ tương tác với các token\n",
            "không gian từ các khung hình trước, cho phép khung hình đầu tiên được mã hóa độc lập. Thiết kế này\n",
            "tạo điều kiện cho việc kết hợp các mô hình text-to-image trong mô hình video và cho phép quá trình\n",
            "tạo video được điều kiện hóa (conditioned) bởi một tập hợp khung hình ban đầu.\n",
            "Các vector đầu ra sau khi đi qua các lớp transformer sẽ được lượng tử hóa về không gian latent rời\n",
            "rạc. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tương tự như trong kiến trúc VQ-VAE.\n",
            "Khối Decoder: Khối decoder của C-ViViT đơn giản là một khối encoder được lật ngược. Đầu\n",
            "tiên token được chuyển đổi thành các embedding. Sau đó là temporal transformer, tiếp theo là spatial\n",
            "transformer. Đầu ra sau đó được áp dụng một phép chiếu tuyến tính đơn để ánh xạ các token trở lại\n",
            "không gian pixel.\n",
            "4.3.2 Tạo sinh video từ văn bản với bidirectional transformers\n",
            "Hình 11: Quá trình training bidirectional transformer\n",
            "Việc chuyển đổi từ văn bản sang video có thể được định nghĩa như một tác vụ sequence-to-sequence,\n",
            "thường được giải quyết bằng cách sử dụng các mô hình autoregressive transformer dự đoán tuần tự các\n",
            "token video từ nhúng văn bản. Tuy nhiên, cách tiếp cận này trở nên không hiệu quả cho các video dài\n",
            "do thời gian lấy mẫu tăng tuyến tính.\n",
            "Để cải thiện hiệu quả, tác giả sử dụng mô hình bidirectional transformer có khả năng dự đoán đồng\n",
            "thời nhiều token video, giảm đáng kể thời gian lấy mẫu bất kể độ dài của chuỗi video. Trong quá trình\n",
            "huấn luyện, một phần các token video được che kín và các token này được dự đoán bằng các embedding\n",
            "văn bản và các token không bị che kín, với mô hình học thông qua hàm loss cross-entropy.\n",
            "Phương pháp này, lấy cảm hứng từ các kỹ thuật như được sử dụng trong MaskGIT, giảm đáng kể\n",
            "số bước lấy mẫu cần thiết (thông thường từ 12 đến 48 bước), có khả năng cải thiện chất lượng video\n",
            "được tạo ra trong khi đảm bảo quá trình xử lý nhanh hơn.\n",
            "Quá trình inference Trong quá trình inferece, trước tiên tất cả các video token được đánh dấu\n",
            "là token đặc biệt [MASK]. Sau đó, tại mỗi bước inference, tất cả các token video bị che được dự đoán\n",
            "cùng một lúc dựa trên các embedding văn bản và các token video không bị che (đã dự đoán). Sau đó,\n",
            "một tỷ lệ βicủa các token được dự đoán tại bước lấy mẫu i được giữ lại, và các token còn lại sẽ được\n",
            "che lại và dự đoán lại ở bước tiếp theo.\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4.3.3 Tổng kết\n",
            "Phenaki được giới thiệu là một mô hình có khả năng tạo ra video có độ dài biến thiên dựa trên chuỗi\n",
            "prompt văn bản từ các chủ đề mở. Nó sử dụng C-ViViT làm bộ mã hóa video, một mô hình mới cung\n",
            "cấp khả năng nén không gian-thời gian hiệu quả trong khi vẫn duy trì tính tự hồi quy theo thời gian.\n",
            "Phenaki cho thấy kết quả hứa hẹn trong việc dự đoán video và có thể tạo ra video dài từ lời nhắc văn\n",
            "bản, với sự linh hoạt để bắt đầu từ một khung hình nhất định. Phenaki có thể tạo ra các câu chuyện\n",
            "video dài, có mạch lạc từ nhiều prompt văn bản, minh họa tiềm năng của nó như một công cụ sáng tạo\n",
            "cho việc kể chuyện bằng video.\n",
            "4.4 CogVideo\n",
            "CogVideo [3] là một mô hình tạo video từ văn bản mô tả sử dụng kiến trúc Transformer với 9 tỷ tham\n",
            "số, được huấn luyện dựa trên mô hình sinh ảnh từ văn bản mô tả CogView2. CogVideo sử dụng chiến\n",
            "lược huấn luyện phân cấp nhiều tốc độ khung hình để cải thiện việc căn chỉnh giữa văn bản mô tả và\n",
            "video, cũng như tinh chỉnh khả năng kiểm soát độ chính xác trong quá trình tạo video. Trong paper\n",
            "CogVideo đề cập đến việc mở rộng và áp dụng cơ chế Swin attention trong tạo video tự động, nhằm\n",
            "tăng cường tốc độ huấn luyện và suy luận.\n",
            "CogVideo sử dụng Multi-frame-rate Hierarchical Training để huấn luyện mô hình. Ý tưởng chính\n",
            "là thêm một frame-rate token vào văn bản mô tả và lấy mẫu các khung hình ở frame-rate này để tạo\n",
            "thành một chuỗi huấn luyện cố định. Động lực dựa trên hai phần:\n",
            "•Táchvideodàithànhcácđoạnởframe-ratecốđịnhthườngdẫnđếnsựkhôngkhớpnghĩa.CogVideo\n",
            "vẫn sử dụng toàn bộ văn bản nhưng đoạn clip bị cắt có thể chỉ chứa hành động không hoàn chỉnh.\n",
            "•Các khung hình liền kề thường rất giống nhau. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Một sự thay đổi lớn so với khung hình trước có\n",
            "thể gây ra sai số lớn. Điều này khiến các mô hình ít có xu hướng khám phá mối liên hệ dài hạn\n",
            "vì đơn giản sao chép khung hình trước đó giống như một lối tắt.\n",
            "Trong quá trình huấn luyện, nhằm đạt được được sự khớp chính xác giữa văn bản mô tả và hình\n",
            "ảnh. CogVideo thiết lập trước một dãy các frame-rate và chọn ra frame-rate thấp nhất có thể cho từng\n",
            "cặp text-video, đảm bảo có thể lấy mẫu được ít nhất là 5 khung hình. Dù phương pháp này cải thiện\n",
            "sự phù hợp giữa văn bản mô tả và video, nhưng video tạo ra ở frame-rate thấp có thể không liền mạch.\n",
            "Do đó, một frame interpolation model được tạo ra để thêm các khung hình chuyển tiếp vào video, giúp\n",
            "cho quá trình sinh video trở nên mượt mà hơn. Nhờ vào sự linh hoạt của CogLM, hai mô hình này có\n",
            "thể sử dụng chung một cấu trúc và quy trình huấn luyện, chỉ khác biệt ở điểm sử dụng các attention\n",
            "masks.\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 12: Multi-frame-rate hierarchical generation framework in CogVideo\n",
            "Quá trình Multi-frame-rate hierarchical generation của CogVideo là một quá trình đệ quy gồm hai\n",
            "giai đoạn. Đầu tiên là sinh tuần tự khung hình chủ chốt dựa trên frame-rate thấp và văn bản mô tả;\n",
            "thứ hai là nội suy đệ quy các khung hình dựa trên văn bản mô tả, frame-rate và các khung hình đã\n",
            "biết, với mục tiêu tạo ra video có nhiều khung hình hơn thông qua việc chia các khung hình đã sinh ra\n",
            "và nội suy thêm khung hình giữa chúng.\n",
            "Cũng trong bài báo CogVideo tác giả đề xuất việc sử dụng các mô hình tạo ảnh đã được huấn luyện\n",
            "trước để hỗ trợ việc tạo video từ văn bản mô tả, thay vì dựa trên việc thu thập dữ liệu ảnh và video\n",
            "chất lượng cao, quá trình này thường tốn kém và mất thời gian. Cụ thể áp dụng Dual-channel Attention\n",
            "bằng cách thêm spatial-temporal attention channel vào mỗi lớp chuyển đổi của mô hình CogView2 đã\n",
            "được huấn luyện trước, giữ nguyên các tham số cũ và chỉ huấn luyện các tham số mới của lớp attention.\n",
            "Điều này giúp giữ lấy kiến thức về mối quan hệ text-image từ CogView2 mà không làm hỏng trọng số\n",
            "đã học được khi chuyển sang tạo video, vốn đòi hỏi sự chú ý đến cả không gian và thời gian.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 13: Dual-channel attention block\n",
            "Để giảm thiểu áp lực về thời gian và bộ nhớ trong quá trình huấn luyện và suy luận, CogVideo áp\n",
            "dụng Swin Attention, mở rộng nó cho các tình huống auto-regressive và temporal scenario bằng cách\n",
            "sử dụng auto-regressive attention mask trong shifted windows. Phát hiện thú vị là Swin Attention cho\n",
            "phép tạo ra song song ở các vùng xa của các khung hình khác nhau, tăng tốc độ cho auto-regressive,\n",
            "với sự phụ thuộc vào việc tạo token dựa trên auto-regressive mask và shifted windows, giới hạn sự chú\n",
            "ý chỉ trong phạm vi kích thước cửa sổ.\n",
            "Hình 14: Autoregressive swin attention (window size 2 ×2)\n",
            "5 Diffusion-based models\n",
            "Một hướng tiếp cận khác cho tác vụ tạo sinh video từ văn bản là hướng áp dụng mô hình diffusion.\n",
            "Hướng tiếp này là một trong những phát triển đáng chú ý gần đây, được thúc đẩy bởi thành công mà\n",
            "các mô hình diffusion đã đạt được trong việc sinh ra hình ảnh chất lượng cao. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Các nghiên cứu tiên tiến\n",
            "trong lĩnh vực này đang khám phá cách thức áp dụng các nguyên tắc diffusion để tạo ra video không\n",
            "chỉ có chất lượng hình ảnh sắc nét mà còn đảm bảo tính liên tục và mượt mà về mặt chuyển động. Dưới\n",
            "đây là một số công trình nổi bật đã đưa ra cách tiếp cận sử dụng mô hình diffusion cho việc sinh video,\n",
            "mở ra những khả năng mới cho việc tạo ra nội dung video phong phú và đa dạng từ văn bản mô tả.\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "5.1 Video Diffusion Models\n",
            "Đây là một trong những công trình nghiên cứu đầu tiến tiếp cận theo hướng sử dụng mô hình diffusion\n",
            "để tạo sinh video. Video Diffusion Models [2] là sự mở rộng tự nhiên của kiến trúc image diffusion và\n",
            "cho phép đào tạo chung từ dữ liệu ảnh và video. Để tạo ra video dài và độ phân giải cao hơn, các tác\n",
            "giả đã giới thiệu một kỹ thuật lấy mẫu điều kiện mới cho việc mở rộng video theo không gian và thời\n",
            "gian.\n",
            "Trong công trình nghiên cứu về mô hình hình ảnh, U-Net là kiến trúc tiêu chuẩn cho image diffusion,\n",
            "bao gồm quá trình giảm và tăng mẫu không gian với các skip connections. U-net được xây dựng từ các\n",
            "khối 2D convolutional và mỗi khối được theo sau bởi một khối spatial attention. Trong bài báo Video\n",
            "Diffusion Models tác giả đề xuất mở rộng kiến trúc này cho dữ liệu video với U-Net 3D, phân tách theo\n",
            "không gian và thời gian, và thêm khối temporal attention, cho phép đào tạo chung trên video và hình\n",
            "ảnh, cải thiện chất lượng mẫu.\n",
            "Hình 15: 3D U-Net architecture trong Video Diffusion Models\n",
            "Thông thường việc giải quyết thách thức tính toán khi mô hình hóa video, thường gồm hàng trăm\n",
            "đến hàng nghìn khung hình, bằng cách đào tạo model trên một tập hợp con khung hình và sau đó mở\n",
            "rộng mẫu để tạo video dài hơn. Hai phương pháp lấy mẫu điều kiện từ diffusion model gồm: sử dụng\n",
            "phương pháp thay thế - không hiệu quả cho mô hình video do thiếu sự liên kết giữa các khung hình\n",
            "được sinh ra, và phương pháp được đề xuất trong paper gọi là reconstruction-guided sampling. Phương\n",
            "pháp này cải thiện chất lượng mẫu bằng cách điều chỉnh denoising model với gradient term based dựa\n",
            "trên sự tái tạo của model, đặc biệt khi kết hợp với Langevin diffusion samplers. Nó cũng mở rộng sang\n",
            "nội suy không gian cho super-resolution, thể hiện tính linh hoạt của phương pháp trong việc tạo video\n",
            "độ phân giải cao từ đầu vào độ phân giải thấp.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "5.2 MagicVideo\n",
            "MagicVideo [11] có thể tạo ra các đoạn video mượt mà phù hợp với văn bản mô tả đã cho. Nhờ vào\n",
            "kiến trúc 3D U-Net và hiệu quả cùng với việc mô hình hóa phân phối video trong không gian low-\n",
            "dimensional. MagicVideo có thể tổng hợp video 256 ×256 spatial resolution trên một card GPU, giảm\n",
            "đến 64 lần lượng tính toán so với Video Diffusion Models (VDM) về FLOPs. MagicVideo còn giới thiệu\n",
            "hai thiết kế mới để thích nghi bộ lọc U-Net được đào tạo trên dữ liệu hình ảnh sang dữ liệu video, và\n",
            "chứng minh khả năng tạo ra các đoạn video chất lượng cao với nội dung thực tế hoặc tưởng tượng.\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 16: (a) data flow cho cả quá trình training và inference: trong quá trình training, timestep t sẽ\n",
            "được chọn mẫu ngẫu nhiên từ [0, T] và các khung hình video đầu vào bị làm nhiễu qua quá trình lan\n",
            "truyền, U-Net được sử dụng để học cách tái tạo các khung hình video. Gaussian noise được chọn mẫu\n",
            "ngẫu nhiên trong suy luận, và denoising process được lặp lại T lần. Latent vector z sau đó được đưa\n",
            "vào bộ giải mã VAE và chuyển đổi sang không gian RGB. (b) là cấu trúc của spatiotemporal attention\n",
            "(ST-Attn). (c) là directed attention được sử dụng trong ST-Attn\n",
            "Trong quá trình huấn luyện model tạo video từ văn bản mô tả, MagicVideo tiếp cận bằng cách lấy\n",
            "mẫu một phần nhỏ các khung hình liên tiếp và xác định rõ frame-rate mới dựa trên độ dài mẫu. Để cải\n",
            "thiện chất lượng, model được huấn luyện trước mà không cần ghép cặp văn bản-video sử dụng dữ liệu\n",
            "video chất lượng cao, sau đó được tinh chỉnh với mục tiêu huấn luyện cụ thể, áp dụng loss function cho\n",
            "từng khung hình và sử dụng các embeddings để tinh chỉnh mô hình, cho phép tạo video liền mạch và\n",
            "chất lượng cao từ văn bản mô tả.\n",
            "Hình 17: VideoVAE decoder\n",
            "Trong quá trình tổng hợp hình ảnh RGB từ các decoding latent features quaVAE decoder đã được\n",
            "đào tạo trước, quá trình tái tạo từng khung hình video dẫn đến hiện tượng pixel dithering, làm giảm\n",
            "chất lượng thẩm mỹ hình ảnh. Các đặc trưng không gian với kích thước lớn hơn sẽ giảm bớt dithering\n",
            "nhưng cũng làm tăng chi phí tính toán. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Để cải thiện chất lượng hình ảnh mà không tăng tính toán, tác\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "giả đã giữ kích thước thấp cho latent features và thêm vào decoder hai khối temporal directed attention\n",
            "layers, tạo nên VideoVAE decoder giúp hiệu quả trong việc giảm thiểu dithering.\n",
            "5.3 Tune-A-Video\n",
            "\"Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation\" [9] là paper\n",
            "giới thiệu một phương pháp mới để tạo ra video từ các prompt văn bản bằng cách tận dụng khả năng của\n",
            "các mô hình diffusion text-to-image (T2I) đã được pretrained. Nghiên cứu này giải quyết vấn đề thiếu\n",
            "hụt các cặp văn bản-video chất lượng cao cho việc đào tạo bằng cách đề xuất phương pháp one-shot\n",
            "video-tuning, từ đó không cần phải phụ thuộc vào các cặp video-văn bản caption.\n",
            "Hình 18: Cái nhìn tổng quát về paper Tune-A-Video\n",
            ".\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cụ thể với một video cho trước, nhiệm vụ của model là fine-tune cụ thể trên video đó, để từ đó có\n",
            "thể edit video đó dựa theo yêu cầu từ text prompt của user. Điều này giúp giảm chi phí tính toán, khi\n",
            "thay vì phải train trên một tập dataset về video lớn, với chi phí về gán nhãn và về phần cứng khổng\n",
            "lồ, ta có thể tận dụng các mô hình Text-to-image có sẵn để tune duy nhất cho một video, và tương tác\n",
            "trên video đó. Phương pháp này được gọi là zero-shot video-tuning.\n",
            "Hình 19: Pipeline của paper Tune-a-video\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Paper này sử dụng Latent Diffusion Model (LDM, [6]) đã được pretrained như một mô hình text-to-\n",
            "image. Trong đó LDM sử dụng kiến trúc U-Net, sử dụng nhiều khối Convolution 2D và khối transformer,\n",
            "với từng khối transformer sử dụng các layer self-attention, cross-attention và feed-forward. Để sử dụng\n",
            "các khối này cho tác vụ video, nghiên cứu này có một số chỉnh sửa cho khối U-Net. Đầu tiên, khối\n",
            "Convolution 2D được thay thế bằng khối Convolution 3D giả, với các filter 3x3 được thay thế bằng các\n",
            "layer 1x3x3. Về khối attention, một khối temporal self-attention (T-Attn) được thêm vào ở cuối cùng\n",
            "ở mối khối transformer để mô tả thông tin về thời gian. Để tăng độ mạch lạc về thời gian cho video,\n",
            "paper này sử dụng một khối spatial-temporal attention thay cho khối self-attention. Trong đó, để giảm\n",
            "tài nguyên cần cho tính toán, attention chỉ được tính giữa frame hiện tại, frame liền trước nó và frame\n",
            "đầu tiên, trong đó, thông tin về feature giữa frame đầu tiên và frame liền trước được concat lại với\n",
            "nhau. Quá trình này được mô tả trong hình 20.\n",
            "Hình 20: Minh họa Spatial-Temporal Attention\n",
            "Tổng kết lại, bài báo giới thiệu một task mới có tên one-shot video-tuning cho việc tạo video từ văn\n",
            "bản (T2V), mà trong đó việc huấn luyện mô hình tạo sinh T2V chỉ sử dụng một cặp văn bản-video\n",
            "duy nhất với sự hỗ trợ của các mô hình chuyển đổi từ văn bản sang hình ảnh (T2I) đã được huấn luyện\n",
            "từ trước. Công cụ được giới thiệu, Tune-A-Video, hỗ trợ việc tạo và chỉnh sửa video dựa trên văn bản\n",
            "thông qua một chiến lược tuning đặc biệt và sự đảo ngược cấu trúc, đảm bảo tính nhất quán về thời\n",
            "gian trong các video được tạo ra. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hiệu quả của phương pháp này được chứng minh thông qua các thử\n",
            "nghiệm rộng rãi trên nhiều ứng dụng, cho thấy khả năng ấn tượng của nó.\n",
            "6 Diffusion Models with Transformer\n",
            "Đây là một phương pháp kết hợp những điểm mạnh của cả hai cách làm trước đây. Bằng cách dùng mô\n",
            "hình diffusion cùng với kiến trúc transformer - thay vì dùng kiến trúc UNet thông thường - cách tiếp\n",
            "cận này mở ra khả năng thiết kế mô hình linh hoạt hơn và tận dụng khả năng nhận diện hình ảnh ưu\n",
            "việt của transformer. Điều này giúp tạo ra những hình ảnh, video chất lượng cao, với hiểu biết sâu sắc\n",
            "về nội dung và bối cảnh hơn.\n",
            "Nghiên cứu \"Scalable Diffusion Models with Transformers\" [5] là một công trình tiên phong khám\n",
            "phá một nhánh mới của mô hình diffusion sử dụng kiến trúc transformer. Khác với các mô hình diffusion\n",
            "truyền thống thường sử dụng cốt lõi U-Net, nghiên cứu này giới thiệu việc sử dụng transformer hoạt\n",
            "động trên các patches trong không gian latent của hình ảnh. Điểm chính của nghiên cứu là về khả năng\n",
            "18\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "mở rộng của các Diffusion Transformers (DiTs) thông qua phân tích độ phức tạp của quá trình lan\n",
            "truyền xuôi, được đo bằng Gflops. Nghiên cứu đã tìm thấy một xu hướng nhất quán, khi mô hình DiTs\n",
            "có Gflops cao hơn, đạt được thông qua việc tăng độ sâu/rộng của transformer hoặc số lượng token đầu\n",
            "vào, thể hiện điểm Frechet Inception Distance (FID) thấp hơn, cho thấy hiệu suất tốt hơn. Đáng chú\n",
            "ý, mô hình lớn nhất, DiT-XL/2, đã vượt qua các mô hình khuếch tán trước đó về hiệu suất trên các\n",
            "benchmark phổ biến.\n",
            "Hình 21: Caption\n",
            "Một trong những đột phá chính của nghiên cứu này là thay thế kiến trúc U-Net thường được sử\n",
            "dụng trong các mô hình diffusion thành kiến trúc diffusion transformer. Hình 21 cho ta thấy cái nhìn\n",
            "tổng quan về thiết kế của khối DiT. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Đầu vào của khối DiT là biểu diễn trong không gian latent zcủa\n",
            "một tấm ảnh (với một tấm ảnh kích thước 256×256×3,zcó kích thước 32×32×4). Sau đó zsẽ được\n",
            "chia thành từng patches ảnh nhỏ, sau đó trải phẳng để tạo thành một chuỗi Tcác token hình ảnh, với\n",
            "mỗi token có chiều là d.\n",
            "6.1 Diffusion Transformer\n",
            "Bây giờ chúng ta sẽ tìm hiểu tổng quan về Diffusion Transformer được đề cập trong bài báo.\n",
            "Diffusion formulation - Diffusion model thêm dần nhiễu vào dữ liệu và sau đó học cách đảo ngược\n",
            "quá trình này. Quá trình đào tạo dựa vào việc giảm thiểu sai số giữa nhiễu dự đoán và nhiễu thực tế.\n",
            "Classifier-free guidance - Phương pháp này cải thiện khả năng tạo mẫu của mô hình bằng cách\n",
            "điều chỉnh đầu ra dựa trên thông tin bổ sung như nhãn lớp để tạo ra ảnh chất lượng cao hơn.\n",
            "Latent diffusion models - Đây là một phương pháp hiệu quả về mặt tính toán, nén ảnh vào biểu\n",
            "diễn không gian nhỏ hơn trước khi tạo ảnh, giúp tiết kiệm tài nguyên tính toán.\n",
            "19\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 22: DiT Block.\n",
            "DiT block design - Với DiT block tác giả đã có một số những thay đổi nhỏ so với ViT block chuẩn\n",
            "thông thường:\n",
            "•In-context conditioning: DiT thêm các vector embedding của timestep và class labels như là hai\n",
            "token bổ sung trong chuỗi đầu vào, xử lý chúng không khác gì so với các token ảnh. Điều này\n",
            "tương tự như token cls trong ViTs, và nó cho phép DiT sử dụng các khối ViT chuẩn mà không\n",
            "cần chỉnh sửa.\n",
            "•Cross-attention block: tại đây nối các embedding của timestep và class labels thành một chuỗi có\n",
            "độ dài hai, tách biệt từ chuỗi token ảnh. Khối transformer được chỉnh sửa để bao gồm thêm một\n",
            "lớp multi-head cross-attention theo sau multi-head self-attention.\n",
            "•Adaptive layer norm (adaLN) block: thay thế các layer norm thông thường trong các khối trans-\n",
            "formerbằngadaptivelayernorm-adaLN.Tạiđây,thayvìhọctrựctiếpcácthamsốdimensionwise\n",
            "scale và shift parameters thì DiT hồi quy chúng từ tổng của các vector embedding của timestep\n",
            "và class labels.\n",
            "•adaLN-Zero block: Trong nghiên cứu về ResNets, việc khởi tạo các residual block để hoạt động\n",
            "như identity function đã được chứng minh là có ích. Mô hình Diffusion U-Net áp dụng phương\n",
            "pháp tương tự với lớp tích chập cuối của mỗi khối. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "DiT áp dụng chiến lược này trong khối adaLN\n",
            "của mô hình DiT, đồng thời hồi quy thêm các tham số tỷ lệ để tối ưu hóa hiệu suất trước khi\n",
            "thực hiện kết nối phần dư.\n",
            "Phần V: Mô hình Sora\n",
            "Sora là một mô hình AI có khả năng tạo ra các video lên đến một phút, với chất lượng hình ảnh cao và\n",
            "nội dung bám sát theo yêu cầu của người dùng. Mô hình hiện đang được mở cho các nhóm kiểm định\n",
            "20\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "để đánh giá về các rủi ro tiềm ẩn và cũng được cung cấp cho các nghệ sĩ, nhà thiết kế và nhà làm phim\n",
            "để thu thập phản hồi nhằm cải thiện mô hình cho nhu cầu sáng tạo. Sora có thể tạo ra các cảnh phức\n",
            "tạp với nhiều nhân vật, các loại chuyển động cụ thể, và chi tiết chính xác về đối tượng và phông nền.\n",
            "Mặc dù có khả năng hiểu biết sâu sắc về ngôn ngữ và tạo ra các nhân vật biểu cảm, mô hình vẫn còn\n",
            "hạn chế như khó khăn trong mô phỏng vật lý của cảnh phức tạp và nhầm lẫn các chi tiết không gian\n",
            "trong yêu cầu.\n",
            "Safety- Trước khi Sora được tích hợp vào các sản phẩm của OpenAI, mô hình sẽ được áp dụng\n",
            "các biện pháp an toàn quan trọng, bao gồm hợp tác với các chuyên gia từ các lĩnh vực như thông tin\n",
            "sai lệch và nội dung độc hại để kiểm thử mô hình. Hiện OpenAI cũng đang phát triển công cụ để phát\n",
            "hiện nội dung lừa đảo và dự định tích hợp metadata C2PA. Sử dụng các phương pháp an toàn từ sản\n",
            "phẩm sử dụng DALL ·E 3 và tiếp tục phát triển kỹ thuật mới nhằm đảm bảo vào việc kiểm soát nội\n",
            "dung vi phạm chính sách sử dụng trước khi hiển thị cho người dùng.\n",
            "7 Research techniques\n",
            "Ở phần này chúng ta sẽ tìm hiểu tổng quan về mô hình Sora. Trong khi nghiên cứu trước đây tập trung\n",
            "vào video ngắn hoặc dữ liệu hình ảnh hạn chế, Sora phá vỡ giới hạn này bằng cách tạo ra video và hình\n",
            "ảnh đa dạng, kéo dài đến một phút với độ nét cao.\n",
            "Xử lý dữ liệu hình ảnh - Áp dụng phương pháp từ các mô hình ngôn ngữ lớn trước đó là dùng\n",
            "dữ liệu quy mô internet để phát triển khả năng tổng quát sau đó chuyển đổi qua dữ liệu ảnh với các\n",
            "image patches thay cho các tokens văn bản. Cách tiếp cận này, đã được chứng minh là hiệu quả trong\n",
            "việc đại diện cho dữ liệu hình ảnh giúp Sora trở nên mạnh mẽ và có thể mở rộng để huấn luyện trên\n",
            "video và hình ảnh đa dạng. Quá trình biến đổi video thành các patches được thực hiện bằng cách nén\n",
            "chúng vào lower-dimensional latent space sau đó phân tách chúng vào spacetime patches.\n",
            "Mạng nén thông tin video Một trong những thành phần rất quan trọng của Sora, nhưng lại\n",
            "không được đề cập quá kĩ trong báo cáo kĩ thuật của OpenAI đó chính là mô hình nén video. Mô hình\n",
            "này có chức năng chính là nén video gốc thành những vector biễu diễn trên không gian latent, và những\n",
            "vector biễu diễn này đã nén cả về chiều không gian lẫn chiều thời gian. Một mạng decoder cũng được\n",
            "train để ánh xạ những biểu diễn này về lại không gian pixel. Có một số suy đoán về kiến trúc của thành\n",
            "phần này, chẳng hạn một mô hình VAE, hay một dạng tượng tự như VQGAN như các mô hình ở phần\n",
            "III có đề cập. Tuy nhiên ta không thể nào biết chính xác kiến trúc và cách training của thành phần này.\n",
            "Spacetime latent patches - Với một video đầu vào đã được nén, Sora trích xuất một chuỗi các\n",
            "spacetime patches hoạt động như các token transformer. Cơ chế này cũng áp dụng cho ảnh vì ảnh chỉ\n",
            "là video với một khung hình duy nhất. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Biểu diễn dựa trên patches của chúng cho phép Sora huấn luyện\n",
            "trên video và hình ảnh với độ phân giải, thời lượng và tỷ lệ khung hình đa dạng. Tại thời điểm suy luận,\n",
            "21\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "chúng ta có thể kiểm soát kích thước của video được sinh ra bằng cách sắp xếp các patches được khởi\n",
            "tạo ngẫu nhiên trong một lưới có kích thước phù hợp.\n",
            "Mở rộng quy mô mạng transformer cho việc tạo sinh video - Như chúng ta đã biết diffusion\n",
            "model là một loại mô hình sinh mô phỏng quá trình xoá mờ và tái tạo dữ liệu, thường được sử dụng\n",
            "trong việc sinh ra hình ảnh, video, hoặc âm thanh. Bằng cách bắt đầu từ dữ liệu nhiễu và dần dần loại\n",
            "bỏ nhiễu đó qua nhiều bước lặp, mô hình học cách tái tạo dữ liệu gốc từ dữ liệu đã bị làm nhiễu, từ\n",
            "từ sinh ra sản phẩm cuối cùng có chất lượng cao. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Quá trình này thường được hỗ trợ bởi thông tin điều\n",
            "kiện, như văn bản mô tả, để hướng dẫn quá trình tái tạo dữ liệu theo mong muốn.\n",
            "Trong bối cảnh của Sora, diffusion model được áp dụng để dự đoán và tái tạo các clean patches từ\n",
            "các noisy patches, với sự hỗ trợ của thông tin điều kiện như văn bản mô tả. Đặc biệt, Sora kết hợp cấu\n",
            "trúc của diffusion transformer (DiT), tận dụng khả năng mở rộng mạnh mẽ của bộ biến đổi qua nhiều\n",
            "lĩnh vực như mô hình hóa ngôn ngữ và sinh hình ảnh. Qua quá trình huấn luyện, chất lượng của dữ liệu\n",
            "sinh ra bởi Sora tiếp tục cải thiện, chứng minh khả năng mở rộng hiệu quả của diffusion model dưới\n",
            "dạng bộ biến đổi cho việc mô hình hóa video.\n",
            "8 Một số khả năng của Sora\n",
            "Khả năng thông hiểu ngôn ngữ : Đầu tiên đó chính là khả năng hiểu ngôn ngữ của Sora, từ đó có\n",
            "thể tạo ra video từ các prompt văn bản. Sora được train trên dữ liệu video-text với caption cho các\n",
            "video được thu thập bằng phương pháp re-captioning được giới thiệu trong paper DALLE 3. Tương\n",
            "tự như DALLE 3, Sora cũng sử dụng các mô hình GPT để biến những prompt của người dùng thành\n",
            "những câu captions dài và chi tiết.\n",
            "Prompting từ hình ảnh và video Ngoài khả năng tạo sinh video từ văn bản, ta còn có thể\n",
            "prompt sora bằng ảnh và video. Khả năng này cho phép Sora có thể thực hiệu những tác vụ về edit\n",
            "hình ảnh và video, chẳng hạn như tạo những video loop, tạo ảnh động từ ảnh tĩnh, kéo dài video tiến\n",
            "hoặc lùi theo thời gian, v.v.\n",
            "Khả năng mô phỏng thế giới Và cuối cùng, một khả năng của Sora khiến giới khoa học thảo\n",
            "luận và tranh cãi khá nhiều đó chính là khả năng mô phỏng thế giới của Sora. Khi được huấn luyện với\n",
            "lượng dữ liệu khổng lồ, Sora có thể có được một số khả năng thú vị, cho phép mô hình có thể mô phỏng\n",
            "một số khía cạnh của con người, động vật và môi trường từ thế giới vật chất. Sora hoàn toàn không\n",
            "được train để làm những tác vụ này, đây hoàn toàn là thành quả tuyệt vời được sinh ra từ dữ liệu lớn.\n",
            "Những khả năng này cho thấy rằng việc mở rộng kích thước của các mô hình video là một con\n",
            "đường đầy hứa hẹn, hướng tới sự phát triển của các mô hình có khả năng mô phỏng thế giới vật chất\n",
            "và tương tác giữa các vật thể, con người và động vật trong đó.\n",
            "Tóm lại, SORA đã chứng minh mình là một bước tiến đáng kể trong lĩnh vực công nghệ, mở ra một\n",
            "tương lai đầy hứa hẹn với khả năng tạo sinh video từ văn bản. Mặc dù còn tồn tại một số hạn chế,\n",
            "22\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "nhưng tiềm năng để phát triển thành một hệ thống mô phỏng thực tế ảo, nơi vật thể và con người có\n",
            "thể tương tác một cách tự nhiên, là điều không thể phủ nhận. SORA không chỉ mở ra cánh cửa cho\n",
            "những cải tiến công nghệ tiếp theo mà còn hứa hẹn sẽ mang lại những ứng dụng sáng tạo và cách mạng\n",
            "trong các ngành như metaverse, điện ảnh, quảng cáo và giáo dục, đánh dấu một bước ngoặt mới trong\n",
            "cách chúng ta tương tác và tạo ra nội dung số.\n",
            "Phần VI: Mô hình Genie\n",
            "Genie - là một generative interactive environment, đánh dấu bước tiến lớn trong việc tạo dựng thế giới\n",
            "ảo thông qua việc học không giám sát từ kho dữ liệu video trên internet không được gắn nhãn. Điểm\n",
            "nổi bật của Genie là khả năng của nó trong việc phản hồi các yêu cầu để sinh ra các thế giới ảo đa\n",
            "dạng, từ văn bản mô tả, hình ảnh tổng hợp, ảnh chụp đến bản vẽ, mở ra không gian sáng tạo không\n",
            "giới hạn cho người dùng. Với 11 tỷ tham số, mô hình này không chỉ là một cơ sở dữ liệu thế giới mà\n",
            "còn là một công cụ mạnh mẽ, bao gồm spatiotemporal video encoder, autoregressive dynamics model\n",
            "và scalable latent action model.\n",
            "Đặc biệt, Genie cho phép người dùng tương tác với các môi trường sinh ra, từng khung hình một,\n",
            "mà không cần đến nhãn hành động sự thật cơ bản hay các yêu cầu đặc thù của lĩnh vực thường thấy\n",
            "trong các nghiên cứu về mô hình thế giới. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Điều này không chỉ làm giảm bớt gánh nặng về dữ liệu mà\n",
            "còn tạo điều kiện cho việc áp dụng rộng rãi. Hơn nữa, latent action space mà Genie học được mở ra\n",
            "khả năng đào tạo các đại lý để mô phỏng hành vi từ video chưa từng thấy, tiến một bước dài hướng\n",
            "tới mục tiêu phát triển các generalist agents cho tương lai.\n",
            "Genie bao gồm ba thành phần chính: latent action model dự đoán hành động giữa các cặp khung\n",
            "hình, video tokenizer chuyển đổi khung hình thô thành token rời rạc, và dynamics model dự đoán khung\n",
            "hình tiếp theo dựa trên latent action và khung hình trước. Quá trình đào tạo mô hình diễn ra qua hai\n",
            "giai đoạn, bắt đầu với video tokenizer, sau đó đồng thời đào tạo latent action model và dynamics model,\n",
            "cho phép tạo ra dòng video liên tục và chân thực từ các pixel, mở ra khả năng tạo ra các trải nghiệm\n",
            "ảo đa dạng và phong phú. Sau đây, chúng ta hãy đi vào tìm hiểu từng thành phần chính của Genie.\n",
            "ST-Transformer Mô hình Genie tích hợp nhiều yếu tố từ kiến trúc Vision Transformer, nổi bật\n",
            "với đặc thù là độ phức tạp tính toán tăng theo cấp số nhân. Điều này đặt ra thách thức không nhỏ\n",
            "trong việc xử lý video, do đó, nghiên cứu này đã chọn giải pháp sử dụng khối ST-Transformer. Phương\n",
            "23\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 23: Kiến trúc khôi ST-Transformer\n",
            "pháp này giúp cân đối hiệu quả giữa khả năng xử lý của mô hình và các giới hạn về khả năng tính toán.\n",
            "Kiến trúc của khối này được minh họa trong Hình 23.\n",
            "Khác biệt so với các khối transformer thông thường, nơi mỗi phần tử dữ liệu (token) quan tâm đến\n",
            "mọi phần tử khác, ST-transformer lại được thiết kế với các khối không gian-thời gian đa dạng. Các lớp\n",
            "chú ý không gian trong đó tập trung vào việc xem xét các phần tử dữ liệu trong cùng một bức ảnh,\n",
            "trong khi các lớp chú ý theo thời gian lại nhắm đến việc kết nối với dữ liệu từ các khung hình trước\n",
            "đó. Nhờ cách tiếp cận này, độ phức tạp tính toán của ST-transformer chỉ tăng theo chiều dài của video\n",
            "một cách tuyến tính thay vì theo cấp số nhân, làm cho việc xử lý video trở nên hiệu quả hơn nhiều.\n",
            "Hình 24: Các thành phần của mô hình Genie\n",
            "Latent Action Model (LAM) Trong mô hình Genie, quá trình tạo ra mỗi khung hình mới phụ\n",
            "thuộc vào hành động của người dùng được ghi nhận từ các khung hình trước đó. Thách thức ở đây là\n",
            "thông tin về những hành động này thường khá hiếm và khó có được từ những video trên internet. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Để\n",
            "giải quyết vấn đề này, mô hình sử dụng khối LAM, giúp máy học được các hành động ẩn mà không cần\n",
            "dữ liệu được gán nhãn cụ thể.\n",
            "Khối LAM hoạt động bằng cách xem xét một loạt các khung hình trước và sau đó dự đoán chuỗi\n",
            "hành động ẩn có thể dẫn đến khung hình tiếp theo. Một bộ giải mã sau đó sử dụng thông tin này cùng\n",
            "với chuỗi khung hình để dự đoán khung hình kế tiếp. Quá trình này được huấn luyện dựa trên kỹ thuật\n",
            "VQ-VAE, giúp hạn chế số lượng hành động có thể xuất hiện và trong trường hợp này là 8 hành động.\n",
            "Do bộ giải mã chỉ nhìn vào các khung hình trước đó, mô hình cần phải nắm bắt được những biến đổi\n",
            "quan trọng nhất giữa các khung hình đã qua và khung hình tiếp theo để có thể dự đoán chính xác.\n",
            "24\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Video Tokenizer Khối này có nhiệm vụ nén các video thành những token rời rạc, với mục đích\n",
            "để giảm chiều và tăng chất lượng tạo sinh video. Một lần nữa kiến trúc VQ-VAE lại được sử dụng cho\n",
            "thành phần này. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Khác với những công trình nghiên cứu khác chỉ tập trung vào việc nén trong chiều\n",
            "không gian, nghiên cứu này sử dụng khối ST-transformer trong cả encoder và decoder để có thể đảm\n",
            "bảo sự liên kết trong chiều thời gian.\n",
            "Khối Dynamics Model Đây là một khối decoder transformer tương tự như trong nghiên cứu\n",
            "MaskGIT [1]. Ở mỗi bước, khối này nhận đầu vào là một chuỗi video đã được tokenize và thông tin về\n",
            "hành động tiềm ẩn được dự đoán bởi khối LAM. Mục tiêu huấn luyện của nó là dự đoán token tiếp\n",
            "theo trong chuỗi video. Trong quá trình train, một số token video sẽ được che đi ngẫu nhiên theo phân\n",
            "phối Bernoulli.\n",
            "Genie được nhấn mạnh là một mô hình đột phá, mang đến khả năng tạo sinh và tương tác với các\n",
            "môi trường ảo một cách linh hoạt. Đặc biệt, dù chỉ dựa trên dữ liệu video, Genie vẫn có thể tạo ra các\n",
            "môi trường đa dạng và kiểm soát chúng một cách hiệu quả. Sự đa năng và tiềm năng của mô hình này\n",
            "mở ra khả năng ứng dụng rộng rãi trong các lĩnh vực như video game và mô phỏng thực tế ảo, hứa hẹn\n",
            "làm thay đổi cách chúng ta tạo sinh và tương tác với thế giới số.\n",
            "Phần VII: Tổng kết\n",
            "Genie và Sora đều là những mô hình tạo sinh video tiên tiến, được huấn luyện trên tập data khổng lồ.\n",
            "Tiềm năng của 2 mô hình này không chỉ dừng lại trong việc tạo sinh video, mà còn là cách mạng trong\n",
            "25\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "nhiều lĩnh vực khác nhau như điện ảnh, làm game, thực tế ảo, v.v. Hơn hết, cả 2 mô hình đều cho thấy\n",
            "việc huấn luyện các mô hình deep learning trên tập data lớn về video có thể giúp các mô hình trí tuệ\n",
            "nhân tạo học được cách vận hành của thế giới vật chất, mở ra hướng mới cho việc phát triển AI có khả\n",
            "năng tương tác với thế giới và tiệm cận trí tuệ con người.\n",
            "References\n",
            "[1] Huiwen Chang et al. “MaskGIT: Masked Generative Image Transformer”. In: The IEEE Confer-\n",
            "ence on Computer Vision and Pattern Recognition (CVPR) . 2022.\n",
            "[2] Jonathan Ho et al. “Video diffusion models”. In: arXiv:2204.03458 (2022).\n",
            "[3] Zheng W. Liu X. Tang J. Hong W. Ding M. “CogVideo: Large-scale Pretraining for Text-to-Video\n",
            "Generation via Transformers”. In: arXiv preprint arXiv:2205.15868 (2022).\n",
            "[4] Aaron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu. “Neural discrete representation\n",
            "learning”. In: Proceedings of the 31st International Conference on Neural Information Processing\n",
            "Systems. NIPS’17. Long Beach, California, USA: Curran Associates Inc., 2017, 6309–6318. isbn:\n",
            "9781510860964.\n",
            "[5] WilliamPeeblesandSainingXie.“ScalableDiffusionModelswithTransformers”.In: arXiv preprint\n",
            "arXiv:2212.09748 (2022).\n",
            "[6] Robin Rombach et al. High-Resolution Image Synthesis with Latent Diffusion Models . 2021. arXiv:\n",
            "2112.10752 [cs.CV] .\n",
            "[7] Thomas Hayes Xi Yin Jie An Songyang Zhang Qiyuan Hu Singer Adam Polyak. “Make-A-Video:\n",
            "Text-to-Video Generation without Text-Video Data”. In: arXiv preprint arXiv:2209.14792 (2022).\n",
            "[8] Ruben Villegas et al. “Phenaki: Variable Length Video Generation From Open Domain Textual\n",
            "Description”. In: ArXivabs/2210.02399 (2022).\n",
            "[9] Jay Zhangjie Wu et al. “Tune-a-video: One-shot tuning of image diffusion models for text-to-video\n",
            "generation”. In: Proceedings of the IEEE/CVF International Conference on Computer Vision .\n",
            "2023, pp. 7623–7633.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "[10] Wilson Yan et al. VideoGPT: Video Generation using VQ-VAE and Transformers . 2021. arXiv:\n",
            "2104.10157 [cs.CV] .\n",
            "[11] Wang W. Yan H. Lv W. Zhu Y. Feng J. Zhou D. “MagicVideo: Efficient Video Generation With\n",
            "Latent Diffusion Models”. In: arXiv preprint arXiv:2211.11018 (2022).\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Hết -\n",
            "26\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2024\n",
            "Tutorial: Phát hiện đối tượng trong ảnh với\n",
            "YOLOv10\n",
            "Dinh-Thang Duong, Nguyen-Thuan Duong, Minh-Duc Bui và\n",
            "Quang-Vinh Dinh\n",
            "Ngày 30 tháng 5 năm 2024\n",
            "I. Giới thiệu\n",
            "Object Detection (Tạm dịch: Phát hiện đối tượng) là một bài toán cổ điển thuộc lĩnh vực\n",
            "Computer Vision. Mục tiêu của bài toán này là tự động xác định vị trí của các đối tượng trong\n",
            "một tấm ảnh. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tính tới thời điểm hiện tại, đã có rất nhiều phương pháp được phát triển nhằm\n",
            "giải quyết hiệu quả bài toán này. Trong đó, các phương pháp thuộc họ YOLO (You Only Look\n",
            "Once) thu hút được sự chú ý rất lớn từ cộng đồng nghiên cứu bởi độ chính xác và tốc độ thực\n",
            "thi mà loại mô hình này mang lại.\n",
            "Hình 1: Logo của mô hình YOLO. Ảnh: link.\n",
            "Thời gian vừa qua, Ao Wang và các cộng sự tại Đại học Thanh Hoa (Tsinghua University)\n",
            "đã đề xuất mô hình YOLOv10 trong bài báo YOLOv10: Real-Time End-to-End Object\n",
            "Detection [10]. Với những cải tiến mới, mô hình đã đạt được hiệu suất vượt trội hơn so với các\n",
            "phiên bản YOLO trước đó ở các khía cạnh khác nhau, tăng cường khả năng phát hiện đối tượng\n",
            "theo thời gian thực (real-time object detection).\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "Hình 2: Hiệu suất của YOLOv10 khi so sánh với các mô hình khác. Trên tập dữ liệu COCO,\n",
            "YOLOv10 đạt được kết quả tốt nhất về khía cạnh Độ trễ (Latency) và Số lượng tham số mô\n",
            "hình (Number of parameters) trong khi vẫn giữ được độ chính xác (COCO AP) cao. Ảnh: [10].\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trong bài viết này, chúng ta sẽ cùng nhau tìm hiểu về YOLOv10 và cách sử dụng mô hình này.\n",
            "Thông qua đó, nhóm cũng sẽ trình bày sơ lược về bài toán Object Detection cũng như tóm tắt\n",
            "ngắn gọn các phiên bản YOLO trước đó để bạn đọc có một cái nhìn tổng quan hơn về nội dung\n",
            "này.\n",
            "Theo đó, bài viết được bố cục như sau:\n",
            "-Phần I: Giới thiệu về nội dung bài viết.\n",
            "-Phần II: Tóm tắt về bài toán Object Detection và các phiên bản YOLO đời trước.\n",
            "-Phần III: Trình bày nội dung YOLOv10.\n",
            "-Phần IV: Hướng dẫn cách cài đặt, huấn luyện và sử dụng YOLOv10.\n",
            "-Phần V: Trích dẫn tài liệu.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "II. Bài toán Object Detection và các\n",
            "phiên bản YOLO đời trước\n",
            "II.I. Bài toán Object Detection\n",
            "Trong Computer Vision, bài toán Object Detection hướng đến xây dựng một chương trình có\n",
            "thể tự động xác định vị trí và nhận diện tên (class) của các vật thể trong một bức ảnh. Tổng\n",
            "hợp hai thông tin đầu ra này còn được gọi với tên là bounding box. Từ đây, ta có thể mô tả\n",
            "Input/Output của một chương trình Object Detection như sau:\n",
            "-Input:Một bức ảnh.\n",
            "-Output: Bounding box của các vật thể cần phát hiện trong ảnh.\n",
            "Hình 3: Minh họa Input/Output của bài toán Object Detection.\n",
            "Đến thời điểm hiện tại, các phương pháp sử dụng mạng Deep Learning cho thấy hiệu suất vượt\n",
            "trội. Ta có thể tóm tắt các hướng tiếp cận theo ba dạng như sau:\n",
            "1.One-stage Object Detection: Việc xác định vị trí tọa độ và phân loại tên class của các\n",
            "vật thể được thực hiện trên một bước duy nhất. Điển hình cho hướng tiếp cận này có thể\n",
            "kể đến SSD [13] và YOLO [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].\n",
            "2.Two-stage Object Detection: Việc xác định vị trí tọa độ và phân loại tên class của các\n",
            "vật thể được thực hiện riêng biệt. Điển hình cho hướng tiếp cận này có thể kể đến RCNN\n",
            "[14] và Faster RCNN [15].\n",
            "3.End-to-end Object Detection: Việc xác định vị trí tọa độ và phân loại tên class của\n",
            "các vật thể được dự đoán bởi một mô hình duy nhất (không sử dụng các bước tiền và hậu\n",
            "xử lý bounding box). Điển hình cho hướng tiếp cận này có thể kể đến DETR [16], DINO\n",
            "[17], và DeFCN [18].\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "Ở phần sau, chúng ta sẽ tập trung điểm qua các phiên bản YOLO (từ v1 đến v9).\n",
            "II.II. YOLOv1\n",
            "YOLOv1 [1] là mô hình one-stage (hoặc single-stage) real-time object detection được giới thiệu\n",
            "vào năm 2016.\n",
            "Hình 4: Kiến trúc mô hình YOLOv1 với 24 lớp conv và 2 lớp mlp. Ảnh: [1].\n",
            "-Điểm mới : YOLOv1 sử dụng một mạng neural đơn để dự đoán cả vị trí và tên class của\n",
            "các object trực tiếp từ ảnh đầu vào.\n",
            "-Ưu điểm : Tốc độ nhanh, khả năng object detection theo thời gian thực.\n",
            "-Nhược điểm : Độ chính xác không cao với các object nhỏ hoặc bị che khuất.\n",
            "II.III. YOLOv2\n",
            "YOLOv2 [2], còn được gọi là YOLO9000, được giới thiệu vào năm 2017 với nhiều cải tiến so với\n",
            "YOLOv1.\n",
            "Hình 5: Hình ảnh minh họa về anchor boxes. Ảnh: Zixuan Zhang.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "-Điểm mới : Sử dụng anchor boxes, mạng Darknet-19, và tăng training data để tăng độ\n",
            "chính xác.\n",
            "-Ưu điểm : Tăng độ chính xác và khả năng nhận diện nhiều object trong 1 cell.\n",
            "-Nhược điểm : Phức tạp hơn, cần nhiều tài nguyên tính toán, và khó detect các object\n",
            "nhỏ.\n",
            "II.IV. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "YOLOv3\n",
            "YOLOv3 [3] ra mắt năm 2018, tiếp tục cải tiến từ YOLOv2.\n",
            "Hình 6: Kiến trúc mô hình YOLOv3. Ảnh: [3].\n",
            "-Điểm mới : Sử dụng mạng Darknet-53 và detect object ở ba cấp độ khác nhau (multi-scale\n",
            "detection) để cải thiện độ chính xác.\n",
            "-Ưu điểm : Độ chính xác cao hơn, khả năng phát hiện object nhỏ tốt hơn.\n",
            "-Nhược điểm : Tốc độ chậm hơn so với các phiên bản trước do sự phức tạp của mô hình.\n",
            "II.V. YOLOv4\n",
            "YOLOv4 [4] ra mắt năm 2020, với mục tiêu cải thiện cả độ chính xác và tốc độ.\n",
            "-Điểm mới : Sử dụng nhiều kỹ thuật mới như CSPDarknet53, PANet, và nhiều cải tiến\n",
            "khác.\n",
            "-Ưu điểm : Cân bằng tốt giữa tốc độ và độ chính xác, dễ dàng sử dụng và triển khai.\n",
            "-Nhược điểm : Yêu cầu phần cứng mạnh để đạt hiệu năng tối ưu.\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "II.VI. YOLOv5\n",
            "YOLOv5 [5], không phải do tác giả gốc phát triển, nhưng được cộng đồng sử dụng rộng rãi từ\n",
            "năm 2020.\n",
            "-Điểm mới : Tập trung vào tối ưu hóa và dễ dàng sử dụng với các framework như PyTorch.\n",
            "Sử dụng CSPNet làm backbone và PANet để fusion giúp cải thiện độ chính xác của mô\n",
            "hình.\n",
            "-Ưu điểm : Dễ dàng triển khai, tối ưu hóa tốt, cộng đồng hỗ trợ mạnh mẽ.\n",
            "-Nhược điểm : Yêu cầu tài nguyên tính toán cao và khó detect được các object nhỏ.\n",
            "II.VII. YOLOv6\n",
            "YOLOv6 [6] là phiên bản tiếp theo với nhiều cải tiến về tốc độ và độ chính xác.\n",
            "-Điểm mới : Sử dụng backbone mới EfficientRep và Rep-PAN Neck để tối ưu hóa và tăng\n",
            "hiệu năng của mô hình. SimOTA, một phương pháp Label Assignment, cũng được sử dụng\n",
            "để tăng tính ổn định khi training.\n",
            "-Ưu điểm : Hiệu năng cao hơn, tốc độ nhanh hơn.\n",
            "-Nhược điểm : Yêu cầu tài nguyên tính toán cao hơn.\n",
            "II.VIII. YOLOv7\n",
            "YOLOv7 [7] tiếp tục phát triển với các cải tiến về mô hình và thuật toán.\n",
            "-Điểm mới : Sử dụng backbone E-ELAN kết hợp với phương pháp trainable bag-of-freebies\n",
            "để tăng độ chính xác của mô hình mà không làm tăng chi phí tính toán.\n",
            "-Ưu điểm : Tăng độ chính xác và khả năng nhận diện trong các điều kiện phức tạp.\n",
            "-Nhược điểm : Mức độ phức tạp cao, cần nhiều thời gian và tài nguyên để huấn luyện.\n",
            "II.IX. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "YOLOv8\n",
            "YOLOv8 [8] được giới thiệu vào năm 2023 bởi Ultralytics. Mô hình này cải thiện độ chính xác\n",
            "và tốc độ so với YOLOv7 và giới thiệu nhiều tính năng mới như anchor-free detection.\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "Hình 7: So sánh 2 phương pháp hand-crafted anchor (trên) và anchor-free (dưới). Ảnh: [11].\n",
            "-Điểm mới : Sử dụng anchor-free detection, giúp đơn giản hóa kiến trúc mô hình và cải\n",
            "thiện hiệu suất.\n",
            "-Ưu điểm :\n",
            "+ Độ chính xác cao hơn: YOLOv8 đạt mAP 50.2% trên bộ dữ liệu COCO, cao hơn so\n",
            "với YOLOv7.\n",
            "+ Dễ sử dụng: YOLOv8 có giao diện Python và CLI dễ sử dụng, giúp người dùng dễ\n",
            "dàng triển khai và huấn luyện mô hình.\n",
            "-Nhược điểm : Yêu cầu tài nguyên tính toán cao: Mặc dù có nhiều cải tiến, YOLOv8 vẫn\n",
            "yêu cầu nhiều tài nguyên tính toán, đặc biệt là khi xử lý hình ảnh độ phân giải cao.\n",
            "II.X. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "YOLOv9\n",
            "YOLOv9 [9] được giới thiệu vào năm 2024 bởi Chien-Yao Wang, I-Hau Yeh, và Hong-Yuan Mark\n",
            "Liao. Mô hình này cải thiện độ chính xác và tốc độ so với YOLOv8 và giới thiệu nhiều kỹ thuật\n",
            "mới như Programmable Gradient Information (PGI) và Generalized Efficient Layer Aggregation\n",
            "Network (GELAN).\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "Hình 8: PGI và các kiến trúc tương tự. Ảnh: [9].\n",
            "-Điểm mới : YOLOv9 sử dụng PGI và GELAN để cải thiện độ chính xác và hiệu suất của\n",
            "mô hình.\n",
            "-Ưu điểm :\n",
            "+ Kiến trúc tiên tiến: Sử dụng PGI và GELAN giúp mô hình duy trì thông tin quan\n",
            "trọng và tối ưu hóa quá trình huấn luyện, làm cho YOLOv9 trở nên mạnh mẽ và linh\n",
            "hoạt hơn trong nhiều ứng dụng khác nhau.\n",
            "+ Tốc độ nhanh hơn: YOLOv9 có thể xử lý hình ảnh nhanh hơn so với YOLOv8 nhờ\n",
            "vào các cải tiến trong kiến trúc mạng.\n",
            "-Nhược điểm :\n",
            "+ Mặc dù nhanh hơn YOLOv8, YOLOv9 vẫn yêu cầu nhiều tài nguyên tính toán, đặc\n",
            "biệt là khi xử lý hình ảnh độ phân giải cao.\n",
            "+ Mặc dù cải thiện so với YOLOv8, YOLOv9 vẫn gặp khó khăn trong việc phát hiện\n",
            "các object rất nhỏ.\n",
            "Hình 9: GELAN và các kiến trúc tương tự. Ảnh: [9].\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "III. YOLOv10: Real-Time End-to-End\n",
            "Object Detection\n",
            "Ao Wang và các cộng sự đã đặt nghi vấn về sự tối ưu trong việc phụ thuộc vào kỹ thuật hậu xử\n",
            "lý Non-maximum Suppresion (NMS) và cách thiết kế mô hình của các phiên bản YOLO trước\n",
            "đó. Với các hạn chế quan sát được từ hai điều trên và mục tiêu xây dựng một mô hình object\n",
            "detection thời gian thực, YOLOv10 đã được đề xuất với những thay đổi mới. Theo đó, có hai\n",
            "điểm nhấn chính trong phương pháp mà nhóm tác giả YOLOv10 đề xuất bao gồm:\n",
            "1.Consistent Dual Assignments for NMS-free Training: Trong quá trình dự đoán của\n",
            "các mạng YOLO đời trước, rất nhiều bounding box được mô hình đưa ra (ví dụ: anchors\n",
            "box,...) và nhiệm vụ của chúng ta là tìm ra đại diện chính xác nhất cho mỗi vật thể có\n",
            "trong ảnh. Để tận dụng tối đa các đề xuất bounding box đúng trong việc huấn luyện,\n",
            "các phương pháp thường ứng dụng kỹ thuật Task Alignment Learning (TAL). Trong đó,\n",
            "chiến lược one-to-many label assignment được áp dụng để gán các bounding box “positive”\n",
            "(bounding box chính xác) vào ground-truth của vật thể tương ứng để tăng cường khả năng\n",
            "nhận biết vật thể của mô hình. Tuy vậy, việc này lại gây ra độ trễ (latency) lớn trong quá\n",
            "trình inference của mô hình bởi việc phụ thuộc vào thuật toán NMS để lọc các dự đoán\n",
            "thừa.\n",
            "Một cách tiếp cận khác đó là sử dụng chiến lược one-to-one label assignment, bằng cách\n",
            "chỉ gán một đề xuất bouding box “positive” với ground-truth của vật thể tương ứng, qua\n",
            "đó tránh việc hậu xử lý với NMS. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tuy vậy, chiến lược này lại dẫn đến hiệu suất mô hình\n",
            "không được tốt.\n",
            "Hình 10: Minh họa chiến lược one-to-one và one-to-many label assignemnts.\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM (AIO2024) aivietnam.edu.vn\n",
            "Để khắc phục trình trạng của hai cách nêu trên, YOLOv10 cài đặt một chiến lược huấn\n",
            "luyện mới là sự kết hợp của one-to-one và one-to-many, mang tên Dual label assignments.\n",
            "Chiến lược này được minh họa theo như hình sau:\n",
            "Hình 11: Minh họa chiến lược Dual label assignments. Ảnh: [10].\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nodes[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RYtSFQmHYaI",
        "outputId": "fc7124c8-bbed-43a0-d6ff-5a51a48b88cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mKết quả truyền trực tuyến bị cắt bớt đến 5000 dòng cuối.\u001b[0m\n",
            "(1.670 ảnh), art painting (2.048 ảnh), cartoon (2.344 ảnh) và sketch (3.929 ảnh). Mỗi domain bao\n",
            "gồm 7 class.\n",
            "Điểm khó của PACS là việc sẽ có nhiều domain cho cùng 1 class, ví dụ trong class person sẽ có 4\n",
            "domain (cột số 2 trong hình 1):\n",
            "•Ảnh person được chụp từ thực tế (photo)\n",
            "•Ảnh person được vẽ phác thảo (sketch)\n",
            "•Ảnh person từ phim hoạt hình (cartoon)\n",
            "•Ảnh vẽ person (art painting)\n",
            "Việc có nhiều domain cho cùng một class như vậy sẽ tăng độ khó của dataset, đòi hỏi model phải\n",
            "có khả năng generalize tốt hơn.\n",
            "Hình 1: Dataset PACS.\n",
            "Sau đây là đoạn code download dataset PACS và tạo dataloader. Vì có 4 domain khác nhau nên\n",
            "ta sẽ có 4 dataset khác nhau.\n",
            "1# means and standard deviations ImageNet because the network is pretrained\n",
            "2means , stds = (0.485 , 0.456 , 0.406) , (0.229 , 0.224 , 0.225)\n",
            "3\n",
            "4# Define transforms to apply to each image\n",
            "5transf = transforms . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Compose (\n",
            "6 [\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "7 transforms . CenterCrop (224) ,\n",
            "8 transforms . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "ToTensor () ,\n",
            "9 transforms . Normalize (means , stds ),\n",
            "10 ]\n",
            "11)\n",
            "12\n",
            "13# Clone github repository with data\n",
            "14if not os. path . isdir (\"./ Homework3 - PACS \"):\n",
            "15 !git clone https :// github .com/ MachineLearning2020 / Homework3 - PACS\n",
            "16\n",
            "17# Define datasets root\n",
            "18DIR_PHOTO = \" Homework3 - PACS / PACS / photo \"\n",
            "19DIR_ART = \" Homework3 - PACS / PACS / art_painting \"\n",
            "20DIR_CARTOON = \" Homework3 - PACS / PACS / cartoon \"\n",
            "21DIR_SKETCH = \" Homework3 - PACS / PACS / sketch \"\n",
            "22\n",
            "23# Prepare Pytorch train / test Datasets\n",
            "24photo_dataset = torchvision . datasets . ImageFolder ( DIR_PHOTO , transform = transf\n",
            ")\n",
            "25art_dataset = torchvision . datasets . ImageFolder ( DIR_ART , transform = transf )\n",
            "26cartoon_dataset = torchvision . datasets . ImageFolder ( DIR_CARTOON , transform =\n",
            "transf )\n",
            "27sketch_dataset = torchvision . datasets . ImageFolder ( DIR_SKETCH , transform =\n",
            "transf )\n",
            "Trong bài toán này, ta sẽ sử dụng domain photo làm tập train, và sử dụng tập val của photo\n",
            "và toàn bộ các domain còn lại để test. Tiếp theo ta sẽ tạo train và test data loader. Ta sẽ dùng\n",
            "ConcatDataset để concat các dataset với nhau.\n",
            "1# Split dataset into train and test\n",
            "2train_size = int (0.8 * len( photo_dataset ))\n",
            "3test_size = len( photo_dataset ) - train_size\n",
            "4\n",
            "5train_dataset , test_dataset = torch . utils . data . random_split (\n",
            "6 photo_dataset , [ train_size , test_size ]\n",
            "7)\n",
            "8\n",
            "9# Concatenate all datasets\n",
            "10test_datasets = torch . utils . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "data . ConcatDataset ([ test_dataset , art_dataset ])\n",
            "11\n",
            "12# Create Dataloaders\n",
            "13trainloader = DataLoader (\n",
            "14 train_dataset , batch_size =128 , shuffle =True , num_workers =4, drop_last =\n",
            "True\n",
            "15)\n",
            "16testloader = DataLoader ( test_datasets , batch_size =128 , shuffle =False ,\n",
            "num_workers =4)\n",
            "4.Áp dụng GNN cho bài toán image classification\n",
            "Ta sẽ định nghĩa model GNN trước khi tích hợp GNN vào model chính. GNN sẽ bao gồm 2 phần\n",
            "chính là Edge và Node network. Edge network sẽ làm nhiệm vụ edge prediction, cụ thể, ta sẽ dùng\n",
            "edge network để predict giữa 2 sample bất kì trong 1 batch có liên kết với nhau không. Ta cần\n",
            "dùng 1 model để predict edge giữa 2 sample bất kì và dùng hàm loss để giúp edge network predict\n",
            "tốt hơn. Nói cách khác, vì khi inference ta không có label nên không thể biết 2 sample bất kì có\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "edge với nhau hay không, nên ta mới cần edge network làm nhiệm vụ edge prediction.\n",
            "1class GCN (nn. Module ):\n",
            "2 def __init__ (self , in_features , edge_features , out_feature , device ,\n",
            "ratio =(1 ,)):\n",
            "3 super (GCN , self ). __init__ ()\n",
            "4\n",
            "5 self . edge_net = EdgeNet (\n",
            "6 in_features = in_features ,\n",
            "7 num_features = edge_features ,\n",
            "8 device =device ,\n",
            "9 ratio =ratio ,\n",
            "10 )\n",
            "11 # set edge to node\n",
            "12 self . node_net = NodeNet (\n",
            "13 in_features = in_features ,\n",
            "14 num_features = out_feature ,\n",
            "15 device =device ,\n",
            "16 ratio =ratio ,\n",
            "17 )\n",
            "18 # mask value for no - gradient edges\n",
            "19 self . mask_val = -1\n",
            "20\n",
            "21 def label2edge (self , targets ):\n",
            "22 \"\"\" convert node labels to affinity mask for backprop \"\"\"\n",
            "23 num_sample = targets . size () [1]\n",
            "24 label_i = targets . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "unsqueeze ( -1). repeat (1, 1, num_sample )\n",
            "25 label_j = label_i . transpose (1, 2)\n",
            "26 edge = torch .eq( label_i , label_j ). float ()\n",
            "27 target_edge_mask = (\n",
            "28 torch .eq( label_i , self . mask_val ) + torch .eq( label_j , self .\n",
            "mask_val )\n",
            "29 ). type ( torch . bool )\n",
            "30 source_edge_mask = ~ target_edge_mask\n",
            "31 init_edge = edge * source_edge_mask . float ()\n",
            "32 return init_edge [0] , source_edge_mask\n",
            "33\n",
            "34 def forward (self , init_node_feat ):\n",
            "35 # compute normalized and not normalized affinity matrix\n",
            "36 edge_feat , edge_sim = self . edge_net ( init_node_feat )\n",
            "37 # compute node features and class logits\n",
            "38 logits_gnn = self . node_net ( init_node_feat , edge_feat )\n",
            "39 return logits_gnn , edge_sim\n",
            "Sau đây là đoạn code về edge network. Ta thấy output của edge network là edge_feat có shape\n",
            "là (batch_size, batch_size), đây chính là correlation matrix. Mỗi vị trí ij trong matrix này là mối\n",
            "liên hệ giữa sample i và sample j, giá trị càng gần 1 thì 2 sample càng có mối liên hệ cao, và ngược\n",
            "lại, giá trị càng thấp thì mối liên hệ càng thấp. Nói cách khác, mối liên hệ cao là các sample có\n",
            "cùng class với nhau, mối quan hệ thấp là các sample khác class với nhau.\n",
            "1class EdgeNet (nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Module ):\n",
            "2 def __init__ (self , in_features , num_features , device , ratio =(1 ,)):\n",
            "3 super ( EdgeNet , self ). __init__ ()\n",
            "4 num_features_list = [ num_features * r for r in ratio ]\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "5 self . device = device\n",
            "6 # define layers\n",
            "7 layer_list = OrderedDict ()\n",
            "8 for l in range (len ( num_features_list )):\n",
            "9 layer_list [\" conv {}\". format (l)] = nn. Conv2d (\n",
            "10 in_channels = num_features_list [l - 1] if l > 0 else\n",
            "in_features ,\n",
            "11 out_channels = num_features_list [l],\n",
            "12 kernel_size =1,\n",
            "13 bias =False ,\n",
            "14 )\n",
            "15 layer_list [\" norm {}\". format (l)] = nn. BatchNorm2d (\n",
            "16 num_features = num_features_list [l]\n",
            "17 )\n",
            "18 layer_list [\" relu {}\". format (l)] = nn. LeakyReLU ()\n",
            "19 # add final similarity kernel\n",
            "20 layer_list [\" conv_out \"] = nn. Conv2d (\n",
            "21 in_channels = num_features_list [-1] , out_channels =1, kernel_size =1\n",
            "22 )\n",
            "23 self . sim_network = nn. Sequential ( layer_list ).to( device )\n",
            "24\n",
            "25 def forward (self , node_feat ):\n",
            "26 node_feat = node_feat . unsqueeze ( dim =0) # (1, bs , dim)\n",
            "27 num_tasks = node_feat . size (0) # 1\n",
            "28 num_data = node_feat . size (1) # bs\n",
            "29 x_i = node_feat . unsqueeze (2) # (1, bs , 1, dim)\n",
            "30 x_j = torch . transpose (x_i , 1, 2) # (1, 1, bs , dim)\n",
            "31 x_ij = torch .abs (x_i - x_j) # (1, bs , bs , dim)\n",
            "32 x_ij = torch . transpose (x_ij , 1, 3) # (1, dim , bs , bs)\n",
            "33 # compute similarity / dissimilarity ( batch_size x feat_size x\n",
            "num_samples x num_samples )\n",
            "34 sim_val = (\n",
            "35 torch . sigmoid ( self . sim_network ( x_ij )). squeeze (1). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "squeeze (0).to(\n",
            "self . device )\n",
            "36 ) # (bs , bs)\n",
            "37 # normalize affinity matrix\n",
            "38 force_edge_feat = (\n",
            "39 torch .eye ( num_data ). unsqueeze (0). repeat ( num_tasks , 1, 1).to( self\n",
            ". device )\n",
            "40 ) # (1, bs , bs)\n",
            "41 edge_feat = sim_val + force_edge_feat # (bs , bs)\n",
            "42 edge_feat = edge_feat + 1e -6 # add small value to avoid nan\n",
            "43 edge_feat = edge_feat / torch .sum( edge_feat , dim =1). unsqueeze (1) #\n",
            "normalize\n",
            "44 return edge_feat , sim_val # (bs , bs), (bs , bs)\n",
            "Lưu ý: edge_feat là tensor sau khi đã normalize sim_val, ta sẽ dùng sim_val để cập nhật hàm\n",
            "loss cho model nên cần return về.\n",
            "Tiếp theo, node network sẽ dùng edge_feat để tổng hợp thông tin. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Node network sẽ dùng các giá\n",
            "trị trong edge_feat để tổng hợp thông tin cho các sample, giá trị càng cao sẽ được tổng hợp càng\n",
            "nhiều, và ngược lại.\n",
            "1class NodeNet (nn. Module ):\n",
            "2 def __init__ (self , in_features , num_features , device , ratio =(1 ,)):\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3 super ( NodeNet , self ). __init__ ()\n",
            "4 num_features_list = [ num_features * r for r in ratio ]\n",
            "5 self . device = device\n",
            "6 # define layers\n",
            "7 layer_list = OrderedDict ()\n",
            "8 for l in range (len ( num_features_list )):\n",
            "9 layer_list [\" conv {}\". format (l)] = nn. Conv2d (\n",
            "10 in_channels = num_features_list [l - 1] if l > 0 else\n",
            "in_features * 2,\n",
            "11 out_channels = num_features_list [l],\n",
            "12 kernel_size =1,\n",
            "13 bias =False ,\n",
            "14 )\n",
            "15 layer_list [\" norm {}\". format (l)] = nn. BatchNorm2d (\n",
            "16 num_features = num_features_list [l]\n",
            "17 )\n",
            "18 if l < (len( num_features_list ) - 1):\n",
            "19 layer_list [\" relu {}\". format (l)] = nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "LeakyReLU ()\n",
            "20 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "network = nn. Sequential ( layer_list ).to( device )\n",
            "21\n",
            "22 def forward (self , node_feat , edge_feat ):\n",
            "23 \"\"\" node_feat : (bs , dim), edge_feat : (bs , bs)\"\"\"\n",
            "24 node_feat = node_feat . unsqueeze ( dim =0) # (1, bs , dim)\n",
            "25 num_tasks = node_feat . size (0) # 1\n",
            "26 num_data = node_feat . size (1) # bs\n",
            "27 # get eye matrix ( batch_size x node_size x node_size ) only use inter\n",
            "dist .\n",
            "28 diag_mask = 1.0 - torch .eye( num_data ). unsqueeze (0). repeat ( num_tasks ,\n",
            "1, 1).to(\n",
            "29 self . device\n",
            "30 ) # (1, bs , bs)\n",
            "31 # set diagonal as zero and normalize\n",
            "32 edge_feat = F. normalize ( edge_feat * diag_mask , p=1, dim = -1) # (bs ,\n",
            "bs)\n",
            "33 # compute attention and aggregate\n",
            "34 aggr_feat = torch .bmm( edge_feat . squeeze (1) , node_feat ) # (bs , dim)\n",
            "35 node_feat = torch .cat ([ node_feat , aggr_feat ], -1). transpose (\n",
            "36 1, 2\n",
            "37 ) # (1, 2* dim , bs)\n",
            "38 # non - linear transform\n",
            "39 node_feat = self . network ( node_feat . unsqueeze ( -1)). transpose (\n",
            "40 1, 2\n",
            "41 ) # (1, bs , dim )\n",
            "42 node_feat = node_feat . squeeze ( -1). squeeze (0) # (bs , dim)\n",
            "43 return node_feat\n",
            "Tóm lại, input của GNN sẽ có shape [batch_size, dim_1] và output có shape [batch_size, dim_2],\n",
            "ta hoàn toàn có thể đặt dim_1 = dim_2 hoặc dim_2 = num_classes.\n",
            "Bước cuối cùng là tích hợp GNN vào một backbone bất kì:\n",
            "1from torchvision . models import mobilenet_v3_small\n",
            "2\n",
            "3class Model (nn. Module ):\n",
            "4 def __init__ (self , num_classes =7):\n",
            "5 super (Model , self ). __init__ ()\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "6 self . backbone = mobilenet_v3_small ( pretrained = True )\n",
            "7 self . backbone . classifier = nn. Sequential ()\n",
            "8\n",
            "9 self . gcn = GCN (\n",
            "10 in_features =576 ,\n",
            "11 edge_features =576 ,\n",
            "12 out_feature = num_classes ,\n",
            "13 device =\" cuda \",\n",
            "14 ratio =(1 ,) ,\n",
            "15 )\n",
            "16\n",
            "17 def forward (self , x):\n",
            "18 x = self . backbone (x)\n",
            "19 x, edge_sim = self .gcn(x)\n",
            "20 return x, edge_sim\n",
            "Để dễ dàng hình dung hơn nữa thì ta hãy nhìn vào model bình thường không có GNN:\n",
            "1from torchvision . models import mobilenet_v3_small\n",
            "2\n",
            "3class Model (nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Module ):\n",
            "4 def __init__ (self , num_classes =2):\n",
            "5 super (Model , self ). __init__ ()\n",
            "6 self . backbone = mobilenet_v3_small ( pretrained = True )\n",
            "7 self . backbone . classifier = nn. Sequential ()\n",
            "8\n",
            "9 self . head = nn. Sequential ( OrderedDict ([\n",
            "10 (’fc1 ’, nn. Linear (576 , 256) ),\n",
            "11 (’relu ’, nn. ReLU ()),\n",
            "12 (’fc2 ’, nn. Linear (256 , num_classes ))\n",
            "13 ]))\n",
            "14\n",
            "15 def forward (self , x):\n",
            "16 x = self . backbone (x)\n",
            "17 x = self . head (x)\n",
            "18 return x\n",
            "Qua 2 đoạn code trên ta thấy chỉ cần một thay đổi đơn giản là ta đã có thể tích hợp GNN vào\n",
            "backbone bất kì cho bài toán image classification.\n",
            "Tiếp theo ta cần định nghĩa thêm hàm loss để giúp model predict edge giữa các sample chính xác\n",
            "hơn. Hàm edge loss này sẽ giúp model predict 1 cho 2 sample cùng class và 0 khi 2 sample khác\n",
            "class, do đó ta cần dùng Binary Cross Entroy (dòng 2). Hàm edege loss sẽ được tính toán ở dòng\n",
            "18-21. Biến edge_sim mà model return về chính là dạng chưa normalize của correlation matrix có\n",
            "shape [bs, bs]. Các label ta dùng để train model không thể trực tiếp sử dụng cho hàm edge loss,\n",
            "các label này cần phải chuyển sang dạng mới có shape [bs, bs] và mang các giá trị 0 hoặc 1 (được\n",
            "tính toán thông qua hàm label2edge).\n",
            "1criterion = nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "CrossEntropyLoss ()\n",
            "2criterion_edge = nn. BCELoss ()\n",
            "3...\n",
            "4for i, (inputs , labels ) in enumerate ( trainloader , 0):\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "5 # Move inputs and labels to the device\n",
            "6 inputs , labels = inputs .to( device ), labels .to( device )\n",
            "7\n",
            "8 # Zero the parameter gradients\n",
            "9 optimizer . zero_grad ()\n",
            "10\n",
            "11 # Forward pass\n",
            "12 outputs , edge_sim = model ( inputs )\n",
            "13\n",
            "14 # Cls loss\n",
            "15 loss_cls = criterion ( outputs , labels )\n",
            "16\n",
            "17 # Edge loss\n",
            "18 edge_gt , edge_mask = model .gcn. label2edge ( labels . unsqueeze (dim =0))\n",
            "19 loss_edge = criterion_edge (\n",
            "20 edge_sim . masked_select ( edge_mask ), edge_gt . masked_select ( edge_mask )\n",
            "21 )\n",
            "22\n",
            "23 # Total loss\n",
            "24 loss = 0.3 * loss_cls + loss_edge\n",
            "25\n",
            "26 running_loss += loss . item ()\n",
            "27\n",
            "28 # Backward pass and optimization\n",
            "29 loss . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "backward ()\n",
            "30 optimizer . step ()\n",
            "31...\n",
            "Lưu ý: file pdf này chỉ cung cấp một số đoạn code chính để tránh người đọc phân tâm. Tất cả\n",
            "các phần code còn lại như một bài toán image classification bình thường, full code sẽ nằm ở file\n",
            "notebook.\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. Đâu là lưu ý khi áp dụng GNN vào các bài toán bất kì?\n",
            "(a) Label là gì?\n",
            "(b) Độ lớn dataset\n",
            "(c) Độ phức tạp của model\n",
            "(d) Edge là gì?\n",
            "2. Đâu là lưu ý khi áp dụng GNN vào các bài toán bất kì?\n",
            "(a) Label là gì?\n",
            "(b) Node là gì?\n",
            "(c) Số lượng param\n",
            "(d) Loss là gì?\n",
            "3. Đâu là lưu ý khi áp dụng GNN vào các bài toán bất kì?\n",
            "(a) Có cần hàm loss phụ trợ hay không?\n",
            "(b) Loại hàm loss của model hiện tại.\n",
            "(c) Model có tính toán song song hay không?\n",
            "(d) Loss là gì?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "4. Sau khi chắc chắn GNN có thể sử dụng, điều gì ta cần cân nhắc tiếp theo là phù hợp nhất?\n",
            "(a) Không cần gì\n",
            "(b) Độ lớn của model sau khi thêm GNN\n",
            "(c) Hiểu rõ cách GNN tổng hợp thông tin\n",
            "(d) Tốc độ của model sau khi thêm GNN\n",
            "5. Nếu input của GNN có shape [batch_size, dim_1] và output có shape [batch_size, dim_2] thì\n",
            "nhận định nào sau đây là SAI:\n",
            "(a) dim_2 có thể bằng dim_1 * 2\n",
            "(b) dim_2 có thể bằng số lượng class\n",
            "(c) dim_1 và dim_2 không bắt buộc bằng nhau\n",
            "(d) dim_1 và dim_2 phải bằng nhau\n",
            "6. Khi muốn kết hợp nhiều dataset với nhau ta có thể dùng:\n",
            "(a) torch.utils.data.MergeDataset\n",
            "(b) torch.utils.data.ConcatDataset\n",
            "(c) torch.utils.data.MergeData\n",
            "(d) torch.utils.data.ConcatData\n",
            "7. Trong GNN, cơ chế nào được sử dụng để lan truyền thông tin qua các node và edge?\n",
            "(a) Feedforward\n",
            "(b) Backpropagation\n",
            "(c) Message passing\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(d) Gradient descent\n",
            "8. Đâu là điểm yếu của GNN?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(a) Tốc độ train model chậm\n",
            "(b) Tốc độ inference nhanh\n",
            "(c) Số lượng param cực lớn\n",
            "(d) Không có điểm yếu nào\n",
            "9. Đâu là điểm yếu của GNN?\n",
            "(a) Cần train model theo 2 stage\n",
            "(b) Cần inference model theo 2 stage\n",
            "(c) Tốc độ inference chậm\n",
            "(d) Tốc độ train model nhanh\n",
            "10. Đâu là những yếu cầu của GNN?\n",
            "(a) Batch size bất kì, data bất kì\n",
            "(b) Batch size = 1, data clean\n",
            "(c) Batch size > 1, data bất kì\n",
            "(d) Batch size > 1, data clean\n",
            "- Hết -\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AIO COURSE 2023\n",
            "Exercise: Multimodal Large Language Models\n",
            "Quoc-Thai Nguyen và Duong-Thuan Nguyen\n",
            "Ngày 23 tháng 4 năm 2024\n",
            "Phần I. Giới thiệu\n",
            "Hình 1: Giới thiệu các thành phần cơ bản trong mô hình MLLMs.\n",
            "Hình 2: Ví dụ về sinh ảnh dựa vào văn bản sử dụng mô hình MLLMs.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "MLLMs - Multimodal Large Language Models ngày càng được phát triển rộng rãi với mục\n",
            "tiêu xây dựng một mô hình ngôn ngữ lớn có thể xử lý cho các kiểu dữ liệu khác nhau như: văn bản,\n",
            "hình ảnh, âm thanh, video.\n",
            "Với các mô hình MLLMs đầu vào có thể là văn bản, hình ảnh, video, âm thanh hoặc kết hợp của\n",
            "các kiểu dữ liệu trên. Đầu ra có thể là văn bản, hình ảnh, video, âm thanh. Ví dụ về sinh hình ảnh dựa\n",
            "vào văn bản được mô tả trong Hình 2.\n",
            "Mô hình MLLMs bao gồm các thành phần chính sau:\n",
            "•Modality Encoder: Bao gồm các module có thể từ các dữ liệu đầu vào như hình ảnh, âm thanh,\n",
            "video biểu diễn thành các đặc trưng. Ví dụ, với hình ảnh / video chúng ta có các mô hình như\n",
            "ViT, CLIP, Eva-CLIP ViT,... Với âm thanh chúng ta có các mô hình như: HuBERT, BEATs,...\n",
            "Hoặc là ImageBind - mô hình chung được sử dụng để encode các kiểu dữ liệu trên.\n",
            "•Input Projector: phần này sẽ học cách kết nối các đặc trưng từ Encoder với văn bản đẩy vào\n",
            "LLMs. Các phương pháp bao gồm: Linear, MLP, Cross-Attention, Q-Former, P-former,...\n",
            "•LLMs: các kiến trúc mô hình LLMs có thể được sử dụng như: GPT, LLaMA, Vicuna, Flan-T5,...\n",
            "•Output Projector: bao gồm các phương pháp có thể ánh xạ từ đặc trưng của mô hình ngôn ngữ\n",
            "sang đặc trưng của kiểu dữ liệu như hình ảnh, video, âm thanh. Ví dụ: MLP, Tiny Transformer,...\n",
            "•Modality Generator: bao gồm các module nhận đặc trưng của từng kiểu dữ liệu để sinh ra dữ\n",
            "liệu mong muốn. Ví dụ như Stable Diffusion cho ảnh, Zeroscope cho video, AudioLDM cho âm\n",
            "thanh,...\n",
            "Dưới đây là một số mô hình MLLMs điển hình hiện nay. Trong đó I: Image (hình ảnh), T: Text (văn\n",
            "bản), V: Video, A: Audio (âm thanh).\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 3: Một số mô hình MLLMs điển hình hiện nay.\n",
            "Trong phần tiếp theo, chúng ta sẽ huấn luyện mô hình cơ bản BLIP-2 trên bài toán VQA - Visual\n",
            "Question Answering.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II. Visual Question Answering us-\n",
            "ing BLIP-2\n",
            "Hình 4: Kiến trúc mô hình BLIP-2.\n",
            "Kiến trúc mô hình BLIP-2 được mô tả trong Hình 4. Đầu vào mô hình là câu hỏi và hình ảnh. Đầu\n",
            "ra của mô hình là câu trả lời dựa vào câu hỏi và ngữ cảnh là hình ảnh. Mô hình BLIP-2 bao gồm các\n",
            "thành phần:\n",
            "•Image Encoder: CLIP ViT.\n",
            "•Input Projector: Q-Former.\n",
            "•LLMs: Flan-T5 / OPT.\n",
            "Trong phần tiếp theo, chúng ta sẽ huấn luyện mô hình BLIP-2 trên bộ dữ liệu VQA dựa vào thư\n",
            "viện transformers. Bộ dữ liệu VQA có 14,550 samples. Mỗi sample bao gồm đầu vào: Image + Question\n",
            "và đầu ra: Answer. Bộ dữ liệu VQA có thể được tải về: tại đây.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2.1. Build Dataset\n",
            "1# install libs\n",
            "2!pip install -q peft transformers bitsandbytes datasets\n",
            "3\n",
            "4import os\n",
            "5import torch\n",
            "6from PIL import Image\n",
            "7\n",
            "8class VQADataset ( torch . utils . data . Dataset ):\n",
            "9 \"\"\" VQA (v2) dataset .\"\"\"\n",
            "10\n",
            "11 def __init__ (self , dataset , processor , data_path ):\n",
            "12 self . dataset = dataset\n",
            "13 self . processor = processor\n",
            "14 self . data_path = data_path\n",
            "15\n",
            "16 def __len__ ( self ):\n",
            "17 return len( self . dataset )\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "18\n",
            "19 def __getitem__ (self , idx):\n",
            "20 # get image + text\n",
            "21 question = self . dataset [idx ][ ’question ’]\n",
            "22 answer = self . dataset [idx ][ ’answer ’]\n",
            "23 image_id = self . dataset [idx ][ ’pid ’]\n",
            "24 image_path = os. path . join ( self . data_path , f\" train_fill_in_blank /\n",
            "train_fill_in_blank /{ image_id }/ image .png\")\n",
            "25 image = Image . open ( image_path ). convert (\"RGB\")\n",
            "26 text = question\n",
            "27\n",
            "28 encoding = self . processor (image , text , padding =\" max_length \", truncation =True ,\n",
            "return_tensors =\"pt\")\n",
            "29 labels = self . processor . tokenizer . encode (\n",
            "30 answer , max_length = 8, pad_to_max_length =True , return_tensors =’pt ’\n",
            "31 )\n",
            "32 encoding [\" labels \"] = labels\n",
            "33 for k,v in encoding . items (): encoding [k] = v. squeeze ()\n",
            "34 return encoding\n",
            "2.2. Load Model\n",
            "1import torch\n",
            "2from peft import LoraConfig , get_peft_model\n",
            "3from transformers import BlipProcessor , BlipForQuestionAnswering\n",
            "4\n",
            "5processor = BlipProcessor . from_pretrained (\" Salesforce /blip -vqa - base \")\n",
            "6model = BlipForQuestionAnswering . from_pretrained (\" Salesforce /blip -vqa - base \")\n",
            "7\n",
            "8config = LoraConfig (\n",
            "9 r=16 ,\n",
            "10 lora_alpha =32 ,\n",
            "11 lora_dropout =0.05 ,\n",
            "12 bias =\" none \",\n",
            "13 target_modules =[\" query \", \"key\"]\n",
            "14)\n",
            "15\n",
            "16model = get_peft_model (model , config )\n",
            "17device = torch . device (\" cuda \" if torch . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "cuda . is_available () else \"cpu \")\n",
            "18model .to( device )\n",
            "19model . print_trainable_parameters ()\n",
            "2.3. Create Dataloader\n",
            "1from datasets import load_dataset\n",
            "2from torch . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "utils . data import DataLoader\n",
            "3\n",
            "4data_path = ’./ IconDomainVQAData ’\n",
            "5ds = load_dataset (\" json \", data_files =f\"{ data_path }/ train . jsonl \")\n",
            "6\n",
            "7train_dataset = VQADataset (\n",
            "8 dataset =ds[’test ’],\n",
            "9 processor = processor ,\n",
            "10 data_path = data_path\n",
            "11)\n",
            "12valid_dataset = VQADataset (\n",
            "13 dataset =ds[’test ’],\n",
            "14 processor = processor ,\n",
            "15 data_path = data_path\n",
            "16)\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "17\n",
            "18batch_size = 8\n",
            "19train_dataloader = DataLoader ( train_dataset , batch_size = batch_size , shuffle =True ,\n",
            "pin_memory = True )\n",
            "20valid_dataloader = DataLoader ( valid_dataset , batch_size = batch_size , shuffle =False ,\n",
            "pin_memory = True )\n",
            "2.4. Train\n",
            "1from tqdm import tqdm\n",
            "2\n",
            "3optimizer = torch . optim . AdamW ( model . parameters () , lr =4e -5)\n",
            "4scheduler = torch . optim . lr_scheduler . ExponentialLR ( optimizer , gamma =0.9 , last_epoch\n",
            "=-1, verbose = False )\n",
            "5\n",
            "6num_epochs = 1\n",
            "7min_eval_loss = float (\"inf \")\n",
            "8scaler = torch . cuda . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "amp. GradScaler ()\n",
            "9\n",
            "10for epoch in range ( num_epochs ):\n",
            "11 epoch_loss = []\n",
            "12 model . train ()\n",
            "13 for idx , batch in zip( tqdm ( range (len ( train_dataloader )), desc =f’Training batch : {\n",
            "epoch +1} ’), train_dataloader ):\n",
            "14 input_ids = batch .pop(’input_ids ’).to( device )\n",
            "15 pixel_values = batch . pop(’ pixel_values ’).to( device )\n",
            "16 attention_masked = batch . pop(’ attention_mask ’).to( device )\n",
            "17 labels = batch .pop(’labels ’).to( device )\n",
            "18\n",
            "19 with torch .amp. autocast ( device_type =’cuda ’, dtype = torch . float16 ):\n",
            "20 outputs = model (\n",
            "21 input_ids = input_ids ,\n",
            "22 pixel_values = pixel_values ,\n",
            "23 labels = labels\n",
            "24 )\n",
            "25\n",
            "26 loss = outputs . loss\n",
            "27 epoch_loss . append ( loss . item ())\n",
            "28\n",
            "29 optimizer . zero_grad ()\n",
            "30 scaler . scale ( loss ). backward ()\n",
            "31 scaler . step ( optimizer )\n",
            "32 scaler . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "update ()\n",
            "33\n",
            "34 model . eval ()\n",
            "35 valid_loss = []\n",
            "36 for idx , batch in zip( tqdm ( range (len ( valid_dataloader )), desc =f’Validating batch :\n",
            "{ epoch +1} ’), valid_dataloader ):\n",
            "37 input_ids = batch .pop(’input_ids ’).to( device )\n",
            "38 pixel_values = batch . pop(’ pixel_values ’).to( device )\n",
            "39 attention_masked = batch . pop(’ attention_mask ’).to( device )\n",
            "40 labels = batch .pop(’labels ’).to( device )\n",
            "41\n",
            "42 with torch .amp. autocast ( device_type =’cuda ’, dtype = torch . float16 ):\n",
            "43 outputs = model (\n",
            "44 input_ids = input_ids ,\n",
            "45 pixel_values = pixel_values ,\n",
            "46 attention_mask = attention_masked ,\n",
            "47 labels = labels\n",
            "48 )\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "49\n",
            "50 loss = outputs . loss\n",
            "51 valid_loss . append ( loss . item ())\n",
            "52 print (\" Epoch : {} - Training loss : {} - Eval Loss : {} - LR: {}\". format ( epoch +1, sum\n",
            "( epoch_loss )/ len( epoch_loss ), sum( valid_loss )/len( valid_loss ), optimizer .\n",
            "param_groups [0][ \"lr\"]))\n",
            "53 scheduler . step ()\n",
            "54 avg_loss = sum( valid_loss )/len( valid_loss )\n",
            "55 if avg_loss < min_eval_loss :\n",
            "56 model . save_pretrained (\"./ save_model \", from_pt = True )\n",
            "57 print (\" Saved model to ./ save_model \")\n",
            "58 min_eval_loss = valid_loss\n",
            "59processor . save_pretrained (\"./ save_model \", from_pt = True )\n",
            "2.5. Predict\n",
            "Sau khi huấn luyện mô hình xong, trong phầ này chúng ta sẽ load mô hình tốt nhất và dự đoán. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Một\n",
            "ví dụ sử dụng đánh giá mô hình được mô tả như Hình 5.\n",
            "Hình 5: Hình ảnh ví dụ với câu hỏi: \"How many diamonds are there?\".\n",
            "1import json\n",
            "2processor = BlipProcessor . from_pretrained (\"./ save_model \")\n",
            "3model = BlipForQuestionAnswering . from_pretrained (\"./ save_model \").to( device )\n",
            "4test_data_dir = f\"{ data_path }/ test_data / test_data \"\n",
            "5samples = os. listdir ( test_data_dir )\n",
            "6sample_path = f\"{ data_path }/ test_data / test_data /{ samples [0]} \"\n",
            "7\n",
            "8# read question , image id\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "9json_path = os. path . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "join ( sample_path , \" data . json \")\n",
            "10with open ( json_path , \"r\") as json_file :\n",
            "11 data = json . load ( json_file )\n",
            "12 question = data [\" question \"] # How many diamonds are there ?\n",
            "13 image_id = data [\"id\"]\n",
            "14\n",
            "15# load image\n",
            "16image_path = os. path . join ( test_data_dir , f\"{ image_id }\", \" image .png\")\n",
            "17image = Image . open ( image_path ). convert (\"RGB\")\n",
            "18\n",
            "19encoding = processor (image , question , return_tensors =\"pt\").to(device , torch . float16 )\n",
            "20\n",
            "21out = model . generate (** encoding )\n",
            "22generated_text = processor . decode (out [0] , skip_special_tokens = True )\n",
            "23\n",
            "24generated_text\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần 4. Câu hỏi trắc nghiệm\n",
            "Câu hỏi 1 Mô hình nào sau đây không phải là mô hình ngôn ngữ lớn (LLMs)?\n",
            "a) Vicuna\n",
            "b) LLaMA\n",
            "c) PaLM\n",
            "d) ResNet\n",
            "Câu hỏi 2 Thành phần nào sau đây không có trong các thành phần chính của mô hình MLLMs?\n",
            "a) Contrastive Search\n",
            "b) Modality Encoder\n",
            "c) LLMs\n",
            "d) Input Projector\n",
            "Câu hỏi 3 Mô hình được sử dụng để encode âm thanh là?\n",
            "a) ViT\n",
            "b) CLIP\n",
            "c) BERT\n",
            "d) BEATs\n",
            "Câu hỏi 4 Phương pháp không được sử dụng trong bước Input Projector là?\n",
            "a) Linear Projector\n",
            "b) MLP\n",
            "c) Q-Former\n",
            "d) Cosine Similarity\n",
            "Câu hỏi 5 Phương pháp nào được sử dụng làm khối Generator cho audio?\n",
            "a) Zeroscope\n",
            "b) AudioLDM\n",
            "c) HuBERT\n",
            "d) WavLM\n",
            "Câu hỏi 6 Mô hình LLaVA sử dụng LLM nào?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "a) Flan-T5\n",
            "b) Vicuna\n",
            "c) GPT3\n",
            "d) PaLM\n",
            "Câu hỏi 7 Mô hình BLIP-2 không xử lý được bài toán nào sau đây?\n",
            "a) Image Captioning\n",
            "b) Prompted Image Captioning\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "c) Visual Question Answering\n",
            "d) Audio Generation\n",
            "Câu hỏi 8 Mô hình nào sau đây có thể encode cho hình ảnh, văn bản, video?\n",
            "a) CLIP\n",
            "b) ViT\n",
            "c) Eva-CLIP ViT\n",
            "d) ImageBlind\n",
            "Câu hỏi 9 Mô hình NExT-GPT sử dụng mô hình nào cho bước Output Generator?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "a) MLP\n",
            "b) Linear Projector\n",
            "c) Tiny Transformer\n",
            "d) Cross-Attention\n",
            "Câu hỏi 10 Mô hình NExT-GPT sử dụng LLM nào?\n",
            "a) Flan-T5\n",
            "b) Vicuna\n",
            "c) GPT3\n",
            "d) PaLM\n",
            "- Hết -\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AIO COURSE 2023\n",
            "Project: Reinforcement Learning From Human\n",
            "Feedback\n",
            "Quoc-Thai Nguyen và Quang-Vinh Dinh\n",
            "PR-Team: Đăng-Nhã Nguyễn, Minh-Châu Phạm và Hoàng-Nguyên Vũ\n",
            "Ngày 1 tháng 4 năm 2024\n",
            "Phần I. Giới thiệu\n",
            "Hình 1: Ứng dụng ChatGPT được cải tiến dựa vào mô hình học tăng cường từ phản hồi người dùng.\n",
            "Hình 2: Ví dụ minh hoạ tóm tắt văn bản sử dụng mô hình học tăng cường từ phản hồi người dùng.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "ChatGPT (Chat Generative Pre-Training Transformer) là mô hình chatbot được phát triển\n",
            "bởi OpenAI ra mắt vào tháng 11 năm 2022. ChatGPT được xây dựng dựa trên việc tinh chỉnh mô hình\n",
            "ngôn ngữ lớn (Large Language Model) kết hợp với học tăng cường dựa trên phản hồi của con người\n",
            "(Reinforcement Learning with Human Feedback).\n",
            "ChatGPT có thể giải quyết nhiều bài toán khác nhau trong xử lý tự nhiên như: phân loại văn bản\n",
            "(Text Classification), bài toán dịch máy (Machine Translation), bài toán hỏi đáp (Question Answering),\n",
            "bài toán tóm tắt văn bản (Text Summarization),... Từ các bài toán gốc cơ bản này, ChatGPT được\n",
            "triển khai cho nhiều lĩnh vực khác nhau: giáo dục, sáng tạo nội dung, chăm sóc sức khoẻ,...\n",
            "Mô hình ChatGPT còn có khả năng tương thích, tối ưu cho bài toán cụ thể trong quá trình dự\n",
            "đoán (Inference - đưa ra phản hồi cho các bài toán) thông qua phương pháp học tập trong ngữ cảnh\n",
            "(In-Content Learning). Phương pháp học tập trong ngữ cảnh được xây dựng thông qua các prompt,\n",
            "được hiểu là các dữ liệu đầu vào với mục tiêu hướng dẫn hoặc mô tả chi tiết cho bài toán giúp ChatGPT\n",
            "có thể xác định được bài toán cần xử lý và tối ưu miền xử lý, nhờ đó ChatGPT có thể cho kết quả tốt\n",
            "hơn.\n",
            "(a) Zero-shot: Đưa ra câu trả lời chỉ dựa vào mô tả của bài toán\n",
            "(b) One-shot: Đưa ra câu trả lời dựa vào mô tả bài toán và một ví dụ mẫu cho bài toán\n",
            "(c) One-shot: Đưa ra câu trả lời dựa vào mô tả bài toán và một vài ví dụ mẫu cho bài toán\n",
            "Một trong những kỹ thuật giúp cho mô hình ngôn ngữ đạt kết quả tốt là cải tiến các mô hình\n",
            "này dựa vào học tăng cường từ phản hồi của người dùng (RLHF - Reinforcement learning from human\n",
            "feedback). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trong phần này chúng ta sẽ tập trung vào đi sâu tìm hiểu về RLHF.\n",
            "Hình 3: Reinforcement Learning from Human Feedback.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(a) Supervised fine-tuning (SFT)\n",
            "Trong phần này chúng ta sử dụng 1 tập các prompt và response để tinh chỉnh mô hình ngôn ngữ.\n",
            "Mô hình GPT2 được chọn với 12 khối Transformer-Decoder. Ngoài ra, có nhiều mô hình ngôn ngữ\n",
            "có thể chọn phù hợp với mục tiêu và open source như BLOOM, LLaMa,...\n",
            "(b) Reward Modeling (RM)\n",
            "Trong phần này chúng ta sử dụng tập dữ liệu Helpful and Harmless để huấn luyện mô hình RM.\n",
            "Với mỗi prompt chúng ta sẽ có 1 response là có nhãn \"chosen\" và 1 response có nhãn là \"rejected\".\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mục tiêu của phần này với mỗi prompt và response chúng ta cần đưa ra điểm số tương ứng.\n",
            "(c) Reinforcement learning (RL)\n",
            "Trong phần này chúng ta sử dụng bộ dữ liệu rm-static, kết hợp với mô hình RM để tinh chỉnh\n",
            "mô hình SFT dựa vào phương pháp huấn luyện sử dụng Proximal Policy Optimization (PPO).\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II. Text Summarization using RLHF\n",
            "Trong phần này, chúng ta sẽ tập trung ứng dụng cải tiến mô hình dựa vào RLHF cho bài toán tóm\n",
            "tắt văn bản.\n",
            "Tóm tắt văn bản (Text Summarization) nhận đầu vào là đoạn văn bản dài hoặc nhiều đoạn văn bản\n",
            "dài. Thông qua mô hình các đoạn văn bản sẽ được tóm tắt ngắn gọn thành vài câu. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ví dụ minh hoạ về\n",
            "bài toán tóm tắt văn bản được minh hoạ như hình 2.\n",
            "Các bước để huấn luyện và tối ưu mô hình được mô tả như sau:\n",
            "Hình 4: Các bước huấn luyện mô hình tóm tắt văn bản sử dụng RLHF.\n",
            "RLHF bao gồm 3 phần:\n",
            "•Supervised Fine-Tuning: Tinh chỉnh mô hình trên bộ dữ liệu có nhãn cho bài toán tóm tắt\n",
            "•Reward Modeling: Huấn luyện mô hình cho điểm chât lượng bản tóm tắt\n",
            "•Reinforcement Learning: Tinh chỉnh mô hình dựa vào học tăng cường để cải tiến mô hình\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1. Supervised Fine-Tuning (SFT)\n",
            "Trong phần này chúng ta sẽ tinh chỉnh mô hình tiền huấn luyện như GPT, BLOOM, FlanT5,... trên\n",
            "bộ dữ liệu được gán nhãn. Bộ dữ liệu openai_summarize_tldr bao gồm các cặp dữ liệu: văn bản và bản\n",
            "tóm tắt.\n",
            "Hình 5: Supervised Fine-Tuning.\n",
            "1.1. Dataset\n",
            "Chúng ta tải về bộ dữ liệu từ thư viện transformers sau đó tiền hành xây dựng cấu trúc dữ liệu như\n",
            "sau: \"Text: document # Summary: summary\"\n",
            "1# install libs\n",
            "2!pip install -q datasets ==2.18.0 trl ==0.8.1 evaluate ==0.4.1 rouge_score ==0.1.2 peft\n",
            "==0.10.0\n",
            "3\n",
            "4# load the dataset\n",
            "5from datasets import load_dataset\n",
            "6\n",
            "7sft_ds_name = ’CarperAI / openai_summarize_tldr ’\n",
            "8sft_ds = load_dataset ( sft_ds_name )\n",
            "9sft_train = sft_ds [’train ’]\n",
            "10sft_valid = sft_ds [’valid ’]\n",
            "11sft_test = sft_ds [’test ’]\n",
            "12\n",
            "13def formatting_func ( example ):\n",
            "14 text = f\"### Text : { example [’ prompt ’]}\\n ### Summary : { example [’ label ’]}\"\n",
            "15 return text\n",
            "16\n",
            "17# demo formating\n",
            "18for example in sft_train :\n",
            "19 print ( formatting_func ( example ))\n",
            "20 break\n",
            "1.2. Model\n",
            "Mô hình tiền huấn luyện được sử dụng là OPT. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Để tăng tốc độ huấn luyện mô hình, chúng ta sẽ sử\n",
            "dụng kỹ thuật quantization và LORA.\n",
            "1import torch\n",
            "2from trl import ModelConfig , get_quantization_config , get_kbit_device_map\n",
            "3from peft import LoraConfig , PeftConfig , PeftModel , get_peft_model ,\n",
            "prepare_model_for_kbit_training\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4\n",
            "5model_config = ModelConfig (\n",
            "6 model_name_or_path =’facebook /opt -350 m’\n",
            "7)\n",
            "8\n",
            "9torch_dtype = (\n",
            "10 model_config . torch_dtype\n",
            "11 if model_config . torch_dtype in [\" auto \", None ]\n",
            "12 else getattr (torch , model_config . torch_dtype )\n",
            "13)\n",
            "14quantization_config = get_quantization_config ( model_config )\n",
            "15model_kwargs = dict (\n",
            "16 revision = model_config . model_revision ,\n",
            "17 trust_remote_code = model_config . trust_remote_code ,\n",
            "18 attn_implementation = model_config . attn_implementation ,\n",
            "19 torch_dtype = torch_dtype ,\n",
            "20 use_cache =False ,\n",
            "21 device_map = get_kbit_device_map () if quantization_config is not None else None ,\n",
            "22 quantization_config = quantization_config ,\n",
            "23)\n",
            "24tokenizer = AutoTokenizer . from_pretrained ( model_config . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "model_name_or_path , use_fast =\n",
            "True )\n",
            "25tokenizer . pad_token = tokenizer . eos_token\n",
            "26\n",
            "27tokenizer . pad_token_id = tokenizer . eos_token_id\n",
            "28\n",
            "29\n",
            "30# lora\n",
            "31peft_config = LoraConfig (\n",
            "32 r=16 ,\n",
            "33 lora_alpha =32 ,\n",
            "34 lora_dropout =0.05 ,\n",
            "35 bias =\" none \",\n",
            "36 task_type =\" CAUSAL_LM \",\n",
            "37)\n",
            "1.3. Metric\n",
            "Chúng ta sử dụng độ ROUGE để đánh giá mô hình\n",
            "1import evaluate\n",
            "2\n",
            "3rouge = evaluate . load (\" rouge \")\n",
            "4\n",
            "5def compute_metrics ( eval_preds ):\n",
            "6 if isinstance ( eval_preds , tuple ):\n",
            "7 eval_preds = eval_preds [0]\n",
            "8 labels_ids = eval_preds . label_ids\n",
            "9 pred_ids = eval_preds . predictions\n",
            "10 pred_str = tokenizer . batch_decode ( pred_ids , skip_special_tokens = True )\n",
            "11 label_str = tokenizer . batch_decode ( labels_ids , skip_special_tokens = True )\n",
            "12 result = rouge . compute ( predictions = pred_str , references = label_str )\n",
            "13 return result\n",
            "1.4. Trainer\n",
            "Chúng ta sẽ thiết lập các tham số huấn luyện mô hình\n",
            "1from trl import SFTTrainer\n",
            "2from transformers import TrainingArguments\n",
            "3\n",
            "4num_epochs = 10\n",
            "5training_args = TrainingArguments (\n",
            "6 output_dir =’./ save_model ’,\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "7 evaluation_strategy =\" epoch \",\n",
            "8 save_strategy =’epoch ’,\n",
            "9 per_device_train_batch_size =4,\n",
            "10 per_device_eval_batch_size =4,\n",
            "11 adam_beta1 =0.9 ,\n",
            "12 adam_beta2 =0.95 ,\n",
            "13 num_train_epochs = num_epochs ,\n",
            "14 load_best_model_at_end =True ,\n",
            "15)\n",
            "16\n",
            "17max_input_length = 512\n",
            "18trainer = SFTTrainer (\n",
            "19 model = model_config . model_name_or_path ,\n",
            "20 model_init_kwargs = model_kwargs ,\n",
            "21 args = training_args ,\n",
            "22 train_dataset = sft_train ,\n",
            "23 eval_dataset = sft_valid ,\n",
            "24 max_seq_length = max_input_length ,\n",
            "25 tokenizer = tokenizer ,\n",
            "26 peft_config = peft_config ,\n",
            "27 compute_metrics = compute_metrics ,\n",
            "28 packing =True ,\n",
            "29 formatting_func = formatting_func\n",
            "30)\n",
            "31trainer . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "train ()\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "2. Reward Modeling\n",
            "Trong phần này chúng ta sẽ xây dụng mô hình đánh giá chất lượng bản tóm tắt. Đầu vào của mô hình\n",
            "là văn bản kết hợp với bản tóm tắt. Đầu ra là giá trị dự đoán từ 0 đến 1. Chúng ta sẽ tinh chỉnh mô\n",
            "hình SFT cho bài toán phân loại. Với bản tóm tắt phù hợp (Chosen) sẽ có nhãn là 1, và bản tóm tắt\n",
            "không phù hợp (Rejected) sẽ có nhãn là 0.\n",
            "Hình 6: Reward Modeling.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2.1. Dataset\n",
            "Bộ dữ liệu openai_summarize_comparisons bao gồm 83 mẫu có nhãn: văn bản, bản tóm tắt phù hợp\n",
            "và bản tóm tắt không phù hợp. Chúng ta sẽ kết hợp lần lượt văn bản với bản tóm tắt phù hợp và không\n",
            "phù hợp để huấn luyện mô hình.\n",
            "1# load dataset\n",
            "2from datasets import load_dataset\n",
            "3\n",
            "4rw_ds_name = ’CarperAI / openai_summarize_comparisons ’\n",
            "5rw_ds = load_dataset ( rw_ds_name )\n",
            "6\n",
            "7def preprocess_function ( examples ):\n",
            "8 new_examples = {\n",
            "9 \" input_ids_chosen \": [],\n",
            "10 \" attention_mask_chosen \": [],\n",
            "11 \" input_ids_rejected \": [],\n",
            "12 \" attention_mask_rejected \": [],\n",
            "13 }\n",
            "14 for prompt , chosen , rejected in zip ( examples [\" prompt \"], examples [\" chosen \"],\n",
            "examples [\" rejected \"]):\n",
            "15 chosen = f\"### Text : { prompt }\\n ### Summary : { chosen }\"\n",
            "16 tokenized_chosen = tokenizer ( chosen )\n",
            "17\n",
            "18 rejected = f\" ### Text : { prompt }\\n ### Summary : { rejected }\"\n",
            "19 tokenized_rejected = tokenizer ( rejected )\n",
            "20\n",
            "21 new_examples [\" input_ids_chosen \"]. append ( tokenized_chosen [\" input_ids \"])\n",
            "22 new_examples [\" attention_mask_chosen \"]. append ( tokenized_chosen [\" attention_mask \"\n",
            "])\n",
            "23 new_examples [\" input_ids_rejected \"]. append ( tokenized_rejected [\" input_ids \"])\n",
            "24 new_examples [\" attention_mask_rejected \"]. append ( tokenized_rejected [\"\n",
            "attention_mask \"])\n",
            "25\n",
            "26 return new_examples\n",
            "27\n",
            "28rw_ds_processed = rw_ds .map (\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "29 preprocess_function ,\n",
            "30 batched =True ,\n",
            "31 num_proc =4,\n",
            "32)\n",
            "33\n",
            "34max_input_length = 512\n",
            "35\n",
            "36rw_ds_filted = rw_ds_processed . filter (\n",
            "37 lambda x: len (x[\" input_ids_chosen \"]) <= max_input_length\n",
            "38 and len(x[\" input_ids_rejected \"]) <= max_input_length\n",
            "39)\n",
            "40\n",
            "41rw_train = rw_ds_filted [\" train \"]\n",
            "42rw_valid = rw_ds_filted [\" valid1 \"]\n",
            "43rw_test = rw_ds_filted [\" test \"]\n",
            "2.2. Model\n",
            "Mô hình được sử dụng sẽ là mô hình SFT và tinh chỉnh để phù hợp cho bài toán phân loại mức câu.\n",
            "1import torch\n",
            "2from trl import ModelConfig , get_quantization_config , get_kbit_device_map\n",
            "3from transformers import AutoModelForSequenceClassification\n",
            "4\n",
            "5model_config = ModelConfig (\n",
            "6 model_name_or_path =’facebook /opt -350 m’ # ./ save_sft_model / checkpoint -1000\n",
            "7)\n",
            "8\n",
            "9torch_dtype = (\n",
            "10 model_config . torch_dtype\n",
            "11 if model_config . torch_dtype in [\" auto \", None ]\n",
            "12 else getattr (torch , model_config . torch_dtype )\n",
            "13)\n",
            "14quantization_config = get_quantization_config ( model_config )\n",
            "15model_kwargs = dict (\n",
            "16 revision = model_config . model_revision ,\n",
            "17 trust_remote_code = model_config . trust_remote_code ,\n",
            "18 attn_implementation = model_config . attn_implementation ,\n",
            "19 torch_dtype = torch_dtype ,\n",
            "20 use_cache =False ,\n",
            "21 device_map = get_kbit_device_map () if quantization_config is not None else None ,\n",
            "22 quantization_config = quantization_config ,\n",
            "23)\n",
            "24tokenizer = AutoTokenizer . from_pretrained ( model_config . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "model_name_or_path , use_fast =\n",
            "True )\n",
            "25model = AutoModelForSequenceClassification . from_pretrained (\n",
            "26 model_config . model_name_or_path , num_labels =1, ** model_kwargs\n",
            "27)\n",
            "28\n",
            "29peft_config = LoraConfig (\n",
            "30 r=16 ,\n",
            "31 lora_alpha =32 ,\n",
            "32 lora_dropout =0.05 ,\n",
            "33 bias =\" none \",\n",
            "34 task_type =\" SEQ_CLS \",\n",
            "35)\n",
            "2.3. Trainer\n",
            "Huấn luyện mô hình Reward\n",
            "1from trl import RewardConfig\n",
            "2from trl import RewardTrainer\n",
            "3\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4num_epochs = 1 # 10\n",
            "5\n",
            "6reward_config = RewardConfig (\n",
            "7 output_dir =’./ save_rw_model ’,\n",
            "8 evaluation_strategy =\" epoch \",\n",
            "9 save_strategy =’epoch ’,\n",
            "10 per_device_train_batch_size =4,\n",
            "11 per_device_eval_batch_size =4,\n",
            "12 num_train_epochs = num_epochs ,\n",
            "13 load_best_model_at_end =True ,\n",
            "14 max_length = max_input_length ,\n",
            "15)\n",
            "16\n",
            "17trainer = RewardTrainer (\n",
            "18 model =model ,\n",
            "19 tokenizer = tokenizer ,\n",
            "20 args = reward_config ,\n",
            "21 train_dataset = rw_train ,\n",
            "22 eval_dataset = rw_valid ,\n",
            "23 peft_config = peft_config ,\n",
            "24)\n",
            "25\n",
            "26trainer . train ()\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3. Reinforcement Learning\n",
            "Trong phần này chúng ta tối ưu mô hình SFT dựa vào mô hình Reward sử dụng thuật toán Proximal\n",
            "Policy Optimization (PPO).\n",
            "Hình 7: Proximal Policy Optimization.\n",
            "2.1. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Dataset\n",
            "Chúng ta sử dụng bộ dữ liệu openai_summarize_tldr. Nối phần văn bản và phần bản tóm tắt để huấn\n",
            "luyện mô hình.\n",
            "1from transformers import AutoTokenizer\n",
            "2\n",
            "3ppo_ds_name = ’CarperAI / openai_summarize_tldr ’\n",
            "4ppo_ds = load_dataset ( sft_ds_name , split =\" train \")\n",
            "5\n",
            "6def build_dataset (ds , tokenizer , max_length =200) :\n",
            "7 ds = ds. filter ( lambda x: len (x[\" prompt \"]) > max_length , batched = False )\n",
            "8\n",
            "9 def tokenize ( sample ):\n",
            "10 sample [\" text \"] = sample [\" prompt \"] + sample [\" label \"]\n",
            "11 sample [\" input_ids \"] = tokenizer . encode ( sample [\" text \"]) [: max_length ]\n",
            "12 sample [\" query \"] = tokenizer . decode ( sample [\" input_ids \"])\n",
            "13 return sample\n",
            "14\n",
            "15 ds = ds.map( tokenize , batched = False )\n",
            "16 ds. set_format ( type =\" torch \")\n",
            "17 return ds\n",
            "18\n",
            "19tokenizer = AutoTokenizer . from_pretrained (\" facebook /opt -350 m\")\n",
            "20tokenizer . pad_token = tokenizer . eos_token\n",
            "21ppo_ds = build_dataset (ppo_ds , tokenizer )\n",
            "2.2. Model\n",
            "Chúng ta sử dụng mô hình CausalLMWithValueHead để khởi tạo mô hình\n",
            "1from trl import AutoModelForCausalLMWithValueHead\n",
            "2\n",
            "3from peft import LoraConfig\n",
            "4\n",
            "5peft_config = LoraConfig (\n",
            "6 r=16 ,\n",
            "7 lora_alpha =32 ,\n",
            "8 lora_dropout =0.05 ,\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "9 bias =\" none \",\n",
            "10 task_type =\" SEQ_CLS \",\n",
            "11)\n",
            "12\n",
            "13model_path = \"./ save_sft_model / checkpoint -1000 \"\n",
            "14model = AutoModelForCausalLMWithValueHead . from_pretrained (\n",
            "15 pretrained_model_name_or_path = model_path ,\n",
            "16 peft_config = peft_config ,\n",
            "17)\n",
            "2.3. Trainer\n",
            "1from trl import PPOConfig , PPOTrainer\n",
            "2\n",
            "3def collator ( data ):\n",
            "4 return {key: [d[key] for d in data ] for key in data [0]}\n",
            "5\n",
            "6ppo_config = PPOConfig (\n",
            "7 model_name =\" facebook /opt -350 m\"\n",
            "8)\n",
            "9\n",
            "10device = 0 if torch . cuda . is_available () else \"cpu \"\n",
            "11\n",
            "12ppo_trainer = PPOTrainer ( ppo_config , model , None , tokenizer , dataset = ppo_ds ,\n",
            "data_collator = collator )\n",
            "2.4. Reward Model\n",
            "Load lại mô hình reward được huấn luyện ở bước 2\n",
            "1from transformers import AutoModelForSequenceClassification , pipeline\n",
            "2\n",
            "3rw_model = model = AutoModelForSequenceClassification . from_pretrained (’./ save_rw_model\n",
            "’)\n",
            "4sentiment_pipe = pipeline (\" sentiment - analysis \", model = rw_model , device = device )\n",
            "5\n",
            "6if sentiment_pipe . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "tokenizer . pad_token_id is None :\n",
            "7 sentiment_pipe . tokenizer . pad_token_id = tokenizer . pad_token_id\n",
            "8\n",
            "9if sentiment_pipe . model . config . pad_token_id is None :\n",
            "10 sentiment_pipe . model . config . pad_token_id = tokenizer . pad_token_id\n",
            "2.5. Training\n",
            "Huấn luyện mô hình với các tham số cài đặt cho quá trình sinh bản tóm tắt và đánh giá bản tóm tắt.\n",
            "1from tqdm import tqdm\n",
            "2\n",
            "3generation_kwargs = {\n",
            "4 \" min_length \": -1,\n",
            "5 \" top_k \": 0.0 ,\n",
            "6 \" top_p \": 1.0 ,\n",
            "7 \" do_sample \": True ,\n",
            "8 \" pad_token_id \": tokenizer . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "eos_token_id ,\n",
            "9 \" max_new_tokens \": 200 ,\n",
            "10}\n",
            "11sent_kwargs = {\" return_all_scores \": True , \" function_to_apply \": \" none \", \" batch_size \":\n",
            "16}\n",
            "12\n",
            "13for _epoch , batch in tqdm ( enumerate ( ppo_trainer . dataloader )):\n",
            "14 query_tensors = batch [\" input_ids \"]\n",
            "15\n",
            "16 # Get response from gpt2\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "17 response_tensors , ref_response_tensors = ppo_trainer . generate (\n",
            "18 query_tensors , return_prompt =False , generate_ref_response =True , **\n",
            "generation_kwargs\n",
            "19 )\n",
            "20 batch [\" response \"] = tokenizer . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "batch_decode ( response_tensors )\n",
            "21 batch [\" ref_response \"] = tokenizer . batch_decode ( ref_response_tensors )\n",
            "22\n",
            "23 # Compute sentiment score\n",
            "24 texts = [q + r for q, r in zip ( batch [\" query \"], batch [\" response \"])]\n",
            "25 pipe_outputs = sentiment_pipe (texts , ** sent_kwargs )\n",
            "26 rewards = [ torch . tensor ( output [1][ \" score \"]) for output in pipe_outputs ]\n",
            "27 ref_texts = [q + r for q, r in zip( batch [\" query \"], batch [\" ref_response \"])]\n",
            "28 ref_pipe_outputs = sentiment_pipe ( ref_texts , ** sent_kwargs )\n",
            "29 ref_rewards = [ torch . tensor ( output [1][ \" score \"]) for output in ref_pipe_outputs ]\n",
            "30 batch [\" ref_rewards \"] = ref_rewards\n",
            "31\n",
            "32 # Run PPO step\n",
            "33 stats = ppo_trainer . step ( query_tensors , response_tensors , rewards )\n",
            "34 ppo_trainer . log_stats (stats , batch , rewards , columns_to_log =[\" query \", \" response \",\n",
            "\" ref_response \", \" ref_rewards \"])\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần 4. Câu hỏi trắc nghiệm\n",
            "Câu hỏi 1 Phương pháp huấn luyện của mô hình ChatGPT là gì?\n",
            "a) Tỉnh chỉnh mô hình ngôn ngữ lớn GPT2\n",
            "b) Tinh chỉnh mô hình ngôn ngữ lớn BLOOM\n",
            "c) Tinh chỉnh mô hình mBART\n",
            "d) Tinh chỉnh mô hình ngôn ngữ lớn GPT 3.5(Large Language Model) với phương pháp học tăng cường\n",
            "dựa trên phản hồi người dùng.\n",
            "Câu hỏi 2 Bộ dữ liêụ để tinh chỉnh mô hình ChatGPT là gì?\n",
            "a) Dữ liệu tóm tắt văn bản\n",
            "b) Dữ liệu các cuộc hội thoại\n",
            "c) Dữ liệu phân loại văn bản\n",
            "d) Dữ liệu dịch máy\n",
            "Câu hỏi 3 Phương pháp cài đặt nào không có trong phương pháp học trong ngữ cảnh (In-Content\n",
            "Learning) được sử dụng trong quá trình sinh văn bản là gì?\n",
            "a) One-shot\n",
            "b) Zero-shot\n",
            "c) One-shot\n",
            "d) Fine-Tuning\n",
            "Câu hỏi 4 Thư viện nào sau đây hỗ trợ sử dụng ChatGPT API?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "a) Spacy\n",
            "b) Fasttext\n",
            "c) Langchain\n",
            "d) Fairseq\n",
            "Câu hỏi 5 Dựa vào dữ liệu đầu vào, bài toán tóm tắt văn bản được chia thành những loại nào?\n",
            "a) Single-Document và Multi-Document\n",
            "b) Abstractive và Single-Document\n",
            "c) Extractive và Abstractive\n",
            "d) Multi-Document và Extractive\n",
            "Câu hỏi 6 Dựa vào dữ liệu đầu ra, bài toán tóm tắt văn bản được chia thành những loại nào?\n",
            "a) Single-Document và Multi-Document\n",
            "b) Abstractive và Single-Document\n",
            "c) Extractive và Abstractive\n",
            "d) Multi-Document và Extractive\n",
            "Câu hỏi 7 Độ đo đánh giá bài toán tóm tắt văn bản là?\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "a) Accuracy\n",
            "b) F1\n",
            "c) BLEU\n",
            "d) ROUGE\n",
            "Câu hỏi 8 Bộ dữ liệu sử dụng cho mô hình SFT là?\n",
            "a) CarperAI/openai_summarize_tldr\n",
            "b) MNIST\n",
            "c) CIFAR10\n",
            "d) CIFAR100\n",
            "Câu hỏi 9 Bài toán nào sau đây sử dụng để huấn luyện mô hình SFT?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "a) Text Classification\n",
            "b) Machine Translation\n",
            "c) Text Generation\n",
            "d) Question Answering\n",
            "Câu hỏi 10 Bài toán nào sau đây sử dụng để huấn luyện mô hình Reward?\n",
            "a) Text Classification\n",
            "b) Machine Translation\n",
            "c) Text Generation\n",
            "d) Question Answering\n",
            "- Hết -\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "Diffusion-based Image Colorization\n",
            "Tien-Huy Nguyen, Khanh Duong and Nhu-Tai Do\n",
            "Ngày 7 tháng 4 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Hình 1: Ví dụ minh họa cho bài toán Image Colorization.\n",
            "Sự bùng nổ của mô hình Diffusion trong những năm gần đây đã tạo ra nhiều bước ngoặt trong vấn\n",
            "đề sinh dữ liệu, đặc biệt là vấn đề tái tạo ảnh. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Theo đó, ở quá trình forward, Diffusion thêm nhiễu vào\n",
            "ảnh một cách có hệ thống, biến ảnh thành một nhiễu tuân theo phân phối Gauss. Sau đó, ở quá trình\n",
            "ngược lại, mô hình này học cách dự đoán nhiễu và tiến hành khử nhiễu dần dần từ một nhiễu chuẩn để\n",
            "tạo ra ảnh mới.\n",
            "Trong bài báo mang tên Palette: Image-to-Image Diffusion Models, mô hình Diffusion đã thực sự\n",
            "chứng minh được khả năng tổng quát mạnh mẽ của mình, khi cùng lúc giải quyết 4 vấn đề khó trong\n",
            "lĩnh vực dịch ảnh chỉ với một mô hình duy nhất, bao gồm: Colorization, Inpainting, Uncropping, và\n",
            "JPEG restoration.\n",
            "Trong dự án này, chúng ta sẽ cùng tìm hiểu ứng dụng của mô hình Diffusion trong bài toán tô màu\n",
            "ảnh, bằng cách sử dụng những ý tưởng cơ bản của công bố nêu trên.\n",
            "Image Colorization là quá trình dự đoán màu cho các ảnh đen trắng, giúp tái tạo lại hình ảnh\n",
            "thực tế từ dữ liệu đơn sắc, mang lại trải nghiệm hình ảnh phong phú và sống động. Với đầu vào là một\n",
            "ảnh xám, biểu thị cường độ sáng của ảnh, mô hình sẽ học cách ước tính các kênh màu của ảnh, tạo ra\n",
            "một hình ảnh hợp lý và hài hòa về mặt thị giác.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 2: Không gian màu Lab.\n",
            "Trong dự án này, chúng ta sẽ tiếp tục sử dụng không gian màu Labcho xử lý dữ liệu. Theo đó, mô\n",
            "hình của chúng ta sẽ nhận đầu vào là kênh Lnhư tấm ảnh gray-scale, đại diện cho độ sáng, và sử dụng\n",
            "kênh abnhư ground truth của mô hình.\n",
            "Đối với vấn đề tô màu cho ảnh, có một thuật ngữ được gọi là Multimodal Predictions . Thuật ngữ\n",
            "này đề cập đến việc một pixel có thể có nhiều kết quả màu hợp lý thay vì chỉ một dự đoán nhất định.\n",
            "Điều này dẫn đến việc, để đánh giá một mô hình Image Colorization, ta không chỉ sử dụng thước đo\n",
            "định lượng, mà cần phải xem xét đến cảm nhận thị giác và những kết quả mang tính định tính khác.\n",
            "Một thước đo định tính đã và đang được sử dụng để giải quyết vấn đề này được gọi là colorization\n",
            "Turing test (hay Fool rate ). Theo đó, người tham gia sẽ cần phải phân biệt những tấm ảnh gốc và\n",
            "những tấm ảnh giả được tạo ra từ mô hình AI. Tỷ lệ người tham gia bị đánh lừa bởi mức độ chân thật\n",
            "của ảnh giả càng cao, chứng tỏ mô hình thu được càng tốt.\n",
            "Chính vì vậy, cần thiết phải có một công cụ giúp người huấn luyện có thể quan sát một cách trực\n",
            "quan những kết quả hình ảnh được tạo ra trong quá trình huấn luyện một mô hình Image Colorization.\n",
            "Thật may mắn, Weights & Biases (wandb), một công cụ cho phép theo dõi và hiển thị kết quả số\n",
            "liệu, hình ảnh, đã và đang ngày càng phổ biến và dễ sử dụng.\n",
            "Trong phần này, chúng ta sẽ tập trung vào việc xây dựng một mô hình dựa trên Diffusion để giải\n",
            "quyết vấn đề Image Colorization, cùng với đó là áp dụng công cụ wandbđể hỗ trợ quá trình huấn luyện.\n",
            "Input và output của chương trình như sau:\n",
            "1.Input: Ảnh xám G (L channel).\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2.Output: Trường ảnh màu C (ab channels).\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Nội dung\n",
            "Trong phần này, chúng ta sẽ triển khai mô hình Diffusion-based Image Colorization dựa trên ý tưởng\n",
            "cơ bản của bài báo Palette: Image-to-Image Diffusion Models để học cách biến đổi một hình ảnh xám\n",
            "đầu vào thành một hình ảnh màu hợp lý. Cụ thể, ta sẽ xây dựng chương trình dựa trên bộ dữ liệu\n",
            "CelebA (Large-scale CelebFaces Attributes), một tập dữ liệu lớn được sử dụng rộng rãi trong lĩnh vực\n",
            "nhận dạng khuôn mặt và phân loại hình ảnh, chứa hơn 200,000 hình ảnh của nhiều người nổi tiếng từ\n",
            "các bộ phim, truyền hình và âm nhạc.\n",
            "Hình 3: Ảnh minh họa cho CelebA dataset\n",
            "Theo đó, nội dung thực nghiệm sẽ trình bày với các thành phần như sau:\n",
            "a) Data Preparation: Chuẩn bị dữ liệu cho tập huấn luyện.\n",
            "b) Models: Xây dựng mô hình UNet và mô hình Diffusion cho Colorization.\n",
            "c) Loss, Metrics: Xây dựng hàm mất mát và độ đo đánh giá cho mô hình.\n",
            "d) Trainer: Xây dựng class Trainer dành riêng cho huấn luyện\n",
            "e) Inference: Minh họa kết quả đạt được sau khi huấn luyện mô hình.\n",
            "1.Data Preparation\n",
            "Đầu tiên, chúng ta cần chuẩn bị bộ dữ liệu CelebA. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Bạn có thể tải bộ dữ liệu và giải nén tại đây.\n",
            "Khai báo các thư viện:\n",
            "1import glob\n",
            "2import torch\n",
            "3import cv2\n",
            "4import numpy as np\n",
            "5from torchvision import transforms\n",
            "6from torch . utils . data import Dataset\n",
            "7from torch . utils . data import DataLoader\n",
            "8\n",
            "9# Load the paths of the images and split into train set and valid set\n",
            "10img_paths = glob . glob (’./ img_align_celeba /*. jpg ’)\n",
            "11num_train , num_val = 200 , 20 # demo with small data\n",
            "12train_imgpaths = img_paths [ : num_train ]\n",
            "13val_imgpaths = img_paths [ num_train : num_train + num_val ]\n",
            "14\n",
            "15\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "16# Build ColorDataset\n",
            "17class ColorDataset ():\n",
            "18 def __init__ (self , img_paths , data_len =2880 , image_size =(128 , 128) ):\n",
            "19 if data_len > 0:\n",
            "20 self . img_paths = img_paths [: int( data_len )]\n",
            "21 else :\n",
            "22 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "img_paths = img_paths\n",
            "23 self .tfs = transforms . Resize (( image_size [0] , image_size [1]) )\n",
            "24\n",
            "25 def __getitem__ (self , index ):\n",
            "26 img_path = self . img_paths [ index ]\n",
            "27 arr_img_bgr = cv2. imread ( img_path )\n",
            "28\n",
            "29 # Convert BGR to LAB\n",
            "30 arr_img_lab = cv2. cvtColor ( arr_img_bgr , cv2. COLOR_BGR2LAB )\n",
            "31\n",
            "32 # Normalize from [0..255] to [ -1..1]\n",
            "33 arr_img_lab = (( arr_img_lab * 2.0) / 255.0) - 1.0\n",
            "34\n",
            "35 # Resize the image to image_size =(128 , 128)\n",
            "36 tens_img_lab = torch . tensor ( arr_img_lab . transpose (2, 0, 1) ,\n",
            "37 dtype = torch . float32 )\n",
            "38\n",
            "39 # Divide the image into gray input and color output\n",
            "40 original_img_l = tens_img_lab [:1 , :, :]\n",
            "41 tens_img_lab = self . tfs( tens_img_lab )\n",
            "42 tens_img_l = tens_img_lab [:1 , :, :]\n",
            "43 tens_img_ab = tens_img_lab [1: , :, :]\n",
            "44 return original_img_l , tens_img_l , tens_img_ab\n",
            "45\n",
            "46 def __len__ ( self ):\n",
            "47 return len( self . img_paths )\n",
            "48\n",
            "49# Create Dataset\n",
            "50train_dataset = ColorDataset ( train_imgpaths , num_train )\n",
            "51val_dataset = ColorDataset ( val_imgpaths , num_val )\n",
            "52\n",
            "53# Create DataLoader\n",
            "54BATCH_SIZE = 4\n",
            "55train_loader = DataLoader ( train_dataset , batch_size = BATCH_SIZE ,\n",
            "56 shuffle =True , drop_last = True )\n",
            "57val_loader = DataLoader ( val_dataset , batch_size = BATCH_SIZE )\n",
            "2.Models\n",
            "Trong phần này, chúng ta sẽ tận dụng một kiến trúc UNet phổ biến trong các bài toán liên quan\n",
            "đến Diffusion, sử dụng nhiều kỹ thuật như Attention Mechanism, Adaptive Group Normalization\n",
            "và được giới thiệu trong một công bố mang tên Diffusion Models Beat GAN on Image Synthesis.\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 4: Minh họa quá trình đảo ngược của mô hình Color Diffusion\n",
            "Ở quá trình đảo ngược, mô hình UNet nhận đầu vào bao gồm: timestep embedding t và một ảnh 3\n",
            "chiều (được hợp thành bởi đầu ra của mô hình UNet tại thời điểm t + 1và thành phần điều kiện\n",
            "là kênh màu xám). Sau đó, mô hình học cách dự đoán và trả về một nhiễu Gauss cho timestep t\n",
            "-1. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Kết quả này sau đó được kết hợp với trường màu ab tại timestep t để tính toán ra abchannels\n",
            "tại timestep t - 1. Quá trình này được lặp lại cho đến khi timestep t = 0. Lúc này ta nhận được\n",
            "trường màu abđã được khử nhiễu. Kết hợp với kênh màu xám, ta thu được một ảnh màu hoàn\n",
            "thiện.\n",
            "UNet model:\n",
            "1import math\n",
            "2import numpy as np\n",
            "3import torch\n",
            "4import torch .nn as nn\n",
            "5\n",
            "6\n",
            "7class GroupNorm32 (nn. GroupNorm ):\n",
            "8 def forward (self , x):\n",
            "9 return super (). forward (x. float ()). type (x. dtype )\n",
            "10\n",
            "11\n",
            "12def zero_module ( module ):\n",
            "13 \"\"\"\n",
            "14 Zero out the parameters of a module and return it.\n",
            "15 \"\"\"\n",
            "16 for p in module . parameters ():\n",
            "17 p. detach (). zero_ ()\n",
            "18 return module\n",
            "19\n",
            "20\n",
            "21def scale_module (module , scale ):\n",
            "22 \"\"\"\n",
            "23 Scale the parameters of a module and return it.\n",
            "24 \"\"\"\n",
            "25 for p in module . parameters ():\n",
            "26 p. detach (). mul_ ( scale )\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "27 return module\n",
            "28\n",
            "29\n",
            "30def mean_flat ( tensor ):\n",
            "31 \"\"\"\n",
            "32 Take the mean over all non - batch dimensions .\n",
            "33 \"\"\"\n",
            "34 return tensor . mean ( dim= list ( range (1, len( tensor . shape ))))\n",
            "35\n",
            "36\n",
            "37def normalization ( channels ):\n",
            "38 \"\"\"\n",
            "39 Make a standard normalization layer .\n",
            "40\n",
            "41 : param channels : number of input channels .\n",
            "42 : return : an nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Module for normalization .\n",
            "43 \"\"\"\n",
            "44 return GroupNorm32 (32 , channels )\n",
            "45\n",
            "46\n",
            "47\n",
            "48def checkpoint (func , inputs , params , flag ):\n",
            "49 \"\"\"\n",
            "50 Evaluate a function without caching intermediate activations , allowing for\n",
            "51 reduced memory at the expense of extra compute in the backward pass .\n",
            "52\n",
            "53 : param func : the function to evaluate .\n",
            "54 : param inputs : the argument sequence to pass to ‘func ‘.\n",
            "55 : param params : a sequence of parameters ‘func ‘ depends on but does not\n",
            "56 explicitly take as arguments .\n",
            "57 : param flag : if False , disable gradient checkpointing .\n",
            "58 \"\"\"\n",
            "59 if flag :\n",
            "60 args = tuple ( inputs ) + tuple ( params )\n",
            "61 return CheckpointFunction . apply (func , len( inputs ), * args )\n",
            "62 else :\n",
            "63 return func (* inputs )\n",
            "64\n",
            "65\n",
            "66class CheckpointFunction ( torch . autograd . Function ):\n",
            "67 @staticmethod\n",
            "68 def forward (ctx , run_function , length , * args ):\n",
            "69 ctx . run_function = run_function\n",
            "70 ctx . input_tensors = list ( args [: length ])\n",
            "71 ctx . input_params = list ( args [ length :])\n",
            "72 with torch . no_grad ():\n",
            "73 output_tensors = ctx. run_function (* ctx. input_tensors )\n",
            "74 return output_tensors\n",
            "75\n",
            "76 @staticmethod\n",
            "77 def backward (ctx , * output_grads ):\n",
            "78 ctx . input_tensors = [x. detach (). requires_grad_ ( True ) for x in ctx.\n",
            "input_tensors ]\n",
            "79 with torch . enable_grad ():\n",
            "80 # Fixes a bug where the first op in run_function modifies the\n",
            "81 # Tensor storage in place , which is not allowed for detach () ’d\n",
            "82 # Tensors .\n",
            "83 shallow_copies = [x. view_as (x) for x in ctx. input_tensors ]\n",
            "84 output_tensors = ctx. run_function (* shallow_copies )\n",
            "85 input_grads = torch . autograd . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "grad (\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "86 output_tensors ,\n",
            "87 ctx . input_tensors + ctx. input_params ,\n",
            "88 output_grads ,\n",
            "89 allow_unused =True ,\n",
            "90 )\n",
            "91 del ctx. input_tensors\n",
            "92 del ctx. input_params\n",
            "93 del output_tensors\n",
            "94 return (None , None ) + input_grads\n",
            "95\n",
            "96\n",
            "97def count_flops_attn (model , _x , y):\n",
            "98 \"\"\"\n",
            "99 A counter for the ‘thop ‘ package to count the operations in an\n",
            "100 attention operation .\n",
            "101 Meant to be used like :\n",
            "102 macs , params = thop . profile (\n",
            "103 model ,\n",
            "104 inputs =( inputs , timestamps ),\n",
            "105 custom_ops ={ QKVAttention : QKVAttention . count_flops },\n",
            "106 )\n",
            "107 \"\"\"\n",
            "108 b, c, * spatial = y [0]. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "shape\n",
            "109 num_spatial = int(np. prod ( spatial ))\n",
            "110 # We perform two matmuls with the same number of ops .\n",
            "111 # The first computes the weight matrix , the second computes\n",
            "112 # the combination of the value vectors .\n",
            "113 matmul_ops = 2 * b * ( num_spatial ** 2) * c\n",
            "114 model . total_ops += torch . DoubleTensor ([ matmul_ops ])\n",
            "115\n",
            "116\n",
            "117def gamma_embedding (gammas , dim , max_period =10000) :\n",
            "118 \"\"\"\n",
            "119 Create sinusoidal timestep embeddings .\n",
            "120 : param gammas : a 1-D Tensor of N indices , one per batch element .\n",
            "121 These may be fractional .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "122 : param dim: the dimension of the output .\n",
            "123 : param max_period : controls the minimum frequency of the embeddings .\n",
            "124 : return : an [N x dim ] Tensor of positional embeddings .\n",
            "125 \"\"\"\n",
            "126 half = dim // 2\n",
            "127 freqs = torch .exp(\n",
            "128 -math .log( max_period ) * torch . arange ( start =0, end=half , dtype = torch .\n",
            "float32 ) / half\n",
            "129 ).to( device = gammas . device )\n",
            "130 args = gammas [:, None ]. float () * freqs [ None ]\n",
            "131 embedding = torch .cat ([ torch . cos( args ), torch .sin( args )], dim = -1)\n",
            "132 if dim % 2:\n",
            "133 embedding = torch .cat ([ embedding , torch . zeros_like ( embedding [:, :1]) ],\n",
            "dim = -1)\n",
            "134 return embedding\n",
            "1import math\n",
            "2import torch\n",
            "3import torch .nn as nn\n",
            "4import torch .nn. functional as F\n",
            "5\n",
            "6from abc import abstractmethod\n",
            "7\n",
            "8class SiLU (nn. Module ):\n",
            "9 def forward (self , x):\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "10 return x * torch . sigmoid (x)\n",
            "11\n",
            "12class EmbedBlock (nn. Module ):\n",
            "13 \"\"\"\n",
            "14 Any module where forward () takes embeddings as a second argument .\n",
            "15 \"\"\"\n",
            "16\n",
            "17 @abstractmethod\n",
            "18 def forward (self , x, emb):\n",
            "19 \"\"\"\n",
            "20 Apply the module to ‘x‘ given ‘emb ‘ embeddings .\n",
            "21 \"\"\"\n",
            "22\n",
            "23class EmbedSequential (nn. Sequential , EmbedBlock ):\n",
            "24 \"\"\"\n",
            "25 A sequential module that passes embeddings to the children that\n",
            "26 support it as an extra input .\n",
            "27 \"\"\"\n",
            "28\n",
            "29 def forward (self , x, emb):\n",
            "30 for layer in self :\n",
            "31 if isinstance (layer , EmbedBlock ):\n",
            "32 x = layer (x, emb)\n",
            "33 else :\n",
            "34 x = layer (x)\n",
            "35 return x\n",
            "36\n",
            "37class Upsample (nn. Module ):\n",
            "38 \"\"\"\n",
            "39 An upsampling layer with an optional convolution .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "40 : param channels : channels in the inputs and outputs .\n",
            "41 : param use_conv : a bool determining if a convolution is applied .\n",
            "42\n",
            "43 \"\"\"\n",
            "44\n",
            "45 def __init__ (self , channels , use_conv , out_channel = None ):\n",
            "46 super (). __init__ ()\n",
            "47 self . channels = channels\n",
            "48 self . out_channel = out_channel or channels\n",
            "49 self . use_conv = use_conv\n",
            "50 if use_conv :\n",
            "51 self . conv = nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Conv2d ( self . channels , self . out_channel , 3, padding =1)\n",
            "52\n",
            "53 def forward (self , x):\n",
            "54 assert x. shape [1] == self . channels\n",
            "55 x = F. interpolate (x, scale_factor =2, mode =\" nearest \")\n",
            "56 if self . use_conv :\n",
            "57 x = self . conv (x)\n",
            "58 return x\n",
            "59\n",
            "60class Downsample (nn. Module ):\n",
            "61 \"\"\"\n",
            "62 A downsampling layer with an optional convolution .\n",
            "63 : param channels : channels in the inputs and outputs .\n",
            "64 : param use_conv : a bool determining if a convolution is applied .\n",
            "65 \"\"\"\n",
            "66\n",
            "67 def __init__ (self , channels , use_conv , out_channel = None ):\n",
            "68 super (). __init__ ()\n",
            "69 self . channels = channels\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "70 self . out_channel = out_channel or channels\n",
            "71 self . use_conv = use_conv\n",
            "72 stride = 2\n",
            "73 if use_conv :\n",
            "74 self .op = nn. Conv2d (\n",
            "75 self . channels , self . out_channel , 3, stride =stride , padding =1\n",
            "76 )\n",
            "77 else :\n",
            "78 assert self . channels == self . out_channel\n",
            "79 self .op = nn. AvgPool2d ( kernel_size =stride , stride = stride )\n",
            "80\n",
            "81 def forward (self , x):\n",
            "82 assert x. shape [1] == self . channels\n",
            "83 return self .op(x)\n",
            "84\n",
            "85\n",
            "86class ResBlock ( EmbedBlock ):\n",
            "87 \"\"\"\n",
            "88 A residual block that can optionally change the number of channels .\n",
            "89 : param channels : the number of input channels .\n",
            "90 : param emb_channels : the number of embedding channels .\n",
            "91 : param dropout : the rate of dropout .\n",
            "92 : param out_channel : if specified , the number of out channels .\n",
            "93 : param use_conv : if True and out_channel is specified , use a spatial\n",
            "94 convolution instead of a smaller 1x1 convolution to change the\n",
            "95 channels in the skip connection .\n",
            "96 : param use_checkpoint : if True , use gradient checkpointing on this module .\n",
            "97 : param up: if True , use this block for upsampling .\n",
            "98 : param down : if True , use this block for downsampling .\n",
            "99 \"\"\"\n",
            "100\n",
            "101 def __init__ (\n",
            "102 self ,\n",
            "103 channels ,\n",
            "104 emb_channels ,\n",
            "105 dropout ,\n",
            "106 out_channel =None ,\n",
            "107 use_conv =False ,\n",
            "108 use_scale_shift_norm =False ,\n",
            "109 use_checkpoint =False ,\n",
            "110 up=False ,\n",
            "111 down =False ,\n",
            "112 ):\n",
            "113 super (). __init__ ()\n",
            "114 self . channels = channels\n",
            "115 self . emb_channels = emb_channels\n",
            "116 self . dropout = dropout\n",
            "117 self . out_channel = out_channel or channels\n",
            "118 self . use_conv = use_conv\n",
            "119 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "use_checkpoint = use_checkpoint\n",
            "120 self . use_scale_shift_norm = use_scale_shift_norm\n",
            "121\n",
            "122 self . in_layers = nn. Sequential (\n",
            "123 normalization ( channels ),\n",
            "124 SiLU () ,\n",
            "125 nn. Conv2d ( channels , self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "out_channel , 3, padding =1) ,\n",
            "126 )\n",
            "127\n",
            "128 self . updown = up or down\n",
            "129\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "130 if up:\n",
            "131 self . h_upd = Upsample ( channels , False )\n",
            "132 self . x_upd = Upsample ( channels , False )\n",
            "133 elif down :\n",
            "134 self . h_upd = Downsample ( channels , False )\n",
            "135 self . x_upd = Downsample ( channels , False )\n",
            "136 else :\n",
            "137 self . h_upd = self . x_upd = nn. Identity ()\n",
            "138\n",
            "139 self . emb_layers = nn. Sequential (\n",
            "140 SiLU () ,\n",
            "141 nn. Linear (\n",
            "142 emb_channels ,\n",
            "143 2 * self . out_channel if use_scale_shift_norm else self .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "out_channel ,\n",
            "144 ),\n",
            "145 )\n",
            "146 self . out_layers = nn. Sequential (\n",
            "147 normalization ( self . out_channel ),\n",
            "148 SiLU () ,\n",
            "149 nn. Dropout (p= dropout ),\n",
            "150 zero_module (\n",
            "151 nn. Conv2d ( self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "out_channel , self . out_channel , 3, padding =1)\n",
            "152 ),\n",
            "153 )\n",
            "154\n",
            "155 if self . out_channel == channels :\n",
            "156 self . skip_connection = nn. Identity ()\n",
            "157 elif use_conv :\n",
            "158 self . skip_connection = nn. Conv2d (\n",
            "159 channels , self . out_channel , 3, padding =1\n",
            "160 )\n",
            "161 else :\n",
            "162 self . skip_connection = nn. Conv2d ( channels , self . out_channel , 1)\n",
            "163\n",
            "164 def forward (self , x, emb):\n",
            "165 \"\"\"\n",
            "166 Apply the block to a Tensor , conditioned on a embedding .\n",
            "167 : param x: an [N x C x ...] Tensor of features .\n",
            "168 : param emb: an [N x emb_channels ] Tensor of embeddings .\n",
            "169 : return : an [N x C x ...] Tensor of outputs .\n",
            "170 \"\"\"\n",
            "171 return checkpoint (\n",
            "172 self . _forward , (x, emb), self . parameters () , self . use_checkpoint\n",
            "173 )\n",
            "174\n",
            "175 def _forward (self , x, emb):\n",
            "176 if self . updown :\n",
            "177 in_rest , in_conv = self . in_layers [: -1] , self . in_layers [ -1]\n",
            "178 h = in_rest (x)\n",
            "179 h = self . h_upd (h)\n",
            "180 x = self . x_upd (x)\n",
            "181 h = in_conv (h)\n",
            "182 else :\n",
            "183 h = self . in_layers (x)\n",
            "184 emb_out = self . emb_layers (emb). type (h. dtype )\n",
            "185 while len( emb_out . shape ) < len(h. shape ):\n",
            "186 emb_out = emb_out [... , None ]\n",
            "187 if self . use_scale_shift_norm :\n",
            "188 out_norm , out_rest = self . out_layers [0] , self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "out_layers [1:]\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "189 scale , shift = torch . chunk ( emb_out , 2, dim =1)\n",
            "190 h = out_norm (h) * (1 + scale ) + shift\n",
            "191 h = out_rest (h)\n",
            "192 else :\n",
            "193 h = h + emb_out\n",
            "194 h = self . out_layers (h)\n",
            "195 return self . skip_connection (x) + h\n",
            "196\n",
            "197class AttentionBlock (nn. Module ):\n",
            "198 \"\"\"\n",
            "199 An attention block that allows spatial positions to attend to each other .\n",
            "200 Originally ported from here , but adapted to the N-d case .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "201 https :// github . com/ hojonathanho / diffusion / blob /1\n",
            "e0dceb3b3495bbe19116a5e1b3596cd0706c543 / diffusion_tf / models / unet .py#L66 .\n",
            "202 \"\"\"\n",
            "203\n",
            "204 def __init__ (\n",
            "205 self ,\n",
            "206 channels ,\n",
            "207 num_heads =1,\n",
            "208 num_head_channels =-1,\n",
            "209 use_checkpoint =False ,\n",
            "210 use_new_attention_order =False ,\n",
            "211 ):\n",
            "212 super (). __init__ ()\n",
            "213 self . channels = channels\n",
            "214 if num_head_channels == -1:\n",
            "215 self . num_heads = num_heads\n",
            "216 else :\n",
            "217 assert (\n",
            "218 channels % num_head_channels == 0\n",
            "219 ), f\"q,k,v channels { channels } is not divisible by num_head_channels\n",
            "{ num_head_channels }\"\n",
            "220 self . num_heads = channels // num_head_channels\n",
            "221 self . use_checkpoint = use_checkpoint\n",
            "222 self . norm = normalization ( channels )\n",
            "223 self .qkv = nn. Conv1d ( channels , channels * 3, 1)\n",
            "224 if use_new_attention_order :\n",
            "225 # split qkv before split heads\n",
            "226 self . attention = QKVAttention ( self . num_heads )\n",
            "227 else :\n",
            "228 # split heads before split qkv\n",
            "229 self . attention = QKVAttentionLegacy ( self . num_heads )\n",
            "230\n",
            "231 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "proj_out = zero_module (nn. Conv1d ( channels , channels , 1))\n",
            "232\n",
            "233 def forward (self , x):\n",
            "234 return checkpoint ( self . _forward , (x ,) , self . parameters () , True )\n",
            "235\n",
            "236 def _forward (self , x):\n",
            "237 b, c, * spatial = x. shape\n",
            "238 x = x. reshape (b, c, -1)\n",
            "239 qkv = self .qkv( self . norm (x))\n",
            "240 h = self . attention (qkv)\n",
            "241 h = self . proj_out (h)\n",
            "242 return (x + h). reshape (b, c, * spatial )\n",
            "243\n",
            "244\n",
            "245class QKVAttentionLegacy (nn. Module ):\n",
            "246 \"\"\"\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "247 A module which performs QKV attention . Matches legacy QKVAttention + input /\n",
            "ouput heads shaping\n",
            "248 \"\"\"\n",
            "249\n",
            "250 def __init__ (self , n_heads ):\n",
            "251 super (). __init__ ()\n",
            "252 self . n_heads = n_heads\n",
            "253\n",
            "254 def forward (self , qkv ):\n",
            "255 \"\"\"\n",
            "256 Apply QKV attention .\n",
            "257 : param qkv: an [N x (H * 3 * C) x T] tensor of Qs , Ks , and Vs.\n",
            "258 : return : an [N x (H * C) x T] tensor after attention .\n",
            "259 \"\"\"\n",
            "260 bs , width , length = qkv . shape\n",
            "261 assert width % (3 * self . n_heads ) == 0\n",
            "262 ch = width // (3 * self . n_heads )\n",
            "263 q, k, v = qkv . reshape (bs * self . n_heads , ch * 3, length ). split (ch , dim =1)\n",
            "264 scale = 1 / math . sqrt ( math . sqrt (ch))\n",
            "265 weight = torch . einsum (\n",
            "266 \"bct ,bcs ->bts\", q * scale , k * scale\n",
            "267 ) # More stable with f16 than dividing afterwards\n",
            "268 weight = torch . softmax ( weight . float () , dim = -1). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "type ( weight . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "dtype )\n",
            "269 a = torch . einsum (\"bts ,bcs ->bct\", weight , v)\n",
            "270 return a. reshape (bs , -1, length )\n",
            "271\n",
            "272 @staticmethod\n",
            "273 def count_flops (model , _x , y):\n",
            "274 return count_flops_attn (model , _x , y)\n",
            "275\n",
            "276\n",
            "277class QKVAttention (nn. Module ):\n",
            "278 \"\"\"\n",
            "279 A module which performs QKV attention and splits in a different order .\n",
            "280 \"\"\"\n",
            "281\n",
            "282 def __init__ (self , n_heads ):\n",
            "283 super (). __init__ ()\n",
            "284 self . n_heads = n_heads\n",
            "285\n",
            "286 def forward (self , qkv ):\n",
            "287 \"\"\"\n",
            "288 Apply QKV attention .\n",
            "289 : param qkv: an [N x (3 * H * C) x T] tensor of Qs , Ks , and Vs.\n",
            "290 : return : an [N x (H * C) x T] tensor after attention .\n",
            "291 \"\"\"\n",
            "292 bs , width , length = qkv . shape\n",
            "293 assert width % (3 * self . n_heads ) == 0\n",
            "294 ch = width // (3 * self . n_heads )\n",
            "295 q, k, v = qkv . chunk (3, dim =1)\n",
            "296 scale = 1 / math . sqrt ( math . sqrt (ch))\n",
            "297 weight = torch . einsum (\n",
            "298 \"bct ,bcs ->bts\",\n",
            "299 (q * scale ). view (bs * self . n_heads , ch , length ),\n",
            "300 (k * scale ). view (bs * self . n_heads , ch , length ),\n",
            "301 ) # More stable with f16 than dividing afterwards\n",
            "302 weight = torch . softmax ( weight . float () , dim = -1). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "type ( weight . dtype )\n",
            "303 a = torch . einsum (\"bts ,bcs ->bct\", weight , v. reshape (bs * self . n_heads , ch ,\n",
            "length ))\n",
            "304 return a. reshape (bs , -1, length )\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "305\n",
            "306 @staticmethod\n",
            "307 def count_flops (model , _x , y):\n",
            "308 return count_flops_attn (model , _x , y)\n",
            "309\n",
            "310class UNet (nn. Module ):\n",
            "311 \"\"\"\n",
            "312 The full UNet model with attention and embedding .\n",
            "313 : param in_channel : channels in the input Tensor , for image colorization :\n",
            "Y_channels + X_channels .\n",
            "314 : param inner_channel : base channel count for the model .\n",
            "315 : param out_channel : channels in the output Tensor .\n",
            "316 : param res_blocks : number of residual blocks per downsample .\n",
            "317 : param attn_res : a collection of downsample rates at which\n",
            "318 attention will take place . May be a set , list , or tuple .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "319 For example , if this contains 4, then at 4x downsampling , attention\n",
            "320 will be used .\n",
            "321 : param dropout : the dropout probability .\n",
            "322 : param channel_mults : channel multiplier for each level of the UNet .\n",
            "323 : param conv_resample : if True , use learned convolutions for upsampling and\n",
            "324 downsampling .\n",
            "325 : param use_checkpoint : use gradient checkpointing to reduce memory usage .\n",
            "326 : param num_heads : the number of attention heads in each attention layer .\n",
            "327 : param num_heads_channels : if specified , ignore num_heads and instead use\n",
            "328 a fixed channel width per attention head .\n",
            "329 : param num_heads_upsample : works with num_heads to set a different number\n",
            "330 of heads for upsampling . Deprecated .\n",
            "331 : param use_scale_shift_norm : use a FiLM - like conditioning mechanism .\n",
            "332 : param resblock_updown : use residual blocks for up/ downsampling .\n",
            "333 : param use_new_attention_order : use a different attention pattern for\n",
            "potentially\n",
            "334 increased efficiency .\n",
            "335 \"\"\"\n",
            "336\n",
            "337 def __init__ (\n",
            "338 self ,\n",
            "339 image_size ,\n",
            "340 in_channel ,\n",
            "341 inner_channel ,\n",
            "342 out_channel ,\n",
            "343 res_blocks ,\n",
            "344 attn_res ,\n",
            "345 dropout =0,\n",
            "346 channel_mults =(1 , 2, 4, 8) ,\n",
            "347 conv_resample =True ,\n",
            "348 use_checkpoint =False ,\n",
            "349 use_fp16 =False ,\n",
            "350 num_heads =1,\n",
            "351 num_head_channels =-1,\n",
            "352 num_heads_upsample =-1,\n",
            "353 use_scale_shift_norm =True ,\n",
            "354 resblock_updown =True ,\n",
            "355 use_new_attention_order =False ,\n",
            "356 ):\n",
            "357\n",
            "358 super (). __init__ ()\n",
            "359\n",
            "360 if num_heads_upsample == -1:\n",
            "361 num_heads_upsample = num_heads\n",
            "362\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "363 self . image_size = image_size\n",
            "364 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "in_channel = in_channel\n",
            "365 self . inner_channel = inner_channel\n",
            "366 self . out_channel = out_channel\n",
            "367 self . res_blocks = res_blocks\n",
            "368 self . attn_res = attn_res\n",
            "369 self . dropout = dropout\n",
            "370 self . channel_mults = channel_mults\n",
            "371 self . conv_resample = conv_resample\n",
            "372 self . use_checkpoint = use_checkpoint\n",
            "373 self . dtype = torch . float16 if use_fp16 else torch . float32\n",
            "374 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "num_heads = num_heads\n",
            "375 self . num_head_channels = num_head_channels\n",
            "376 self . num_heads_upsample = num_heads_upsample\n",
            "377\n",
            "378 cond_embed_dim = inner_channel * 4\n",
            "379 self . cond_embed = nn. Sequential (\n",
            "380 nn. Linear ( inner_channel , cond_embed_dim ),\n",
            "381 SiLU () ,\n",
            "382 nn. Linear ( cond_embed_dim , cond_embed_dim ),\n",
            "383 )\n",
            "384\n",
            "385 ch = input_ch = int( channel_mults [0] * inner_channel )\n",
            "386 self . input_blocks = nn. ModuleList (\n",
            "387 [ EmbedSequential (nn. Conv2d ( in_channel , ch , 3, padding =1))]\n",
            "388 )\n",
            "389 self . _feature_size = ch\n",
            "390 input_block_chans = [ch]\n",
            "391 ds = 1\n",
            "392 for level , mult in enumerate ( channel_mults ):\n",
            "393 for _ in range ( res_blocks ):\n",
            "394 layers = [\n",
            "395 ResBlock (\n",
            "396 ch ,\n",
            "397 cond_embed_dim ,\n",
            "398 dropout ,\n",
            "399 out_channel =int ( mult * inner_channel ),\n",
            "400 use_checkpoint = use_checkpoint ,\n",
            "401 use_scale_shift_norm = use_scale_shift_norm ,\n",
            "402 )\n",
            "403 ]\n",
            "404 ch = int( mult * inner_channel )\n",
            "405 if ds in attn_res :\n",
            "406 layers . append (\n",
            "407 AttentionBlock (\n",
            "408 ch ,\n",
            "409 use_checkpoint = use_checkpoint ,\n",
            "410 num_heads = num_heads ,\n",
            "411 num_head_channels = num_head_channels ,\n",
            "412 use_new_attention_order = use_new_attention_order ,\n",
            "413 )\n",
            "414 )\n",
            "415 self . input_blocks . append ( EmbedSequential (* layers ))\n",
            "416 self . _feature_size += ch\n",
            "417 input_block_chans . append (ch)\n",
            "418 if level != len( channel_mults ) - 1:\n",
            "419 out_ch = ch\n",
            "420 self . input_blocks . append (\n",
            "421 EmbedSequential (\n",
            "422 ResBlock (\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "423 ch ,\n",
            "424 cond_embed_dim ,\n",
            "425 dropout ,\n",
            "426 out_channel =out_ch ,\n",
            "427 use_checkpoint = use_checkpoint ,\n",
            "428 use_scale_shift_norm = use_scale_shift_norm ,\n",
            "429 down =True ,\n",
            "430 )\n",
            "431 if resblock_updown\n",
            "432 else Downsample (\n",
            "433 ch , conv_resample , out_channel = out_ch\n",
            "434 )\n",
            "435 )\n",
            "436 )\n",
            "437 ch = out_ch\n",
            "438 input_block_chans . append (ch)\n",
            "439 ds *= 2\n",
            "440 self . _feature_size += ch\n",
            "441\n",
            "442 self . middle_block = EmbedSequential (\n",
            "443 ResBlock (\n",
            "444 ch ,\n",
            "445 cond_embed_dim ,\n",
            "446 dropout ,\n",
            "447 use_checkpoint = use_checkpoint ,\n",
            "448 use_scale_shift_norm = use_scale_shift_norm ,\n",
            "449 ),\n",
            "450 AttentionBlock (\n",
            "451 ch ,\n",
            "452 use_checkpoint = use_checkpoint ,\n",
            "453 num_heads = num_heads ,\n",
            "454 num_head_channels = num_head_channels ,\n",
            "455 use_new_attention_order = use_new_attention_order ,\n",
            "456 ),\n",
            "457 ResBlock (\n",
            "458 ch ,\n",
            "459 cond_embed_dim ,\n",
            "460 dropout ,\n",
            "461 use_checkpoint = use_checkpoint ,\n",
            "462 use_scale_shift_norm = use_scale_shift_norm ,\n",
            "463 ),\n",
            "464 )\n",
            "465 self . _feature_size += ch\n",
            "466\n",
            "467 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "output_blocks = nn. ModuleList ([])\n",
            "468 for level , mult in list ( enumerate ( channel_mults )) [:: -1]:\n",
            "469 for i in range ( res_blocks + 1):\n",
            "470 ich = input_block_chans . pop ()\n",
            "471 layers = [\n",
            "472 ResBlock (\n",
            "473 ch + ich ,\n",
            "474 cond_embed_dim ,\n",
            "475 dropout ,\n",
            "476 out_channel =int ( inner_channel * mult ),\n",
            "477 use_checkpoint = use_checkpoint ,\n",
            "478 use_scale_shift_norm = use_scale_shift_norm ,\n",
            "479 )\n",
            "480 ]\n",
            "481 ch = int( inner_channel * mult )\n",
            "482 if ds in attn_res :\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "483 layers . append (\n",
            "484 AttentionBlock (\n",
            "485 ch ,\n",
            "486 use_checkpoint = use_checkpoint ,\n",
            "487 num_heads = num_heads_upsample ,\n",
            "488 num_head_channels = num_head_channels ,\n",
            "489 use_new_attention_order = use_new_attention_order ,\n",
            "490 )\n",
            "491 )\n",
            "492 if level and i == res_blocks :\n",
            "493 out_ch = ch\n",
            "494 layers . append (\n",
            "495 ResBlock (\n",
            "496 ch ,\n",
            "497 cond_embed_dim ,\n",
            "498 dropout ,\n",
            "499 out_channel =out_ch ,\n",
            "500 use_checkpoint = use_checkpoint ,\n",
            "501 use_scale_shift_norm = use_scale_shift_norm ,\n",
            "502 up=True ,\n",
            "503 )\n",
            "504 if resblock_updown\n",
            "505 else Upsample (ch , conv_resample , out_channel = out_ch )\n",
            "506 )\n",
            "507 ds //= 2\n",
            "508 self . output_blocks . append ( EmbedSequential (* layers ))\n",
            "509 self . _feature_size += ch\n",
            "510\n",
            "511 self .out = nn. Sequential (\n",
            "512 normalization (ch),\n",
            "513 SiLU () ,\n",
            "514 zero_module (nn. Conv2d ( input_ch , out_channel , 3, padding =1)),\n",
            "515 )\n",
            "516\n",
            "517 def forward (self , x, gammas ):\n",
            "518 \"\"\"\n",
            "519 Apply the model to an input batch .\n",
            "520 : param x: an [N x 2 x ...] Tensor of inputs (B&W)\n",
            "521 : param gammas : a 1-D batch of gammas .\n",
            "522 : return : an [N x C x ...] Tensor of outputs .\n",
            "523 \"\"\"\n",
            "524 hs = []\n",
            "525 gammas = gammas . view (-1, )\n",
            "526 emb = self . cond_embed ( gamma_embedding (gammas , self . inner_channel ))\n",
            "527\n",
            "528 h = x. type ( torch . float32 )\n",
            "529 for module in self . input_blocks :\n",
            "530 h = module (h, emb)\n",
            "531 hs. append (h)\n",
            "532 h = self . middle_block (h, emb)\n",
            "533 for module in self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "output_blocks :\n",
            "534 h = torch . cat ([h, hs.pop ()], dim =1)\n",
            "535 h = module (h, emb)\n",
            "536 h = h. type (x. dtype )\n",
            "537 return self .out (h)\n",
            "Color Diffusion Model\n",
            "1def make_beta_schedule ( schedule , n_timestep , linear_start =1e -5, linear_end =1e -2):\n",
            "2 if schedule == ’linear ’:\n",
            "3 betas = np. linspace (\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4 linear_start , linear_end , n_timestep , dtype =np. float64\n",
            "5 )\n",
            "6 else :\n",
            "7 raise NotImplementedError ( schedule )\n",
            "8 return betas\n",
            "9\n",
            "10def get_index_from_list (vals , t, x_shape =(1 ,1 ,1 ,1)):\n",
            "11 \"\"\"\n",
            "12 Returns a specific index t of a passed list of values vals\n",
            "13 while considering the batch dimension .\n",
            "14 \"\"\"\n",
            "15 batch_size , *_ = t. shape\n",
            "16 out = vals . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "gather (-1, t)\n",
            "17 return out. reshape ( batch_size , *((1 ,) * (len( x_shape ) - 1))).to( device )\n",
            "1from tqdm import tqdm\n",
            "2from functools import partial\n",
            "3\n",
            "4class ColorDiffusion (nn. Module ):\n",
            "5 def __init__ (self , unet_config , beta_schedule , ** kwargs ):\n",
            "6 super ( ColorDiffusion , self ). __init__ (** kwargs )\n",
            "7 self . denoise_fn = UNet (** unet_config )\n",
            "8 self . beta_schedule = beta_schedule\n",
            "9\n",
            "10 def set_new_noise_schedule (self , device ):\n",
            "11 to_torch = partial ( torch .tensor , dtype = torch . float32 , device = device )\n",
            "12 betas = make_beta_schedule (** self . beta_schedule )\n",
            "13 alphas = 1. - betas\n",
            "14 timesteps , = betas . shape\n",
            "15 self . num_timesteps = int( timesteps )\n",
            "16\n",
            "17 gammas = np. cumprod ( alphas , axis =0) # alphas_cumprod\n",
            "18 gammas_prev = np. append (1. , gammas [: -1])\n",
            "19\n",
            "20 # calculations for diffusion q(x_t | x_{t -1}) and others\n",
            "21 self . register_buffer (’gammas ’, to_torch ( gammas ))\n",
            "22 self . register_buffer (’ sqrt_recip_gammas ’, to_torch (np. sqrt (1. / gammas )))\n",
            "23 self . register_buffer (’ sqrt_recipm1_gammas ’, to_torch (np. sqrt (1. / gammas\n",
            "- 1)))\n",
            "24\n",
            "25 # calculations for posterior q(x_{t -1} | x_t , x_0)\n",
            "26 posterior_variance = betas * (1. - gammas_prev ) / (1. - gammas )\n",
            "27 # below : log calculation clipped because the posterior variance is 0 at\n",
            "the beginning of the diffusion chain\n",
            "28 self . register_buffer (’ posterior_log_variance_clipped ’, to_torch (np.log(np\n",
            ". maximum ( posterior_variance , 1e -20) )))\n",
            "29 self . register_buffer (’ posterior_mean_coef1 ’, to_torch ( betas * np. sqrt (\n",
            "gammas_prev ) / (1. - gammas )))\n",
            "30 self . register_buffer (’ posterior_mean_coef2 ’, to_torch ((1. - gammas_prev )\n",
            "* np. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "sqrt ( alphas ) / (1. - gammas )))\n",
            "31\n",
            "32 def set_loss (self , loss_fn ):\n",
            "33 self . loss_fn = loss_fn\n",
            "34\n",
            "35 def predict_start_from_noise (self , y_t , t, noise ):\n",
            "36 return (\n",
            "37 get_index_from_list ( self . sqrt_recip_gammas , t, y_t. shape ) * y_t -\n",
            "38 get_index_from_list ( self . sqrt_recipm1_gammas , t, y_t. shape ) * noise\n",
            "39 )\n",
            "40\n",
            "41 def q_posterior (self , y_0_hat , y_t , t):\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "42 \"\"\"\n",
            "43 Compute the mean and variance of the diffusion posterior :\n",
            "44\n",
            "45 q(x_{t -1} | x_t , x_0)\n",
            "46\n",
            "47 \"\"\"\n",
            "48 posterior_mean = (\n",
            "49 get_index_from_list ( self . posterior_mean_coef1 , t, y_t. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "shape ) *\n",
            "y_0_hat +\n",
            "50 get_index_from_list ( self . posterior_mean_coef2 , t, y_t. shape ) * y_t\n",
            "51 )\n",
            "52 posterior_log_variance_clipped = get_index_from_list (\n",
            "53 self . posterior_log_variance_clipped , t, y_t. shape\n",
            "54 )\n",
            "55 return posterior_mean , posterior_log_variance_clipped\n",
            "56\n",
            "57 def p_mean_variance (self , y_t , t, clip_denoised : bool , y_cond = None ):\n",
            "58 noise_level = get_index_from_list ( self .gammas , t, x_shape =(1 , 1)).to( y_t.\n",
            "device )\n",
            "59 y_0_hat = self . predict_start_from_noise (\n",
            "60 y_t , t=t, noise = self . denoise_fn ( torch .cat ([ y_cond , y_t ], dim =1) ,\n",
            "noise_level ))\n",
            "61\n",
            "62 if clip_denoised :\n",
            "63 y_0_hat . clamp_ (-1. , 1.)\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "64\n",
            "65 model_mean , posterior_log_variance = self . q_posterior (\n",
            "66 y_0_hat = y_0_hat , y_t =y_t , t=t)\n",
            "67 return model_mean , posterior_log_variance\n",
            "68\n",
            "69 def q_sample (self , y_0 , sample_gammas , noise = None ):\n",
            "70 noise = noise if noise is not None else torch . randn_like ( y_0)\n",
            "71 return (\n",
            "72 sample_gammas . sqrt () * y_0 +\n",
            "73 (1 - sample_gammas ). sqrt () * noise\n",
            "74 )\n",
            "75\n",
            "76 @torch . no_grad ()\n",
            "77 def p_sample (self , y_t , t, clip_denoised =True , y_cond = None ):\n",
            "78 model_mean , model_log_variance = self . p_mean_variance (\n",
            "79 y_t =y_t , t=t, clip_denoised = clip_denoised , y_cond = y_cond )\n",
            "80 noise = torch . randn_like (y_t) if any(t >0) else torch . zeros_like ( y_t)\n",
            "81 return model_mean + noise * (0.5 * model_log_variance ).exp ()\n",
            "82\n",
            "83 @torch . no_grad ()\n",
            "84 def restoration (self , y_cond , y_t=None , y_0=None , sample_num =8):\n",
            "85 b, _, h, w = y_cond . shape\n",
            "86\n",
            "87 sample_inter = ( self . num_timesteps // sample_num )\n",
            "88\n",
            "89 y_t = y_t if y_t is not None else torch . randn ((b, 2, h, w))\n",
            "90 y_t = y_t.to( y_cond . device )\n",
            "91 ret_arr = y_t\n",
            "92 for i in reversed ( range (0, self . num_timesteps )):\n",
            "93 t = torch . full ((b ,) , i, device = y_cond .device , dtype = torch . long )\n",
            "94 y_t = self . p_sample (y_t , t, y_cond = y_cond )\n",
            "95 ret_arr = torch .cat ([ ret_arr , y_t], dim =0)\n",
            "96 return y_t , ret_arr\n",
            "97\n",
            "98 def forward (self , y_0 , y_cond =None , noise = None ):\n",
            "18\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "99 # sampling from p( gammas )\n",
            "100 b, *_ = y_0. shape\n",
            "101 t = torch . randint (1, self . num_timesteps , (b ,) , device =y_0. device ). long ()\n",
            "102 gamma_t1 = get_index_from_list ( self . gammas , t -1, x_shape =(1 , 1))\n",
            "103 sqrt_gamma_t2 = get_index_from_list ( self .gammas , t, x_shape =(1 , 1))\n",
            "104 sample_gammas = ( sqrt_gamma_t2 - gamma_t1 ) * torch . rand ((b, 1) , device =y_0.\n",
            "device ) + gamma_t1\n",
            "105 sample_gammas = sample_gammas . view (b, -1)\n",
            "106\n",
            "107 noise = noise if noise is not None else torch . randn_like ( y_0)\n",
            "108 y_noisy = self . q_sample (\n",
            "109 y_0 =y_0 , sample_gammas = sample_gammas . view (-1, 1, 1, 1) , noise = noise )\n",
            "110\n",
            "111 noise_hat = self . denoise_fn ( torch .cat ([ y_cond , y_noisy ], dim =1) ,\n",
            "sample_gammas )\n",
            "112 loss = self . loss_fn (noise , noise_hat )\n",
            "113 return loss\n",
            "1unet_config = {\n",
            "2 \" in_channel \": 3,\n",
            "3 \" out_channel \": 2,\n",
            "4 \" inner_channel \": 64,\n",
            "5 \" channel_mults \": [1, 2, 4, 8],\n",
            "6 \" attn_res \": [16] ,\n",
            "7 \" num_head_channels \": 32,\n",
            "8 \" res_blocks \": 2,\n",
            "9 \" dropout \": 0.2 ,\n",
            "10 \" image_size \": 128\n",
            "11}\n",
            "12\n",
            "13beta_schedule = {\n",
            "14 \" schedule \": \" linear \",\n",
            "15 \" n_timestep \": 20,\n",
            "16 \" linear_start \": 1e -4,\n",
            "17 \" linear_end \": 0.09\n",
            "18}\n",
            "19\n",
            "20colordiff_model = ColorDiffusion ( unet_config , beta_schedule )\n",
            "3.Loss and Metrics\n",
            "Trong phần này, chúng ta thiết lập hàm mất mát cho mô hình Color Diffusion. Trong đó, L2\n",
            "norm, còn được biết đến là Mean Square Error , được dùng làm hàm mất mát do sự đa dạng đáng\n",
            "kể về mặt kết quả so với Mean Absolute Error (L1 norm ), được kiểm chứng qua quá trình thực\n",
            "nghiệm bởi Saharia, C. và các cộng sự. Ngoài ra, MAEcũng đóng vai trò như một độ đo để đánh\n",
            "giá mô hình trong dự án này.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1import torch .nn. functional as F\n",
            "2\n",
            "3def mse_loss (output , target ):\n",
            "4 return F. mse_loss (output , target )\n",
            "5\n",
            "6\n",
            "7def mae(input , target ):\n",
            "8 with torch . no_grad ():\n",
            "9 loss = nn. L1Loss ()\n",
            "10 output = loss (input , target )\n",
            "11 return output\n",
            "19\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "4.Trainer\n",
            "Ở giai đoạn huấn luyện, chúng ta sẽ xây dựng class Trainer dành cho việc huấn luyện mô hình Dif-\n",
            "fusion. Ngoài ra, chúng ta cũng sẽ sử dụng một công cụ theo dõi được sử dụng phổ biến trong việc\n",
            "huấn luyện các mô hình học máy, được gọi là wandb. Theo đó, các kết quả bao gồm cả thông số\n",
            "mất mát của mô hình và hình ảnh mà mô hình dự đoán cũng có thể được trực quan hóa, giúp người\n",
            "dùng dễ dàng kiểm soát quy trình huấn luyện, từ đó đưa ra những chiến lược thích hợp và kịp thời.\n",
            "Để có thể sử dụng wandb, bạn có thể đăng ký và nhận API cá nhân thông qua wandb.ai.\n",
            "Hình 5: Ảnh minh họa cho việc sử dụng wandb.\n",
            "Khởi tạo class Trainer\n",
            "1import time\n",
            "2\n",
            "3class Trainer ():\n",
            "4 def __init__ (self , model , optimizers , train_loader ,\n",
            "5 val_loader , epochs , sample_num ,\n",
            "6 device , save_model , use_wandb = False ):\n",
            "7\n",
            "8 self . model = model .to( device )\n",
            "9 self . optimizer = torch . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "optim . Adam ( list ( filter (\n",
            "10 lambda p: p. requires_grad , self . model . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "parameters ()\n",
            "11 )), ** optimizers )\n",
            "12 self . model . set_loss ( mse_loss )\n",
            "13 self . model . set_new_noise_schedule ( device )\n",
            "14 self . sample_num = sample_num\n",
            "15 self . train_loader = train_loader\n",
            "16 self . val_loader = val_loader\n",
            "17 self . device = device\n",
            "18 self . epochs = epochs\n",
            "19 self . save_model = save_model\n",
            "20 self . use_wandb = use_wandb\n",
            "21\n",
            "22 def train_step ( self ):\n",
            "23 self . model . train ()\n",
            "24 losses = []\n",
            "20\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "25 for original_gray , gray , color in tqdm ( self . train_loader ):\n",
            "26 cond_gray = gray .to( self . device )\n",
            "27 gt_color = color .to( self . device )\n",
            "28\n",
            "29 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "optimizer . zero_grad ()\n",
            "30\n",
            "31 loss = self . model ( gt_color , cond_gray )\n",
            "32 loss . backward ()\n",
            "33 losses . append ( loss . item ())\n",
            "34 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "optimizer . step ()\n",
            "35 return sum( losses )/ len( losses )\n",
            "36\n",
            "37 def val_step (self , epoch ):\n",
            "38 self . model . eval ()\n",
            "39 losses , metrics = [], []\n",
            "40 pred_images = []\n",
            "41 gt_images = []\n",
            "42\n",
            "43 with torch . no_grad ():\n",
            "44 for i, ( original_gray , gray , color ) in tqdm ( enumerate ( self . val_loader\n",
            ")):\n",
            "45 cond_gray = gray .to( self . device )\n",
            "46 gt_color = color .to( self . device )\n",
            "47 loss = self . model ( gt_color , cond_gray )\n",
            "48\n",
            "49 output , visuals = self . model . restoration (\n",
            "50 cond_gray , sample_num = self . sample_num )\n",
            "51 if i == 0:\n",
            "52 for i in range ( output . shape [0]) :\n",
            "53 # Show predicted image\n",
            "54 pred_bgr_image = self . show_wandb_image ( original_gray [i],\n",
            "output [i]. detach ().cpu ())\n",
            "55 pred_wandb_image = wandb . Image ( pred_bgr_image , caption =f\"\n",
            "epoch { epoch }\")\n",
            "56 pred_images . append ( pred_wandb_image )\n",
            "57\n",
            "58 # Show grouth truth image\n",
            "59 gt_bgr_image = self . show_wandb_image ( original_gray [i],\n",
            "color [i])\n",
            "60 gt_wandb_image = wandb . Image ( gt_bgr_image , caption =f\"\n",
            "epoch { epoch }\")\n",
            "61 gt_images . append ( gt_wandb_image )\n",
            "62\n",
            "63 mae_score = mae( gt_color , output )\n",
            "64 losses . append ( loss . item ())\n",
            "65 metrics . append ( mae_score . item ())\n",
            "66 return sum( losses )/ len( losses ), sum ( metrics )/len( metrics ), pred_images ,\n",
            "gt_images\n",
            "67\n",
            "68 # Postprocess the image before logging to WanDB\n",
            "69 def show_wandb_image (self , img_l , img_ab , is_save = False ):\n",
            "70 img_l = img_l . permute (1, 2, 0). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "numpy ()\n",
            "71 img_ab = img_ab . permute (1, 2, 0). numpy ()\n",
            "72 img_ab = cv2 . resize ( img_ab , ( img_l . shape [1] , img_l . shape [0]) ,\n",
            "interpolation = cv2. INTER_LINEAR )\n",
            "73 arr_lab = np. concatenate ([ img_l , img_ab ], axis =2)\n",
            "74 arr_lab = ( arr_lab + 1.0) * 255 / 2\n",
            "75 arr_lab = np. clip ( arr_lab , 0, 255) . astype (np. uint8 )\n",
            "76 arr_bgr = cv2. cvtColor ( arr_lab , cv2 . COLOR_LAB2RGB )\n",
            "77 return arr_bgr\n",
            "21\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "78\n",
            "79\n",
            "80 def train ( self ):\n",
            "81 best_mae = 100000\n",
            "82 for epoch in range ( self . epochs ):\n",
            "83 epoch_start_time = time . time ()\n",
            "84 train_loss = self . train_step ()\n",
            "85 val_loss , val_mae , pred_images , gt_images = self . val_step ( epoch )\n",
            "86\n",
            "87 # Log the results to WanDB\n",
            "88 if self . use_wandb :\n",
            "89 wandb .log ({\n",
            "90 \" train_loss \": train_loss ,\n",
            "91 \" val_loss \": val_loss ,\n",
            "92 \" val_mae \": val_mae ,\n",
            "93 \" pred_images \": pred_images ,\n",
            "94 \" gt_images \": gt_images\n",
            "95 })\n",
            "96\n",
            "97 if val_mae < best_mae :\n",
            "98 torch . save ( self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "model . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "state_dict () , self . save_model )\n",
            "99 # Print loss , acc end epoch\n",
            "100 print (\"-\" * 59)\n",
            "101 print (\n",
            "102 \"| End of epoch {:3d} | Time : {:5.2 f}s | Train Loss {:8.3 f} \"\n",
            "103 \"| Valid Loss {:8.3 f} | Valid MAE {:8.3 f} \". format (\n",
            "104 epoch +1, time . time () - epoch_start_time ,\n",
            "105 train_loss , val_loss , val_mae\n",
            "106 )\n",
            "107 )\n",
            "108 print (\"-\" * 59)\n",
            "109 self . model . load_state_dict ( torch . load ( self . save_model ))\n",
            "Tải thư viện wandb.\n",
            "1!pip install wandb\n",
            "2import wandb\n",
            "Khởi tạo các tham số và Trainer object.\n",
            "1epochs = 3\n",
            "2sample_num = 8\n",
            "3save_model = ’./ save_model / best_model .pth ’\n",
            "4optimizers = { \"lr\": 5e -5, \" weight_decay \": 0}\n",
            "5device = \" cuda \" if torch . cuda . is_available () else \" cpu\"\n",
            "6use_wandb = True\n",
            "7\n",
            "8trainer = Trainer (\n",
            "9 colordiff_model , optimizers ,\n",
            "10 train_loader , val_loader ,\n",
            "11 epochs , sample_num ,\n",
            "12 device , save_model ,\n",
            "13 use_wandb\n",
            "14)\n",
            "Đăng nhập wandbthông qua API được lấy từ tài khoản wandbcá nhân.\n",
            "1if use_wandb :\n",
            "2 wandb_api =\"387 da1f220b55f23dec29347d30650c011d7exxx \"\n",
            "3 wandb . login ( key= wandb_api )\n",
            "Khởi tạo một wandbsession.\n",
            "22\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1if use_wandb :\n",
            "2 wandb . init (\n",
            "3 # set the wandb project where this run will be logged\n",
            "4 project =\"my -diff - color \",\n",
            "5\n",
            "6 # track hyperparameters and run metadata\n",
            "7 config ={\n",
            "8 \" learning_rate \": optimizers [\"lr\"],\n",
            "9 \" weight_decay \": optimizers [\" weight_decay \"],\n",
            "10 \" architecture \": \" UNet \",\n",
            "11 \" dataset \": \" CelebA \",\n",
            "12 \" epochs \": epochs ,\n",
            "13 \" save_model \": save_model ,\n",
            "14 \" sample_num \": sample_num\n",
            "15 }\n",
            "16 )\n",
            "Tiến hành huấn luyện. Lúc này, nếu wandb được sử dụng thông qua việc cài đặt tham số\n",
            "use_wandb = True , các thông tin về loss, metrics và hình ảnh sẽ được đẩy lên giao diện\n",
            "wandb, giúp người dùng có thể dễ dàng theo dõi và đánh giá tiến độ huấn luyện.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1trainer . train ()\n",
            "Sau khi hoàn thành huấn luyện, hãy kết thúc wandbsession.\n",
            "1if use_wandb :\n",
            "2 wandb . finish ()\n",
            "Theo dõi quá trình huấn luyện trên wandb.\n",
            "Hình 6: Theo dõi kết quả loss và metrics theo từng epoch trên wandb.\n",
            "23\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 7: Theo dõi quá trình tạo ảnh của mô hình theo từng epoch trên wandb.\n",
            "5.Inference\n",
            "Bạn có thể sử dụng checkpoint sẵn có để tiến hành quá trình suy luận thử nghiệm.\n",
            "1# Download the checkpoint\n",
            "2! gdown 1-0 IcaofrE8cNbvUn1Ydo2WyShkxohv9r\n",
            "1# Load the model\n",
            "2colordiff_model = ColorDiffusion ( unet_config , beta_schedule )\n",
            "3colordiff_model . set_new_noise_schedule ( device )\n",
            "4load_state = torch . load (’./ best_model .pth ’)\n",
            "5colordiff_model . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "load_state_dict ( load_state , strict = True )\n",
            "6colordiff_model . eval ().to( device )\n",
            "7\n",
            "8\n",
            "9# Load original image\n",
            "10showed_img_idx = 55\n",
            "11img_path = img_paths [ showed_img_idx ]\n",
            "12img_bgr = cv2. imread ( img_path )\n",
            "13\n",
            "14img_lab = cv2. cvtColor (img , cv2. COLOR_BGR2LAB )\n",
            "15img_l = img_lab [: ,: ,:1]\n",
            "16plt . imshow (img_l , cmap =’gray ’)\n",
            "17plt . axis ( False )\n",
            "18plt . savefig (\" e1_gray .png \")\n",
            "19plt . show ()\n",
            "20\n",
            "21img_rgb = cv2. cvtColor ( img_bgr , cv2 . COLOR_BGR2RGB )\n",
            "22plt . imshow ( img_rgb )\n",
            "23plt . axis ( False )\n",
            "24plt . savefig (\" e2_full_color . png\")\n",
            "25plt . show ()\n",
            "26\n",
            "27\n",
            "28# Infer\n",
            "29test_imgpath = img_paths [ showed_img_idx ]\n",
            "30test_dataset = ColorDataset ([ test_imgpath ])\n",
            "31test_sample = next ( iter ( test_dataset ))\n",
            "24\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "32\n",
            "33def inference (model , test_sample ):\n",
            "34 with torch . no_grad ():\n",
            "35 output , visuals = model . restoration (\n",
            "36 test_sample [1]. unsqueeze (0).to( device )\n",
            "37 )\n",
            "38 return output , visuals\n",
            "39\n",
            "40output , visuals = inference ( colordiff_model , test_sample )\n",
            "41\n",
            "42\n",
            "43# Show the results\n",
            "44def show_tensor_image (img_l , img_ab , is_save = False ):\n",
            "45 img_l = img_l . permute (1, 2, 0). numpy ()\n",
            "46 img_ab = img_ab . permute (1, 2, 0). numpy ()\n",
            "47 img_ab = cv2 . resize ( img_ab , ( img_l . shape [1] , img_l . shape [0]) , interpolation =\n",
            "cv2 . INTER_LINEAR )\n",
            "48 arr_lab = np. concatenate ([ img_l , img_ab ], axis =2)\n",
            "49 arr_lab = ( arr_lab + 1.0) * 255 / 2\n",
            "50 arr_lab = np. clip ( arr_lab , 0, 255) . astype (np. uint8 )\n",
            "51 arr_bgr = cv2. cvtColor ( arr_lab , cv2 . COLOR_LAB2BGR )\n",
            "52 if is_save :\n",
            "53 cv2 . imwrite (\" results .png \", arr_bgr )\n",
            "54 arr_bgr = cv2. cvtColor ( arr_bgr , cv2 . COLOR_BGR2RGB )\n",
            "55 plt . imshow ( arr_bgr )\n",
            "56 plt . axis ( False )\n",
            "57\n",
            "58output , visuals = inference ( colordiff_model , test_sample )\n",
            "59show_tensor_image ( test_sample [0] , output [0]. cpu () , is_save = True )\n",
            "60plt . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "show ()\n",
            "Kết quả thực nghiệm mô hình sau khi huấn luyện\n",
            "Hình 8: Kết quả thực nghiệm mô hình sau khi huấn luyện.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "25\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1.Trong Diffusion Model, Loss Function là:\n",
            "(a) ELBO (Evidence Lower Bound)\n",
            "(b) VLB (Variational Lower Bound)\n",
            "(c) Simplified MSE\n",
            "(d) Tất cả đáp án đều đúng.\n",
            "2.Gray channel đóng vai trò gì trong quá trình huấn luyện mô hình Diffusion-based Image Coloriza-\n",
            "tion?\n",
            "(a) Nó được sử dụng làm điều kiện mang thông tin cấu trúc của ảnh trong quá trình tạo màu.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(b) Nó bị bỏ qua trong quá trình tạo màu để chỉ tập trung vào sắc độ.\n",
            "(c) Nó được tăng cường thông tin qua mô hình khuếch tán để cải thiện độ trung thực của màu\n",
            "sắc ở đầu ra cuối cùng.\n",
            "3.Đâu là nhược điểm chính của DDPM trong việc sinh ảnh dữ liệu có chất lượng, độ phân giải cao?\n",
            "(chọn phương án đúng nhất)\n",
            "(a) Tốn nhiều thời gian, tài nguyên tính toán để thực hiện sampling process.\n",
            "(b) Không ổn định trong việc huyến luyện\n",
            "(c) Phụ thuộc vào surrogate loss.\n",
            "(d) Khó khăn trong việc thiết kế kiến trúc mô hình.\n",
            "4.Phát biểu nào sau đây đúng về Diffusion-based Image Colorization:\n",
            "(a) Cần xác định tấm ảnh đầy màu sắc làm groundtruth.\n",
            "(b) Ràng buộc trong việc sử dụng các kênh màu phổ biến RGB hoặc HSV.\n",
            "(c) Quá trình Sampling là sự kết hợp giữa việc sử dụng color channel được mô hình dự đoán (sau\n",
            "khi denoise) và việc sử dụng kênh màu gray-scale để tạo nên tấm ảnh Lab Image.\n",
            "5.Phương pháp định tính được sử dụng để đánh giá mô hình Image Colorization là?\n",
            "(a) PSNR\n",
            "(b) SSIM\n",
            "(c) FID Score\n",
            "(d) Fooling rate\n",
            "6.Công dụng chính của Weights & Biases (Wandb) trong việc huấn luyện các mô hình Machine\n",
            "Learning là gì?\n",
            "(a) Tiền xử lý và làm sạch dữ liệu cho quá trình huấn luyện.\n",
            "(b) Huấn luyện và triển khai trực tiếp các mô hình Machine Learning.\n",
            "(c) Theo dõi, quan sát và so sánh các thử nghiệm Machine Learning.\n",
            "(d) Finetune các siêu tham số một cách tự động.\n",
            "- Hết -\n",
            "26\n",
            "----------------------------------------------------------------------------------------------------\n",
            "ANACONDA VSCODE INSTALLATION AND\n",
            "USAGE GUIDE\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 Mở đầu\n",
            "Anaconda là một nền tảng mã nguồn mở được thiết kế đặc biệt cho khoa học dữ liệu và học máy, nó giúp\n",
            "người dùng dễ dàng quản lí các thư viện và môi trường phát triển dự án. Ngoài ra Anaconda còn cung\n",
            "cấp nhiều công cụ và thư viện phổ biến như Python, R, Vscode, Jupyter notebook, Jupyterlab...Trong\n",
            "bài viết này sẽ hướng dẫn bạn cài đặt và sử dụng Anaconda, Vscode để lập trình python.\n",
            "2 Cài đặt và sử dụng Anaconda\n",
            "2.1 Cài đặt Anaconda\n",
            "Anaconda hỗ trợ trên 3 hệ điều hành Window, Mac, Linux. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Để cài đặt Anaconda, bạn tiến hành tải về\n",
            "tại đây. Trong hướng dẫn này, chúng ta sẽ cài đặt trên hệ điều hành Window.\n",
            "Hình 1: Annconda hỗ trợ Window, Mac, Linux\n",
            "Sau khi tải về file cài đặt, chúng ta tiến hành nhấn chuột hai lần vào file cài đặt để mở file và tiến hành\n",
            "cài đặt. Việc cài đặt này khá dễ dàng, bạn thực hiện theo các bước sau, lưu ý khi cài đặt bạn nên click\n",
            "vào lựa chọn \"add Anaconda to your PATH environment variable\"để thêm đường dẫn Anaconda vào\n",
            "môi trường máy tính đang sử dụng. Các bước cài đặt đơn giản như sau:\n",
            "Khi cửa sổ cài đặt xuất hiện, bạn nhấn next để chuyển sang bước tiếp theo:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "Tiếp theo chọn \"Next-> \"I Agree-> \"Just me->\"Next->\"Next\". Khi cửa sổ Advanced xuất hiện, tích\n",
            "vào lựa chọn \"add Anaconda to your PATH environment variable\".\n",
            "Cuối cùng bạn chọn \"Install-> \"Next-> \"Finish\"để hoàn tất quá trình cài đặt. Để kiểm tra đã cài đặt\n",
            "thành công hay chưa, bạn mở Command Prompt hoặc Anaconda Prompt và nhập lệnh sau để kiểm tra\n",
            "phiên bản conda trên máy:\n",
            "1conda -V\n",
            "Nếu kết quả hiển thị giống như conda 23.7.4 thì tức là bạn đã cài đặt thành công.\n",
            "2.2 Sử dụng Anaconda\n",
            "Một trong những chức năng chính của Anaconda là quản lí môi trường phát triển với conda. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nếu bạn\n",
            "chưa biết môi trường trong các dự án python thì nó là không gian làm việc độc lập chứa các phiên bản\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "riêng biệt của Python và các gói liên quan. Mỗi môi trường có thể có các phiên bản Python, cài đặt và\n",
            "quản lý gói riêng biệt, giúp cô lập và quản lý dễ dàng cho từng dự án.\n",
            "2.2.1 Hướng dẫn tạo một môi trường mới\n",
            "Để tạo một môi trường mới, chúng ta sử dụng cú pháp:\n",
            "1conda create --name my_python_env python =3.10\n",
            "Trong đó my_python_env là tên của môi trường do chúng ta đặt, python=3.10 là phiên bản python\n",
            "mà chúng ta sẽ sử dụng trong môi trường này, chúng ta nên chọn phiên bản python thấp hơn 1 đến 2\n",
            "phiên bản mới nhất, tùy vào từng dự án.\n",
            "2.2.2 Quản lí môi trường: activate, deactivate, delete\n",
            "Để sử dụng môi trường đã tạo, chúng ta sử dụng cú pháp sau để kích hoạt môi trường:\n",
            "1conda create --name my_python_env python =3.10\n",
            "Để hủy kích hoạt hay nói cách khác là thoát ra khỏi môi trường hiện đang kích hoạt thì ta sử dụng lệnh\n",
            "sau:\n",
            "1conda deactivate\n",
            "Khi muốn xóa một môi trường không còn sử dụng nữa, chúng ta sử dụng lệnh sau:\n",
            "1conda remove --name my_python_env --all\n",
            "Để kiểm tra danh sách các môi trường đã tạo, chúng ta sử dụng lệnh:\n",
            "1conda env list\n",
            "2.2.3 Anaconda navigator\n",
            "Anaconda Navigator là một ứng dụng đồ họa cung cấp giao diện người dùng đồ họa (GUI) cho việc\n",
            "quản lý môi trường, gói và các công cụ tích hợp trong Anaconda. Đây là một công cụ tiện lợi cho người\n",
            "dùng mới bắt đầu với Python và dữ liệu khoa học, với các tính năng như:\n",
            "•Giao diện người dùng trực quan, rất hữu ích cho những người mới chưa quen với các cú pháp\n",
            "dòng lệnh.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Chúng ta có thể quản lí các gói và môi trường tại Environments\n",
            "•Chúng ta có thể dễ dàng cài đặt các công cụ như Vscode, Jupyter Notebook, Spider... bằng cách\n",
            "nhấn vào nút install. Để mở các công cụ này ta nhấn vào Launch, hoặc cũng có thể mở từ thanh\n",
            "tìm kiếm window.\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "3 Cài đặt và sử dụng Vscode\n",
            "Visual Studio Code (VSCode) là một trình soạn thảo mã nguồn mở được phát triển bởi Microsoft. Nó\n",
            "cung cấp một loạt các tính năng hữu ích cho lập trình Python và khoa học dữ liệu và nhiều ngôn ngữ\n",
            "lập trình khác.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3.1 Cài đặt Vscode\n",
            "Để cài đặt Vscode, chúng ta có thể cài đặt theo hai cách, cách đầu tiên là chúng ta truy cập vào đường\n",
            "dẫn https://code.visualstudio.com/download và tiến hành lựa chọn tải xuống theo hệ điều hành trên\n",
            "máy, sau đó tiến hành cài đặt.\n",
            "Hình 2: Hai cách cài đặt Vscode\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "Quá trình cài đặt khá đơn giản, chỉ cần mở file cài đặt và tiến hành nhấn next theo mặc định. Cách thứ\n",
            "hai thì đơn giản hơn, trong giao diện Anaconda Navigator chúng ta tìm đến Vscode và nhấn install.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3.2 Cài đặt các tiện ích quan trọng trong Vscode\n",
            "Tiện ích là các phần mở rộng được cung cấp bởi cộng đồng hoặc các nhà phát triển để mở rộng tính\n",
            "năng của VSCode. Chúng ta sẽ cài đặt hai tiện ích là Python và Jupyter trong đó:\n",
            "•Tiện ích Python hỗ trợ cho lập trình Python trong VSCode, bao gồm hỗ trợ cú pháp, tự động\n",
            "hoàn thành, gỡ lỗi, và nhiều tính năng khác.\n",
            "•Tiện ích Jupyter cho phép chúng ta làm việc với notebook Jupyter trực tiếp trong VSCode, giúp\n",
            "tạo, chỉnh sửa và chạy mã Python một cách thuận tiện.\n",
            "Để cài đặt các tiện ích trên, chúng ta tìm kiếm \"Jupyter\", \"Python\"trong tab Extensions và chọn tiện\n",
            "ích có tên \"Jupyter\", \"Python\"của Microsoft để cài đặt.\n",
            "Hình 3: Cài đặt tiện ích vscode\n",
            "3.3 Tạo một dự án Python\n",
            "Để tạo một dự án python, đầu tiên chúng ta cần tạo một thư mục để chứa dự án, sau đó tại giao diện\n",
            "vscode chọn \"File-> \"Open Folder\"và chọn folder mà chúng ta vừa tạo.\n",
            "Để tạo tệp mã Python, tại cửa sổ EXPLORER phía trái màn hình, bạn trỏ chuột đến tên của dự án sẽ\n",
            "thấy xuất hiện icon new file, tiếp theo bạn click để tạo một file mới và đặt tên cho file là my_scripts.py.\n",
            "Sau khi tạo file, bạn tiến hành viết code và dùng tổ hợp phím ctl+S để lưu file.\n",
            "Để thực thi file, trong giao diện Vscode bạn nhấn vào biểu tượng tam giác ở góc trên phải màn hình,\n",
            "hoặc chọn \"Terminal->\"New Terminal\"sau đó dùng lênh sau để thực thi chương trình:\n",
            "1python my_script .py\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "Hình 4: Thực thi chương trình python\n",
            "3.4 Lựa chọn môi trường dự án\n",
            "Khi chạy chương trình trên, chương trình được chạy trên môi trường mặc định của máy tính. Để chọn\n",
            "môi trường cụ thể, hãy chọn \"View\"> \"Command Palette\"từ thanh menu hoặc nhấn tổ hợp phím Ctrl\n",
            "+ Shift + P sau đó nhập \"Select Interpreter\"và click vào \"Python:Select Interpreter\", một danh sách\n",
            "các môi trường chúng ta đã tạo được hiển thị, ta chọn môi trường có tên là \"my_python_env\"mà chúng\n",
            "ta đã tạo với conda ở phần 2.2.1.\n",
            "Hình 5: Chọn môi trường với select interpreter\n",
            "Tại Terminal ta thấy môi trường đã được kích hoạt và chương trình đã được thực thi trong môi trường\n",
            "này. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trong một số trường hợp nếu bạn đã làm theo các bước trên mà không thấy môi trường được kích\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "hoạt có thể do Terminal của bạn đang sử dụng Powershell, bạn hãy thay đổi sang Command Prompt\n",
            "bằng cách nhấn vào biểu tượng dấu cộng trong cửa sổ terminal và chọn Command Prompt.\n",
            "3.5 Tạo notebook Jupyter\n",
            "Vscode hỗ trợ chúng ta sử dụng file jupyter notebook mà không cần phải mở phần mềm này. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Điều này\n",
            "rất hữu ích khi mà dự án của chúng ta vừa sử dụng file .py vừa sử dụng file notebook .ipynb. Chúng ta\n",
            "sẽ tạo file với đuôi .ipynb trong thư mục dự án tương tự như cách tạo file my_script.py ở phần trên.\n",
            "Sau đó ta tiến hành viết code và thực thi code bằng cách nhấn vào biểu tượng run ở đầu ô đó.\n",
            "Hình 6: Tạo file jupyter notebook\n",
            "Với lần đầu thực thi code trong file notebook, một thông báo yêu cầu cài đặt ipykernel chúng ta hãy\n",
            "chọn yes để cài đặt và sau đó chương trình sẽ được thực thi.\n",
            "4 Kết Luận\n",
            "Trong bài viết này đã hướng dẫn cách cài đặt và sử dụng Anaconda, Vscode để tạo môi trường, thiết\n",
            "lập dự án để lập trình Python trên Window. Hy vọng giúp các bạn có thêm kỹ năng cài đặt và sử dụng\n",
            "các công cụ cần thiết để bắt đầu hành trình học lập trình Python.\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 1 tháng 4 năm 2024\n",
            "Basic Python - Data Analysis with Visualization\n",
            "Hoàng-Nguyên Vũ\n",
            "1.Mô tả: Làm quen với thư viện PygWalker\n",
            "•Thư viện PygWalker là một thư viện Python mã nguồn mở giúp bạn dễ dàng\n",
            "chuyển đổi dữ liệu thành các ứng dụng phân tích trực quan. Thư viện này cung\n",
            "cấp một bộ công cụ mạnh mẽ để khám phá, tóm tắt và trực quan hóa dữ liệu của\n",
            "bạn, giúp bạn hiểu rõ hơn về dữ liệu và đưa ra quyết định sáng suốt hơn.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "•Điểm nổi bật của PyGWalker:\n",
            "+Tạo bảng điều khiển tương tác: PyGWalker cho phép bạn tạo các bảng\n",
            "điều khiển trực quan và dễ sử dụng để khám phá dữ liệu của bạn. Bạn có thể\n",
            "dễ dàng thêm và loại bỏ các biểu đồ, thay đổi bộ lọc và tương tác với dữ liệu\n",
            "theo thời gian thực.\n",
            "+Hỗ trợ nhiều loại biểu đồ: PyGWalker cung cấp nhiều loại biểu đồ khác\n",
            "nhau để trực quan hóa dữ liệu của bạn, bao gồm biểu đồ thanh, biểu đồ\n",
            "đường, biểu đồ phân tán, biểu đồ nhiệt, v.v.\n",
            "+Khả năng lọc và nhóm dữ liệu: PyGWalker cho phép bạn lọc dữ liệu theo\n",
            "các tiêu chí cụ thể và nhóm dữ liệu theo các trường khác nhau.\n",
            "+Tích hợp với Jupyter Notebook: PyGWalker có thể được sử dụng trong\n",
            "Jupyter Notebook, cho phép bạn kết hợp phân tích dữ liệu với mã Python\n",
            "khác.\n",
            "+Dễ sử dụng: PyGWalker có API đơn giản và dễ sử dụng, giúp bạn dễ dàng\n",
            "bắt đầu.\n",
            "•Ứng dụng của PygWalker trong việc trực quan hóa dữ liệu:\n",
            "+Khoa học dữ liệu: PyGWalker có thể được sử dụng để khám phá và phân\n",
            "tích dữ liệu trong khoa học dữ liệu.\n",
            "+Học máy: PyGWalker có thể được sử dụng để chuẩn bị dữ liệu và đánh giá\n",
            "mô hình học máy.\n",
            "+Tài chính: PyGWalker có thể được sử dụng để phân tích dữ liệu tài chính\n",
            "và thị trường chứng khoán.\n",
            "+Tiếp thị: PyGWalker có thể được sử dụng để phân tích dữ liệu khách hàng\n",
            "và chiến dịch tiếp thị.\n",
            "www.facebook.com/aivietnam.edu.vn 1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 1 tháng 4 năm 2024\n",
            "2.Cách cài đặt và sử dụng một số tính năng:\n",
            "Để cài đặt thư viện PygWalker, chúng ta có thể cài trên Google Colab, hoặc ở máy cá\n",
            "nhân thông qua Jupyter Notebook. Cách cài đặt như sau:\n",
            "1.Cài đặt thư viện PygWalker:\n",
            "+ Để cài đặt thư PygWalker, chúng ta sử dụng câu lệnh sau ở Google Colab:\n",
            "1!pip install pygwalker\n",
            "+ Để cài thư viện trên máy cá nhân và chạy với Jupyter Notebook, chúng ta\n",
            "sẽ chạy thông qua Terminal đối với hệ điều hành MacOS và CMD đối với hệ\n",
            "điều hành Windows thông qua lệnh sau:\n",
            "1pip install pandas\n",
            "2pip install pygwalker\n",
            "Hình 1: Cài đặt PygWalker\n",
            "+ Sau khi cài xong chúng ta khởi động jupyter notebook tại thư mục chứa\n",
            "project của chúng ta để sử dụng, thông qua lệnh sau:\n",
            "1jupyter notebook\n",
            "Hình 2: Khởi chạy Jupyter Notebook\n",
            "+ Để khởi động thư viện PygWalker trong Colab/Jupyter Notebook, trước tiên\n",
            "ta cần phải có dataset để thư viện có thể trực quan hóa dữ liệu. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Sau khi\n",
            "chúng ta đã có data, để khởi tạo thư viện PygWalker như sau:\n",
            "1import pygwalker as pyg\n",
            "2import pandas as pd\n",
            "3# FILE_PATH: đường dẫn tới tập tin CSV\n",
            "4data = pd.read_csv(FILE_PATH)\n",
            "5pyg.walk(data)\n",
            "www.facebook.com/aivietnam.edu.vn 2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 1 tháng 4 năm 2024\n",
            "Hình 3: Giao diện PygWalker\n",
            "2.Sử dụng một số tính năng trực quan hóa:\n",
            "+Tạo biểu đồ cột: Tạo biểu đồ cột cho tập data mẫu trên để thể hiện dân số\n",
            "(Population) theo quốc gia (Country).\n",
            "(*) Ta sẽ thực hiện kéo 2 cột: Country vào X-Axis và Population vào Y-Axis.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ứng với 2 thông số của biểu đồ cột mà chúng ta cần thực hiện trực quan hóa\n",
            "biểu đồ: Trục Ox (Trục ngang) thể hiện cho Quốc gia (Country) và Trục Oy\n",
            "(Trục dọc) thể hiện cho Dân số (Population)\n",
            "www.facebook.com/aivietnam.edu.vn 3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 1 tháng 4 năm 2024\n",
            "Hình 4: Biểu đồ cột thể hiện dân số theo quốc gia\n",
            "+Lấy Top 20 Quốc Gia có giảm dần theo dân số, và tô màu theo độ\n",
            "lớn của dân số:\n",
            "(*) Ta sẽ thực hiện kéo 2 cột: Chúng ta cũng thực hiện tương tự bài trên\n",
            "nhưng chúng sẽ thực hiện sắp xếp Population giảm dần và Limit 20 dòng.\n",
            "Đồng thời gắn Color là cột Population để thư viện hiện hiện tô màu theo\n",
            "Population.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Hình 5: Biểu đồ cột thể hiện dân số theo quốc gia\n",
            "+Vẽ biểu đồ hộp thể hiện phân phối dữ liệu:\n",
            "www.facebook.com/aivietnam.edu.vn 4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 1 tháng 4 năm 2024\n",
            "Hình 6: Biểu đồ hộp thể hiện dân số theo quốc gia\n",
            "+Vẽ bản đồ hộp thể hiện phân phối dữ liệu:\n",
            "Hình 7: Bản đồ thể hiện dân số theo quốc gia\n",
            "3.Bài tập: Hãy đọc dữ liệu ở file: advertising.csv và khởi chạy thư viện PygWalker sau\n",
            "đó thực hiện trực quan các biểu đồ sau đây:\n",
            "•Câu 1:Vẽ biểu đồ phân phối dữ liệu cho 3 loại: TV, Radio, Paper và được Color\n",
            "theo độ lớn của giá bán (Sales).\n",
            "www.facebook.com/aivietnam.edu.vn 5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 1 tháng 4 năm 2024\n",
            "Kết Quả:\n",
            "Hình 8: Biểu đồ phân phối dữ liệu cho 3 loại: TV, Radio, Paper\n",
            "•Câu 2: Vẽ biểu đồ cột thể hiện doanh số bán (Sales) ⩾10 của cả 3 loại TV,\n",
            "Radio và Newspaper.\n",
            "Kết quả:\n",
            "Hình 9: Biểu đồ doanh số bán hàng trên 10 sản phẩm cho 3 loại: TV, Radio, Paper\n",
            "•Câu 3:Hãy vẽ bản đồ biểu diễn phân bố dân số theo thành phố của các nước\n",
            "thuộc các nước: Việt Nam, Hàn Quốc, Nhật Bản, Singapore và Thái Lan dựa\n",
            "theo dữ liệu sau: Dữ liệu dân số thế giới\n",
            "www.facebook.com/aivietnam.edu.vn 6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) Ngày 1 tháng 4 năm 2024\n",
            "Kết quả:\n",
            "Hình 10: Bản đồ thể hiện phân bố dân số theo thành phố của các nước thuộc các nước: Việt\n",
            "Nam, Hàn Quốc, Nhật Bản, Singapore và Thái Lan\n",
            "- Hết -\n",
            "www.facebook.com/aivietnam.edu.vn 7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "XỬ LÝ TỆP PDF ĐƠN GIẢN VỚI PYPDF\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 Mở đầu\n",
            "Làm sao để trích xuất nội dung văn bản và hình ảnh trong file pdf? Làm thế nào để ghép nhiều file pdf\n",
            "thành một file duy nhất? Trong bài viết này, chúng ta sẽ trả lời những câu hỏi đó bằng cách sử dụng\n",
            "thư viên pypdf-một thư viện xử lý file pdf hiệu quả.\n",
            "Yêu cầu:\n",
            "•Máy tính đã cài đặt Python >=3.7\n",
            "•Biết lập trình Python cơ bản.\n",
            "2 Hướng dẫn cài đặt và sử dụng pypdf\n",
            "Để cài đặt pypdf ta sử dụng lệnh sau:\n",
            "1pip install pypdf\n",
            "2.1 Trích xuất văn bản từ pdf\n",
            "Pypdf cho phép ta trích xuất nội dung văn bản từ một hoặc nhiều trang trong tập tin PDF. Điều này\n",
            "rất hữu ích khi ta cần trích xuất thông tin hoặc dữ liệu văn bản từ tài liệu PDF để sử dụng trong các\n",
            "ứng dụng khác.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ví dụ chương trình dưới đây, chúng ta khai báo sử dụng thư viện pypdf và sử dụng PdfReader để đọc\n",
            "file yolov9.pdf sau đó lưu kết quả vào biến reader. Tiếp theo ta sử dụng reader.pages, phương thức\n",
            "này trả về một danh sách các trang trong tập tin PDF đã được đọc bằng PdfReader. Mỗi phần tử\n",
            "trong danh sách này đại diện cho một trang trong tập tin PDF và có thể được truy cập bằng cách sử\n",
            "dụng chỉ mục hoặc vòng lặp. Ví dụ, để truy cập trang thứ hai trong tập tin PDF, ta có thể sử dụng\n",
            "reader.pages[1], vì chỉ mục trong Python bắt đầu từ 0. Điều này sẽ trả về một đối tượng đại diện cho\n",
            "trang thứ hai trong tài liệu PDF. Để truy cập vào nội dung của một trang cụ thể, ta có thể sử dụng\n",
            "phương thức extract_text(), như trong ví dụ.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "1from pypdf import PdfReader\n",
            "2\n",
            "3# Đọc file PDF\n",
            "4reader = PdfReader(\"yolov9.pdf\")\n",
            "5\n",
            "6# Lấy số trang\n",
            "7num_pages = len(reader.pages)\n",
            "8\n",
            "9# Lấy nội dung trang đầu tiên\n",
            "10page_1 = reader.pages[0]\n",
            "11page_1_txt = page_1.extract_text()\n",
            "12\n",
            "13# Lấy nội dung toàn bộ các trang\n",
            "14pages_txt = \"\"\n",
            "15for i in range(num_pages):\n",
            "16 page = reader.pages[i]\n",
            "17 pages_txt += page.extract_text() + \"\\n\"\n",
            "Hình 1: Trích xuất văn bản từ file PDF\n",
            "2.2 Trích xuất hình ảnh từ pdf\n",
            "Trích xuất hình ảnh từ các tập tin PDF là quá trình lấy các hình ảnh từ các trang trong tài liệu PDF\n",
            "và lưu chúng thành các tập tin hình ảnh độc lập, chẳng hạn như JPEG hoặc PNG. Việc này thường\n",
            "được thực hiện để xử lý và sử dụng hình ảnh từ tài liệu PDF trong các ứng dụng khác nhau, như xây\n",
            "dựng bộ sưu tập hình ảnh, phân tích hình ảnh...\n",
            "Trong pypdf cung cấp phương thức page.images để hỗ trợ trích xuất các hình ảnh trong tập tin pdf.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ta cùng xem ví dụ sau:\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "1# extract images\n",
            "2from pypdf import PdfReader\n",
            "3\n",
            "4reader = PdfReader(\"yolov9.pdf\")\n",
            "5count = 0\n",
            "6for page in reader.pages:\n",
            "7for image_file_object in page.images:\n",
            "8 with open(str(count) + image_file_object.name, \"wb\") as fp:\n",
            "9 fp.write(image_file_object.data)\n",
            "10 count += 1\n",
            "Trong ví dụ trên, chúng ta đọc và sử dụng vòng lặp để duyệt qua từng trang trong file pdf, với mỗi trang\n",
            "chúng ta sẽ trích xuất các hình ảnh thông qua phương thức page.images, phương thức này sẽ trả về danh\n",
            "sách các hình ảnh mà nó trích xuất được từ 1 trang, sau đó chúng ta lưu lại file hình ảnh với tên hình\n",
            "ảnh là số thứ tự + tên hình ảnh trong file pdf ta lấy được qua phương thức image_file_object.name\n",
            "Hình 2: Trích xuất các hình ảnh từ file PDF\n",
            "2.3 Nối các file pdf\n",
            "Merge PDF cho phép bạn tổ chức các tài liệu PDF riêng lẻ thành một tài liệu lớn hơn, giúp dễ dàng\n",
            "quản lý và tìm kiếm thông tin. Trong pypdf cung cấp tính năng PdfWriter để thực hiện điều này.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1# Merge PDFs\n",
            "2from pypdf import PdfWriter\n",
            "3\n",
            "4merger = PdfWriter()\n",
            "5for pdf in [\"yolov6.pdf\", \"yolov7.pdf\", \"yolov9.pdf\"]:\n",
            "6merger.append(pdf)\n",
            "7\n",
            "8merger.write(\"merged-yolov-679.pdf\")\n",
            "9merger.close()\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "Trong ví dụ trên, ta thực hiện nối ba bài báo yolov6, yolov7, yolov9 lại với nhau, đầu tiên chúng ta sẽ\n",
            "import Pdfwriter từ thư viện pypdf, tiếp theo chúng ta tạo đối tượng merger từ PdfWriter(), đối tượng\n",
            "này sẽ được sử dụng để merge các tập tin PDF. Tiếp theo chúng ta duyệt qua từng file pdf và thêm\n",
            "chúng vào đối tượng merger qua phương thức append. Cuối cùng ta ghi dữ liệu từ đối tượng merger\n",
            "vào tệp tin mới có tên là merged-yolov-679.pdf và phương thức close() được gọi để đóng tập tin PDF\n",
            "đã được merge.\n",
            "2.4 Nén file pdf\n",
            "Chức năng nén file trong thư viện pypdf cho phép bạn giảm kích thước của các tập tin PDF bằng cách\n",
            "nén lại các luồng nội dung của mỗi trang. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Việc này không chỉ giúp tiết kiệm không gian lưu trữ mà còn\n",
            "làm tăng tốc độ tải xuống và chia sẻ tập tin PDF.\n",
            "1from pypdf import PdfWriter\n",
            "2\n",
            "3writer = PdfWriter(clone_from=\"yolov9.pdf\")\n",
            "4\n",
            "5for page in writer.pages:\n",
            "6page.compress_content_streams(level=8) # This is CPU intensive!\n",
            "7\n",
            "8with open(\"out.pdf\", \"wb\") as f:\n",
            "9writer.write(f)\n",
            "Trong ví dụ trên, ta tạo một bản sao của tập tin PDF \"yolov9.pdf\", nén lại nội dung của mỗi trang\n",
            "trong tập tin PDF này với mức độ nén là 8, và sau đó lưu lại thành một tập tin PDF mới có tên là\n",
            "\"out.pdf\". Đầu tiên ta tạo một đối tượng PdfWriter mới gọi là writer với số clone_from chỉ định tên\n",
            "tập tin PDF mà chúng ta muốn tạo bản sao. Tiếp theo chúng ta lặp qua từng trang của pdf, sau đó sử\n",
            "dụng page.compress_content_streams(level=8) để nén, trong đó level là mức nén có giá trị từ 1 đến 9.\n",
            "Cuối cùng chúng ta lưu lại file có tên out.pdf.\n",
            "Chúng ta có thể kiểm tra dung lượng file qua đoạn mã dưới đây:\n",
            "1# get size of file pdf\n",
            "2import os\n",
            "3\n",
            "4file_size = os.path.getsize(\"yolov9.pdf\")\n",
            "/(1024 * 1024)\n",
            "5print(f\"yolo9.pdf size:{file_size}\")\n",
            "6\n",
            "7file_out = os.path.getsize(\"out.pdf\")\n",
            "/(1024 * 1024)\n",
            "8print(f\"out.pdf size:{file_out}\")================= Output ================\n",
            "yolo9.pdf size:4.738467216491699\n",
            "out.pdf size:4.718204498291016\n",
            "==========================================\n",
            "Có thể thấy dung lượng file out.pdf được nén từ file yolov9.pdf có dung lượng thấp hơn.\n",
            "3 Kết Luận\n",
            "Trong bài viết này, chúng ta đã tìm hiểu cách sử dụng thư viện pypdf trong Python để thực hiện hai\n",
            "tác vụ quan trọng là trích xuất văn bản và hình ảnh từ các tập tin PDF, cũng như thực hiện các tính\n",
            "năng nén, merge (gộp) các tập tin PDF lại với nhau. Qua bài viết, hy vọng có thể giúp mọi người biết\n",
            "thêm cách sử dụng công cụ hữu ích pypdf để xử lý dữ liệu pdf.\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "Ứng dụng cơ sở dữ liệu vector Milvus cho hệ\n",
            "thống hỏi-đáp mở\n",
            "Dinh-Thang Duong và Quang-Vinh Dinh\n",
            "Ngày 20 tháng 2 năm 2024\n",
            "Milvus là một trong những hệ cơ sở dữ liệu vector (vector database) mã nguồn mở, chuyên dùng\n",
            "cho việc lưu trữ các vector embedding và tìm kiếm tương đồng (similarity search) giữa các vector với\n",
            "nhau. Từ đó, trở thành một công cụ cực kỳ mạnh mẽ hỗ trợ cho các ứng dụng AI trong việc truy cập\n",
            "vào nguồn kiến thức từ các cơ sở dữ liệu nội bộ, qua đó cải thiện độ chính xác một cách đáng kể. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Các\n",
            "bạn có thể theo dõi và đọc thêm về thư viện này tại trang chủ hoặc trang github của thư viện.\n",
            "Hình 1: Biểu tượng của Milvus\n",
            "Trong bài viết này, chúng ta sẽ tìm hiểu cách cài đặt nhanh Milvus trên máy tính cá nhân và ứng\n",
            "dụng Milvus trong việc tìm kiếm các tài liệu (context) có liên quan nhằm hỗ trợ hệ thống hỏi-đáp mở\n",
            "(Open Domain Question Answering).\n",
            "1.Cài đặt Milvus: Trong phần này, chúng ta sẽ tìm hiểu cách cài đặt Milvus thông qua Docker.\n",
            "Đây là cách đơn giản và nhanh chóng để cài đặt thư viện này. Phần demo được thực hiện trên hệ\n",
            "điều hành MacOS, vì vậy có một số bước thực hiện sẽ khác so với các hệ điều hành còn lại. Bạn\n",
            "đọc hãy thay đổi cho phù hợp với hệ điều hạnh của máy mình nhé. Đầu tiên, các bạn hãy kiểm\n",
            "tra cấu hình yêu cầu để cài đặt Milvus theo như ảnh dưới đây:\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 2: Yêu cầu cấu hình về phần cứng cho Milvus\n",
            "Tiếp theo, chúng ta đến với phần cài đặt Milvus. Như đã đề cập ở trên, chúng ta sẽ cài đặt thông\n",
            "qua Docker. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Vì vậy, chúng ta sẽ tiến hành cài đặt Docker và Docker compose tại bước này. Các\n",
            "bạn hãy lên trang chủ của Docker và thực hiện theo hướng dẫn cài đặt theo đúng hệ điều hành\n",
            "của máy mình tại đây:\n",
            "Hình 3: Các lựa chọn cài đặt Docker cho từng hệ điều hành riêng biệt\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Khi quá trình cài đặt Docker hoàn tất, chúng ta sẽ kiểm tra Docker đã sẵn sàng để sử dụng hay\n",
            "chưa. Đối với MacOS/Windows, ta mở ứng dụng Docker Desktop để khởi động Docker:\n",
            "Hình 4: Giao diện Docker Desktop trên hệ điều hành MacOS\n",
            "Sau đó, các bạn mở Terminal/CMD lên và chạy lần lượt các dòng lệnh sau:\n",
            "1$ docker -v\n",
            "2$ docker - compose -v\n",
            "Hình 5: Kết quả kiểm tra phiên bản của Docker và Docker Compose\n",
            "Nếu không có lỗi gì xảy ra khi chạy 2 dòng lệnh trên, chúng ta coi như đã cài đặt thành công\n",
            "Docker. Từ đây, ta tiến hành cài dặt Milvus, các bạn hãy chạy các dòng lệnh sau:\n",
            "(a) Tải file script chứa các lệnh sử dụng Milvus:\n",
            "1$ wget https :// raw. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "githubusercontent .com/milvus -io/ milvus / master / scripts /\n",
            "standalone_embed .sh\n",
            "Khi chạy xong lệnh này, tại vị trí chạy lệnh, các bạn sẽ thấy file standalone_embed.sh . Các bạn\n",
            "cần lưu ý vị trí tải file này, vì chúng ta cần phải ở đúng vị trí tải file hoặc thay đổi đường\n",
            "dẫn hợp lý thì mới chạy lệnh gọi file này được.\n",
            "(b) Chạy file script:\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1$ bash standalone_embed .sh start\n",
            "Lưu ý rằng, lệnh này sẽ mất một khoảng thời gian để hoàn tất tùy vào tốc độ mạng.\n",
            "(c) Kiểm tra cài đặt: Khi đã tải và triển khai xong, các bạn có thể kiểm tra bằng lệnh sau:\n",
            "1$ docker ps\n",
            "Hình 6: Kết quả kiểm tra cài đặt Milvus trên Terminal\n",
            "Như vậy, chúng ta đã hoàn tất cài đặt và triển khai Milvus.\n",
            "2.Cài đặt các thư viện Python cần thiết: Để tương tác được với Milvus trong môi trường\n",
            "Python, chúng ta cần tải một vài các thư viện được liệt kê ở phía dưới đây. Để thuận tiện trong\n",
            "việc cài đặt, các bạn hãy copy danh sách thư viện này vào trong một file tên là requirements.txt :\n",
            "1# > requirements .txt\n",
            "2pandas\n",
            "3transformers\n",
            "4torch\n",
            "5datasets\n",
            "6milvus - cli ==0.4.2\n",
            "7protobuf ==3.20.0\n",
            "8pymilvus ==2.3.4\n",
            "Sau đó, ta gọi lệnh pip để cài đặt, ở đây mình sẽ cài đặt trên môi trường conda:\n",
            "1$ conda create -n milvus_env -y\n",
            "2$ conda activate milvus_env\n",
            "3$ pip3 install -- upgrade pip\n",
            "4$ pip3 install -r requirements .txt\n",
            "3.Kiểm tra hoạt động của Milvus: Chúng ta sẽ thử tương tác với Milvus trong Python thông\n",
            "qua thư viện pymilvus. Milvus có sử dụng một số từ khóa mới, song các bạn có thể nắm cơ bản\n",
            "rằng chúng ta sẽ có các Collection , một dạng bảng dữ liệu của Milvus. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Như vậy, để lưu trữ một\n",
            "vector database trong Milvus, chúng ta sẽ cần tạo một Collection, từ đó kết nối và tương tác với\n",
            "Collection này:\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 7: Một vài thành phần trong Milvus. Nguồn: link\n",
            "Các bạn có thể tìm hiểu những khái niệm khác trong Milvus tại đây. Bây giờ, chúng ta sẽ thử\n",
            "kiểm tra danh sách các Collection có trong Milvus hiện tại. Các bạn tạo một file .py bất kì, ở đây\n",
            "mình tạm đặt tên là check_milvus.py , có nội dung như sau:\n",
            "1from pymilvus import connections , utility\n",
            "2\n",
            "3connections . connect (’default ’, host =’localhost ’, port =’19530 ’)\n",
            "4\n",
            "5print ( utility . list_collections ())\n",
            "6# Output : []\n",
            "Chương trình trên sử dụng phương thức connections.connect() để kết nối tới Milvus Standalone\n",
            "mà chúng ta đã host ở bước đầu tiên. Sau đó, sử dụng utility.list_collections() để kiểm tra danh\n",
            "sách các Collections hiện có, kết quả trả về là một list rỗng cho thấy chúng ta đang chưa có một\n",
            "bảng dữ liệu nào trên kho lưu trữ. Phần tiếp theo chúng ta sẽ tiến hành xây dựng một vector\n",
            "database cho bài QA.\n",
            "4.Xây dựng vector database cho bộ dữ liệu QA: Chúng ta sẽ xây dựng một vector database\n",
            "trên bộ dữ liệu QA là SQuAD. Mục tiêu của chúng ta khi sử dụng cơ sở dữ liệu này nhằm tìm\n",
            "kiếm các câu hỏi có liên quan đến câu hỏi input, từ đó tìm được các context có khả năng cao chứa\n",
            "đáp án cho câu hỏi.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 8: Pipeline của hệ thống End-to-end QA trong bài\n",
            "Các bạn tạo một file code .py mới (ở đây mình sẽ tạo file build_database.py ) và thực hiện các bước\n",
            "sau đây:\n",
            "(a)Import các thư viện cần thiết:\n",
            "1from pymilvus import (\n",
            "2 connections ,\n",
            "3 utility ,\n",
            "4 FieldSchema ,\n",
            "5 CollectionSchema ,\n",
            "6 DataType ,\n",
            "7 Collection ,\n",
            "8)\n",
            "9\n",
            "10from datasets import load_dataset , Dataset\n",
            "11from transformers import AutoTokenizer , AutoModel\n",
            "12from torch import clamp , sum\n",
            "(b)Khai báo các hyperparameters sẽ dùng trong code:\n",
            "1DATASET_NAME = ’squad_v2 ’ # Huggingface Dataset to use\n",
            "2MODEL_NAME = ’distilbert -base - uncased ’ # Transformer to use for embeddings\n",
            "3TOKENIZATION_BATCH_SIZE = 1000 # Batch size for tokenizing operation\n",
            "4INFERENCE_BATCH_SIZE = 64 # batch size for transformer\n",
            "5INSERT_RATIO = 0.001 # How many samples to embed and insert\n",
            "6COLLECTION_NAME = ’ huggingface_squad_db ’ # Collection name\n",
            "7DIMENSION = 768 # Embeddings size\n",
            "8LIMIT = 3 # How many results to search for\n",
            "9MILVUS_HOST = \" localhost \"\n",
            "10MILVUS_PORT = \" 19530 \"\n",
            "11REPLICA_NUMBER = 1\n",
            "Một vài tham số các bạn cần quan tâm:\n",
            "•INFERENCE_BATCH_SIZE: Số lượng mẫu dữ liệu đưa vào mô hình BERT để\n",
            "lấy vector embedding, các bạn hãy điều chỉnh nhỏ hơn nếu không đủ GPU hoặc cao hơn\n",
            "trong trường hợp ngược lại.\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•INSERT_RATIO: Kích thước bộ dữ liệu để đưa vào database. Ở đây mình chỉnh tỉ\n",
            "lệ rất thấp để việc demo trở nên nhanh hơn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Các bạn muốn test nhiều hơn có thể tăng\n",
            "tỉ lệ này lên.\n",
            "•LIMIT: Số lượng kết quả truy vấn trả về từ Milvus. Các bạn muốn tăng số lượng tài\n",
            "liệu trả về có thể tăng tham số này lên.\n",
            "(c)Xây dựng hàm tạo Collection: Ta dùng hàm này để tạo một bảng dữ liệu (Collection),\n",
            "lưu ý rằng kết quả của hàm sẽ là một Collection có đầy đủ các trường thông tin (các cột)\n",
            "nhưng chưa có dữ liệu (records):\n",
            "1def create_collection ( collection_name , dim ):\n",
            "2 if utility . has_collection ( collection_name ):\n",
            "3 utility . drop_collection ( collection_name )\n",
            "4\n",
            "5 fields = [\n",
            "6 FieldSchema ( name =’id ’, dtype = DataType .INT64 , is_primary =True , auto_id\n",
            "= True ),\n",
            "7 FieldSchema ( name =’title ’, dtype = DataType . VARCHAR , max_length =1000) ,\n",
            "8 FieldSchema ( name =’question ’, dtype = DataType . VARCHAR , max_length =1000)\n",
            ",\n",
            "9 FieldSchema ( name =’context ’, dtype = DataType . VARCHAR , max_length =10000)\n",
            ",\n",
            "10 FieldSchema ( name =’answer ’, dtype = DataType . VARCHAR , max_length =1000) ,\n",
            "11 FieldSchema ( name =’ question_embedding ’, dtype = DataType . FLOAT_VECTOR ,\n",
            "dim =dim)\n",
            "12 ]\n",
            "13 schema = CollectionSchema ( fields =fields , description =’question search ’)\n",
            "14 collection = Collection ( name = collection_name , schema = schema )\n",
            "15\n",
            "16 # create IVF_FLAT index for collection .\n",
            "17 index_params = {\n",
            "18 ’metric_type ’:’L2 ’,\n",
            "19 ’index_type ’:\" IVF_FLAT \",\n",
            "20 ’params ’:{\" nlist \" :2048}\n",
            "21 }\n",
            "22 collection . create_index ( field_name =\" question_embedding \", index_params =\n",
            "index_params )\n",
            "23\n",
            "24 return collection\n",
            "(d)Xây dựng hàm tokenization:\n",
            "1tokenizer = AutoTokenizer . from_pretrained ( MODEL_NAME )\n",
            "2def tokenize_question ( batch ):\n",
            "3 results = tokenizer (\n",
            "4 batch [’question ’],\n",
            "5 add_special_tokens =True ,\n",
            "6 truncation =True ,\n",
            "7 padding =\" max_length \",\n",
            "8 return_attention_mask =True ,\n",
            "9 return_tensors =\"pt\"\n",
            "10 )\n",
            "11\n",
            "12 batch [’input_ids ’] = results [’input_ids ’]\n",
            "13 batch [’ attention_mask ’] = results [’ attention_mask ’]\n",
            "14\n",
            "15 return batch\n",
            "(e)Xây dựng hàm get embedding: Ta cần xây dựng hàm đổi từ text sang dạng vector\n",
            "embedding của nó. Tương tự như trong bài học chính, ở đây ta cũng sử dụng model BERT\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "và lấy final hidden state của token [CLS] để làm vector embedding:\n",
            "1model = AutoModel . from_pretrained ( MODEL_NAME )\n",
            "2def quest_embedding ( batch ):\n",
            "3 sentence_embs = model (\n",
            "4 input_ids = batch [’input_ids ’],\n",
            "5 attention_mask = batch [’ attention_mask ’]\n",
            "6 )\n",
            "7 batch [’ question_embedding ’] = sentence_embs . last_hidden_state [:, 0]\n",
            "8\n",
            "9 return batch\n",
            "Hình 9: Final hidden state của token [CLS] trong BERT\n",
            "(f)Xây dựng hàm cập nhật dữ liệu SQuADv2 vào Collection: Hàm này sẽ tải về bộ dữ\n",
            "liệu SQuADv2 gốc và thực hiện đưa từng sample vào Collection:\n",
            "1def create_squad_database ( qa_collection ):\n",
            "2 squad_v2_dataset = load_dataset ( DATASET_NAME , split =’all ’)\n",
            "3 squad_v2_dataset = squad_v2_dataset . train_test_split ( test_size =\n",
            "INSERT_RATIO , seed =0)[’test ’]\n",
            "4 squad_v2_dataset = squad_v2_dataset .map ( lambda val: {’answer ’: val[’\n",
            "answers ’][ ’text ’][0]} if val[’answers ’][ ’text ’] else {’answer ’: ’’},\n",
            "remove_columns =[ ’answers ’])\n",
            "5\n",
            "6 # Generate the tokens for each entry .\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "7 squad_v2_dataset = squad_v2_dataset .map ( tokenize_question , batch_size =\n",
            "TOKENIZATION_BATCH_SIZE , batched = True )\n",
            "8 squad_v2_dataset . set_format (’torch ’, columns =[ ’input_ids ’, ’\n",
            "attention_mask ’], output_all_columns = True )\n",
            "9\n",
            "10 squad_v2_dataset = squad_v2_dataset .map (\n",
            "11 quest_embedding ,\n",
            "12 remove_columns =[ ’input_ids ’, ’ attention_mask ’],\n",
            "13 batched =True ,\n",
            "14 batch_size = INFERENCE_BATCH_SIZE\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "15 )\n",
            "16\n",
            "17 # Due to the varchar constraint we are going to limit the question size\n",
            "when inserting\n",
            "18 def insert_function ( batch ):\n",
            "19 insertable = [\n",
            "20 batch [’title ’],\n",
            "21 batch [’question ’],\n",
            "22 [x [:9995] + ’... ’ if len(x) > 9999 else x for x in batch [’context\n",
            "’]],\n",
            "23 [x [:995] + ’... ’ if len (x) > 999 else x for x in batch [’answer ’\n",
            "]],\n",
            "24 batch [’ question_embedding ’]. tolist ()\n",
            "25 ]\n",
            "26 qa_collection . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "insert ( insertable )\n",
            "27\n",
            "28 squad_v2_dataset .map ( insert_function , batched =True , batch_size =64)\n",
            "29 qa_collection . flush ()\n",
            "Lưu ý rằng trong đoạn code này ở dòng số 3 các sử dụng hàm train_test_split() để tách nhỏ\n",
            "bộ dữ liệu ra nhằm mục đích có thể test trên một lượng sample nhỏ. Các bạn có thể điều\n",
            "chỉnh số lượng này thông qua tham số INSERT_RATIO đã khai báo ở đầu code.\n",
            "(g)Khởi tạo vector database: Với các hàm trên, ta tiến hành thực hiện lời gọi hàm để khởi\n",
            "tạo vector database cho bộ dữ liệu QA:\n",
            "1connections . connect ( host = MILVUS_HOST , port = MILVUS_PORT )\n",
            "2if not utility . has_collection ( COLLECTION_NAME ):\n",
            "3 qa_collection = create_collection ( COLLECTION_NAME , DIMENSION )\n",
            "4 qa_collection . load ( replica_number = REPLICA_NUMBER )\n",
            "5else :\n",
            "6 qa_collection = Collection ( COLLECTION_NAME )\n",
            "7 qa_collection . load ( replica_number = REPLICA_NUMBER )\n",
            "8\n",
            "9if qa_collection . is_empty :\n",
            "10 create_squad_database ( qa_collection )\n",
            "(h)Xây dựng hàm search: Khi đã tạo xong vector database, chúng ta sẽ xây dựng một hàm\n",
            "cho phép nhận vào một batch các vector embedding của câu truy vấn (trong trường hợp này\n",
            "là các câu hỏi). Sau đó, tìm kiếm tương đồng và trả về các mẫu dữ liệu có liên quan nhất:\n",
            "1def search ( question_batch ):\n",
            "2 res = qa_collection . search (\n",
            "3 question_batch [’ question_embedding ’]. tolist () ,\n",
            "4 anns_field =’ question_embedding ’,\n",
            "5 param ={\n",
            "6 \" metric_type \": \"L2\",\n",
            "7 \" params \": {\" nprobe \": 10} ,\n",
            "8 },\n",
            "9 output_fields =[ ’question ’, ’context ’],\n",
            "10 limit = LIMIT\n",
            "11 )\n",
            "12 overall_id = []\n",
            "13 overall_distance = []\n",
            "14 overall_question = []\n",
            "15 overall_context = []\n",
            "16\n",
            "17 for hits in res:\n",
            "18 ids = []\n",
            "19 distances = []\n",
            "20 questions = []\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "21 contexts = []\n",
            "22\n",
            "23 for hit in hits :\n",
            "24 ids . append (hit.id)\n",
            "25 distances . append (hit. distance )\n",
            "26 questions . append (hit. entity .get(’question ’))\n",
            "27 contexts . append ( hit. entity .get(’context ’))\n",
            "28\n",
            "29 overall_id . append (ids)\n",
            "30 overall_distance . append ( distances )\n",
            "31 overall_question . append ( questions )\n",
            "32 overall_context . append ( contexts )\n",
            "33\n",
            "34 return {\n",
            "35 ’id ’: overall_id ,\n",
            "36 ’distance ’: overall_distance ,\n",
            "37 ’context ’: overall_context ,\n",
            "38 ’ similar_question ’: overall_question\n",
            "39 }\n",
            "5.Kết hợp công cụ tìm kiếm và mô hình hỏi-đáp: Khi chạy xong file build_dataset.py , chúng\n",
            "ta đã có một vector database mong muốn. Bây giờ, để kết hợp với mô hình QA để trở thành\n",
            "End-to-end QA, chúng ta sẽ viết một file code để triển khai vấn đề này. Tại đây, mình sẽ tạo một\n",
            "file mới mang tên qa.pyvà có nội dung như sau:\n",
            "(a)Import các thư viện, hàm và tham số cần thiết:\n",
            "1import argparse\n",
            "2from datasets import Dataset\n",
            "3from transformers import pipeline\n",
            "4from pymilvus import connections , utility , Collection\n",
            "5from build_database import tokenize_question , quest_embedding , search\n",
            "6from build_database import (\n",
            "7 MILVUS_HOST ,\n",
            "8 MILVUS_PORT ,\n",
            "9 COLLECTION_NAME ,\n",
            "10 REPLICA_NUMBER ,\n",
            "11 TOKENIZATION_BATCH_SIZE ,\n",
            "12 INFERENCE_BATCH_SIZE\n",
            "13)\n",
            "Các bạn lưu ý có một số hàm và biến sẽ được import từ file code build_dataset.py .\n",
            "(b)Kết nối tới vector database:\n",
            "1connections . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "connect ( host = MILVUS_HOST , port = MILVUS_PORT )\n",
            "2if utility . has_collection ( COLLECTION_NAME ):\n",
            "3 qa_collection = Collection ( COLLECTION_NAME )\n",
            "4 qa_collection . load ( replica_number = REPLICA_NUMBER )\n",
            "5else :\n",
            "6 raise RuntimeError\n",
            "(c)Khai báo mô hình QA: Chúng ta sẽ dùng mô hình đã huấn luyện ở buổi học về QA để sử\n",
            "dụng trong chương trình code này. Ở đây, mình sẽ sử dụng mô hình đã huấn luyện và được\n",
            "lưu trên HuggingFace:\n",
            "1PIPELINE_NAME = ’question - answering ’\n",
            "2MODEL_NAME = ’ thangduong0509 / distilbert - finetuned - squadv2 ’\n",
            "3qa_pipeline = pipeline ( PIPELINE_NAME , model = MODEL_NAME )\n",
            "Các bạn nên sử dụng mô hình mình đã huấn luyện và thay tên ở biến MODEL_NAME nhé.\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(d)Xây dựng hàm main cho chương trình: Cuối cùng, ta viết code nhận đầu vào là câu\n",
            "hỏi từ command line, thực hiện embedding câu hỏi và chạy hàm search. Từ đó, với các tài\n",
            "liệu có liên quan, ta chạy mô hình QA để trả lời câu hỏi từ input:\n",
            "1def main ():\n",
            "2 parser = argparse . ArgumentParser ()\n",
            "3 parser . add_argument (’-- question ’, type =str , required = True )\n",
            "4 args = parser . parse_args ()\n",
            "5\n",
            "6 questions = {’question ’: [f’{ args . question }’]}\n",
            "7 question_dataset = Dataset . from_dict ( questions )\n",
            "8\n",
            "9 question_dataset = question_dataset .map (\n",
            "10 tokenize_question ,\n",
            "11 batched =True ,\n",
            "12 batch_size = TOKENIZATION_BATCH_SIZE\n",
            "13 )\n",
            "14 question_dataset . set_format (\n",
            "15 ’torch ’,\n",
            "16 columns =[ ’input_ids ’, ’ attention_mask ’],\n",
            "17 output_all_columns = True\n",
            "18 )\n",
            "19 question_dataset = question_dataset .map (\n",
            "20 quest_embedding ,\n",
            "21 remove_columns =[ ’input_ids ’, ’ attention_mask ’],\n",
            "22 batched =True ,\n",
            "23 batch_size = INFERENCE_BATCH_SIZE\n",
            "24 )\n",
            "25\n",
            "26 retrieval_results = question_dataset . map(search , batched =True , batch_size\n",
            "=1)\n",
            "27 for result in retrieval_results :\n",
            "28 print ()\n",
            "29 print (’Input Question :’)\n",
            "30 print ( result [’question ’])\n",
            "31 print ()\n",
            "32 for rank_idx , candidate in enumerate (zip( result [’ similar_question ’],\n",
            "result [’context ’], result [’distance ’])):\n",
            "33 context = candidate [1]\n",
            "34 distance = candidate [2]. tolist ()\n",
            "35 predicted_answer = qa_pipeline (\n",
            "36 context = context ,\n",
            "37 question = args . question\n",
            "38 )\n",
            "39\n",
            "40 print (f’Relevant Context Rank { rank_idx +1}: ’)\n",
            "41 print (f’Context : { context }’)\n",
            "42 print (f’Score : { distance }’)\n",
            "43 print (f’Predicted Answer : { predicted_answer }’)\n",
            "44 print ()\n",
            "45\n",
            "46if __name__ == ’__main__ ’:\n",
            "47 main ()\n",
            "48 qa_collection . release ()\n",
            "Cuối cùng, chúng ta sẽ chạy file này để xem thử thành quả. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ở đây, mình sẽ chạy với câu hỏi\n",
            "sau (câu hỏi này thuộc bộ dữ liệu SQuADv2):\n",
            "1$ python3 qa.py -- question ’In what year did Wesley Clark retire ?’\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 10: Kết quả End-to-end QA sử dụng hàm search trên Milvus vector database\n",
            "Như vậy, thông qua việc cài đặt theo các bước trên, các bạn đã thành công ứng dụng Milvus vector\n",
            "database để xây dựng một chương trình về End-to-end Question Answering. Các bạn muốn hiểu\n",
            "thêm về Milvus có thể tìm đọc code đính kèm có file hello_milvus.py để hiểu thêm về các hàm cơ\n",
            "bản trong Milvus nhé.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "6.Trường hợp muốn ngắt kết nối với Milvus và xóa dữ liệu: Để nhanh chóng ngắt kết nối\n",
            "với Milvus, các bạn hãy sử dụng lệnh sau trong Terminal:\n",
            "1$ bash standalone_embed .sh stop\n",
            "ĐểxóahẳndữliệuđượclưutrongMilvus,đầutiêncácbạnhãychạylệnhdướiđâytrongTerminal:\n",
            "1$ docker ps -a\n",
            "Tại đây, các bạn sẽ thấy một danh sách các CONTAINER ID, các bạn hãy tìm hàng có tên tại\n",
            "dòng IMAGE là milvusdb:\n",
            "Hình 11: Hàng Container ID của Milvus\n",
            "CácbạnhãycopyCONTAINERIDcủamilvusdb,trongtrườnghợpởảnhtrênsẽlàa846426c46b7.\n",
            "Sau đó, các bạn chạy lệnh sau:\n",
            "1$ docker rm a846426c46b7\n",
            "Như vậy, các bạn đã ngắt kết nối khỏi Milvus cũng như xóa toàn bộ dữ liệu đã đưa vào.\n",
            "- Hết -\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AIO COURSE 2023\n",
            "Project: Multi-Task Learning\n",
            "Quoc-Thai Nguyen và Quang-Vinh Dinh\n",
            "Ngày 30 tháng 4 năm 2024\n",
            "Phần I. Giới thiệu\n",
            "Hình 1: Ví dụ về mô hình học đa tác vụ cho bài toán image semantic segmentation và depth-image\n",
            "prediction\n",
            "Hình 2: Các phương pháp huấn luyện mô hình học đa tác vụ.\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Mô hình học đa tác vụ (Multi-Task Learning) là phương pháp huấn luyện cho một mô hình\n",
            "nhưng có thể giải quyết cho nhiều bài toán khác nhau. Ví dụ, chúng ta huấn luyện một mô hình với\n",
            "đầu vào là một hình ảnh và đầu ra giải quyết cho hai bài toán khác nhau như: semantic segmentation\n",
            "và depth-image prediction được mô tả như Hình 1.\n",
            "Các phương pháp huấn luyện các mô hình MTL có thể được chia thành 2 nhóm:\n",
            "1. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Deep Multi-Task Architectures. Bao gồm các phương pháp tập trung vào xây dựng các mô hình\n",
            "chung để giải quyết các bài toán khác nhau. Trong đó gồm 2 thành phần chính: thành phần thứ\n",
            "nhất bao gồm các layer chung hoặc chia sẻ trọng số để học các đặc trưng thường gọi là shared-\n",
            "encoder; thành phần thứ hai bao gồm các layer riêng để học các đặc trưng để tối ưu cho từng bài\n",
            "toán riêng thường được gọi là task-specific layer.\n",
            "2. Optimization Strategy. Với mỗi bài toán sẽ có hàm loss đánh giá khác nhau. Trong phần này\n",
            "sẽ tập trung xây dựng các thuật toán tối ưu trong quá trình huấn luyện và cập nhật trọng số.\n",
            "Điển hình trong đó là các phương pháp cân bằng trọng số khi tổng hợp hàm loss, như gradient\n",
            "normalization, uncertainy weighting,...\n",
            "Trong phần này để bước đầu hiểu rõ về các phương pháp huấn luyện mô hình MTL, chúng ta sẽ triển\n",
            "khai mô hình MTL cơ bản tập trung vào tinh chỉnh phần encoder là hard parameter sharing model.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II. Multi-Task Learning for Com-\n",
            "puter Vision\n",
            "Hai phương pháp chính bao gồm: hard parameter sharing được mô tả trong hình 3 và soft parameter\n",
            "sharing được mô tả trong hình 4.\n",
            "Hình 3: Hard parameter sharing.\n",
            "Hình 4: Soft parameter sharing.\n",
            "Hard parameter sharing bao gồm các layer dùng chung cho tất cả các task, shared layers. Sau các\n",
            "shared layers bao gồm các task-specific layers cho các task khác nhau.\n",
            "Soft parameter sharing bao gồm các layer dùng riêng cho các task khác nhau. Tuy nhiên, thay vì ở\n",
            "các layer đầu tiên của các mô hình sẽ hoạt động riêng lẽ cho các task thì sẽ có các kết nốt với đến task\n",
            "khác. Các kết nối có thể là tuyến tính hoặc sử dụng các hàm kích hoạt để kết nối các layer khác nhau.\n",
            "Trong phần này chúng ta sẽ huấn luyện hard parameter sharing model trên bộ dữ liệu NYUD-V2\n",
            "cho hai bài toán semantic segmentation và depth-image prediction. Bộ dữ liệu sau khi thực hiện các\n",
            "bước tiền xử lý như chuyển sang tensor,... có thể được tải về tại đây.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1.1. Dataset\n",
            "1import os\n",
            "2import torch\n",
            "3import fnmatch\n",
            "4import numpy as np\n",
            "5from torch . utils . data import DataLoader\n",
            "6\n",
            "7class NYUv2 ( torch . utils . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "data . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "dataset . Dataset ):\n",
            "8 def __init__ (self , root , train = True ):\n",
            "9 self . train = train\n",
            "10 self . root = os. path . expanduser ( root )\n",
            "11\n",
            "12 # read the data file\n",
            "13 if train :\n",
            "14 self . data_path = root + ’/ train ’\n",
            "15 else :\n",
            "16 self . data_path = root + ’/val ’\n",
            "17\n",
            "18 # calculate data length\n",
            "19 self . data_len = len( fnmatch . filter (os. listdir ( self . data_path + ’/ image ’), ’*.\n",
            "npy ’))\n",
            "20\n",
            "21 def __getitem__ (self , index ):\n",
            "22 # load data from the pre - processed npy files\n",
            "23 image = torch . from_numpy (np. moveaxis (np. load ( self . data_path + ’/ image /{:d}. npy\n",
            "’. format ( index )), -1, 0))\n",
            "24 semantic = torch . from_numpy (np. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "load ( self . data_path + ’/ label /{: d}. npy ’. format (\n",
            "index )))\n",
            "25 depth = torch . from_numpy (np. moveaxis (np. load ( self . data_path + ’/ depth /{:d}. npy\n",
            "’. format ( index )), -1, 0))\n",
            "26\n",
            "27 return {\n",
            "28 ’image ’: image . float () ,\n",
            "29 ’semantic ’: semantic . float () ,\n",
            "30 ’depth ’: depth . float ()\n",
            "31 }\n",
            "32\n",
            "33 def __len__ ( self ):\n",
            "34 return self . data_len\n",
            "35\n",
            "36data_path = ’./ data / NYUDv2 ’\n",
            "37train_ds = NYUv2 ( root = data_path , train = True )\n",
            "38val_ds = NYUv2 ( root = data_path , train = False )\n",
            "39\n",
            "40batch_size = 4\n",
            "41train_loader = DataLoader ( train_ds , batch_size = batch_size , shuffle = True )\n",
            "42val_loader = DataLoader (val_ds , batch_size = batch_size , shuffle = False )\n",
            "1.2. Model\n",
            "Trong phần này chúng ta xây dựng mô hình hard parameter sharing được mô tả như hình 3. Trong đó,\n",
            "các layer sẽ bao gồm các lớp convolution, batch normalization, activation,...\n",
            "1import torch .nn as nn\n",
            "2import torch .nn. functional as F\n",
            "3\n",
            "4class HardParameterSharingModel (nn. Module ):\n",
            "5 def __init__ ( self ):\n",
            "6 super ( HardParameterSharingModel , self ). __init__ ()\n",
            "7 # initialise network parameters\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "8 filter = [64 , 128 , 256 , 512 , 512]\n",
            "9\n",
            "10 self . class_nb = 13\n",
            "11\n",
            "12 # define encoder decoder layers\n",
            "13 self . encoder_block = nn. ModuleList ([ self . conv_layer ([3 , filter [0]]) ])\n",
            "14 self . decoder_block = nn. ModuleList ([ self . conv_layer ([ filter [0] , filter [0]]) ])\n",
            "15 for i in range (4) :\n",
            "16 self . encoder_block . append ( self . conv_layer ([ filter [i], filter [i + 1]]) )\n",
            "17 self . decoder_block . append ( self . conv_layer ([ filter [i + 1], filter [i]]))\n",
            "18\n",
            "19 # define convolution layer\n",
            "20 self . conv_block_enc = nn. ModuleList ([ self . conv_layer ([ filter [0] , filter [0]]) ])\n",
            "21 self . conv_block_dec = nn. ModuleList ([ self . conv_layer ([ filter [0] , filter [0]]) ])\n",
            "22 for i in range (4) :\n",
            "23 if i == 0:\n",
            "24 self . conv_block_enc . append ( self . conv_layer ([ filter [i + 1], filter [i +\n",
            "1]]) )\n",
            "25 self . conv_block_dec . append ( self . conv_layer ([ filter [i], filter [i ]]))\n",
            "26 else :\n",
            "27 self . conv_block_enc . append (nn. Sequential ( self . conv_layer ([ filter [i +\n",
            "1], filter [i + 1]]) ,\n",
            "28 self . conv_layer ([ filter [i +\n",
            "1], filter [i + 1]]) ))\n",
            "29 self . conv_block_dec . append (nn. Sequential ( self . conv_layer ([ filter [i],\n",
            "filter [i]]) ,\n",
            "30 self . conv_layer ([ filter [i],\n",
            "filter [i]])))\n",
            "31\n",
            "32 # define task specific layers\n",
            "33 self . pred_task1 = nn. Sequential (nn. Conv2d ( in_channels = filter [0] , out_channels =\n",
            "filter [0] , kernel_size =3, padding =1) ,\n",
            "34 nn. Conv2d ( in_channels = filter [0] , out_channels =\n",
            "self . class_nb , kernel_size =1, padding =0))\n",
            "35 self . pred_task2 = nn. Sequential (nn. Conv2d ( in_channels = filter [0] , out_channels =\n",
            "filter [0] , kernel_size =3, padding =1) ,\n",
            "36 nn. Conv2d ( in_channels = filter [0] , out_channels\n",
            "=1, kernel_size =1, padding =0))\n",
            "37\n",
            "38 # define pooling and unpooling functions\n",
            "39 self . down_sampling = nn. MaxPool2d ( kernel_size =2, stride =2, return_indices = True\n",
            ")\n",
            "40 self . up_sampling = nn. MaxUnpool2d ( kernel_size =2, stride =2)\n",
            "41\n",
            "42 for m in self . modules ():\n",
            "43 if isinstance (m, nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Conv2d ):\n",
            "44 nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "init . xavier_normal_ (m. weight )\n",
            "45 nn. init . constant_ (m.bias , 0)\n",
            "46 elif isinstance (m, nn. BatchNorm2d ):\n",
            "47 nn. init . constant_ (m.weight , 1)\n",
            "48 nn. init . constant_ (m.bias , 0)\n",
            "49 elif isinstance (m, nn. Linear ):\n",
            "50 nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "init . xavier_normal_ (m. weight )\n",
            "51 nn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "init . constant_ (m.bias , 0)\n",
            "52\n",
            "53 # define convolutional block\n",
            "54 def conv_layer (self , channel ):\n",
            "55 conv_block = nn. Sequential (\n",
            "56 nn. Conv2d ( in_channels = channel [0] , out_channels = channel [1] , kernel_size\n",
            "=3, padding =1) ,\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "57 nn. BatchNorm2d ( num_features = channel [1]) ,\n",
            "58 nn. ReLU ( inplace = True )\n",
            "59 )\n",
            "60 return conv_block\n",
            "61\n",
            "62 def forward (self , x):\n",
            "63 g_encoder , g_decoder , g_maxpool , g_upsampl , indices = ([0] * 5 for _ in range\n",
            "(5) )\n",
            "64 for i in range (5) :\n",
            "65 g_encoder [i], g_decoder [-i - 1] = ([0] * 2 for _ in range (2))\n",
            "66\n",
            "67 # global shared encoder - decoder network\n",
            "68 for i in range (5) :\n",
            "69 if i == 0:\n",
            "70 g_encoder [i ][0] = self . encoder_block [i](x)\n",
            "71 g_encoder [i ][1] = self . conv_block_enc [i]( g_encoder [i ][0])\n",
            "72 g_maxpool [i], indices [i] = self . down_sampling ( g_encoder [i ][1])\n",
            "73 else :\n",
            "74 g_encoder [i ][0] = self . encoder_block [i]( g_maxpool [i - 1])\n",
            "75 g_encoder [i ][1] = self . conv_block_enc [i]( g_encoder [i ][0])\n",
            "76 g_maxpool [i], indices [i] = self . down_sampling ( g_encoder [i ][1])\n",
            "77\n",
            "78 for i in range (5) :\n",
            "79 if i == 0:\n",
            "80 g_upsampl [i] = self . up_sampling ( g_maxpool [-1], indices [-i - 1])\n",
            "81 g_decoder [i ][0] = self . decoder_block [-i - 1]( g_upsampl [i])\n",
            "82 g_decoder [i ][1] = self . conv_block_dec [-i - 1]( g_decoder [i ][0])\n",
            "83 else :\n",
            "84 g_upsampl [i] = self . up_sampling ( g_decoder [i - 1][ -1] , indices [-i - 1])\n",
            "85 g_decoder [i ][0] = self . decoder_block [-i - 1]( g_upsampl [i])\n",
            "86 g_decoder [i ][1] = self . conv_block_dec [-i - 1]( g_decoder [i ][0])\n",
            "87\n",
            "88 # define task prediction layers\n",
            "89 t1_pred = F. log_softmax ( self . pred_task1 ( g_decoder [i ][1]) , dim =1)\n",
            "90 t2_pred = self . pred_task2 ( g_decoder [i ][1])\n",
            "91\n",
            "92 return {\n",
            "93 ’semantic ’: t1_pred ,\n",
            "94 ’depth ’: t2_pred\n",
            "95 }\n",
            "1.3. Loss\n",
            "Trong phần này chúng ta xây dựng hai hàm loss khác nhau cho bài toán semantic segmentation là\n",
            "pixel-wise cross entropy và depth-image prediction là L1.\n",
            "1def compute_loss (x_pred , x_output , task_type ):\n",
            "2 device = x_pred . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "device\n",
            "3\n",
            "4 # binary mark to mask out undefined pixel space\n",
            "5 binary_mask = ( torch .sum( x_output , dim =1) != 0). float (). unsqueeze (1).to( device )\n",
            "6\n",
            "7 if task_type == ’semantic ’:\n",
            "8 # semantic loss : depth - wise cross entropy\n",
            "9 loss = F. nll_loss ( x_pred , x_output , ignore_index = -1)\n",
            "10\n",
            "11 if task_type == ’depth ’:\n",
            "12 # depth loss : l1 norm\n",
            "13 loss = torch .sum ( torch .abs( x_pred - x_output ) * binary_mask ) / torch . nonzero (\n",
            "binary_mask , as_tuple = False ). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "size (0)\n",
            "14\n",
            "15 return loss\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1.4. Training\n",
            "1from tqdm import tqdm\n",
            "2\n",
            "3def train_epoch ( train_loader , model , device , optimizer ):\n",
            "4 # iteration for all batches\n",
            "5 model . train ()\n",
            "6 losses = {’semantic ’: [], ’depth ’: [], ’total ’: []}\n",
            "7 for i, batch in tqdm ( enumerate ( train_loader )):\n",
            "8 images = batch [’image ’]. to( device )\n",
            "9 semantic = batch [’semantic ’]. long ().to( device )\n",
            "10 depth = batch [’depth ’]. to( device )\n",
            "11\n",
            "12 output = model ( images )\n",
            "13\n",
            "14 optimizer . zero_grad ()\n",
            "15 train_loss = {\n",
            "16 ’semantic ’: compute_loss ( output [’semantic ’], semantic , ’semantic ’),\n",
            "17 ’depth ’: compute_loss ( output [’depth ’], depth , ’depth ’)\n",
            "18 }\n",
            "19\n",
            "20 loss = train_loss [’semantic ’] + train_loss [’depth ’]\n",
            "21\n",
            "22 loss . backward ()\n",
            "23 optimizer . step ()\n",
            "24\n",
            "25 losses [’semantic ’]. append ( train_loss [’semantic ’]. item ())\n",
            "26 losses [’depth ’]. append ( train_loss [’depth ’]. item ())\n",
            "27 losses [’total ’]. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "append ( loss . item ())\n",
            "28\n",
            "29 avg_losses = { task : sum ( task_loss )/len( task_loss ) for task , task_loss in losses .\n",
            "items ()}\n",
            "30\n",
            "31 return avg_losses\n",
            "32\n",
            "33\n",
            "34def evaluation_epoch ( val_loader , model , device ):\n",
            "35 # iteration for all batches\n",
            "36 model . eval ()\n",
            "37 losses = {’semantic ’: [], ’depth ’: [], ’total ’:[]}\n",
            "38 with torch . no_grad ():\n",
            "39 for i, batch in tqdm ( enumerate ( val_loader )):\n",
            "40 images = batch [’image ’]. to( device )\n",
            "41 semantic = batch [’semantic ’]. long ().to( device )\n",
            "42 depth = batch [’depth ’]. to( device )\n",
            "43\n",
            "44 output = model ( images )\n",
            "45\n",
            "46 train_loss = {\n",
            "47 ’semantic ’: compute_loss ( output [’semantic ’], semantic , ’semantic ’),\n",
            "48 ’depth ’: compute_loss ( output [’depth ’], depth , ’depth ’)\n",
            "49 }\n",
            "50\n",
            "51 loss = train_loss [’semantic ’] + train_loss [’depth ’]\n",
            "52\n",
            "53 losses [’semantic ’]. append ( train_loss [’semantic ’]. item ())\n",
            "54 losses [’depth ’]. append ( train_loss [’depth ’]. item ())\n",
            "55 losses [’total ’]. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "append ( loss . item ())\n",
            "56\n",
            "57 avg_losses = { task : sum ( task_loss )/len( task_loss ) for task , task_loss in losses .\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "items ()}\n",
            "58 return avg_losses\n",
            "59\n",
            "60def train ( train_loader , val_loader , model , device , optimizer , epochs ):\n",
            "61 best_loss = 100.\n",
            "62 for epoch in range ( epochs ):\n",
            "63 train_loss = train_epoch ( train_loader , model , device , optimizer )\n",
            "64 val_loss = train_epoch ( train_loader , model , device , optimizer )\n",
            "65 scheduler . step ()\n",
            "66 if val_loss [’total ’] < best_loss :\n",
            "67 best_loss = val_loss [’total ’]\n",
            "68 torch . save ( model . state_dict () , ’./ model /\n",
            "soft_parameter_sharing_model_weights .pth ’)\n",
            "69 print (f\" Model save : ./ model / soft_parameter_sharing_model_weights .pth \")\n",
            "70 print (’Epoch : {:04 d} | Train : Semantic Loss {:.4 f} - Depth Loss {:.4 f} - Total\n",
            "Loss {:.4 f} || ’\n",
            "71 ’Eval : Semantic Loss {:.4 f} - Depth Loss {:.4 f} - Total Loss {:.4 f} ’\n",
            "72 . format ( epoch +1, train_loss [’semantic ’], train_loss [’depth ’], train_loss [’\n",
            "total ’],\n",
            "73 val_loss [’semantic ’], val_loss [’depth ’], val_loss [’total ’]))\n",
            "74 returnn model\n",
            "75\n",
            "76device = torch . device (\" cuda \" if torch . cuda . is_available () else \"cpu \")\n",
            "77model = HardParameterSharingModel ()\n",
            "78model .to( device )\n",
            "79optimizer = torch . optim . Adam ( model . parameters () , lr =1e -4)\n",
            "80scheduler = torch . optim . lr_scheduler . StepLR ( optimizer , step_size =100 , gamma =0.5)\n",
            "81\n",
            "82epochs = 10\n",
            "83model = train ( train_loader , val_loader , model , device , optimizer , epochs )\n",
            "1.5. Inference\n",
            "1model_path = ’./ model / hard_parameter_sharing_model_weights .pth ’\n",
            "2model = HardParameterSharingModel ()\n",
            "3model . load_state_dict ( torch . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "load ( model_path ))\n",
            "4model . eval ()\n",
            "5model .to( device )\n",
            "6\n",
            "7test_sample = next ( iter ( val_ds ))\n",
            "8test_sample = { task : test_sample [ task ]. unsqueeze (0).to( device ) for task in test_sample\n",
            ". keys ()}\n",
            "9\n",
            "10with torch . no_grad ():\n",
            "11 output = model ( test_sample [’image ’])\n",
            "12# output : output [’ depth ’], output [’ sematic ’]\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần 3. Câu hỏi trắc nghiệm\n",
            "Câu hỏi 1 Học đa tác vụ (Multi-Task Learning) là gì?\n",
            "a) Học cách thực hiện nhiều tác vụ khác nhau một cách độc lập\n",
            "b) Học cách thực hiện nhiều tác vụ cùng một lúc\n",
            "c) Học cách thực hiện một tác vụ duy nhất\n",
            "d) Học cách thực hiện nhiều tác vụ theo thứ tự\n",
            "Câu hỏi 2 Lợi ích chính của học đa tác vụ là gì?\n",
            "a) Tăng độ chính xác của mỗi tác vụ\n",
            "b) Tăng khả năng chuyển giao kiến thức giữa các tác vụ\n",
            "c) Cả 2 đáp án đều đúng\n",
            "d) Cả 2 đáp án đều sai\n",
            "Câu hỏi 3 Phương pháp nào sau đây không phải là phương pháp học đa tác vụ?\n",
            "a) Chia sẻ tham số\n",
            "b) Chia sẻ biểu diễn\n",
            "c) Chia sẻ dữ liệu\n",
            "d) Học tuần tự\n",
            "Câu hỏi 4 Mô hình MTL nào sau đây tập trung vào tinh chỉnh khối encoder?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "a) PAD-Net\n",
            "b) PAP-Net\n",
            "c) MTI-Net\n",
            "d) Cross-Stitch Networks\n",
            "Câu hỏi 5 Mô hình MTL nào sau đây tập trung vào tinh chỉnh khối decoder?\n",
            "a) PAD-Net\n",
            "b) MTAN\n",
            "c) NDDR-CNN\n",
            "d) Cross-Stitch Networks\n",
            "Câu hỏi 6 Hàm loss để huấn luyện cho bài toán semantic segmentation là?\n",
            "a) Pixel-wise Cross Entropy\n",
            "b) Huber Loss\n",
            "c) Recontruction Loss\n",
            "d) Contrastive Loss\n",
            "Câu hỏi 7 Hàm loss để huấn luyện cho bài toán depth-image prediction là?\n",
            "a) Pixel-wise Cross Entropy\n",
            "b) Huber Loss\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "c) L1\n",
            "d) Contrastive Loss\n",
            "Câu hỏi 8 Bộ dữ liệu sử dụng cho phần thực nghiệm là?\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "a) NYUD-V2\n",
            "b) CIFAR10\n",
            "c) CIFAR100\n",
            "d) MNIST\n",
            "Câu hỏi 9 Bộ dữ liệu NYUD-V2 bao nhiêu sample?\n",
            "a) 499\n",
            "b) 1119\n",
            "c) 1449\n",
            "d) 1999\n",
            "Câu hỏi 10 Độ đo để đánh giá cho bài toán semantic segmentation là?\n",
            "a) IoU\n",
            "b) F-Score\n",
            "c) Recall\n",
            "d) Precision\n",
            "- Hết -\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIET NAM – AI COURSE 2023\n",
            "Reinforcement Learning - Exercise\n",
            "Dinh-Thang Duong và Quang-Vinh Dinh\n",
            "PR-Team: Hoàng-Nguyên Vũ, Đăng-Nhã Nguyễn và Minh-Châu Phạm\n",
            "Ngày 18 tháng 4 năm 2024\n",
            "Phần I: Giới thiệu\n",
            "Reinforcement Learning (RL) (Tạm dịch: Học tăng cường) , là một trong 3 nhánh chính trong\n",
            "Machine Learning (bên cạnh Supervised Learning và Unsupervised Learning). Đây là một nhánh học\n",
            "liên quan đến việc nghiên cứu cách để tạo ra một tác tử (Agents), có khả năng tương tác trong một môi\n",
            "trường giả lập (Environments) bằng một số các hành động (Actions) phù hợp, nhằm hoàn thành được\n",
            "mục tiêu của bài toán và tối đa điểm thưởng tích lũy kỳ vọng nhận được (Expected Cumulative Reward)\n",
            "qua mỗi hành động thực hiện. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Reinforcement learning thường được thử nghiệm trong môi trường game\n",
            "giả lập, song vẫn góp mặt trong một vài các ứng dụng nổi tiếng như: AlphaGo, ChatGPT...\n",
            "Để hiểu rõ hơn một số từ khóa sử dụng trong bài viết, chúng ta sẽ mô tả lại ý tưởng chính của một\n",
            "bài toán Học tăng cường qua framework sau:\n",
            "1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Hình 1: Reinforcement Learning Framework. Mô tả tổng quan về bài toán Học tăng cường.\n",
            "Như đã nói ở trên, Reinforcement Learning liên quan đến việc triển khai một tác tử có khả năng\n",
            "tương tác với môi trường, từ đó học cách để tối ưu điểm thưởng tích lũy kỳ vọng nhận được qua mỗi\n",
            "nước đi. Với hình minh họa trên, ta có thể hình dung một ngữ cảnh khi quá trình huấn luyện bắt đầu\n",
            "(trò chơi bắt đầu) tại thời điểm t= 0như sau:\n",
            "1. Đầu tiên, tác tử nhận thông tin trạng thái S0(khởi tạo) từ môi trường.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "2. Dựa vào thông tin trạng thái S0, tác tử thực hiện hành động Atlên môi trường.\n",
            "3. Môi trường từ đó thay đổi sang trạng thái S1.\n",
            "4. Môi trường đồng thời trả về cho tác tử điểm thưởng R1.\n",
            "Và cứ như vậy, quá trình trên sẽ lặp đi lặp lại cho đến khi tác tử hoàn thành mục tiêu của trò chơi hoặc\n",
            "hết giờ (timeout), trò chơi sẽ kết thúc (gọi là terminate state).\n",
            "Hình 2: Hai loại thuật toán Reinforcement Learning sẽ được tìm hiểu trong bài\n",
            "Trong bài tập lần này, chúng ta sẽ cùng triển khai và chạy thử các thuật toán Reinforcement\n",
            "Learning cơ bản trên một số môi trường game, bao gồm các game trong thư viện gym của OpenAI\n",
            "(Taxi, LunarLander) và game PACMAN. Các thuật toán chúng ta sẽ triển khai bao gồm: Q-Learning,\n",
            "Approximate Q-Learning và Policy Gradient.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần II: Bài tập\n",
            "Để có thể quan sát tác tử chơi game, các bạn cần chạy animation của game. Ở đây, chúng ta có thể\n",
            "hiển thị animation game trên cả 2 nền tảng code (máy local và Google Colab):\n",
            "•Đối với máy local: Các bạn hãy sử dụng môi trường ảo conda (cách cài đặt conda các bạn hãy\n",
            "tham khảo tại đây) và cài đặt thư viện gym như sau:\n",
            "1$ pip3 install ’gym[all ]’\n",
            "Sau khi quá trình tải hoàn tất, các bạn có thể test thư viện bằng cách chạy thử môi trường game\n",
            "CartPole-v1 bằng cách copy đoạn lệnh này vào một file .py bất kì (giả sử test.py):\n",
            "1# test .py\n",
            "2import gym\n",
            "3\n",
            "4env = gym. make (’CartPole -v1 ’, render_mode =’human ’)\n",
            "5env . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "reset ()\n",
            "6for _ in range (100) :\n",
            "7 env . render ()\n",
            "8 env . step ( env. action_space . sample ())\n",
            "9env . close ()\n",
            "Sau đó, thực thi file test.py trong terminal bằng lệnh:\n",
            "1$ python3 test .py\n",
            "Nếu thực thi thành công, các bạn sẽ thấy một cửa sổ animation game CartPole hiện lên như sau:\n",
            "Hình 3: Hình ảnh trực quan của môi trường CartPole-v1\n",
            "•Đối với Google Colab: Mặc dù không thể chạy trực tiếp animation game như ở máy local, song\n",
            "vẫn có nhiều cách khác nhau giúp ta có thể quan sát animation game. Ở đây, chúng ta coi các\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "trạng thái của môi trường như các frame, sau đó lưu lại thành một file .gif, từ đó có thể dễ dàng\n",
            "hiển thị lên colab. Các bước thực hiện như sau:\n",
            "1.Cài đặt một số package cần thiết:\n",
            "1! sudo apt - get update\n",
            "2!apt install imagemagick\n",
            "3!pip install ’gym[all]’ pygame\n",
            "2.Xây dựng hàm tạo ảnh gif: Hàm này nhận vào danh sách các frame, sau đó xuất thành\n",
            "file có tên demo.gif :\n",
            "1import matplotlib . pyplot as plt\n",
            "2from matplotlib import animation\n",
            "3\n",
            "4def save_frames_as_gif (\n",
            "5 frames ,\n",
            "6 path =’./ ’,\n",
            "7 filename =’demo . gif ’,\n",
            "8 fps =1\n",
            "9):\n",
            "10 temp_frame = frames [0]\n",
            "11 plt . figure ( figsize =( temp_frame . shape [1] / 72.0 , temp_frame . shape [0] /\n",
            "72.0) , dpi =72)\n",
            "12\n",
            "13 patch = plt. imshow ( frames [0])\n",
            "14 plt . axis (’off ’)\n",
            "15\n",
            "16 def animate (i):\n",
            "17 patch . set_data ( frames [i])\n",
            "18\n",
            "19 anim = animation . FuncAnimation (plt .gcf () , animate , frames = len( frames ),\n",
            "interval =50)\n",
            "20 anim . save ( path + filename , writer =’imagemagick ’, fps =fps)\n",
            "21 plt . close ()\n",
            "3.Khởi tạo môi trường và kiểm thử: Ta khởi tạo môi trường CartPole-v1 để kiểm thử hàm\n",
            "tạo ảnh gif trên bằng đoạn lệnh sau:\n",
            "1import gym\n",
            "2\n",
            "3from IPython . display import Image\n",
            "4\n",
            "5env_id = ’CartPole -v1 ’\n",
            "6env = gym. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "make (env_id , render_mode =’rgb_array ’)\n",
            "7images = []\n",
            "8state , info = env. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "reset ()\n",
            "9img = env. render ()\n",
            "10images . append (img)\n",
            "11\n",
            "12for _ in range (100) :\n",
            "13 action = env. action_space . sample ()\n",
            "14 state , reward , terminated , truncated , info = env . step ( action )\n",
            "15 img = env. render ()\n",
            "16 images . append (img)\n",
            "17\n",
            "18 if terminated or truncated :\n",
            "19 break\n",
            "20\n",
            "21env . close ()\n",
            "22save_frames_as_gif (images , fps =10)\n",
            "23Image ( open (’demo .gif ’,’rb ’). read ())\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Nếu toàn bộ các bước trên thành công, ta sẽ thấy animation game hiển thị trong Colab như\n",
            "hình sau:\n",
            "Hình 4: Hình ảnh trực quan của môi trường CartPole-v1 trong Google Colab\n",
            "Để thuận tiện trong việc thực hiện bài tập này, bài tập 1 và 3 trong bài viết sẽ được thực hiện trong\n",
            "Google Colab.\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Câu 1: Q-Learning\n",
            "Cho môi trường game Taxi trong thư viện OpenAI Gym, với một số thông tin chính như sau (các\n",
            "bạn có thể đọc thêm thông tin chi tiết về môi trường này tại đây):\n",
            "Hình 5: Hình ảnh trực quan của game Taxi\n",
            "•Kiểu môi trường: Grid World (Deterministic Environment).\n",
            "•Không gian hành động (Action Space): 6 (Discrete).\n",
            "•Không gian trạng thái (State Space): 500 (Discrete).\n",
            "•Mục tiêu (Objective): Di chuyển Taxi đến đón khách hàng và đưa họ đến một trong bốn vị trí\n",
            "trả khách.\n",
            "•Trạng thái kết thúc (Terminate State): Taxi trả khách đúng nơi đã định.\n",
            "•Hàm điểm thưởng (Reward Function):\n",
            "– +20 điểm nếu trả hàng khách đúng nơi.\n",
            "– -1 điểm mỗi một lần Taxi di chuyển.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "– -10 điểm nếu đón và trả hàng khách không đúng nơi đã định.\n",
            "Các bạn hãy cài đặt thuật toán Q-Learning để huấn luyện tác tử hoàn thành nhiệm vụ, cũng như đạt\n",
            "điểm thưởng tích lũy tối đa trên môi trường Taxi này. Để triển khai thuật toán này, các bạn có thể\n",
            "tham khảo một số bước hướng dẫn sau:\n",
            "1.Khai báo các thư viện cần thiết:\n",
            "1import numpy as np\n",
            "2import gymnasium as gym\n",
            "3import os\n",
            "4import tqdm\n",
            "5import matplotlib . pyplot as plt\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "6\n",
            "7from IPython . display import Image\n",
            "8from matplotlib import animation\n",
            "9from tqdm . notebook import tqdm\n",
            "2.Khởi tạo môi trường Taxi-v3:\n",
            "1env_id = ’Taxi -v3 ’\n",
            "2env = gym. make (env_id , render_mode =’rgb_array ’)\n",
            "3.Xây dựng hàm khởi tạo Q-Table:\n",
            "1def init_q_table ( state_space , action_space ):\n",
            "2 q_table = np. zeros (( state_space , action_space ))\n",
            "3\n",
            "4 return q_table\n",
            "4.Xây dựng hàm khởi tạo Greedy Policy:\n",
            "1def greedy_policy ( q_table , state ):\n",
            "2 action = np. argmax ( q_table [state , :])\n",
            "3\n",
            "4 return action\n",
            "5.Xây dựng hàm khởi tạo Epsilon-greedy Policy:\n",
            "1def epsilon_greedy_policy ( q_table , state , epsilon ):\n",
            "2 rand_n = float (np. random . uniform (0, 1))\n",
            "3\n",
            "4 if rand_n > epsilon :\n",
            "5 action = greedy_policy ( q_table , state )\n",
            "6 else :\n",
            "7 action = np. random . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "choice ( q_table . shape [1])\n",
            "8\n",
            "9 return action\n",
            "6.Khai báo một số siêu tham số cần thiết:\n",
            "1n_training_episodes = 30000\n",
            "2n_eval_episodes = 100\n",
            "3lr = 0.7\n",
            "4\n",
            "5max_steps = 99\n",
            "6gamma = 0.95\n",
            "7eval_seed = range ( n_eval_episodes )\n",
            "8\n",
            "9max_epsilon = 1.0\n",
            "10min_epsilon = 0.05\n",
            "11decay_rate = 0.0005\n",
            "7.Xây dựng hàm training:\n",
            "1def train (\n",
            "2 env ,\n",
            "3 max_steps ,\n",
            "4 q_table ,\n",
            "5 n_training_episodes ,\n",
            "6 min_epsilon ,\n",
            "7 max_epsilon ,\n",
            "8 decay_rate ,\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "9 lr ,\n",
            "10 gamma\n",
            "11):\n",
            "12 for episode in tqdm ( range ( n_training_episodes )):\n",
            "13 epsilon = min_epsilon + ( max_epsilon - min_epsilon ) * np.exp(- decay_rate\n",
            "* episode )\n",
            "14\n",
            "15 state , info = env. reset ()\n",
            "16 step = 0\n",
            "17 terminated = False\n",
            "18 truncated = False\n",
            "19\n",
            "20 for step in range ( max_steps ):\n",
            "21 action = epsilon_greedy_policy ( q_table , state , epsilon )\n",
            "22 new_state , reward , terminated , truncated , info = env . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "step ( action )\n",
            "23\n",
            "24 q_table [state , action ] = q_table [state , action ] + lr * ( reward +\n",
            "gamma * np. max( q_table [ new_state ]) - q_table [state , action ])\n",
            "25\n",
            "26 if terminated or truncated :\n",
            "27 break\n",
            "28\n",
            "29 state = new_state\n",
            "30\n",
            "31 return q_table\n",
            "8.Thực hiện huấn luyện:\n",
            "1q_table = init_q_table ( state_space , action_space )\n",
            "2trained_q_table = train (\n",
            "3 env ,\n",
            "4 max_steps ,\n",
            "5 q_table ,\n",
            "6 n_training_episodes ,\n",
            "7 min_epsilon ,\n",
            "8 max_epsilon ,\n",
            "9 decay_rate ,\n",
            "10 lr ,\n",
            "11 gamma\n",
            "12)\n",
            "Sau khi quá trình training hoàn tất, ta sẽ có một Q-table với các giá trị Q-value đã được cập nhật.\n",
            "8\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Câu 2: Approximate Q-Learning\n",
            "Cho môi trường game Pacman với một số thông tin chính như sau:\n",
            "Hình 6: Hình ảnh trực quan của game Pacman\n",
            "•Kiểu môi trường: Grid World (Stochastic Environment).\n",
            "•Không gian hành động (Actions Space): 5 (Discrete).\n",
            "•Mục tiêu (Objective): Di chuyển Pacman ăn toàn bộ tất cả các đồ ăn (chấm màu trắng) trên\n",
            "bản đồ đồng thời tránh né các ghosts.\n",
            "•Trạng thái kết thúc (Terminate State): Pacman ăn được toàn bộ các đồ ăn trên bản đồ.\n",
            "•Hàm điểm thưởng (Reward Function):\n",
            "– +10 điểm nếu ăn được 1 đồ ăn.\n",
            "– +200 điểm nếu tiêu diệt được 1 ghost.\n",
            "– -500 điểm nếu bị tiêu diệt bởi ghosts.\n",
            "– -1 điểm mỗi một lần thực hiện hành động bất kì.\n",
            "Các bạn hãy tải source code của game Pacman theo đường dẫn này và cài đặt thuật toán Approximate\n",
            "Q-Learning để huấn luyện tác tử hoàn thành nhiệm vụ, cũng như đạt được điểm thưởng tích lũy tối đa\n",
            "trên môi trường game Pacman này. Bên cạnh đó, dựa vào chức năng recording game trong source code,\n",
            "các bạn hãy thực nghiệm với 4 bản demo tác tử chơi 1 ván game như sau:\n",
            "•Demo 1: Tác tử khi không được huấn luyện.\n",
            "•Demo 2: Tác tử khi được huấn luyện qua 10 episodes.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "9\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "•Demo 3: Tác tử khi được huấn luyện qua 100 episodes.\n",
            "•Demo 4: Tác tử khi được huấn luyện qua 1000 episodes.\n",
            "Để thực hiện được bài tập này, các bạn có thể tham khảo cách làm sau:\n",
            "1.Cài đặt source code game Pacman: Dựa vào đường dẫn đã cung cấp ở trên, các bạn hãy tải\n",
            "source code game Pacman thông qua lệnh sau:\n",
            "1$ git clone https :// dagshub . com/ DavidN /Pacman -RL. git\n",
            "Hình 7: Cấu trúc cây thư mục của mã nguồn game Pacman\n",
            "Để nhanh chóng tiếp cận, các bạn cần lưu ý một vài file/thư mục chính như sau:\n",
            "•./pacman.py: File main dùng để thực hiện chạy chương trình game Pacman cũng như huấn\n",
            "luyện tác tử. Các bạn có thể chạy thử game này bằng lệnh:\n",
            "1$ python3 pacman .py -n 1 -z 2\n",
            "Nếu thực thi thành công, cửa sổ game sẽ mở và các bạn có thể dùng nút lên xuống trái phải\n",
            "của bàn phím để chơi game.\n",
            "•./agents: Thư mục chứa các class định nghĩa các kiểu tác tử, trong đó bao gồm Pacman và\n",
            "Ghosts. Đối với tác tử Pacman, hiện tại có 3 phiên bản gồm:\n",
            "– KeyboardAgent: Phiên bản cho phép ta điều khiển tác tử. Đây là mặc định của game.\n",
            "– LeftTurnAgent: Phiên bản Pacman sẽ luôn tự động chọn hướng rẽ trái để di chuyển.\n",
            "– GreedyAgent: Phiên bản tác tử sẽ luôn tự động chọn hành động mang lại điểm thưởng\n",
            "tức thời cao nhất.\n",
            "Ví dụ, để sử dụng GreedyAgent, các bạn sử dụng lệnh sau:\n",
            "1$ python3 pacman .py -p GreedyAgent -n 1 -z 2\n",
            "Có thể thấy rằng, để tạo một phiên bản tác tử mới, ta cần định nghĩa một class mới trong các\n",
            "file trong thư mục ./agents . Để dễ dàng tiếp cận bài toán, các bạn hãy tham khảo file code\n",
            "Approximate Q-Learning trong repo này và tích hợp vào mã nguồn của đề bài.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "10\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Câu 3: Policy Gradient\n",
            "Cho môi trường game LunarLander-v2 trong thư viện OpenAI Gym, với một số thông tin chính như\n",
            "sau (các bạn có thể đọc thêm thông tin chi tiết về môi trường này tại đây):\n",
            "Hình 8: Hình ảnh trực quan của môi trường LunarLander\n",
            "•Kiểu môi trường: Box2D (Stochastic Environment).\n",
            "•Không gian hành động (Actions Space): 4 (Discrete).\n",
            "•State Shape: (8,).\n",
            "•Mục tiêu (Objective): Điều khiển tàu tên lửa đáp xuống đúng vị trí (càng sát càng tốt) đã\n",
            "định trên màn hình, trong khi giữ cho lượng nguyên liệu tiêu thụ ít nhất, đặc biệt không để tàu\n",
            "phát nổ.\n",
            "•Trạng thái kết thúc (Terminate State): Tàu tên lửa đáp xuống thành công, hoặc phát nổ,\n",
            "hoặc bay khỏi giới hạn màn hình.\n",
            "•Hàm điểm thưởng (Reward Function):\n",
            "– +100 điểm nếu đáp xuống bãi đáp thành công.\n",
            "– -100 điểm nếu tàu tên lửa phát nổ.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "– -0.3 điểm cho mỗi đơn vị thời gian trôi qua.\n",
            "– +10 điểm cho mỗi chân tàu nằm gọn bên trong bãi đáp.\n",
            "Các bạn hãy triển khai thuật toán REINFORCE (một trong những thuật toán policy gradient) và\n",
            "huấn luyện tác tử có thể hoàn thành được trò chơi này, tối thiểu phải có điểm thưởng tích lũy tối đa là\n",
            "dương. Các bạn có thể tham khảo các bước thực hiện như sau:\n",
            "Lưu ý:Để tăng tốc độ training, các bạn hãy sử dụng GPU cho bài tập này.\n",
            "1.Khai báo các thư viện cần thiết:\n",
            "11\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "1import numpy as np\n",
            "2import gym\n",
            "3import os\n",
            "4import tqdm\n",
            "5import matplotlib . pyplot as plt\n",
            "6\n",
            "7import torch\n",
            "8import torch .nn as nn\n",
            "9import torch .nn. functional as F\n",
            "10import torch . optim as optim\n",
            "11from torch . distributions import Categorical\n",
            "12\n",
            "13from collections import deque\n",
            "14from IPython . display import Image\n",
            "15from matplotlib import animation\n",
            "16from tqdm . notebook import tqdm\n",
            "2.Khởi tạo môi trường LunarLander-v2:\n",
            "1env_id = ’LunarLander -v2 ’\n",
            "2env = gym. make (env_id , new_step_api = True )\n",
            "3\n",
            "4state_space = env. observation_space . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "shape [0]\n",
            "5action_space = env . action_space .n\n",
            "3.Xây dựng Policy Network:\n",
            "1class Policy (nn. Module ):\n",
            "2 def __init__ (self , s_size , a_size , h_size ):\n",
            "3 super (Policy , self ). __init__ ()\n",
            "4 self . fc1 = nn. Linear ( s_size , h_size )\n",
            "5 self . fc2 = nn. Linear ( h_size , h_size * 2)\n",
            "6 self . fc3 = nn. Linear ( h_size * 2, a_size )\n",
            "7\n",
            "8 def forward (self , x):\n",
            "9 x = F. relu ( self .fc1(x))\n",
            "10 x = F. relu ( self .fc2(x))\n",
            "11 x = self . fc3(x)\n",
            "12\n",
            "13 return F. softmax (x, dim =1)\n",
            "14\n",
            "15 def act(self , state ):\n",
            "16 state = torch . from_numpy ( state ). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "float (). unsqueeze (0).to( device )\n",
            "17 probs = self . forward ( state ). cpu ()\n",
            "18 m = Categorical ( probs )\n",
            "19 action = m. sample ()\n",
            "20\n",
            "21 return action . item () , m. log_prob ( action )\n",
            "4.Xây dựng hàm training:\n",
            "1def reinforce (\n",
            "2 policy ,\n",
            "3 optimizer ,\n",
            "4 n_training_episodes ,\n",
            "5 max_steps ,\n",
            "6 gamma ,\n",
            "7 print_every\n",
            "8):\n",
            "9 scores_deque = deque ( maxlen =100)\n",
            "12\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "10 scores = []\n",
            "11\n",
            "12 for i_episode in range (1, n_training_episodes + 1):\n",
            "13 saved_log_probs = []\n",
            "14 rewards = []\n",
            "15 state = env. reset ()\n",
            "16\n",
            "17 for t in range ( max_steps ):\n",
            "18 action , log_prob = policy .act( state )\n",
            "19 saved_log_probs . append ( log_prob )\n",
            "20 state , reward , done , _, info = env. step ( action )\n",
            "21 rewards . append ( reward )\n",
            "22 if done :\n",
            "23 break\n",
            "24 scores_deque . append (sum( rewards ))\n",
            "25 scores . append (sum ( rewards ))\n",
            "26\n",
            "27 returns = deque ( maxlen = max_steps )\n",
            "28 n_steps = len( rewards )\n",
            "29\n",
            "30 for t in range ( n_steps ) [:: -1]:\n",
            "31 disc_return_t = returns [0] if len( returns ) > 0 else 0\n",
            "32 returns . appendleft ( gamma * disc_return_t + rewards [t])\n",
            "33\n",
            "34 eps = np. finfo (np. float32 ). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "eps. item ()\n",
            "35\n",
            "36 returns = torch . tensor ( returns )\n",
            "37 returns = ( returns - returns . mean ()) / ( returns .std () + eps)\n",
            "38\n",
            "39 policy_loss = []\n",
            "40 for log_prob , disc_return in zip( saved_log_probs , returns ):\n",
            "41 policy_loss . append (- log_prob * disc_return )\n",
            "42 policy_loss = torch .cat( policy_loss ). sum ()\n",
            "43\n",
            "44 optimizer . zero_grad ()\n",
            "45 policy_loss . backward ()\n",
            "46 optimizer . step ()\n",
            "47\n",
            "48 if i_episode % print_every == 0:\n",
            "49 print (\" Episode {}\\ tAverage Score : {:.2 f}\". format ( i_episode , np. mean (\n",
            "scores_deque )))\n",
            "50\n",
            "51 return scores\n",
            "5.Khai báo policy network và optimizer:\n",
            "1device = torch . device (’cuda ’ if torch . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "cuda . is_available () else ’cpu ’)\n",
            "2\n",
            "3policy = Policy (\n",
            "4 s_size = state_space ,\n",
            "5 a_size = action_space ,\n",
            "6 h_size =h_size ,\n",
            "7).to( device )\n",
            "8\n",
            "9optimizer = optim . Adam ( policy . parameters () , lr=lr)\n",
            "6.Thực hiện huấn luyện:\n",
            "1scores = reinforce (\n",
            "2 policy ,\n",
            "13\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "3 optimizer ,\n",
            "4 n_training_episodes ,\n",
            "5 max_steps ,\n",
            "6 gamma ,\n",
            "7 print_every =100\n",
            "8)\n",
            "14\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "Phần III: Câu hỏi trắc nghiệm\n",
            "1. Trong Reinforcement Learning, mục tiêu của tác tử là?\n",
            "(a) Tối ưu điểm thưởng nhận được tại mỗi trạng thái.\n",
            "(b) Tối ưu điểm thưởng tích lũy kỳ vọng.\n",
            "(c) Tối ưu thời gian hoàn thành mục tiêu.\n",
            "(d) Tối ưu tiền thưởng nhận được trong trò chơi.\n",
            "2. Theo Reinforcement Learning Framework, sau khi tác tử thực hiện hành động At, môi trường sẽ\n",
            "trả lại cho tác tử những gì?\n",
            "(a) Điểm thưởng Rtvà Trạng thái St.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(b) Trạng thái St+1.\n",
            "(c) Điểm thưởng Rt+1và Trạng thái St+1.\n",
            "(d) Điểm thưởng Rt+1.\n",
            "3. Đáp án nào sau đây là một dạng bài toán trong Reinforcement Learning?\n",
            "(a) Adversarial\n",
            "(b) Recursive\n",
            "(c) Dynamic\n",
            "(d) Episodic\n",
            "4. Trong Reinforcement Learning, trạng thái (S) được hiểu là?\n",
            "(a) Mô tả các hành động thực hiện được của tác tử.\n",
            "(b) Mô tả toàn cục của môi trường.\n",
            "(c) Mô tả cục bộ của môi trường.\n",
            "(d) Mô tả điểm thưởng nhận được của tác tử.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "5. Trong trò chơi Super Mario Bros phiên bản OpenAI Gym (có không gian trò chơi như ảnh minh\n",
            "họa trên), nhân vật Mario có thể thực hiện được các hành động bao gồm: Di chuyển Trái/Phải,\n",
            "Ngồi xuống, Nhảy lên và Đứng yên. Theo đó, không gian hành động (Action Space) của môi\n",
            "trường này là?\n",
            "15\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(a) Discrete(4)\n",
            "(b) Discrete(5)\n",
            "(c) Discrete(6)\n",
            "(d) Discrete(7)\n",
            "6. Trong Reinforcement Learning, Policy là gì?\n",
            "(a) Hàm ánh xạ hành động sang điểm thưởng.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "(b) Hàm ánh xạ trạng thái sang hành động.(c) Hàm ánh xạ điểm thưởng sang hành động.\n",
            "(d) Hàm ánh xạ hành động sang trạng thái.\n",
            "7. Trong phương pháp Value-based, việc luôn lựa chọn hành động cho điểm thưởng tích lũy cao nhất\n",
            "còn được gọi là gì?\n",
            "(a) Softmax Policy.\n",
            "(b) Random Policy.\n",
            "(c)ε-greedy Policy.\n",
            "(d) Greedy Policy.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "8. Dòng code nào sau đây biểu diễn chiến lược cân bằng giữa exploration và exploitation?\n",
            "(a)np.argmax(Q[s])\n",
            "(b)np.random.choice(A)\n",
            "(c)np.argmin(Q[s])\n",
            "(d)np.argmax(Q[s]) if np.random.rand() > e else np.random.choice(A)\n",
            "9. Mục đích của yếu tố Hệ số chiết khấu (Discounting Factor) là gì?\n",
            "(a) Gia tăng kích thước của không gian trạng thái.\n",
            "(b) Giảm kích thước của không gian trạng thái.\n",
            "(c) Tăng điểm thưởng tích lũy kỳ vọng nhận được.\n",
            "(d) Cân bằng độ quan trọng giữa điểm thưởng nhận được tức khắc và tương lai.\n",
            "10. Trong Q-learning, hàm nào sau đây miêu tả tìm kiếm optimal policy?\n",
            "(a)π∗(s) = arg maxaQ∗(s, a)\n",
            "(b)π∗(s) = arg maxaV∗(s)\n",
            "(c)π∗(s) = arg minaQ∗(s, a)\n",
            "(d)π∗(s) = arg minaV∗(s)\n",
            "11. Trong Q-Learning, công thức nào dưới đây biểu diễn hàm cập nhật Q-Value của trạng thái svà\n",
            "hành động a?\n",
            "(a)Q(s, a) =Q(s, a) +α[r+γP\n",
            "a′Q(s′, a′)−Q(s, a)]\n",
            "(b)Q(s, a) =Q(s, a) +α[r+γQ(s′, a′)−Q(s, a)]\n",
            "(c)Q(s, a) =Q(s, a) +α[r+γmax a′Q(s′, a′)−Q(s, a)]\n",
            "(d)Q(s, a) =Q(s, a) +α[r−γmax a′Q(s′, a′)−Q(s, a)]\n",
            "12. Hàm nào sau đây không phải là hàm điểm thưởng tích lũy kỳ vọng?\n",
            "(a)Vπ(s) =Eπ\n",
            "τt∼p(τt)[P∞\n",
            "i=0γi·rt+i|st=s]\n",
            "16\n",
            "----------------------------------------------------------------------------------------------------\n",
            "AI VIETNAM aivietnam.edu.vn\n",
            "(b)Vπ(s) =P\n",
            "a∈AQπ(s, a)\n",
            "(c)Vπ(s) =P\n",
            "a∈Aπ(a|s)Qπ(s, a)\n",
            "(d)Vπ(s) =Eπ[Rt+1+γRt+2+γ2Rt+3+...|St=s]\n",
            "13. Thuật toán nào sau đây thuộc nhóm thuật toán Policy Gradient?\n",
            "(a) REINFORCE\n",
            "(b) Q-Learning\n",
            "(c) SARSA\n",
            "(d) Value Iteration\n",
            "14. Trong Policy Gradient, hàm nào dưới đây biểu diễn stochastic policy?\n",
            "(a)πθ(s) = arg maxaQπ(s, a)\n",
            "(b)πθ(a|s) = arg maxaQπ(s, a)\n",
            "(c)πθ(s) = arg maxaVπ(s)\n",
            "(d)πθ(a|s) =P(a|s;θ)\n",
            "15. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Cho đoạn code Q-Learning sau:\n",
            "1state = env. reset ()\n",
            "2for t in range ( max_steps ):\n",
            "3 action = np. argmax (Q[ state ])\n",
            "4 next_state , reward , done , _ = env. step ( action )\n",
            "5 Q[state , action ] = Q[state , action ] + alpha * ( reward + gamma * np.max(Q[\n",
            "next_state ]) - Q[state , action ])\n",
            "6 state = next_state\n",
            "7 if done :\n",
            "8 break\n",
            "Loại policy dùng để lựa chọn hành động tại step tđã được triển khai là?\n",
            "(a)ε-greedy Policy\n",
            "(b) Softmax Policy\n",
            "(c) Greedy Policy\n",
            "(d) Random Policy\n",
            "- Hết -\n",
            "17\n",
            "----------------------------------------------------------------------------------------------------\n",
            "THỰC HÀNH TRÍCH XUẤT BẢNG TRONG\n",
            "PDF VỚI TABULA-PY VÀ PANDAS\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 Mở đầu\n",
            "PDF là một trong những định dạng tài liệu phổ biến nhất được sử dụng trên Internet và trong nhiều\n",
            "lĩnh vực khác nhau. Trích xuất dữ liệu từ các tài liệu PDF thường gặp phải nhiều khó khăn, đặc biệt\n",
            "là đối với các bảng dữ liệu. Tiếp nối bài viết \"Xử Lý Tệp PDF Đơn Giản Với PYPDF\", trong bài viết\n",
            "này chúng ta sẽ tìm hiểu về tabula-py - một thư viện Python hỗ trợ trích xuất bảng từ PDF, đồng thời\n",
            "kết hợp nó với thư viện pandas để xử lý dữ liệu trích xuất.\n",
            "Yêu cầu:\n",
            "•Máy tính đã cài đặt Python >=3.8, Java 8+\n",
            "•Biết lập trình Python, Pandas cơ bản.\n",
            "2 Cài đặt Tabula-py\n",
            "Tabula-py là một thư viện Python mã nguồn mở với chức năng chính là trích xuất dữ liệu từ các bảng\n",
            "trong tài liệu PDF. Dữ liệu được trích xuất bằng tabula-py có thể dễ dàng được chuyển đổi thành các\n",
            "cấu trúc dữ liệu của pandas để tiếp tục xử lý và phân tích. Để cài đặt thư viện này, ta sử dụng lệnh\n",
            "sau:\n",
            "1pip install tabula-py\n",
            "Vì thư viện này yêu cầu cài đặt java 8+ để xử lý, nên chúng ta cần phải cài đặt nó. Đối với google colab\n",
            "đã được cài đặt sẵn java nên chúng ta bỏ qua bước này. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Đối với máy tính window, chúng ta tải java tại\n",
            "đây, sau đó tiến hành mở file và cài đặt theo các tùy chọn mặc định. Sau khi quá trình cài đặt hoàn\n",
            "tất, ta cần thêm đường dẫn của java vào Environment Variables của window theo các bước dưới đây:\n",
            "•Truy cập vào thư mục java đã cài đặt trên máy và sao chép đường dẫn của thư mục này\n",
            "C:\\Program Files (x86)\\Java\\jre-1.8\\bin\n",
            "•Truy cập vào Environment Variables và thêm đường dẫn : Control Panel -> System and Security\n",
            "-> System -> Advanced System Settings -> Environment Variables -> Select PATH –> Edit\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "Sau khi thiết lập hoàn tất, chúng ta có thể kiểm tra xem thư viện đã cài đặt thành công chưa thông\n",
            "qua lệnh sau:\n",
            "1import tabula\n",
            "2!java -version\n",
            "====================================== Output ========================================\n",
            "java version \"1.8.0_411\"\n",
            "Java(TM) SE Runtime Environment (build 1.8.0_411-b09)\n",
            "Java HotSpot(TM) Client VM (build 25.411-b09, mixed mode, sharing)\n",
            "======================================================================================\n",
            "Nếu bạn nhận được kết quả tương tự như trên tức là quá trình cài đặt đã thành công và có thể bắt đầu\n",
            "sử dụng. Nếu quá trình cài đặt này quá phức tạp với bạn, hãy dùng google colab.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "3 Trích xuất bảng với Tabula-py\n",
            "Trong tài liệu pdf, có rất nhiều định dạng bảng khác nhau. Chúng ta sẽ tìm hiểu cách trích xuất các\n",
            "loại bảng phổ biến nhất như: Bảng với cấu trúc rõ ràng, bảng không có đường viền...\n",
            "3.1 Bảng với cấu trúc rõ ràng\n",
            "Bảng có cấu trúc rõ ràng là bảng có đường viền rõ ràng xung quanh cả bảng và các ô bên trong, giúp\n",
            "dễ dàng nhận diện và trích xuất. Chúng thường được tạo ra từ các ứng dụng như Microsoft Word hoặc\n",
            "Excel trước khi chuyển đổi sang định dạng PDF.\n",
            "Bảng 1: Thông tin Học Sinh\n",
            "TênLớpĐiểm Trung Bình\n",
            "Anh10A 8.5\n",
            "Bình10B 7.2\n",
            "Châu10C 9.1\n",
            "Dũng10A 6.8\n",
            "Bảng trên có cấu trúc rõ ràng, ta sẽ thực hiện trích xuất bảng này:\n",
            "1import tabula\n",
            "2pdf_path = \"https://github.com/NguyenDinhTiem/tabula-py-examples/raw/main/data/tables.\n",
            "pdf\"\n",
            "3\n",
            "4dfs = tabula.read_pdf(pdf_path, pages=\"1\", lattice=True)\n",
            "5print(len(dfs))\n",
            "6dfs[0]\n",
            "Trong chương trình trên, chúng ta bắt đầu bằng việc khai báo thư viện tabula, sau đó tiến hành trích\n",
            "xuất bảng tại trang 1 trong tệp pdf. Chúng ta sẽ sử dụng hàm read_pdf trong đó:\n",
            "•pdf_path là đường dẫn đến tệp pdf\n",
            "•pages là tham số xác định trang nào trong tệp PDF sẽ được trích xuất. Trong ví dụ trên,\n",
            "pages=\"1\"chỉ định rằng chỉ trang đầu tiên của tệp PDF sẽ được xem xét để trích xuất dữ liệu.\n",
            "Ta cũng có thể chỉ định nhiều trang cụ thể bằng cách sử dụng một chuỗi như \"1,2,3\"hoặc một\n",
            "phạm vi trang như \"1-3\". Để trích xuất tất cả các trangta có thể sử dụng pages=\"all\".\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "•lattice là một tham số boolean cho biết liệu hàm có nên sử dụng chế độ \"lattice\"để trích xuất\n",
            "bảng hay không. Khi lattice=True, tabula-py sẽ cố gắng phát hiện các đường kẻ bảng (cả ngang\n",
            "và dọc) để xác định chính xác ranh giới của các ô trong bảng.\n",
            "Kết quả trả về từ tabula.read_pdf là một danh sách chứa các dataframe. Trong ví dụ trên kết quả đầu\n",
            "ra là danh sách chứa 1 dataframe, chúng ta có thể truy cập bằng chỉ mục của danh sách, ví dụ dfs[0].\n",
            "3.2 Bảng không có đường viền\n",
            "Bảng không có đường viền là loại bảng không có đường viền xác định rõ ràng giữa các hàng và cột, chỉ\n",
            "dựa vào khoảng cách để phân chia các ô. Việc trích xuất từ các bảng này có thể khó khăn hơn do thiếu\n",
            "các dấu hiệu nhận biết.\n",
            "Bảng 2: Thông tin khách hàng\n",
            "Tên Tuổi Thành phố\n",
            "An 22 Hà Nội\n",
            "Cúc 25 TP HCM\n",
            "Hoa 20 Đà Nẵng\n",
            "Nụ 23 Cần Thơ\n",
            "Bảng trên là một ví dụ điển hình cho bảng không có đường viền, chúng ta sẽ thực hiện trích xuất bảng\n",
            "này từ tệp pdf.\n",
            "1import tabula\n",
            "2pdf_path = \"https://github.com/NguyenDinhTiem/tabula-py-examples/raw/main/data/tables.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "pdf\"\n",
            "3\n",
            "4dfs = tabula.read_pdf(pdf_path, pages=\"2\", stream=True)\n",
            "5print(len(dfs))\n",
            "6dfs[0]\n",
            "Trong chương trình trên, ta sử dụng tabula.read_pdf để trích xuất bảng tại trang 2 của tệp pdf. Đối\n",
            "với loại bảng này chúng ta sử dụng tham số stream = True, tabula-py sẽ phân tích trang PDF dựa trên\n",
            "cấu trúc các hàng và khoảng trống giữa chúng để xác định ranh giới.\n",
            "3.3 Bảng với cấu trúc phức tạp\n",
            "Bảng có cấu trúc phức tạp là bảng có hàng hoặc cột được gộp lại, chứa các bảng con, hoặc các bảng\n",
            "chứa nhiều cấp độ của thông tin. Các bảng này thường xuất hiện trong các tài liệu kỹ thuật, tài chính\n",
            "hoặc khoa học. Việc trích xuất dữ liệu từ chúng khó hơn các loại bảng thông thường, đòi hỏi chúng ta\n",
            "phải xử dụng các kỹ thuật trong pandas để xử lý đầu ra.\n",
            "Bảng 3: Lịch Thi Cuối Kỳ\n",
            "Môn học Ngày thi Giờ bắt đầu Phòng thi\n",
            "Toán20/12/2024 08:00 101A\n",
            "21/12/2024 09:00 102B\n",
            "Lý 22/12/202408:00 101A\n",
            "10:00 102B\n",
            "Hóa 23/12/202408:00 101A\n",
            "10:00 102B\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "Bảng trên có cấu trúc khá phức tạp, có những ô được gộp lại dẫn đến việc trích xuất đòi hỏi chúng ta\n",
            "phải thử các tham số khác nhau và phải xử lý đầu ra với pandas.\n",
            "Đầu tiên, để trích xuất bảng này từ file pdf, ta sẽ thử các tham số khác nhau để thu được kết quả\n",
            "output phù hợp. Trong ví dụ này, ta sẽ sử dụng stream=True thay vì lattice=True, mặc dù bảng này\n",
            "cũng được bao bởi các đường kẻ, tuy nhiên trong trường hợp này sử dụng lattice sẽ không thu được kết\n",
            "quả mong muốn.\n",
            "1import tabula\n",
            "2pdf_path = \"https://github.com/NguyenDinhTiem/tabula-py-examples/raw/main/data/tables.\n",
            "pdf\"\n",
            "3dfs = tabula.read_pdf(pdf_path, pages=\"3\", stream=True)\n",
            "Bảng 4: Dataframe trích xuất từ bảng trong tệp pdf\n",
            "#Môn học Ngày thi Giờ bắt đầu Phòng thi\n",
            "0NaN 20/12/2024 08:00 101A\n",
            "1Toán NaN NaN NaN\n",
            "2NaN 21/12/2024 09:00 102B\n",
            "3NaN NaN 08:00 101A\n",
            "4Lý 22/12/2024 NaN NaN\n",
            "5NaN NaN 10:00 102B\n",
            "6NaN NaN 08:00 101A\n",
            "7Hóa 23/12/2024 NaN NaN\n",
            "8NaN NaN 10:00 102B\n",
            "Tiếp theo chúng ta cần xử lí dataframe thu được, nhận thấy dữ liệu của môn Toán nằm rải rác ở 3\n",
            "dòng đầu, môn Lí nằm ở 3 dòng tiếp theo, môn Hóa nằm ở 3 dòng cuối cùng. Ta sẽ thực hiện lấp đầy\n",
            "các ô có giá trị NaN ở dòng phía sau bởi các giá trị của các ô ở dòng trước đó.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "1# Điền các giá trị NaN bằng các giá trị từ hàng trước đó\n",
            "2df[’Môn học’].fillna(method=’ffill’, inplace=True)\n",
            "3df[’Ngày thi’].fillna(method=’ffill’, inplace=True)\n",
            "4df[’Giờ bắt đầu’].fillna(method=’ffill’, inplace=True)\n",
            "5df[’Phòng thi’].fillna(method=’ffill’, inplace=True)\n",
            "Bảng 5: Dataframe sau khi đã fillna\n",
            "#Môn học Ngày thi Giờ bắt đầu Phòng thi\n",
            "0NaN 20/12/2024 08:00 101A\n",
            "1Toán 20/12/2024 08:00 101A\n",
            "2Toán 21/12/2024 09:00 102B\n",
            "3Toán 21/12/2024 08:00 101A\n",
            "4Lý 22/12/2024 08:00 101A\n",
            "5Lý 22/12/2024 10:00 102B\n",
            "6Lý 22/12/2024 08:00 101A\n",
            "7Hóa 23/12/2024 08:00 101A\n",
            "8Hóa 23/12/2024 10:00 102B\n",
            "Sau khi lấp đầy các ô NaN, chúng ta nhận thấy, các giá trị ở hàng 0, 3, 6 không cần thiết, ta sẽ loại bỏ\n",
            "chúng:\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "1df_cleaned = df.drop([0, 3, 6])\n",
            "Và cuối cùng, chúng ta sẽ thu được dataframe được làm sạch.\n",
            "Bảng 6: Dataframe trích xuất từ bảng trong tệp pdf\n",
            "#Môn học Ngày thi Giờ bắt đầu Phòng thi\n",
            "1Toán 20/12/2024 08:00 101A\n",
            "2Toán 21/12/2024 09:00 102B\n",
            "4Lý 22/12/2024 08:00 101A\n",
            "5Lý 22/12/2024 10:00 102B\n",
            "7Hóa 23/12/2024 08:00 101A\n",
            "8Hóa 23/12/2024 10:00 102B\n",
            "3.4 Bảng với vị trí được chỉ định\n",
            "Trong các tài liệu pdf, đặc biệt là các bài báo khoa học, các bảng thường rất phức tạp và ở nhiều các vị\n",
            "trí khác nhau, thư viện tabula-py thường cho kết quả trích xuất bảng rất tệ trong những tài liệu dạng\n",
            "này. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Tuy nhiên có một số trường hợp có thể khác phục bằng cách yêu cầu tabula-py chỉ thực hiện trích\n",
            "xuất bảng tại vị trí được chỉ định trên trang.\n",
            "Đây là cách làm thủ công và khá tốn sức, đầu tiên chúng ta cần một công cụ để xác định vị trí của\n",
            "bảng trong tệp tin pdf. Trong bài viết này, chúng ta sẽ sử dụng phần mềm Adobe reader, bạn có thể\n",
            "tải và cài đặt phần mềm tại đây.\n",
            "Hình 1: Xác định vị trí bảng trong file pdf\n",
            "Chúng ta sẽ thực hiện ví dụ với bài báo YOLO. Vị trí của bảng chúng ta cần xác định là vị trí của 4\n",
            "điểm:\n",
            "5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "•top: Vị trí trên cùng của bảng\n",
            "•left: Vị trí cạnh trái của bảng\n",
            "•width: Vị ví cạnh phải của bảng\n",
            "•botton: Vị trí cạnh dưới cùng của bảng\n",
            "Chúng ta sẽ sử dụng công cụ mesuaring tool trong phần mềm Adobe reader để đo khoảng cách từ các\n",
            "cạnh của tài liệu đến các vị trí các cạnh của bảng tương ứng. Khoảng cách này được tính theo giá trị\n",
            "inch, để chuyển đổi sang giá trị điểm trong pdf, chúng ta sẽ thực hiện theo phép chuyển đổi: 1 inch =\n",
            "72 point pdf\n",
            "1top = 0.88\n",
            "2left = 0.6\n",
            "3botton = 3.06\n",
            "4width = 4.09\n",
            "5\n",
            "6loc = [i*72 for i in [top, left, botton,\n",
            "width]]\n",
            "7print(loc)================= Output ================\n",
            "[63.36, 43.199999999999996, 220.32,\n",
            "294.48]\n",
            "==========================================\n",
            "Sau khi xác định được vị trí của bảng, chúng ta thực hiện trích xuất bảng:\n",
            "1import tabula\n",
            "2pdf_path = \"https://arxiv.org/pdf/1506.02640.pdf\"\n",
            "3dfs = tabula.read_pdf(pdf_path, pages=\"6\", area = loc)\n",
            "Trong chương trình trên, chúng ta sử dụng hàm tabula.read_pdf để trích xuất bảng tại trang 6 và\n",
            "area=loc là vị trí mà chúng ta đã đo phía trên. Dưới đây là kết quả bảng trích xuất được:\n",
            "Bảng 7: Comparison of Real-Time Detectors\n",
            "IndexReal-Time Detectors Train mAPFPS\n",
            "0100Hz DPM [31] 2007 16.0100.0\n",
            "130Hz DPM [31] 2007 26.130.0\n",
            "2Fast YOLO 2007+2012 52.7155.0\n",
            "3YOLO 2007+2012 63.445.0\n",
            "4Less Than Real-Time NaN NaNNaN\n",
            "5Fastest DPM [38] 2007 30.415.0\n",
            "6R-CNN Minus R [20] 2007 53.5 6.0\n",
            "7Fast R-CNN [14] 2007+2012 70.0 0.5\n",
            "8Faster R-CNN VGG-16 [28] 2007+2012 73.2 7.0\n",
            "9Faster R-CNN ZF [28] 2007+2012 62.118.0\n",
            "10YOLO VGG-16 2007+2012 66.421.0\n",
            "4 Kết Luận\n",
            "Trong bài viết này, chúng ta đã tìm hiểu và sử dụng thư viện tabula-py để trích xuất dữ liệu bảng từ\n",
            "các tài liệu PDF và cách làm sạch, xử lý dữ liệu với pandas. Chúng ta đã đi qua từng bước từ việc cài\n",
            "đặt thư viện, sử dụng các phương thức trích xuất bảng, cho đến các kỹ thuật cơ bản để làm sạch dữ\n",
            "liệu. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Mặc dù tabula-py còn khá nhiều hạn chế đối với cấu trúc bảng phức tạp tuy nhiên nó cũng có\n",
            "nhiều ưu điểm đáng để ta ưu tiên sử dụng khi trích xuất bảng trong pdf.\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "NÂNG CAO HIỆU QUẢ VIẾT CODE VỚI\n",
            "TYPE HINTS VÀ MYPY\n",
            "Dinh-Tiem Nguyen và Quang-Vinh Dinh\n",
            "1 Mở đầu\n",
            "Làm sao để viết code Python dễ đọc, dễ hiểu và dễ bảo trì hơn? Làm thế nào để có thể kiểm tra tính\n",
            "đúng đắn của code trước khi thực thi chúng? \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Và liệu có cách nào để phát hiện và sửa lỗi kiểu dữ liệu\n",
            "một cách dễ dàng và nhanh chóng không? Trong bài viết này sẽ hướng dẫn sử dụng Type Hints để xác\n",
            "định và gợi ý kiểu dữ liệu của các biến, giá trị trả về của các hàm, phương thức... Đồng thời kết hợp\n",
            "với Mypy-một công cụ kiểm tra kiểu dữ liệu static mạnh mẽ cho các chương trình Python, giúp nâng\n",
            "cao hiệu quả viết code trong quá trình phát triển dự án.\n",
            "Yêu cầu:\n",
            "•Máy tính đã cài đặt python>=3.10, Vscode.\n",
            "•Đã biết lập trình Python cơ bản.\n",
            "2 Hướng dẫn sử dụng Type Hints và Mypy\n",
            "2.1 Hướng dẫn sử dụng Type Hints\n",
            "Type Hints là một tính năng đã được tích hợp sẵn trong Python, cho phép ta khi viết code có thể khai\n",
            "báo kiểu dữ liệu của các biến, tham số và giá trị trả về của hàm. Và điều thú vị là khi thực thi chương\n",
            "trình Python trình thông dịch sẽ bỏ qua các gợi ý kiểu dữ liệu trong code. Chúng ta sẽ hiểu rõ hơn\n",
            "thông qua các ví dụ.\n",
            "2.1.1 Type hints cho biến\n",
            "Chúng ta sẽ bắt đầu bằng ví dụ tạo biến theo cách thông thường:\n",
            "1# Cách không dùng type hints\n",
            "2name = \"AI VIETNAM \"\n",
            "3year = 2024\n",
            "4\n",
            "5print (f\" Welcome to { name } { year }!\")================= Output ================\n",
            "Welcome to AI VIETNAM 2024!\n",
            "==========================================\n",
            "Để gợi ý về kiểu dữ liệu của một biến, ta có thể sử dụng Type Hints như sau:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "1name : str = \"AI VIETNAM \"\n",
            "2year : int = 2024\n",
            "3\n",
            "4print (f\" Welcome to { name } { year }!\")\n",
            "5print ( __annotations__ )================= Output ================\n",
            "Welcome to AI VIETNAM 2024!\n",
            "{’name ’: <class ’str ’>, ’year ’: <class ’\n",
            "int ’>}\n",
            "==========================================\n",
            "Trong ví dụ trên chúng ta khai báo kiểu dữ liệu cho name là string, year với kiểu int tuy nhiên khi thực\n",
            "thi chương trình thì đều cho kết quả giống nhau vì Python sẽ bỏ qua phần gợi ý kiểu dữ liệu. Khác biệt\n",
            "duy nhất là khi sử dụng type hints chương trình sẽ tạo ra một thộc tính đặc biệt __annotations__ để\n",
            "chứa thông tin về kiểu dữ liệu của các biến, điều này sẽ giúp IDE(Vscode) đưa ra những gợi ý cú pháp\n",
            "chính xác. Ngoài ra thuộc tính này sẽ là thông tin quan trọng để các công cụ hỗ trợ như Mypy có thể\n",
            "kiểm tra kiểu dữ liệu của chương trình.\n",
            "Khi sử dụng type hints, có nhiều trường hợp gợi ý kiểu cho biến là kiểu list, tuple, boolean, hoặc biến\n",
            "đó có thể có nhiều kiểu dữ liệu khác nhau.\n",
            "1# Biến với Type Hint là list chứa các số nguy ên\n",
            "2numbers : list [int ]\n",
            "3\n",
            "4# Biến với Type Hint là tuple chứa một chuỗi và một số nguy ên\n",
            "5person : tuple [str , int]\n",
            "6\n",
            "7# Biến với Type Hint là int hoặc float\n",
            "8value : int| float\n",
            "9\n",
            "10# Biến với Type Hint là list chứa chuỗi và tuple chứa số nguy ên\n",
            "11data : list [str ]| tuple [int , int]\n",
            "12\n",
            "13# Biến với Type Hint là Tuple chứa một list các số nguy ên và một dict\n",
            "14info : tuple [ list [int], dict ]\n",
            "15\n",
            "16# Biến với Type hint là boolean\n",
            "17is_active : bool\n",
            "Trong ví dụ trên, chúng ta đã sử dụng Type Hints để chỉ định kiểu dữ liệu của các biến numbers, person,\n",
            "value, data, và info. Khi chúng ta tạo type hints cho biến mà không gán giá trị như vậy, thì các biến\n",
            "này vẫn chưa thực sự được tạo ra. Mà chỉ có __annotations__ được tạo ra chứa thông tin gợi ý kiểu\n",
            "dữ liệu cho từng biến. Chúng ta có thể kiểm tra điều này bằng cách in biến đó ra để xem thông tin.\n",
            "1print ( __annotations__ )\n",
            "2print ( numbers , person , value , data , info )\n",
            "====================================== Output ========================================\n",
            "{’ numbers ’: list [int], ’person ’: tuple [str , int], ’value ’: int | float , ’data ’: list [\n",
            "str ] | tuple [int , int], ’info ’: tuple [ list [int], dict ], ’is_active ’: <class ’bool\n",
            "’>}\n",
            "Traceback ( most recent call last ):\n",
            "File \" create_type_hints .py\", line 20, in <module >\n",
            "print ( numbers , person , value , data , info , is_active )\n",
            "NameError : name ’numbers ’ is not defined\n",
            "======================================================================================\n",
            "2.1.2 Type hints cho hàm\n",
            "Để gợi ý về kiểu dữ liệu của các tham số và giá trị trả về của một hàm, ta có thể sử dụng Type Hints\n",
            "như ví dụ phía dưới. Trong hàm add, chúng ta gợi ý rằng x và y là các số nguyên (int) và hàm trả về là\n",
            "một số nguyên (int). \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Nhưng nếu ta cố tình sử dụng kiểu dữ liệu float thì chương trình vẫn hoạt động\n",
            "bình thường, không một cảnh báo lỗi nào xuất hiện.\n",
            "2\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "1def add(x: int , y: int) -> int :\n",
            "2 return x + y\n",
            "3\n",
            "4if __name__ == \" __main__ \":\n",
            "5 print (add (x= 1.5 , y=2) )\n",
            "6 print (add . __annotations__ )================= Output ================\n",
            "3.5\n",
            "{’x ’: <class ’int ’>, ’y ’: <class ’int ’>,\n",
            "’return ’: <class ’int ’>}\n",
            "==========================================\n",
            "Ưu điểm của việc sử dụng type hints là giúp code của chúng ta dễ đọc hơn, ngoài ra thì giúp công cụ\n",
            "IDE code gợi ý cú pháp hiệu quả hơn. Thông thường, khi chúng ta tạo hàm, nếu các tham số trong\n",
            "hàm không được gán giá trị mặc định thì IDE không biết kiểu dữ liệu của tham số đó là gì, nên không\n",
            "đưa ra gợi ý code cho chúng ta được. Nhưng khi sử dụng type hints, điều này lại được khắc phục.\n",
            "Hình 1: Gợi ý code trong Vscode xuất hiện khi sử dụng type hints\n",
            "2.1.3 Type hints cho class\n",
            "Để sử dụng type hints cho class, đối với thuộc tính chúng ta tạo type hints cho chúng như cách làm với\n",
            "biến, đối với các phương thức thì chúng ta tạo type hints như cách chúng ta làm với hàm.\n",
            "1class Person :\n",
            "2 name : str\n",
            "3 age : int\n",
            "4\n",
            "5 def __init__ (self , name : str , age: int) -> None :\n",
            "6 self . \n",
            "----------------------------------------------------------------------------------------------------\n",
            "name = name\n",
            "7 self . age = age\n",
            "8\n",
            "9 def greet ( self ) -> str:\n",
            "10 return f\"Xin chào, Tôi là { self . name } năm nay tôi { self .age} tuổi.\"\n",
            "11\n",
            "12if __name__ == \" __main__ \":\n",
            "13 person_1 = Person (\"Tom\", 25)\n",
            "14 print ( person_1 . greet ())\n",
            "====================================== Output ========================================\n",
            "Tôi là Tom năm nay tôi 25 tuổi.\n",
            "======================================================================================\n",
            "3\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "Trong lớp Person trên, chúng ta gợi ý rằng thuộc tính name là một chuỗi (str), thuộc tính age là một\n",
            "số nguyên (int) và phương thức greet trả về một chuỗi (str).\n",
            "Lưu ý: Việc tạo type hints trong code chương trình là không bắt buộc, không có chúng thì chương\n",
            "trình vẫn chạy bình thường. Vậy thì khi nào nên và không nên sử dụng type hints? Thì sẽ tùy vào từng\n",
            "dự án, nhóm bạn làm việc có muốn sử dụng type hints không. Nhìn chung, type hints có nhiều ưu điểm\n",
            "giúp code chương trình rõ ràng và dễ phát hiện và sửa lỗi bảo trì hơn so với nhược điểm như phải dành\n",
            "thêm nhiều thời gian hơn để viết mã.\n",
            "2.2 Kết hợp Type Hints với Mypy\n",
            "Type hints giúp code của chúng ta rõ ràng, dễ đọc và dễ sửa lỗi hơn, tuy nhiên việc phát hiện lỗi chúng\n",
            "ta vẫn thực hiện thủ công, người lập trình phải tự đọc hiểu và cố gắng kiểm soát các kiểu dữ liệu để\n",
            "đảm bảo tính logic nhưng điều này có thể gây mất nhiều thời gian mà không hiệu quả.\n",
            "Công cụ mypy ra đời để khắc phục điều này, nó là một công cụ kiểm tra kiểu dữ liệu static Python, cho\n",
            "phép chúng ta kiểm tra kiểu dữ liệu trong chương trình mà không cần phải thực thi chúng. Nó được\n",
            "phát triển bởi Jukka Lehtosalo và được công bố dưới dạng mã nguồn mở.\n",
            "Để sử dụng mypy, trước tiên chúng ta cần cài đặt nó thông qua câu lệnh sau:\n",
            "1pip install mypy\n",
            "Sau khi cài đặt thành công, chúng ta có thể sử dụng mypy để kiểm tra kiểu dữ liệu trong chương trình\n",
            "của chúng ta bằng cách chạy lệnh:\n",
            "1mypy my_script .py\n",
            "Trong đó my_script.py là file chứa code chương trình và các type hints. Ta cần lưu ý là mypy chỉ kiểm\n",
            "tra được cho tệp có đuôi .py, đối với tệp notebook.ipynb chúng ta cần sử dụng công cụ khác như nbqa.\n",
            "Trong phạm vi bài viết này, chúng ta chỉ kiểm tra kiểu đối với file .py.\n",
            "Chúng ta cùng quay trở lại ví dụ tính tổng hai số, ta tạo type hints cho các tham số là kiểu int, nhưng\n",
            "trong ví dụ, chúng ta truyền giá trị cho hai tham số là kiểu float và int thì chương trình vẫn chạy bình\n",
            "thường. Dưới đây, chúng ta sẽ kiểm tra kiểu bằng mypy.\n",
            "1def add(x: int , y: int) -> int :\n",
            "2 return x + y\n",
            "3\n",
            "4if __name__ == \" __main__ \":\n",
            "5 print (add (x= 1, y=2))\n",
            "6 print (add (x= 1.5 , y=2) )\n",
            "7 print (add . __annotations__ )\n",
            "====================================== Output ========================================\n",
            "mypy add.py\n",
            "add .py :6: error : Argument \"x\" to \"add\" has incompatible type \" float \"; expected \"int \"\n",
            "[arg - type ]\n",
            "Found 1 error in 1 file ( checked 1 source file )\n",
            "======================================================================================\n",
            "Kết quả mypy trả về cho thấy trong file code của chúng ta add.py xuất hiện lỗi kiểu ở dòng 6 tức là\n",
            "dòng print(add(x= 1.5, y=2)), lỗi này do x=1.5 có kiểu là float không khớp với kiểu dữ liệu dự kiến từ\n",
            "type hints là int. Sau khi xác định lỗi, chúng ta dễ dàng sửa lỗi và chương trình sẽ trở lên đúng đắn\n",
            "hơn. \n",
            "----------------------------------------------------------------------------------------------------\n",
            "Ta thấy mypy thật tiện lợi phải không?\n",
            "4\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Daily AI Exercise (AIO) aivietnam.edu.vn\n",
            "3 Bài tập\n",
            "Viết một chương trình Python để kiểm tra xem một số có phải là số nguyên tố hay không. Số nguyên\n",
            "tố là số nguyên dương lớn hơn 1 và chỉ có hai ước số dương là 1 và chính nó.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Yêu cầu:\n",
            "•Viết một hàm có tên là is_prime nhận một số nguyên dương n và trả về một giá trị boolean. Nếu\n",
            "n là số nguyên tố, hàm sẽ trả về True, ngược lại trả về False.\n",
            "•Sử dụng Type Hints để gợi ý về kiểu dữ liệu của tham số và giá trị trả về của hàm.\n",
            "•Sử dụng mypy để kiểm tra kiểu dữ liệu trong chương trình\n",
            "5\n",
            "Tutorial on Denoising Diffusion-based\n",
            "Generative Modeling\n",
            "Nguyen Vu Hoa Binh Khai Trinh Xuan Hoang-Bach ngo Minh-Hung An\n",
            "Ngày 7 tháng 2 năm 2024\n",
            "Phần I: Một số khái niệm cơ bản\n",
            "Trước khi chúng ta bắt đầu tìm hiểu về Stable Diffusion (SD) thì ở phần này chúng ta sẽ cùng nhau\n",
            "tổng quan lại một số kiến thức nền tảng, những khái niệm trong phần này sẽ là cơ sở để chúng ta hiểu\n",
            "và chứng minh được cách mà một mô hình SD vận hành.\n",
            "1 Wiener process\n",
            "Wiener process còn được gọi là Brownian process (Brownian motion), là một quá trình ngẫu nhiên\n",
            "không giảm dần theo thời gian. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nodes[1].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooU1Zx2sHeA-",
        "outputId": "63c94d6b-b133-4d0d-c57a-e24f1f82897f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Được đặt tên theo nhà toán học và nhà vật lý học Norbert Wiener và\n",
            "Robert Brown.\n",
            "Một số đặc điểm của Wiener process:\n",
            "•Liên tục : Nó là một quá trình liên tục trong không gian và thời gian. Điều này có nghĩa rằng nó\n",
            "không bị gián đoạn và có giá trị tại mọi thời điểm.\n",
            "•Không xác định : Wiener process có tính chất ngẫu nhiên mạnh, nghĩa là không thể dự đoán\n",
            "được cách nó di chuyển tại một thời điểm cụ thể. Nó thường được mô tả bằng một biến ngẫu\n",
            "nhiên theo phân phối chuẩn (normal).\n",
            "•Điểm xuất phát : Quá trình Wiener thường được mô tả bằng một điểm xuất phát, sau đó tiến\n",
            "hành theo một quá trình ngẫu nhiên không giảm dần.\n",
            "•Được sử dụng rộng rãi : Quá trình Wiener được sử dụng trong nhiều lĩnh vực như tài chính\n",
            "(để mô phỏng biến động giá cổ phiếu), khoa học máy tính (để mô phỏng quá trình ngẫu nhiên),\n",
            "toán học,...\n",
            "Wiener process là một ví dụ quan trọng trong lĩnh vực lý thuyết xác suất và quá trình ngẫu nhiên\n",
            "và chúng thường được sử dụng để mô phỏng và nghiên cứu sự biến đổi ngẫu nhiên trong các hệ thống\n",
            "thực tế.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Retrival"
      ],
      "metadata": {
        "id": "ObdRkIl2GfNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "from weaviate.embedded import EmbeddedOptions\n",
        "client = weaviate.Client(embedded_options=EmbeddedOptions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmQ9BICRFEg0",
        "outputId": "492ee88d-837d-4480-a714-778af132ec29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary /root/.cache/weaviate-embedded did not exist. Downloading binary from https://github.com/weaviate/weaviate/releases/download/v1.23.7/weaviate-v1.23.7-Linux-amd64.tar.gz\n",
            "Started /root/.cache/weaviate-embedded: process ID 5030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex, StorageContext\n",
        "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
        "\n",
        "\n",
        "index_name = \"AIO_Doc\"\n",
        "embed_model = HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5', device=device)\n",
        "\n",
        "# Construct vector store\n",
        "vector_store = WeaviateVectorStore(\n",
        "    weaviate_client = client,\n",
        "    index_name = index_name,\n",
        ")\n",
        "# Set up the storage for the embeddings\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# If an index with the same index name already exists within Weaviate, delete it\n",
        "if client.schema.exists(index_name):\n",
        "    client.schema.delete_class(index_name)\n",
        "\n",
        "# Setup the index\n",
        "# build VectorStoreIndex that takes care of chunking documents\n",
        "# and encoding chunks to embeddings for future retrieval\n",
        "index = VectorStoreIndex(\n",
        "    nodes,\n",
        "    storage_context=storage_context,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "grQo_FqZH1UP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "91ab8700-7583-40fd-d53e-9f5fe9afabbf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Client' object has no attribute 'collections'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-8b7bfbb82cbb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Construct vector store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m vector_store = WeaviateVectorStore(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mweaviate_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mindex_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/vector_stores/weaviate/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weaviate_client, class_prefix, index_name, text_key, auth_config, client_kwargs, url, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# create default schema if does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclass_schema_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mcreate_default_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/vector_stores/weaviate/utils.py\u001b[0m in \u001b[0;36mclass_schema_exists\u001b[0;34m(client, class_name)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m\"\"\"Check if class schema exists.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mvalidate_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'collections'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "Settings.llm = None\n",
        "\n",
        "query = index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    vector_store_query_node=\"hybrid\" # type search\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "8_Et5D1NIIzD",
        "outputId": "b72057ad-0dd0-4f19-e2b7-878502871796",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM is explicitly disabled. Using MockLLM.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'index' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2d69ba275485>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m query = index.as_query_engine(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msimilarity_top_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvector_store_query_node\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hybrid\"\u001b[0m \u001b[0;31m# type search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(query.query(\"What is mamba ?\"))"
      ],
      "metadata": {
        "id": "TeDjg6_9KD75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Reranking"
      ],
      "metadata": {
        "id": "4_MgyQ15QGvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llm_index.core.postprocessor import SentenceTransformerRerank\n",
        "\n",
        "rerank_postprocessor = SentenceTransfomerRerank(\n",
        "    model='mixedbread-ai/mxbai-rerank-xsmall-v1',\n",
        "    top_n=2,\n",
        "    keep_retrieval_score=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "fXU2YXzeQGXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=5,\n",
        "    node_postprocessor=[rerank_postprocessor]\n",
        ")"
      ],
      "metadata": {
        "id": "OTZUfs3SQnLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_engine.query(\"What is the mamba ?\").response)"
      ],
      "metadata": {
        "id": "Ngc5VlQTRcKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Query Rewriting"
      ],
      "metadata": {
        "id": "3s7F9ftSRrH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 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\n",
        "\n",
        "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
        "from llama_index.llms.groq import Groq\n",
        "import os\n",
        "\n",
        "llm = Groq(\n",
        "    model='llama3-8b-8192',\n",
        "    api_key=\"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\"\n",
        ")\n",
        "hype = HyDEQueryTransform(include_original=True)\n",
        "\n",
        "query_bundle = hype.run(\"What is Mamba ?\")"
      ],
      "metadata": {
        "id": "MMnHt9yvRt4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_bundle.custom_embedding_strs"
      ],
      "metadata": {
        "id": "hKBehPtp3jVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6313c042-f5b2-4f06-a117-96b7ca6fbe87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Please write a passage to answer the question\\nTry to include as many key details as possible.\\n\\n\\nWhat is Mamba ?\\n\\n\\nPassage:\"\"\"\\n',\n",
              " 'What is Mamba ?']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine import TransformQueryEngine\n",
        "hype_query_engine = TransformQueryEngine(query_engine, hype)\n",
        "\n",
        "response = hype_query_engine.query(\"What is Mamba ?\")\n",
        "print(\"-\" * 100)\n",
        "print(\"After HyDEQueryTransform\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "sw6hK7bb3P-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "528ce60c-38d0-4220-c6f1-0e488d83fe42",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'query_engine' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-71b6fb728a0b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_engine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformQueryEngine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhype_query_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformQueryEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhype_query_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is Mamba ?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'query_engine' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Generation"
      ],
      "metadata": {
        "id": "jr_j_11z4kas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCauseLLM, AutoTokenizer\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model_id = \"Viet-Mistral/Vistral-7B-Chat\"\n",
        "hf_token = \"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\"\n",
        "model = AutoModelForCauseLLM.from_pretrained(\n",
        "    model_id, quantization_config=nf4_config, token=hf_token\n",
        ")\n",
        "\n",
        "tokenizer  = AutoTokenizer.from_pretrained(model_id, token=hf_token)"
      ],
      "metadata": {
        "id": "fprmGrI84mYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_llm = HunggingFace(model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "rWiwCX-d_EYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_llm.complete(\"Xin chào!\")"
      ],
      "metadata": {
        "id": "TmYvIFy8_TUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm = hf_llm"
      ],
      "metadata": {
        "id": "fry6wKFl_U2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=3,\n",
        "    vector_store_query_mode=\"hybrid\",\n",
        "    llm=llm,\n",
        "    streaming=True\n",
        ")"
      ],
      "metadata": {
        "id": "F52xhU0Y_VqW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e68906cd-b9ab-45c8-db3a-d4951411fce4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'index' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e84e639202c7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m query_engine = index.as_query_engine(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msimilarity_top_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvector_store_query_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hybrid\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "streaming_response  = query_engine.query(\"Decision Tree hoạt động trên cơ chế nào?\")\n",
        "streaming_response.print_response_stream()\n"
      ],
      "metadata": {
        "id": "P65uoh9p_6Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import ChatPromptTemplate, PromptTemplate\n",
        "from llama_index.core.llms import ChatMessage, MessageRole\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are an expert Q&A system that is trusted around the world.\n",
        "Always answer the query using the provided context information, and not prior knowledge.\n",
        "Some rules to follow:\n",
        "1. Never directly reference the given context in your answer.\n",
        "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"\"\"\n",
        "Context information is below.\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "Given the context information and not prior knowledge, answer the query.\n",
        "Query: {query_str}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "refine_prompt = \"\"\"\n",
        "The original query is as follows: {query_str}\n",
        "We have provided an existing answer: {existing_answer}\n",
        "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
        "------------\n",
        "{context_msg}\n",
        "------------\n",
        "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
        "Refined Answer:\n",
        "\"\"\"\n",
        "\n",
        "message_template = [\n",
        "    ChatMessage(content=system_prompt, role=MessageRole.SYSTEM),\n",
        "    ChatMessage(content=user_prompt, role=MessageRole.USER)\n",
        "]\n",
        "prompt_template = PromptTemplate(user_prompt)\n",
        "refine_template = PromptTemplate(refine_prompt)"
      ],
      "metadata": {
        "id": "ricM_XEHAEcm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}